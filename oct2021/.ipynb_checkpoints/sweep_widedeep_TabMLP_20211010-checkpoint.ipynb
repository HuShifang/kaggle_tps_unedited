{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# WideDeep - TabMLP Hyperparameter Sweep 20211009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d27e064-d5c9-407b-b941-0b7346edd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "COLAB = False\n",
    "USE_GPU = True\n",
    "# libraries = ['xgboost', 'lightgbm', 'catboost']\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9e1aa6-8b29-418b-9c7e-dc3262c51e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc11bb1e-66a7-460e-a2d1-b74389954668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3638c086-a63d-46e8-bcdb-1500280b6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_widedeep_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d66a209-5a5c-4331-b66b-c45b5c3c2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if COLAB:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "#     !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "#     !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if USE_GPU: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if USE_GPU:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d13d6-bb19-41b8-acf5-0b689fb559dc",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1511c588-6bdb-4661-8aff-595d5300e154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfaf8220-ed5b-4381-b251-a74493c6ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b9f745-883c-43f0-abe8-8602a6e92761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844abe51-ce07-4d8c-977d-d407c8fa668a",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8d6c50-fe6a-4b27-980a-cc3209c1de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea097bb-90c5-4eb5-88f3-1fccde218654",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/oct2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'optuna_studies'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699fdfa5-d1ef-488b-a7c8-aed4875fea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a572b0b-21c5-4937-96e9-bb77f76217d6",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f02fc-d748-44b1-a9aa-15541448e6c6",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb7ac74-977e-4db8-bdaf-852b7c8bed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835fa960-78a9-4e27-8b5a-3087d325cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "# df.index.name = 'id'\n",
    "y = np.array(df.target)\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features] # passing X as a pd.DataFrame to the trainer below, rather than as an np.ndarray\n",
    "# X_train = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca1ffb2-c342-461d-ba4a-c06772bd2325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "900aa001-d8e6-4e97-9244-bcc8a8b1b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide_cols = [f for f in X_train.columns if X_train[f].nunique() == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6df40ee-cd8f-4dd2-9765-2c1d619ce14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wide_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999e8986-713a-487f-bd23-9b1be4a392b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cedcf5-7213-45ac-8bed-7d28fd0833c5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c902f851-640a-4ac3-b744-49b73364ca4e",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'widedeep',\n",
    "    \"model\": \"TabMLP\",\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "    'optuna_trials': 100,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep', 'deep-learning', 'TabMLP'],\n",
    "    'notes': \"Sweep for WideDeep with Optuna\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1dc842b-ffa9-49f6-8b98-24d7f1a1a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "exmodel_config['feature_count'] = X.shape[1]\n",
    "exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "exmodel_config['train_source'] = str(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beef9c1a-96e6-45ba-b9eb-41c0bec1798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04654ee2-4338-433a-9c57-646a2ac6257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90e6bc6b-f6c4-4680-ba31-54849c6f7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_df.iloc[:, list(X_df.columns)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a28db352-7c97-47ab-bf0a-6dbb00b0912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = datapath/'test.feather'\n",
    "exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "# X_test = X_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99ed4960-3a8b-4632-bf93-3e4187885b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2fabdab-67e6-4490-b145-049faaa01a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c6f2a-118c-41fc-be03-6fa13c97b135",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2805e-8fc7-4e8e-a4a3-c544a0e0d647",
   "metadata": {},
   "source": [
    "- Recall that at this point, `X` is a `pd.DataFrame` and `y` is a `np.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a0e8c7c-b884-4c53-940e-67c856b297b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols = [f for f in X.columns if X[f].nunique() == 2]\n",
    "cont_cols = [f for f in X.columns if X[f].nunique() > 2]\n",
    "\n",
    "exmodel_config['wide_cols'] = str(wide_cols) # str(wide_cols)\n",
    "exmodel_config['cont_cols'] = str(cont_cols) # str(cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac356ce5-9102-4a18-afa6-b828a5f8524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cddde826-36e0-48d8-8897-435d28477a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols)#, embed_cols=embed_cols, )\n",
    "X_tab = tab_preprocessor.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ff6695-087e-41f5-ae49-00eb632701d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# X_test_wide = wide_preprocessor.transform(X_test)\n",
    "# X_test_tab = tab_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e8bb29c-4855-4e22-96d4-e3bc77aeeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(X_wide, datapath/'X_train_wide_original_dataset.joblib')\n",
    "# dump(X_tab, datapath/'X_train_tab_original_dataset,joblib')\n",
    "# dump(X_test_wide, datapath/'X_test_wide_original_dataset,joblib')\n",
    "# dump(X_test_tab, datapath/'X_test_tab_original_dataset.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f472949a-bcef-4beb-a84d-b5165feb9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_wide = load(datapath/'X_train_wide_original_dataset.joblib')\n",
    "# X_tab = load(datapath/'X_train_tab_original_dataset,joblib')\n",
    "# X_test_wide = load(datapath/'X_test_wide_original_dataset,joblib')\n",
    "# X_test_tab = load(datapath/'X_test_tab_original_dataset.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "       \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train_wide, X_valid_wide, y_train, y_valid = train_test_split(X_wide, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    X_train_tab, X_valid_tab, y_train_tab, y_valid_tab = train_test_split(X_tab, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    \n",
    "#     if (y_train_tab != y_train) or (y_valid_tab != y_valid):\n",
    "#         print(\"Splits are not the same\")\n",
    "    \n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "    \n",
    "    # to be passed directly to the MLP via splat\n",
    "    mlp_params = {\n",
    "        'cont_norm_layer': trial.suggest_categorical('cont_norm_layer', ['batchnorm', 'layernorm', None]),\n",
    "        'mlp_activation': trial.suggest_categorical('mlp_activation', ['relu', 'tanh', 'leaky_relu', 'gelu']),\n",
    "        'mlp_batchnorm': trial.suggest_categorical('mlp_batchnorm', [True, False]),\n",
    "        'mlp_linear_first': trial.suggest_categorical('mlp_linear_first', [True, False]),\n",
    "    }\n",
    "    \n",
    "    # to be passed a la carte to the composite arg (i.e. list)\n",
    "    mlp_hidden_dim_one = trial.suggest_int('mlp_hidden_dim_one', 64, 400)\n",
    "    mlp_hidden_dim_two = trial.suggest_int('mlp_hidden_dim_two', 32, 200)\n",
    "    \n",
    "    mlp_dropout_layer_one = trial.suggest_uniform('mlp_dropout_layer_one', 0.05, 0.5)\n",
    "    mlp_dropout_layer_two = trial.suggest_uniform('mlp_dropout_layer_two', 0.05, 0.5)\n",
    "\n",
    "    wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "    deeptabular = TabMlp(\n",
    "        mlp_dropout=[mlp_dropout_layer_one, mlp_dropout_layer_two],\n",
    "        mlp_hidden_dims=[mlp_hidden_dim_one, mlp_hidden_dim_two],\n",
    "        column_idx=tab_preprocessor.column_idx,\n",
    "    #     embed_input=tab_preprocessor.embeddings_input,\n",
    "        continuous_cols=cont_cols,\n",
    "        **mlp_params\n",
    "    )\n",
    "\n",
    "    # model instantiation and training\n",
    "    model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "    \n",
    "#     # optimizers -- optimizer params all default for now\n",
    "#     wide_opt = trial.suggest_categorical('wide_opt', [\n",
    "#         torch.optim.Adam(model.wide.parameters()),\n",
    "#         torch.optim.AdamW(model.wide.parameters()),\n",
    "#         torch.optim.Adagrad(model.wide.parameters()),\n",
    "#         torch.optim.SGD(model.wide.parameters()),\n",
    "#         torch.optim.RMSProp(model.wide.parameters()),\n",
    "#         torch.optim.LBFGS(model.wide.parameters()),\n",
    "#     ])\n",
    "    \n",
    "#     deep_opt = trial.suggest_categorical('deep_opt', [\n",
    "#         torch.optim.Adam(model.deep.parameters()),\n",
    "#         torch.optim.AdamW(model.deep.parameters()),\n",
    "#         torch.optim.Adagrad(model.deep.parameters()),\n",
    "#         torch.optim.SGD(model.deep.parameters()),\n",
    "#         torch.optim.RMSProp(model.deep.parameters()),\n",
    "#         torch.optim.LBFGS(model.deep.parameters()),\n",
    "#     ])\n",
    "    \n",
    "    # optimizers -- optimizer params all default for now\n",
    "    wide_opt = trial.suggest_categorical('wide_opt', [Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS])\n",
    "    \n",
    "    deep_opt = trial.suggest_categorical('deep_opt', [Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS])\n",
    "\n",
    "    optimizers = {\n",
    "        'wide': wide_opt(model.wide.parameters(), lr=0.1),\n",
    "        'deeptabular': deep_opt(model.deeptabular.parameters(), lr=0.1), # note this is deeptabular, NOT deep (as in some old examples)\n",
    "    }\n",
    "    \n",
    "    # schedulers\n",
    "    # required params\n",
    "#     step_size = trial.suggest_int('lr_step_size', 3, 7)\n",
    "#     base_lr = trial.suggest_uniform('base_lr', 0.01, 0.1)\n",
    "#     max_lr = trial.suggest_uniform('max_lr', 0.1, 0.3)\n",
    "    \n",
    "    # leaving params default for now, except for required ones\n",
    "    wide_sch = trial.suggest_categorical('wide_sch', [StepLR, ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR])\n",
    "    \n",
    "    \n",
    "#         torch.optim.lr_scheduler.StepLR(wide_opt, step_size=5),\n",
    "#         torch.optim.lr_scheduler.ReduceLROnPlateau(wide_opt),\n",
    "#         torch.optim.lr_scheduler.CosineAnnealingLR(wide_opt),\n",
    "#         torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(wide_opt, T_0=3),\n",
    "#         torch.optim.lr_scheduler.CyclicLR(wide_opt, base_lr=0.01, max_lr=0.3),\n",
    "#         torch.optim.lr_scheduler.OneCycleLR(wide_opt, max_lr=0.3),\n",
    "#     ])\n",
    "    \n",
    "    deep_sch = trial.suggest_categorical('deep_sch', [StepLR, ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR])\n",
    "    \n",
    "#         torch.optim.lr_scheduler.StepLR(deep_opt, step_size=3),\n",
    "#         torch.optim.lr_scheduler.ReduceLROnPlateau(deep_opt),\n",
    "#         torch.optim.lr_scheduler.CosineAnnealingLR(deep_opt),\n",
    "#         torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(deep_opt, T_0=3),\n",
    "#         torch.optim.lr_scheduler.CyclicLR(deep_opt, base_lr=0.01, max_lr=0.3),\n",
    "#         torch.optim.lr_scheduler.OneCycleLR(deep_opt, max_lr=0.3),\n",
    "#     ])\n",
    "    \n",
    "    # defining dict containing the schedulers -- still need to supply args\n",
    "    schedulers = {\n",
    "        'wide': wide_sch,\n",
    "        'deeptabular': deep_sch\n",
    "    }\n",
    "    \n",
    "    # pass the appropriate arguments, depending on the schedulers' interfaces\n",
    "    for modality in schedulers.keys():\n",
    "        if schedulers[modality] == StepLR:\n",
    "            if modality == 'wide':\n",
    "                schedulers[modality] = schedulers[modality](optimizers[modality], step_size=5)\n",
    "            else: # deep\n",
    "                schedulers[modality] = schedulers[modality](optimizers[modality], step_size=3)\n",
    "        elif schedulers[modality] == CosineAnnealingLR:\n",
    "            schedulers[modality] = schedulers[modality](optimizers[modality], T_max=10)\n",
    "        elif schedulers[modality] == CosineAnnealingWarmRestarts:\n",
    "            schedulers[modality] = schedulers[modality](optimizers[modality], T_0=3)\n",
    "        elif schedulers[modality] == CyclicLR:\n",
    "            schedulers[modality] = schedulers[modality](optimizers[modality],base_lr=0.01, max_lr=0.3)\n",
    "        elif schedulers[modality] == OneCycleLR:\n",
    "            schedulers[modality] = schedulers[modality](optimizers[modality],base_lr=0.01)\n",
    "        else:\n",
    "            schedulers[modality] = schedulers[modality](optimizers[modality])\n",
    "                \n",
    "                \n",
    "#     if StepLR in [wide_sch, deep_sch]:\n",
    "#         step_size_wide = 5\n",
    "#         step_size_deep = 3\n",
    "        \n",
    "#     if CosineAnnealingWarmRestarts in [wide_sch, deep_sch]:\n",
    "#         T_0 = 3\n",
    "        \n",
    "#     if CyclicLR in [wide_sch, deep_sch] or OneCycleLR in [wide_sch, deep_sch]:\n",
    "#         base_lr = 0.01\n",
    "#         max_lr = 0.3\n",
    "#         wide_sch_with_args = \n",
    "    \n",
    "    # to be passed via splat to the Trainer\n",
    "#     trainer_params = {\n",
    "#         'optimizers': optimizers,\n",
    "#         'lr_schedulers': trial.suggest_categorical('lr_schedulers', [ReduceLROnPlateau, CyclicLR, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts, StepLR]),\n",
    "#         'initializers': trial.suggest_categorical('initializers' #),\n",
    "#     }\n",
    "        \n",
    "\n",
    "    # to be passed to the Trainer.fit call\n",
    "    n_epochs = trial.suggest_int('n_epochs', 5, 100)\n",
    "\n",
    "    trainer = Trainer(model=model, \n",
    "                      objective='binary', \n",
    "                      metrics=[Accuracy],#, AUROC], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                      seed=SEED, \n",
    "                      optimizers=optimizers,\n",
    "                      lr_schedulers=schedulers, # note the lack of lr in the identifier\n",
    "                      callbacks=[\n",
    "                          LRHistory(n_epochs=n_epochs), \n",
    "                          ModelCheckpoint(\n",
    "#                               filepath=modelpath/f\"{exmodel_config['library']}_{exmodel_config['model']}_rs{42}_best-model_{datetime.now().strftime('%Y%m%d%H%M%S')}.joblib\",\n",
    "                              filepath='/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/optuna_widedeep_tabmlp_20211010_best.pth',\n",
    "                              save_best_only=True,\n",
    "                          ),\n",
    "                      ],\n",
    "                     )\n",
    "\n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "\n",
    "    \n",
    "    trainer.fit( # this is where problem is beginning\n",
    "        X_wide=X_train_wide,\n",
    "        X_tab=X_train_tab,\n",
    "        target=y_train,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=1024, # default value is 32\n",
    "\n",
    "#         initializers= # pending\n",
    "    )\n",
    "    \n",
    "    # generate predictions\n",
    "    train_preds = trainer.predict_proba(X_wide=X_train_wide, X_tab=X_train_tab, batch_size=1024)\n",
    "    valid_preds = trainer.predict_proba(X_wide=X_valid_wide, X_tab=X_valid_tab, batch_size=1024)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    train_auc = roc_auc_score(y_true=y_train, y_score=train_preds)\n",
    "    valid_auc = roc_auc_score(y_true=y_valid, y_score=valid_preds)\n",
    "    print('ROC AUC Score on Training Set of TabMLP model =', train_auc)\n",
    "    print('ROC AUC Score on Validation Set of TabMLP model =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,})\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_widedeep_20211010.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/157wayo8\" target=\"_blank\">sweep_widedeep_20211010_095505</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-10 09:57:36,247]\u001b[0m A new study created in memory with name: widedeep_TabMLP_20211010\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"widedeep_TabMLP_{datetime.now().strftime('%Y%m%d')}\")\n",
    "\n",
    "# study = load(datapath/f'optuna_lightgbm_26trials-complete_20211002.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304fa51-6cff-4ac6-8de3-3fe9b1949640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8520d85e-1229-4bbb-be89-61895d33a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "F1cSVFH9gkW_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "epoch 1:   0%|          | 0/655 [00:00<?, ?it/s]\n",
      "\u001b[33m[W 2021-10-10 09:58:47,017]\u001b[0m Trial 0 failed because of the following error: TypeError(\"step() missing 1 required positional argument: 'closure'\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-40-1fd96969bb6c>\", line 175, in objective\n",
      "    trainer.fit( # this is where problem is beginning\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\", line 61, in __call__\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\", line 61, in __call__\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\", line 61, in __call__\n",
      "    return wrapped(*args, **kwargs)\n",
      "  [Previous line repeated 10 more times]\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/trainer.py\", line 610, in fit\n",
      "    train_score, train_loss = self._train_step(data, targett, batch_idx)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/trainer.py\", line 1047, in _train_step\n",
      "    self.optimizer.step()\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/_multiple_optimizer.py\", line 14, in step\n",
      "    op.step()\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "TypeError: step() missing 1 required positional argument: 'closure'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'closure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-50910ac6f454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_jobs = multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(f\"{x+26} trials complete\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudypath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_{exmodel_config['library']}-{exmodel_config['model']}_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-1fd96969bb6c>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     trainer.fit( # this is where problem is beginning\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mX_wide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_wide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mX_tab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_tab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/utils/general_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 ] = alias\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_wide, X_tab, X_text, X_img, X_train, X_val, val_split, target, n_epochs, validation_freq, batch_size, custom_dataloader, finetune, finetune_epochs, finetune_max_lr, finetune_deeptabular_gradual, finetune_deeptabular_max_lr, finetune_deeptabular_layers, finetune_deeptext_gradual, finetune_deeptext_max_lr, finetune_deeptext_layers, finetune_deepimage_gradual, finetune_deepimage_max_lr, finetune_deepimage_layers, finetune_routine, stop_after_finetuning, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargett\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargett\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mprint_loss_and_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/trainer.py\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, data, target, batch_idx)\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/_multiple_optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'closure'"
     ]
    }
   ],
   "source": [
    "for x in range(1,101):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], catch=(ValueError,)) #n_jobs = multiprocessing.cpu_count())\n",
    "#     print(f\"{x+26} trials complete\")\n",
    "    dump(study, filename=studypath/f\"optuna_{exmodel_config['library']}-{exmodel_config['model']}_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a746ff-c0e1-4218-8809-f102a58d2491",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "# dump(study, filename=datapath/f\"optuna_lightgbm_26trials-complete_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# dump(study.best_trial.params, filename=datapath/f\"optuna_lightgbm_all-500trials-best_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.log({'optuna_best_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eeb816-42da-43df-9131-e301e2ad94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
