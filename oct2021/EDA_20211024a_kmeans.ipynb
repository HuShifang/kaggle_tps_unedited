{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# Dataset Sweep usign XGBoost on GPU\n",
    "Trying different variations on the dataset using PCA, other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_qtimPUchWD",
   "metadata": {
    "id": "U_qtimPUchWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {
    "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {
    "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb"
   },
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {
    "id": "16849bd2-428c-497b-ba3b-675002f8d041"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
    "outputId": "6bd53922-c4d7-43ce-c04f-ac1079087966"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
    "outputId": "5483656e-2943-4d97-b5d4-65cfb9795430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    # !pip install category_encoders\n",
    "    # !pip install catboost\n",
    "#     !pip install --upgrade -q lightgbm\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    # !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    # ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    # !pip install cmake --upgrade\n",
    "    # # !pip install sklearn --upgrade\n",
    "    # !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    # %cd /content/xgboost\n",
    "    # !mkdir build\n",
    "    # %cd build\n",
    "    # !cmake .. -DUSE_CUDA=ON\n",
    "    # !make -j4\n",
    "    # %cd /content/xgboost/python-package\n",
    "    # !python setup.py install --use-cuda --use-nccl\n",
    "    # !/opt/bin/nvidia-smi\n",
    "    # !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {
    "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd"
   },
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {
    "id": "a01e85f7-d602-4dde-bef9-611683cd74c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "# import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accfe297-1d47-41bd-9c84-a819d5e565f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9987ab54-45db-40b2-abad-bfc5d6523fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {
    "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe"
   },
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {
    "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351"
   },
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67530ca9-6317-48be-bf6c-8621158b0020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
    "outputId": "76d62b41-4171-40fa-936c-4481a9fdab36"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "#     datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'optuna_studies'\n",
    "    altdatapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/')\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath, altdatapath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {
    "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {
    "id": "fbec2e77-2081-4815-ac6d-39f2a2616386"
   },
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f08480-1725-4520-8995-92b76b8f2cea",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "#     'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['EDA'],\n",
    "    'notes': \"Exploring KMeans\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {
    "id": "a52d9012-34f1-435a-ba16-4416e0d4a286"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ca14-2718-49d9-89e2-91d55f72d706",
   "metadata": {
    "id": "c912a62f-970a-48b4-b428-d886f2612fc2"
   },
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bdd965b-a823-432d-a1ef-4c676bb2be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = datapath/'train.feather'\n",
    "# train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "# df = pd.read_feather(path=train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cff1e9b6-ad6c-4f52-943b-4e7c5eb34c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(datapath/'train.feather')\n",
    "# X_orig = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1b4da3-35ca-413f-84e7-4d7dc65adeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa405c53-3afb-491b-bdd1-fa0669a49945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_orig.to_feather(path=altdatapath/'X_orig.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c6ccf8-77d4-4ec9-9cec-7797a3edf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = load(altdatapath/'pca.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33822ce0-28ac-4869-a71c-eb8132d40166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4648555d-63f0-419d-bae4-1fa574ab53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = datapath/'train.feather'\n",
    "# train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "# train_source = altdatapath/'X_orig.feather'\n",
    "# X = pd.read_feather(train_source)\n",
    "y = load(datapath/'y.joblib')\n",
    "# df = pd.read_feather(path=train_source)\n",
    "# df.index.name = 'id'\n",
    "# y = df.target\n",
    "# features = [x for x in df.columns if x != 'target']\n",
    "# X = df[features]\n",
    "# X = df.iloc[:, :-1]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "# test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "# X_test = pd.read_feather(path=test_source)\n",
    "# X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9661645-0190-4dee-a0e9-8e271c91cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_boruta = pd.read_feather(altdatapath/'X_boruta_shap_200trials.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1528f99-ea42-417b-b8ff-5bdc48cf2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcc62e3b-a330-4a6b-a044-2143f8b1f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0326ff89-df34-458f-97f9-730388c93085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8d06b71-025d-49fb-98ad-ff5c16bb5d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a598e3-0d59-4927-8d00-35801a220f16",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8581877-6442-44c4-b5a1-740bd586bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(datapath/'train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b17fd863-a14f-49ec-885e-4ad096f8d37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.410993</td>\n",
       "      <td>0.176775</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.423543</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.534873</td>\n",
       "      <td>0.147295</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.473119</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.441593</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>0.238509</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182583</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.207116</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.751107</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.439211</td>\n",
       "      <td>0.432055</td>\n",
       "      <td>0.776147</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>0.260886</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.548819</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>0.158321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.205979  0.410993  0.176775  0.223581  0.423543  0.476140  0.413590   \n",
       "1  0.181004  0.473119  0.011734  0.213657  0.619678  0.441593  0.230407   \n",
       "2  0.182583  0.307431  0.325950  0.207116  0.605699  0.309695  0.493337   \n",
       "3  0.180240  0.494592  0.008367  0.223580  0.760618  0.439211  0.432055   \n",
       "4  0.177172  0.495513  0.014263  0.548819  0.625396  0.562493  0.117158   \n",
       "\n",
       "         f7        f8        f9  ...  f276  f277  f278  f279  f280  f281  \\\n",
       "0  0.612021  0.534873  0.147295  ...     0     1     0     0     0     0   \n",
       "1  0.686013  0.281971  0.238509  ...     0     1     0     0     0     0   \n",
       "2  0.751107  0.536272  0.286813  ...     0     0     0     1     1     0   \n",
       "3  0.776147  0.483958  0.260886  ...     0     0     0     0     1     0   \n",
       "4  0.561255  0.077115  0.158321  ...     0     1     1     0     1     0   \n",
       "\n",
       "   f282  f283  f284  target  \n",
       "0     0     0     0       1  \n",
       "1     0     0     0       1  \n",
       "2     0     0     0       1  \n",
       "3     0     0     0       1  \n",
       "4     0     1     0       1  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ece4f404-d8f2-4af8-bac0-e39622f27a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20864c51-4ce9-4dd3-8c12-f4895d1b2d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 286)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c5e4f2-f540-4f55-9fc2-3e798f23b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>-0.006450</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.003869</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>-0.001394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.004458</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>-0.029324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>-0.005837</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>-0.015663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>-0.006450</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>-0.024096</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>-0.006445</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-0.003336</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>-0.002430</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.036279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>0.005437</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>-0.005837</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002361</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>0.019811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0        f1        f2        f3        f4        f5        f6  \\\n",
       "f0  1.000000 -0.001394  0.002228 -0.006450  0.005437 -0.007128 -0.003869   \n",
       "f1 -0.001394  1.000000  0.001856  0.005209 -0.002631 -0.003103  0.006982   \n",
       "f2  0.002228  0.001856  1.000000  0.008163 -0.005837  0.001922 -0.000976   \n",
       "f3 -0.006450  0.005209  0.008163  1.000000  0.009656  0.004251 -0.024096   \n",
       "f4  0.005437 -0.002631 -0.005837  0.009656  1.000000 -0.002361  0.001605   \n",
       "\n",
       "          f7        f8        f9  ...      f276      f277      f278      f279  \\\n",
       "f0  0.000043  0.006060  0.003302  ...  0.001481  0.001076  0.001809  0.000371   \n",
       "f1  0.000650  0.004013 -0.005154  ... -0.001599 -0.001704  0.001096 -0.000160   \n",
       "f2 -0.002580 -0.002813  0.004317  ...  0.001042  0.002569  0.002608  0.002077   \n",
       "f3  0.008788 -0.006445  0.011000  ... -0.001411 -0.003336  0.002938  0.001219   \n",
       "f4  0.001026  0.012946 -0.005513  ...  0.000045 -0.000327 -0.000987  0.000348   \n",
       "\n",
       "        f280      f281      f282      f283      f284    target  \n",
       "f0  0.000534 -0.000224  0.001863  0.000382  0.003530  0.004067  \n",
       "f1 -0.004458  0.002074 -0.001471 -0.003102 -0.000589 -0.029324  \n",
       "f2 -0.000907  0.001557  0.002067  0.002581  0.003950 -0.015663  \n",
       "f3  0.002064  0.005564 -0.002430  0.002464  0.004908  0.036279  \n",
       "f4  0.000495  0.000289  0.002657  0.002152 -0.001884  0.019811  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ba38ed-baee-47b1-989b-dc0f08a4a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = df_corr.loc['target':'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc5b09-bc2f-4f96-9df0-ad45f727cf2d",
   "metadata": {},
   "source": [
    "- This pulls out the correlations with the `target`, which is what matters most, and puts it into a `DataFrame` (vs. `df_corr.loc['target']`, which would yield a `Series` only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "767b8981-5860-456a-be65-5dc7a05686c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.004067</td>\n",
       "      <td>-0.029324</td>\n",
       "      <td>-0.015663</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>-0.043557</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.003869</td>\n",
       "      <td>-0.004477</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0        f1        f2        f3        f4        f5        f6  \\\n",
       "target  0.004067 -0.029324 -0.015663  0.036279  0.019811 -0.012301 -0.012332   \n",
       "\n",
       "              f7        f8        f9  ...     f276      f277      f278  \\\n",
       "target  0.013528 -0.043557 -0.002662  ... -0.00329 -0.003869 -0.004477   \n",
       "\n",
       "            f279      f280      f281      f282      f283    f284  target  \n",
       "target -0.004503 -0.004319 -0.004587 -0.002426 -0.005901 -0.0037     1.0  \n",
       "\n",
       "[1 rows x 286 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b431d9-31f3-4826-ab1a-832c86167fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.004067</td>\n",
       "      <td>-0.029324</td>\n",
       "      <td>-0.015663</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>-0.043557</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00442</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.003869</td>\n",
       "      <td>-0.004477</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.0037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0        f1        f2        f3        f4        f5        f6  \\\n",
       "target  0.004067 -0.029324 -0.015663  0.036279  0.019811 -0.012301 -0.012332   \n",
       "\n",
       "              f7        f8        f9  ...     f275     f276      f277  \\\n",
       "target  0.013528 -0.043557 -0.002662  ... -0.00442 -0.00329 -0.003869   \n",
       "\n",
       "            f278      f279      f280      f281      f282      f283    f284  \n",
       "target -0.004477 -0.004503 -0.004319 -0.004587 -0.002426 -0.005901 -0.0037  \n",
       "\n",
       "[1 rows x 285 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_target = corr_target.drop(['target'], axis=1)\n",
    "corr_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5630177-848d-46c0-ab90-bdb1b598a469",
   "metadata": {},
   "source": [
    "- No need to include the self-correlation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472164f7-3ef6-484a-92a6-14f39e953479",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target_abs = abs(corr_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd6b940a-8d91-4222-b0e8-eff1b5da3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sorted = corr_target_abs.sort_values(by='target', axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3397c741-29cc-4029-ad33-c6d2772ace78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f22', 'f179', 'f69', 'f156', 'f58', 'f136', 'f214', 'f78']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = list(corr_sorted.columns[:8])\n",
    "useful_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6305868e-63f6-4fd3-9487-885763539e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 12\n",
    "cd_feature = True # i.e. cluster distance rather than cluster number\n",
    "cluster_cols = [f\"cluster{i+1}\" for i in range(n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "769527be-b8f0-461a-91d2-8fa808453000",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b55570b2-3004-4217-a21d-25dce6b5bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_feather(datapath/'test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e9827be-0d13-4c41-8d4d-5feaa97b84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cd_feature:\n",
    "    X_cd = kmeans.fit_transform(df[useful_features])\n",
    "    X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=df.index)\n",
    "    X_cd.to_feather(altdatapath/f'train-ONLY-KMeans_{n_clusters}cluster_kmeans++_maxiter1000_rs42.feather')\n",
    "    train = df.join(X_cd)\n",
    "    train.to_feather(altdatapath/f'train-WITH-KMeans_{n_clusters}cluster_kmeans++_maxiter1000_rs42.feather')\n",
    "    X_cd = kmeans.transform(test_df[useful_features])\n",
    "    X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=test_df.index)\n",
    "    X_cd.to_feather(altdatapath/f'test-ONLY-KMeans_{n_clusters}cluster_kmeans++_maxiter1000_rs42.feather')\n",
    "    test = test_df.join(X_cd)\n",
    "    test.to_feather(altdatapath/f'test-WITH-KMeans_{n_clusters}cluster_kmeans++_maxiter1000_rs42.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0820a32-c52d-499b-89aa-a3265c13132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster3</th>\n",
       "      <th>cluster4</th>\n",
       "      <th>cluster5</th>\n",
       "      <th>cluster6</th>\n",
       "      <th>cluster7</th>\n",
       "      <th>cluster8</th>\n",
       "      <th>cluster9</th>\n",
       "      <th>cluster10</th>\n",
       "      <th>cluster11</th>\n",
       "      <th>cluster12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.410993</td>\n",
       "      <td>0.176775</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.423543</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.534873</td>\n",
       "      <td>0.147295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118063</td>\n",
       "      <td>1.120353</td>\n",
       "      <td>0.498104</td>\n",
       "      <td>1.065476</td>\n",
       "      <td>1.080335</td>\n",
       "      <td>0.404707</td>\n",
       "      <td>0.376228</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>0.566420</td>\n",
       "      <td>0.273633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.473119</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.441593</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>0.238509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177302</td>\n",
       "      <td>1.121155</td>\n",
       "      <td>0.521874</td>\n",
       "      <td>1.024940</td>\n",
       "      <td>1.033481</td>\n",
       "      <td>0.257178</td>\n",
       "      <td>0.232656</td>\n",
       "      <td>1.015721</td>\n",
       "      <td>0.511074</td>\n",
       "      <td>0.270840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182583</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.207116</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.751107</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106350</td>\n",
       "      <td>0.137834</td>\n",
       "      <td>1.006925</td>\n",
       "      <td>0.584342</td>\n",
       "      <td>0.609170</td>\n",
       "      <td>1.173763</td>\n",
       "      <td>1.161392</td>\n",
       "      <td>0.470892</td>\n",
       "      <td>1.040839</td>\n",
       "      <td>1.122642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.439211</td>\n",
       "      <td>0.432055</td>\n",
       "      <td>0.776147</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>0.260886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085023</td>\n",
       "      <td>1.122756</td>\n",
       "      <td>0.504192</td>\n",
       "      <td>1.036171</td>\n",
       "      <td>1.077985</td>\n",
       "      <td>0.398120</td>\n",
       "      <td>0.279080</td>\n",
       "      <td>1.005104</td>\n",
       "      <td>0.569666</td>\n",
       "      <td>0.281321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.548819</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>0.158321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018883</td>\n",
       "      <td>0.519324</td>\n",
       "      <td>1.123513</td>\n",
       "      <td>0.384397</td>\n",
       "      <td>0.430975</td>\n",
       "      <td>1.087314</td>\n",
       "      <td>1.073945</td>\n",
       "      <td>0.200169</td>\n",
       "      <td>1.155846</td>\n",
       "      <td>1.048198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.205979  0.410993  0.176775  0.223581  0.423543  0.476140  0.413590   \n",
       "1  0.181004  0.473119  0.011734  0.213657  0.619678  0.441593  0.230407   \n",
       "2  0.182583  0.307431  0.325950  0.207116  0.605699  0.309695  0.493337   \n",
       "3  0.180240  0.494592  0.008367  0.223580  0.760618  0.439211  0.432055   \n",
       "4  0.177172  0.495513  0.014263  0.548819  0.625396  0.562493  0.117158   \n",
       "\n",
       "         f7        f8        f9  ...  cluster3  cluster4  cluster5  cluster6  \\\n",
       "0  0.612021  0.534873  0.147295  ...  0.118063  1.120353  0.498104  1.065476   \n",
       "1  0.686013  0.281971  0.238509  ...  0.177302  1.121155  0.521874  1.024940   \n",
       "2  0.751107  0.536272  0.286813  ...  1.106350  0.137834  1.006925  0.584342   \n",
       "3  0.776147  0.483958  0.260886  ...  0.085023  1.122756  0.504192  1.036171   \n",
       "4  0.561255  0.077115  0.158321  ...  1.018883  0.519324  1.123513  0.384397   \n",
       "\n",
       "   cluster7  cluster8  cluster9  cluster10  cluster11  cluster12  \n",
       "0  1.080335  0.404707  0.376228   1.007677   0.566420   0.273633  \n",
       "1  1.033481  0.257178  0.232656   1.015721   0.511074   0.270840  \n",
       "2  0.609170  1.173763  1.161392   0.470892   1.040839   1.122642  \n",
       "3  1.077985  0.398120  0.279080   1.005104   0.569666   0.281321  \n",
       "4  0.430975  1.087314  1.073945   0.200169   1.155846   1.048198  \n",
       "\n",
       "[5 rows x 298 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b5158e9-08c3-435b-a9ca-ed61ed4c6858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster3</th>\n",
       "      <th>cluster4</th>\n",
       "      <th>cluster5</th>\n",
       "      <th>cluster6</th>\n",
       "      <th>cluster7</th>\n",
       "      <th>cluster8</th>\n",
       "      <th>cluster9</th>\n",
       "      <th>cluster10</th>\n",
       "      <th>cluster11</th>\n",
       "      <th>cluster12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.410993</td>\n",
       "      <td>0.176775</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.423543</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.534873</td>\n",
       "      <td>0.147295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006856</td>\n",
       "      <td>1.120371</td>\n",
       "      <td>0.505164</td>\n",
       "      <td>0.273927</td>\n",
       "      <td>1.068043</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.118066</td>\n",
       "      <td>0.410462</td>\n",
       "      <td>1.012058</td>\n",
       "      <td>1.036928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.473119</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.441593</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>0.238509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015795</td>\n",
       "      <td>1.121241</td>\n",
       "      <td>0.506705</td>\n",
       "      <td>0.270957</td>\n",
       "      <td>1.026489</td>\n",
       "      <td>0.232978</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>1.041144</td>\n",
       "      <td>1.036402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182583</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.207116</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.751107</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472956</td>\n",
       "      <td>0.137650</td>\n",
       "      <td>1.009546</td>\n",
       "      <td>1.122660</td>\n",
       "      <td>0.589676</td>\n",
       "      <td>1.161223</td>\n",
       "      <td>1.106344</td>\n",
       "      <td>1.171501</td>\n",
       "      <td>0.528632</td>\n",
       "      <td>0.510218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.439211</td>\n",
       "      <td>0.432055</td>\n",
       "      <td>0.776147</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>0.260886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003634</td>\n",
       "      <td>1.122804</td>\n",
       "      <td>0.510653</td>\n",
       "      <td>0.281623</td>\n",
       "      <td>1.037806</td>\n",
       "      <td>0.279855</td>\n",
       "      <td>0.085024</td>\n",
       "      <td>0.404116</td>\n",
       "      <td>1.030548</td>\n",
       "      <td>1.039165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.548819</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>0.158321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194657</td>\n",
       "      <td>0.519368</td>\n",
       "      <td>1.126789</td>\n",
       "      <td>1.048274</td>\n",
       "      <td>0.390756</td>\n",
       "      <td>1.074191</td>\n",
       "      <td>1.018884</td>\n",
       "      <td>1.089476</td>\n",
       "      <td>0.113174</td>\n",
       "      <td>0.314312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.205979  0.410993  0.176775  0.223581  0.423543  0.476140  0.413590   \n",
       "1  0.181004  0.473119  0.011734  0.213657  0.619678  0.441593  0.230407   \n",
       "2  0.182583  0.307431  0.325950  0.207116  0.605699  0.309695  0.493337   \n",
       "3  0.180240  0.494592  0.008367  0.223580  0.760618  0.439211  0.432055   \n",
       "4  0.177172  0.495513  0.014263  0.548819  0.625396  0.562493  0.117158   \n",
       "\n",
       "         f7        f8        f9  ...  cluster3  cluster4  cluster5  cluster6  \\\n",
       "0  0.612021  0.534873  0.147295  ...  1.006856  1.120371  0.505164  0.273927   \n",
       "1  0.686013  0.281971  0.238509  ...  1.015795  1.121241  0.506705  0.270957   \n",
       "2  0.751107  0.536272  0.286813  ...  0.472956  0.137650  1.009546  1.122660   \n",
       "3  0.776147  0.483958  0.260886  ...  1.003634  1.122804  0.510653  0.281623   \n",
       "4  0.561255  0.077115  0.158321  ...  0.194657  0.519368  1.126789  1.048274   \n",
       "\n",
       "   cluster7  cluster8  cluster9  cluster10  cluster11  cluster12  \n",
       "0  1.068043  0.376954  0.118066   0.410462   1.012058   1.036928  \n",
       "1  1.026489  0.232978  0.177303   0.262626   1.041144   1.036402  \n",
       "2  0.589676  1.161223  1.106344   1.171501   0.528632   0.510218  \n",
       "3  1.037806  0.279855  0.085024   0.404116   1.030548   1.039165  \n",
       "4  0.390756  1.074191  1.018884   1.089476   0.113174   0.314312  \n",
       "\n",
       "[5 rows x 298 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107ef29-8a05-4763-aea7-8eb234c2eaab",
   "metadata": {},
   "source": [
    "- The above numbers generally track with the ones [here](https://www.kaggle.com/motchan/tps-oct-2021-kmeans), but with a few variations, because he left the `id` column in the table, and I didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8180e572-0bdc-465f-aa59-de5babaf19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=train[cluster_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7744566a-0cdf-4e37-8c7f-203cd2069117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster1</th>\n",
       "      <th>cluster2</th>\n",
       "      <th>cluster3</th>\n",
       "      <th>cluster4</th>\n",
       "      <th>cluster5</th>\n",
       "      <th>cluster6</th>\n",
       "      <th>cluster7</th>\n",
       "      <th>cluster8</th>\n",
       "      <th>cluster9</th>\n",
       "      <th>cluster10</th>\n",
       "      <th>cluster11</th>\n",
       "      <th>cluster12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.834818</td>\n",
       "      <td>-0.827085</td>\n",
       "      <td>0.883170</td>\n",
       "      <td>-0.902748</td>\n",
       "      <td>0.967413</td>\n",
       "      <td>0.956921</td>\n",
       "      <td>-0.859552</td>\n",
       "      <td>-0.859226</td>\n",
       "      <td>0.985605</td>\n",
       "      <td>-0.927443</td>\n",
       "      <td>-0.843773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2</th>\n",
       "      <td>-0.834818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982237</td>\n",
       "      <td>-0.909122</td>\n",
       "      <td>0.864781</td>\n",
       "      <td>-0.857575</td>\n",
       "      <td>-0.860419</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.960619</td>\n",
       "      <td>-0.830518</td>\n",
       "      <td>0.861883</td>\n",
       "      <td>0.979839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster3</th>\n",
       "      <td>-0.827085</td>\n",
       "      <td>0.982237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.892228</td>\n",
       "      <td>0.861461</td>\n",
       "      <td>-0.840468</td>\n",
       "      <td>-0.843665</td>\n",
       "      <td>0.950219</td>\n",
       "      <td>0.961465</td>\n",
       "      <td>-0.809768</td>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.986456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster4</th>\n",
       "      <td>0.883170</td>\n",
       "      <td>-0.909122</td>\n",
       "      <td>-0.892228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.819827</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>0.871823</td>\n",
       "      <td>-0.921475</td>\n",
       "      <td>-0.920426</td>\n",
       "      <td>0.880446</td>\n",
       "      <td>-0.843821</td>\n",
       "      <td>-0.909280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster5</th>\n",
       "      <td>-0.902748</td>\n",
       "      <td>0.864781</td>\n",
       "      <td>0.861461</td>\n",
       "      <td>-0.819827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.913318</td>\n",
       "      <td>-0.921709</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>0.857794</td>\n",
       "      <td>-0.888421</td>\n",
       "      <td>0.983489</td>\n",
       "      <td>0.867239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster6</th>\n",
       "      <td>0.967413</td>\n",
       "      <td>-0.857575</td>\n",
       "      <td>-0.840468</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>-0.913318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>-0.870570</td>\n",
       "      <td>-0.842435</td>\n",
       "      <td>0.968453</td>\n",
       "      <td>-0.936778</td>\n",
       "      <td>-0.856282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster7</th>\n",
       "      <td>0.956921</td>\n",
       "      <td>-0.860419</td>\n",
       "      <td>-0.843665</td>\n",
       "      <td>0.871823</td>\n",
       "      <td>-0.921709</td>\n",
       "      <td>0.947582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.833056</td>\n",
       "      <td>-0.872849</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>-0.916789</td>\n",
       "      <td>-0.860250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster8</th>\n",
       "      <td>-0.859552</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.950219</td>\n",
       "      <td>-0.921475</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>-0.870570</td>\n",
       "      <td>-0.833056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939392</td>\n",
       "      <td>-0.846012</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>0.952604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster9</th>\n",
       "      <td>-0.859226</td>\n",
       "      <td>0.960619</td>\n",
       "      <td>0.961465</td>\n",
       "      <td>-0.920426</td>\n",
       "      <td>0.857794</td>\n",
       "      <td>-0.842435</td>\n",
       "      <td>-0.872849</td>\n",
       "      <td>0.939392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.845674</td>\n",
       "      <td>0.857471</td>\n",
       "      <td>0.963912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster10</th>\n",
       "      <td>0.985605</td>\n",
       "      <td>-0.830518</td>\n",
       "      <td>-0.809768</td>\n",
       "      <td>0.880446</td>\n",
       "      <td>-0.888421</td>\n",
       "      <td>0.968453</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>-0.846012</td>\n",
       "      <td>-0.845674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.914063</td>\n",
       "      <td>-0.828154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster11</th>\n",
       "      <td>-0.927443</td>\n",
       "      <td>0.861883</td>\n",
       "      <td>0.855848</td>\n",
       "      <td>-0.843821</td>\n",
       "      <td>0.983489</td>\n",
       "      <td>-0.936778</td>\n",
       "      <td>-0.916789</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>0.857471</td>\n",
       "      <td>-0.914063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster12</th>\n",
       "      <td>-0.843773</td>\n",
       "      <td>0.979839</td>\n",
       "      <td>0.986456</td>\n",
       "      <td>-0.909280</td>\n",
       "      <td>0.867239</td>\n",
       "      <td>-0.856282</td>\n",
       "      <td>-0.860250</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.963912</td>\n",
       "      <td>-0.828154</td>\n",
       "      <td>0.864448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster1  cluster2  cluster3  cluster4  cluster5  cluster6  \\\n",
       "cluster1   1.000000 -0.834818 -0.827085  0.883170 -0.902748  0.967413   \n",
       "cluster2  -0.834818  1.000000  0.982237 -0.909122  0.864781 -0.857575   \n",
       "cluster3  -0.827085  0.982237  1.000000 -0.892228  0.861461 -0.840468   \n",
       "cluster4   0.883170 -0.909122 -0.892228  1.000000 -0.819827  0.877304   \n",
       "cluster5  -0.902748  0.864781  0.861461 -0.819827  1.000000 -0.913318   \n",
       "cluster6   0.967413 -0.857575 -0.840468  0.877304 -0.913318  1.000000   \n",
       "cluster7   0.956921 -0.860419 -0.843665  0.871823 -0.921709  0.947582   \n",
       "cluster8  -0.859552  0.950699  0.950219 -0.921475  0.838853 -0.870570   \n",
       "cluster9  -0.859226  0.960619  0.961465 -0.920426  0.857794 -0.842435   \n",
       "cluster10  0.985605 -0.830518 -0.809768  0.880446 -0.888421  0.968453   \n",
       "cluster11 -0.927443  0.861883  0.855848 -0.843821  0.983489 -0.936778   \n",
       "cluster12 -0.843773  0.979839  0.986456 -0.909280  0.867239 -0.856282   \n",
       "\n",
       "           cluster7  cluster8  cluster9  cluster10  cluster11  cluster12  \n",
       "cluster1   0.956921 -0.859552 -0.859226   0.985605  -0.927443  -0.843773  \n",
       "cluster2  -0.860419  0.950699  0.960619  -0.830518   0.861883   0.979839  \n",
       "cluster3  -0.843665  0.950219  0.961465  -0.809768   0.855848   0.986456  \n",
       "cluster4   0.871823 -0.921475 -0.920426   0.880446  -0.843821  -0.909280  \n",
       "cluster5  -0.921709  0.838853  0.857794  -0.888421   0.983489   0.867239  \n",
       "cluster6   0.947582 -0.870570 -0.842435   0.968453  -0.936778  -0.856282  \n",
       "cluster7   1.000000 -0.833056 -0.872849   0.956731  -0.916789  -0.860250  \n",
       "cluster8  -0.833056  1.000000  0.939392  -0.846012   0.880281   0.952604  \n",
       "cluster9  -0.872849  0.939392  1.000000  -0.845674   0.857471   0.963912  \n",
       "cluster10  0.956731 -0.846012 -0.845674   1.000000  -0.914063  -0.828154  \n",
       "cluster11 -0.916789  0.880281  0.857471  -0.914063   1.000000   0.864448  \n",
       "cluster12 -0.860250  0.952604  0.963912  -0.828154   0.864448   1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[cluster_cols].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daabb7d-d072-461b-b170-25f8b71204b8",
   "metadata": {},
   "source": [
    "- So this is suggesting that the following clusters are correlated:\n",
    "    - 1 & 3\n",
    "    - 4 & 6\n",
    "    - 5 & 8\n",
    "    - 7 & 2\n",
    "- In [mottchan](https://www.kaggle.com/motchan/tps-oct-2021-kmeans)'s notebook (which I'm following), he opts to add 8 new features on the basis of these: for each pair, there's one feature that divides the first by the second, adn another that multiplies the first by the second.\n",
    "- All of these features prove more important for predicting the final figure than even `f22`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5069f12c-75db-4e06-b13f-effe397318ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_synthetic_features(df):\n",
    "    df['new_f1'] = df['cluster1'] / df['cluster3']\n",
    "    df['new_f2'] = df['cluster8'] / df['cluster5']\n",
    "    df['new_f3'] = df['cluster7'] / df['cluster2']\n",
    "    df['new_f4'] = df['cluster4'] / df['cluster6']\n",
    "    df['new_f5'] = df['cluster1'] * df['cluster3']\n",
    "    df['new_f6'] = df['cluster8'] * df['cluster5']\n",
    "    df['new_f7'] = df['cluster7'] * df['cluster2']\n",
    "    df['new_f8'] = df['cluster4'] * df['cluster6']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86d7e04c-7ab3-450c-bde1-8e860937a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_synthetic_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ec06a1e-dc64-480c-897a-4d4540acc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_synthetic_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "956e483e-a4d9-4ff2-b432-e0784b4ead43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_feather(altdatapath/'train-WITH-KMeans_8cluster_ninit50_maxiter1000_rs42-AND-synthetic.feather')\n",
    "test.to_feather(altdatapath/'test-WITH-KMeans_8cluster_ninit50_maxiter1000_rs42-AND-synthetic.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13be42-2209-4806-a137-2dfb41c4f362",
   "metadata": {},
   "source": [
    "# (old) ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7fc3ade-47f5-455e-9eae-23f035f093aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f265': 2},\n",
       " {'f255': 2},\n",
       " {'f22': 2},\n",
       " {'f117': 75104},\n",
       " {'f256': 2},\n",
       " {'f103': 76473},\n",
       " {'f260': 2},\n",
       " {'f252': 2},\n",
       " {'f247': 2},\n",
       " {'f274': 2},\n",
       " {'f243': 2},\n",
       " {'f108': 66767},\n",
       " {'f210': 65746},\n",
       " {'f43': 2},\n",
       " {'f258': 2},\n",
       " {'f266': 2},\n",
       " {'f269': 2},\n",
       " {'f245': 2},\n",
       " {'f99': 86896}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) < 100000]\n",
    "low_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f477e01d-c7c3-41ce-be7e-1bbe25f14c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f174': 542053},\n",
       " {'f72': 573057},\n",
       " {'f44': 241770},\n",
       " {'f53': 240013},\n",
       " {'f62': 332336},\n",
       " {'f16': 313228},\n",
       " {'f206': 431717},\n",
       " {'f74': 175223},\n",
       " {'f33': 324185},\n",
       " {'f143': 444524},\n",
       " {'f6': 421827},\n",
       " {'f169': 606385},\n",
       " {'f29': 132977},\n",
       " {'f208': 365225},\n",
       " {'f107': 147096},\n",
       " {'f71': 125690},\n",
       " {'f152': 399983},\n",
       " {'f90': 426170},\n",
       " {'f18': 163185},\n",
       " {'f56': 225538},\n",
       " {'f77': 322750},\n",
       " {'f4': 401939},\n",
       " {'f5': 241585},\n",
       " {'f87': 198478},\n",
       " {'f129': 183006},\n",
       " {'f7': 265619},\n",
       " {'f58': 482130},\n",
       " {'f187': 188558},\n",
       " {'f3': 244851},\n",
       " {'f225': 558377},\n",
       " {'f229': 358098},\n",
       " {'f20': 226437},\n",
       " {'f211': 223364},\n",
       " {'f70': 157423},\n",
       " {'f199': 302838},\n",
       " {'f61': 268732},\n",
       " {'f118': 189040},\n",
       " {'f144': 607935},\n",
       " {'f93': 410485},\n",
       " {'f130': 352035},\n",
       " {'f128': 177314},\n",
       " {'f27': 223306},\n",
       " {'f1': 374634},\n",
       " {'f85': 325589},\n",
       " {'f212': 216199},\n",
       " {'f80': 140510},\n",
       " {'f86': 365382},\n",
       " {'f76': 212732},\n",
       " {'f200': 420271},\n",
       " {'f64': 132128},\n",
       " {'f83': 202494},\n",
       " {'f127': 226315},\n",
       " {'f138': 497263},\n",
       " {'f11': 141980},\n",
       " {'f19': 161302},\n",
       " {'f82': 107320},\n",
       " {'f231': 325664},\n",
       " {'f239': 239593},\n",
       " {'f60': 245103},\n",
       " {'f119': 171081},\n",
       " {'f42': 171131},\n",
       " {'f2': 452401},\n",
       " {'f75': 116914},\n",
       " {'f79': 188230},\n",
       " {'f214': 460571},\n",
       " {'f73': 328802},\n",
       " {'f92': 386351},\n",
       " {'f40': 294067},\n",
       " {'f156': 152362},\n",
       " {'f157': 492134},\n",
       " {'f147': 251131},\n",
       " {'f226': 594319},\n",
       " {'f52': 120431},\n",
       " {'f98': 367956},\n",
       " {'f179': 497596},\n",
       " {'f173': 500033},\n",
       " {'f112': 305296},\n",
       " {'f140': 128487},\n",
       " {'f89': 324090},\n",
       " {'f141': 489019},\n",
       " {'f65': 307414},\n",
       " {'f195': 412007},\n",
       " {'f192': 490036},\n",
       " {'f14': 302868},\n",
       " {'f139': 436631},\n",
       " {'f78': 260647},\n",
       " {'f222': 355695},\n",
       " {'f184': 513613},\n",
       " {'f163': 453071},\n",
       " {'f114': 499970},\n",
       " {'f96': 146100},\n",
       " {'f154': 446224},\n",
       " {'f35': 123688},\n",
       " {'f133': 214341},\n",
       " {'f241': 244154},\n",
       " {'f55': 177793},\n",
       " {'f8': 428659},\n",
       " {'f17': 231233},\n",
       " {'f48': 182403},\n",
       " {'f191': 529250},\n",
       " {'f12': 246156},\n",
       " {'f63': 259988},\n",
       " {'f69': 214266},\n",
       " {'f26': 183403},\n",
       " {'f162': 445373},\n",
       " {'f213': 175959},\n",
       " {'f238': 179040},\n",
       " {'f150': 226675},\n",
       " {'f13': 257319},\n",
       " {'f136': 101424},\n",
       " {'f201': 199649},\n",
       " {'f113': 141591},\n",
       " {'f134': 195021},\n",
       " {'f95': 160801},\n",
       " {'f227': 553207},\n",
       " {'f125': 579880},\n",
       " {'f164': 125692}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) > 100000]\n",
    "higher_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017d3d8c-2b4e-45f2-aee4-ecf5ab4452e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in X.columns:\n",
    "#     pct_diff = (1000000 - X[f].nunique()) / 1000000\n",
    "#     if pct_diff >= 0.9:\n",
    "#         print(f\"for {f}: {pct_diff}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834c63e7-ebc6-41d7-ae9e-44e23823714e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in X.columns:\n",
    "#     pct_diff = (1000000 - X[f].nunique()) / 1000000\n",
    "#     if pct_diff >= 0.8:\n",
    "#         print(f\"for {f}: {pct_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc8a0af-0c2a-4889-8d7d-2ff810c3356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a10ee18-1828-4956-92ba-1623697e19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d193ee2-055a-4098-96cf-a2c10b850daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ce.woe.WOEEncoder(cols=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fcbae3b-21a9-4c90-ac50-85f20faa3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbcfd3b9-c288-4b63-8772-b758e4fc087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb61bf31-b2c2-4a49-9783-57adbce550c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X_woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16abc985-3a89-45d2-bf20-611a87e3ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c828b2c2-bbf0-4d7a-a2aa-0e103f894df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_test(X,y):\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "    #         n_jobs=-1,\n",
    "    #         **params\n",
    "    )    \n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813b42c-8375-40d4-9424-21a1d82351ea",
   "metadata": {},
   "source": [
    "The best parametece.sum_codingto present have been:\n",
    "\n",
    "```python\n",
    "best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "```\n",
    "\n",
    "These params get the following ROC_AUC scores on a 20% holdout for these dataset versions:\n",
    "\n",
    "| Version | Feature Count | category_encoder | Valid ROC-AUC |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| original | 285 | none | 0.8572984856383443 |\n",
    "| Boruta green-only | 98 | none | 0.8553163413048461 |\n",
    "| Boruta green-and-blue | 109 | none | 0.8558487581638441 |\n",
    "| Boruta with SHAP | 136 | none | 0.8566790062778752 |\n",
    "| Boruta with SHAP | 136 | woe | 0.8899772033406148 |\n",
    "| original | 285 | woe | 0.8903361849466815 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033696c5-e21b-4005-8d28-b741516738f2",
   "metadata": {},
   "source": [
    "So, Boruta with SHAP performs better than Boruta with green-only *and* Boruta with green and blue, landing 0.8566790062778752"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b20a9-e2f5-4515-a018-38dda183557e",
   "metadata": {},
   "source": [
    "So, boruta with green only gets 0.8553163413048461, vs 0.8572984856383443 for the same model on the vanilla training set. Not bad.\n",
    "\n",
    "Let's try a more conservative take -- the green zone *plus* the blue zone (i.e. the take-it-or-leave-it features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fdefdf2-442e-49e5-911f-8567231125d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_test(X_woe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b0455ba-ac71-4d12-90f3-d7652021ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_feather(datapath/'train.feather').iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ab90b2-cfe8-4979-8701-a31282b6eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 136)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fad2ce44-ae26-4296-9fd3-16a58f8d3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f699676-cd46-48da-b7d4-6de4e987c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe_orig = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15ba69ba-b56c-4100-8664-b98d5b49b1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline_test(X_woe_orig,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d66676f6-c5ab-41a5-8610-febaa2b31fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe.to_feather(path=altdatapath/'X_boruta_SHAP_woe.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ef3f1f8-f422-4f4d-8cd6-b5f2476fa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe_orig.to_feather(path=altdatapath/'X_orig_woe.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7424fb-4012-416c-9bd4-f2433a3f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_woe, X_woe_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d53c9c23-3fe3-434f-911a-ca0d8c54aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [\n",
    "#     ce.SumEncoder(cols=categoricals),\n",
    "#     ce.BackwardDifferenceEncoder(cols=categoricals),\n",
    "    ce.CatBoostEncoder(cols=categoricals), # best yet, > 0.89\n",
    "    ce.CountEncoder(cols=categoricals), #  pretty weak, ~0.855\n",
    "#     ce.GLMMEncoder(cols=categoricals),\n",
    "#     ce.HelmertEncoder(cols=categoricals),\n",
    "#     ce.JamesSteinEncoder(cols=categoricals),\n",
    "#     ce.LeaveOneOutEncoder(cols=categoricals),\n",
    "#     ce.MEstimateEncoder(cols=categoricals),\n",
    "#     ce.OrdinalEncoder(cols=categoricals),\n",
    "#     ce.PolynomialEncoder(cols=categoricals),\n",
    "    ce.TargetEncoder(cols=categoricals),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d613988-f901-49af-8836-84b52fb3dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "# del X \n",
    "# X = pd.read_feather(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e9273fc-a668-4528-9191-73a88508c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CatBoostEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                      'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                      'f258', 'f266', 'f269', 'f245', 'f99'])\n",
      "[17:02:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8910374882085335\n",
      "Testing CountEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                   'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                   'f258', 'f266', 'f269', 'f245', 'f99'],\n",
      "             combine_min_nan_groups=True)\n",
      "[17:05:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8566317964270773\n",
      "Testing TargetEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                    'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                    'f258', 'f266', 'f269', 'f245', 'f99'])\n",
      "[17:09:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8911081124097271\n"
     ]
    }
   ],
   "source": [
    "for encoder in encoders:\n",
    "    print(f\"Testing {str(encoder)}\")\n",
    "    encoder.fit(X,y)\n",
    "    X_enc = encoder.transform(X)\n",
    "    baseline_test(X_enc,y)\n",
    "    del X_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {
    "id": "69ff4abf-560b-450e-a7a5-040878b66565"
   },
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993947ab-fae6-4d7e-b73a-eb4e171ea61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 285)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82cb1b5b-73c9-45d2-943a-5361328f07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b055e2b-ebbb-4d36-b995-7a50d4adbc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eca68f8-930e-4c4f-9d0f-767ebe561d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_picker = XGBClassifier(\n",
    "#     verbosity = 1,\n",
    "#     tree_method = 'gpu_hist',\n",
    "#     booster = 'gbtree',\n",
    "#     random_state = SEED\n",
    "# )\n",
    "\n",
    "feature_picker = CatBoostClassifier(task_type='GPU', silent=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6230e00-931d-4e25-b4a4-1f2305fdbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta = BorutaShap(model=feature_picker,\n",
    "                    importance_measure='shap',\n",
    "                    classification=True)\n",
    "#     verbose=True,\n",
    "# #     random_state=SEED,\n",
    "#     estimator=feature_picker,\n",
    "#     n_estimators='auto',\n",
    "#     max_iter=200,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5ea27b-53a5-4c4c-a45a-2528c86349c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe31795217c42ef87dad7a193276d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 attributes confirmed important: ['f174', 'f72', 'f265', 'f44', 'f53', 'f62', 'f16', 'f206', 'f74', 'f33', 'f143', 'f6', 'f169', 'f29', 'f255', 'f208', 'f107', 'f71', 'f152', 'f90', 'f22', 'f18', 'f56', 'f77', 'f4', 'f5', 'f87', 'f129', 'f117', 'f7', 'f58', 'f256', 'f187', 'f103', 'f3', 'f225', 'f229', 'f20', 'f211', 'f260', 'f70', 'f199', 'f61', 'f118', 'f144', 'f93', 'f130', 'f128', 'f27', 'f1', 'f85', 'f212', 'f252', 'f80', 'f86', 'f76', 'f200', 'f64', 'f83', 'f127', 'f138', 'f11', 'f19', 'f82', 'f231', 'f247', 'f239', 'f60', 'f119', 'f42', 'f2', 'f75', 'f79', 'f214', 'f73', 'f92', 'f40', 'f156', 'f157', 'f147', 'f226', 'f52', 'f98', 'f179', 'f274', 'f173', 'f112', 'f140', 'f89', 'f141', 'f65', 'f195', 'f192', 'f14', 'f139', 'f78', 'f222', 'f184', 'f163', 'f114', 'f96', 'f243', 'f108', 'f154', 'f35', 'f133', 'f241', 'f55', 'f210', 'f8', 'f17', 'f48', 'f191', 'f12', 'f63', 'f69', 'f26', 'f162', 'f43', 'f213', 'f238', 'f258', 'f150', 'f266', 'f13', 'f136', 'f201', 'f113', 'f134', 'f269', 'f245', 'f95', 'f227', 'f125', 'f99', 'f164']\n",
      "146 attributes confirmed unimportant: ['f68', 'f142', 'f185', 'f146', 'f31', 'f122', 'f167', 'f46', 'f158', 'f172', 'f41', 'f66', 'f30', 'f186', 'f47', 'f168', 'f45', 'f21', 'f280', 'f116', 'f34', 'f145', 'f115', 'f220', 'f10', 'f207', 'f190', 'f109', 'f230', 'f251', 'f49', 'f67', 'f250', 'f81', 'f151', 'f36', 'f59', 'f205', 'f166', 'f228', 'f105', 'f177', 'f137', 'f275', 'f123', 'f155', 'f215', 'f217', 'f233', 'f277', 'f171', 'f54', 'f279', 'f246', 'f111', 'f132', 'f153', 'f104', 'f23', 'f180', 'f194', 'f271', 'f268', 'f24', 'f131', 'f283', 'f160', 'f165', 'f202', 'f189', 'f224', 'f237', 'f278', 'f38', 'f124', 'f9', 'f176', 'f236', 'f94', 'f223', 'f254', 'f235', 'f135', 'f39', 'f204', 'f15', 'f282', 'f262', 'f37', 'f216', 'f0', 'f240', 'f32', 'f148', 'f219', 'f263', 'f244', 'f175', 'f25', 'f209', 'f276', 'f259', 'f270', 'f126', 'f221', 'f91', 'f28', 'f183', 'f196', 'f248', 'f170', 'f188', 'f88', 'f100', 'f50', 'f253', 'f84', 'f159', 'f281', 'f218', 'f242', 'f232', 'f102', 'f161', 'f149', 'f182', 'f284', 'f120', 'f51', 'f101', 'f234', 'f257', 'f272', 'f273', 'f267', 'f198', 'f264', 'f106', 'f178', 'f110', 'f203', 'f97', 'f197', 'f261', 'f121', 'f249']\n",
      "3 tentative attributes remains: ['f181', 'f57', 'f193']\n"
     ]
    }
   ],
   "source": [
    "boruta.fit(X=X, y=y, n_trials=200, sample=False, train_or_test='train', normalize=False, verbose=True, random_state=SEED, stratify=False)\n",
    "# boruta = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e09f3111-5c8a-4e29-8f26-a90916a100c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boruta.plot(which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "731d3a0f-3b6f-4cd1-8d20-e89e9fc941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap = boruta.Subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722eb36e-4d38-4f02-a924-d40779ff7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb568c-130f-490b-8032-a365774c7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_zone = X.columns[boruta.support_].to_list()\n",
    "# blue_zone = X.columns[boruta.support_weak_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f9ae9-71fc-4c53-b611-a9e47cac9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_ranks = boruta.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae4c65-54e1-4663-8205-59891154d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_filtered = boruta.transform(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc719a0a-2e9e-4954-a098-ecf70c5d3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_shap.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X_boruta_shap, filename=altdatapath/'X_boruta_shap_200trials.joblib')\n",
    "dump(boruta, filename=altdatapath/'boruta_shap.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46bb0214-7786-48c1-aba4-fda2357c3b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_boruta_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7afef0c9-08d4-4326-bf27-ee4908d1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e6300f4-721e-4126-8f5d-6f6ff1172adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap.to_feather(path=altdatapath/'X_boruta_shap_200trials.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6faff75-3cc9-4aea-9a6e-79ea36ac35db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f174</th>\n",
       "      <th>f72</th>\n",
       "      <th>f265</th>\n",
       "      <th>f44</th>\n",
       "      <th>f53</th>\n",
       "      <th>f62</th>\n",
       "      <th>f16</th>\n",
       "      <th>f206</th>\n",
       "      <th>f74</th>\n",
       "      <th>f33</th>\n",
       "      <th>...</th>\n",
       "      <th>f201</th>\n",
       "      <th>f113</th>\n",
       "      <th>f134</th>\n",
       "      <th>f269</th>\n",
       "      <th>f245</th>\n",
       "      <th>f95</th>\n",
       "      <th>f227</th>\n",
       "      <th>f125</th>\n",
       "      <th>f99</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.192042</td>\n",
       "      <td>0.519336</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.257688</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216079</td>\n",
       "      <td>0.087502</td>\n",
       "      <td>0.217984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559151</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.407014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821982</td>\n",
       "      <td>0.224053</td>\n",
       "      <td>0.447242</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.415982</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240681</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>0.222525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145737</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.111834</td>\n",
       "      <td>0.090468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162094</td>\n",
       "      <td>0.239486</td>\n",
       "      <td>0.749593</td>\n",
       "      <td>0.257763</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.274105</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163251</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144596</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.110486</td>\n",
       "      <td>0.090032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834834</td>\n",
       "      <td>0.175250</td>\n",
       "      <td>0.605277</td>\n",
       "      <td>0.335907</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.319312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163644</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.248067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146811</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.361132</td>\n",
       "      <td>0.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844187</td>\n",
       "      <td>0.249345</td>\n",
       "      <td>0.415167</td>\n",
       "      <td>0.319548</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233770</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.219750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.148517</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.092484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f174       f72  f265       f44       f53       f62       f16      f206  \\\n",
       "0  0.010250  0.004855     0  0.193430  0.192042  0.519336  0.341702  0.011936   \n",
       "1  0.005768  0.004312     0  0.821982  0.224053  0.447242  0.459358  0.011285   \n",
       "2  0.012026  0.004507     0  0.162094  0.239486  0.749593  0.257763  0.009230   \n",
       "3  0.011034  0.002806     0  0.834834  0.175250  0.605277  0.335907  0.007412   \n",
       "4  0.008832  0.004219     1  0.844187  0.249345  0.415167  0.319548  0.013731   \n",
       "\n",
       "        f74       f33  ...      f201      f113      f134  f269  f245  \\\n",
       "0  0.257688  0.034818  ...  0.216079  0.087502  0.217984     1     1   \n",
       "1  0.415982  0.033018  ...  0.240681  0.084309  0.222525     0     0   \n",
       "2  0.274105  0.035977  ...  0.163251  0.085933  0.224012     0     1   \n",
       "3  0.260443  0.319312  ...  0.163644  0.085584  0.248067     0     1   \n",
       "4  0.215576  0.034490  ...  0.233770  0.083699  0.219750     0     1   \n",
       "\n",
       "        f95      f227      f125       f99      f164  \n",
       "0  0.559151  0.011277  0.003969  0.112203  0.407014  \n",
       "1  0.145737  0.011031  0.004784  0.111834  0.090468  \n",
       "2  0.144596  0.009546  0.003502  0.110486  0.090032  \n",
       "3  0.146811  0.006251  0.008915  0.361132  0.091527  \n",
       "4  0.148517  0.006527  0.005913  0.113454  0.092484  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boruta_shap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645beb05-411a-4f71-8ad3-3e355a502bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(boruta, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8c5ca-20b2-4b6c-8ac5-97054c6c1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(green_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377b4a2-dcf7-4139-8d0f-6e8d98a658e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(blue_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54976834-33a4-48f5-9df8-27e42c786864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed15bc-0223-41af-a506-b9395ff8907b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f79d4-336b-4d0b-88c3-39c7195b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3000f1-35e5-4bf7-8cac-ce351fc498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3eb45-bc64-4375-a533-dba7760033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b7113-4389-484b-85b0-1206d99861d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X_filtered), type(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b68e1908-a301-4939-8b01-3635133e5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_boruta_shap, np.array(y), test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec43ce0-12e4-44c3-86a4-1b1125250a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8566790062778752\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) # was 0.7783978025549229 for pca_poly; 0.8572984856383443 for vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1419c9e3-d0b9-40e2-b53c-de93779e1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3878f19-14e3-4b91-9fb5-78662b01e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_blue_green = np.concatenate((X_filtered, np.array(X[blue_zone])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55114317-dd1e-4521-806c-0e63edfa4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 109)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boruta_blue_green.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5efbff7b-7bca-4d3d-83be-ca2465a9e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8558487581638441\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_boruta_blue_green, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754fe12-1939-4128-9825-78fb3f54f10a",
   "metadata": {},
   "source": [
    "So Boruta with green and blue gets 0.8558487581638441 -- a bit better than the green-zone only. Now, let's try adding polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6adeaa-0713-40df-9a32-c7abec077807",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_boruta_blue_green_poly = poly.fit_transform(X_boruta_blue_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46b765-584f-4b28-a80d-d76639da9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_boruta_blue_green, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/X_boruta_200iter_green+blue_109features.joblib')\n",
    "del X_boruta_blue_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37893d85-c063-4425-9665-cb5b969c62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da6f7-7573-4aae-b7c8-f90696304bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c16bd622-ec4b-4744-b552-2ec6b869d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_pca_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f10abfc-2f98-4814-ac42-98fab0eab6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b81d1498-77b6-4a04-bc77-db6e40a705ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd3d5544-df0e-4af5-9096-3e3e821dcaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8572984856383443\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "    \n",
    "#     pca_components = trial.suggest_int('pca_components', 50, 285)\n",
    "    pca = PCA(n_components=pca_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "    \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 900, 6000), # was 900-4500 for CPU\n",
    "#         'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "#         'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 30),\n",
    "#         'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "# #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "#         'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 10),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "#         'gamma': trial.suggest_uniform('gamma', 0.1, 30)\n",
    "#     }  \n",
    "\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    "    )    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "              })\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_xgboost_20211010.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/2b286ehp\" target=\"_blank\">sweep_xgboost_20211010_115658</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-10 11:57:06,723]\u001b[0m A new study created in memory with name: pca_20211010\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"pca_{datetime.now().strftime('%Y%m%d')}\")\n",
    "\n",
    "# study = load(studypath/f\"optuna_xgboost_study_106trials_20211004.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02e3b84-ee16-48b9-94db-c738b408a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a454cc8-f135-4d36-8b6c-a964f4b52288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3860cbd2-1d08-4b2e-ac53-92b8a2ce016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Error thrown by xgboost trainer.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.core.XGBoostError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8ad6db-2722-4f04-bd51-4b795bec93c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ed3ac943a45fa8dc339194d2cab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:57:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 1; dropping {'pca_components': 138, 'value': 0.8283967087232865}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8283967087232865\n",
      "\u001b[32m[I 2021-10-10 11:59:12,446]\u001b[0m Trial 0 finished with value: 0.8283967087232865 and parameters: {'pca_components': 138}. Best is trial 0 with value: 0.8283967087232865.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c995da28a1d44a78001aca7668f1bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 2; dropping {'pca_components': 274, 'value': 0.8472107426301871}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472107426301871\n",
      "\u001b[32m[I 2021-10-10 12:02:45,979]\u001b[0m Trial 1 finished with value: 0.8472107426301871 and parameters: {'pca_components': 274}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fccb3fa1d664c2c9182df86e0916f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 3; dropping {'pca_components': 222, 'value': 0.8411313966895685}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8411313966895685\n",
      "\u001b[32m[I 2021-10-10 12:06:07,082]\u001b[0m Trial 2 finished with value: 0.8411313966895685 and parameters: {'pca_components': 222}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa85acfc834a6eb8f4993b66a345d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 4; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:09:03,422]\u001b[0m Trial 3 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeb5cbc6d8f498aaeafbcbd5baf86c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 5; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:10:25,360]\u001b[0m Trial 4 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ed1965573401a893b3bcf5d741830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 6; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:11:46,686]\u001b[0m Trial 5 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5122220c3f24f86abb9c62111e5b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 7; dropping {'pca_components': 63, 'value': 0.7904181686815366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.7904181686815366\n",
      "\u001b[32m[I 2021-10-10 12:12:47,694]\u001b[0m Trial 6 finished with value: 0.7904181686815366 and parameters: {'pca_components': 63}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add254087a4548f8943e78283019acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 8; dropping {'pca_components': 254, 'value': 0.8452885185751505}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8452885185751505\n",
      "\u001b[32m[I 2021-10-10 12:15:43,607]\u001b[0m Trial 7 finished with value: 0.8452885185751505 and parameters: {'pca_components': 254}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa23627f1d4045d888d13dfda8f652fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 9; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:18:38,689]\u001b[0m Trial 8 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5422d08b044f46318acef3ee9a059d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 10; dropping {'pca_components': 217, 'value': 0.8409412517853502}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8409412517853502\n",
      "\u001b[32m[I 2021-10-10 12:21:58,921]\u001b[0m Trial 9 finished with value: 0.8409412517853502 and parameters: {'pca_components': 217}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5828e8c8e4c4e88ada0bcfd0a1e657c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 11; dropping {'pca_components': 281, 'value': 0.8474176983005992}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474176983005992\n",
      "\u001b[32m[I 2021-10-10 12:25:32,672]\u001b[0m Trial 10 finished with value: 0.8474176983005992 and parameters: {'pca_components': 281}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d792ab5b54f7e94cac11539cb2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 12; dropping {'pca_components': 270, 'value': 0.8462401528718595}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8462401528718595\n",
      "\u001b[32m[I 2021-10-10 12:29:05,642]\u001b[0m Trial 11 finished with value: 0.8462401528718595 and parameters: {'pca_components': 270}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ede0e145554dab8b24e39e112f384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 13; dropping {'pca_components': 278, 'value': 0.8472224222376469}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472224222376469\n",
      "\u001b[32m[I 2021-10-10 12:32:39,229]\u001b[0m Trial 12 finished with value: 0.8472224222376469 and parameters: {'pca_components': 278}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c03a5fab942cc8bc82dedea9ea5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 14; dropping {'pca_components': 239, 'value': 0.8446363408619656}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8446363408619656\n",
      "\u001b[32m[I 2021-10-10 12:35:35,341]\u001b[0m Trial 13 finished with value: 0.8446363408619656 and parameters: {'pca_components': 239}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8986b171a6b14e7db312199a0ada6e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 15; dropping {'pca_components': 283, 'value': 0.8474194357944366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474194357944366\n",
      "\u001b[32m[I 2021-10-10 12:39:09,826]\u001b[0m Trial 14 finished with value: 0.8474194357944366 and parameters: {'pca_components': 283}. Best is trial 14 with value: 0.8474194357944366.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5e682ca174a228a244baa13a8c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31be9a9972d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e2748e41b07>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpca_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca_components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m285\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     dump(pca60, edapath/'PCA_60.joblibg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# sign flipping is done inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             U, S, Vt = randomized_svd(X, n_components=n_components,\n\u001b[0m\u001b[1;32m    549\u001b[0m                                       \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                       \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     Q = randomized_range_finder(\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Sample the range of A using by linear projection of Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Extract an orthonormal basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'economic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    162\u001b[0m                       lwork=lwork, overwrite_a=1)\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'economic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         Q, = safecall(gor_un_gqr, \"gorgqr/gungqr\", qr, tau, lwork=lwork,\n\u001b[0m\u001b[1;32m    165\u001b[0m                       overwrite_a=1)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36msafecall\u001b[0;34m(f, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lwork'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ValueError(\"illegal value in %dth argument of internal %s\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(1,200):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=True, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=datapath/f\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d6fb3-b4b3-40bd-8ff9-e2919c234f7d",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "# dump(study, filename=datapath/f\"optuna_xgboost_100trials-complete_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# dump(study.best_trial.params, filename=datapath/f\"optuna_lightgbm_all-500trials-best_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e398cb-f0f4-4400-8fe7-9012b4bc33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
