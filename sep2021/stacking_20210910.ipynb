{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Setting up a more robust baseline notebook, suitable for use with all of the \"Big Three\" (XGBoost, CatBoost, LightGBM) libraries and on either Google Colab or the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = False\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"stacking_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if gpu_available: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if gpu_available:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "    \"scaler\": StandardScaler, # TODO: experiment with others (but imputation may be slow)\n",
    "    \"scale_b4_impute\": False,\n",
    "    \"imputer\": SimpleImputer(strategy='median', add_indicator=True),\n",
    "    \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': 42,\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912a62f-970a-48b4-b428-d886f2612fc2",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b8603b-68c3-40da-8406-53e143758905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9716ae38-a859-44f1-bf4e-caf0c7a40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here's how to load the original, unaltered dataset and separate features from targets\n",
    "# df = pd.read_feather(path=datapath/'dataset_df.feather') # this is the unaltered original dataset\n",
    "# features = [x for x in df.columns if x != 'claim']\n",
    "# X = df[features]\n",
    "# y = df.claim\n",
    "\n",
    "\n",
    "\n",
    "# load the version of the dataset with imputations; X and y were stored separately, as feather and joblib respectively\n",
    "X = pd.read_feather(datapath/'X_NaNcounts_imputed-Median-wIndicators-StandardScaled.feather') \n",
    "y = load(datapath/'y.joblib')    \n",
    "X.index.name = 'id'\n",
    "y.index.name = 'id'\n",
    "\n",
    "exmodel_config['feature_count'] = len(X.columns)\n",
    "exmodel_config['feature_generator'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe60f69-2f22-403c-a13f-8ea8af4ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = exmodel_config['scaler']()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59020939-0ca1-4e0d-9af3-9fb122646ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       227       228       229       230  \\\n",
       "id                                ...                                           \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "\n",
       "         231       232       233      234       235      236  \n",
       "id                                                            \n",
       "0  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "1  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "2  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "3  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "4  -0.127119 -0.127985 -0.128494 -0.12862  7.821398 -0.12703  \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bd3364-0f44-45fb-bdbb-0748fe2d68e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47647b-3652-4f7e-ae62-6972d25f1a74",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7341ba-22c1-4887-bbda-ff2c7504bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configurator(library, gpu_available=True):#, config=universal_config):\n",
    "    \"\"\"\n",
    "    Function that provide task-specific or general preference arguments for the various models. \n",
    "    \n",
    "    At first, will rely largely on defaults for hyperparameters, but later this function \n",
    "    can be supplemented later with optimal values, as they're learned in sweeps.\n",
    "    .\n",
    "    \n",
    "    Rationale: creating a helper function will allow more experimentation later, and also\n",
    "    composite runs that cycle through a series of models.\n",
    "    \n",
    "    :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "    :return config: A dict that supplements default hyperparameter values with 1) \n",
    "                    task-appropriate ones, and perhaps later 2) optimal hyperparameter values.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    \n",
    "    # library-specific config\n",
    "    if library in ['xgboost', 'lightgbm']:\n",
    "        config['n_jobs'] = -1\n",
    "        \n",
    "    # best params per sweep `icac24c5`, generated from notebook `sweep_20210905.ipynb`\n",
    "    # runtime per fold should be around 12m 38s\n",
    "    # should get auc of 0.7434 on the random_state=42 holdout\n",
    "    # haven't yet tried dart\n",
    "    if library == 'xgboost':\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "#         config['model'] = XGBClassifier\n",
    "        config['verbosity'] = 1\n",
    "        config['objective'] = 'binary:logistic'\n",
    "#         config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "        config['tree_method'] = 'gpu_hist' if (gpu_available and colab) else 'auto' \n",
    "        \n",
    "        # comment out the below to get defaults\n",
    "        config['n_estimators'] = 902\n",
    "        config['learning_rate'] = 0.0304\n",
    "        config['max_depth'] = 3\n",
    "        config['reg_alpha'] = 0.863\n",
    "        config['reg_lambda'] = 2.442\n",
    "        config['subsample'] = 0.8627\n",
    "\n",
    "    # best params per sweep `sjghewf0`, generated from notebook `sweep_lightgbm_20210907`\n",
    "    # run name `sweep_lightgbm_20210907_195641`\n",
    "    # runtime per fold should be around 39s\n",
    "    # should get an auc of 0.7435 on random_state=42 holdout\n",
    "    if library == 'lightgbm':\n",
    "#         config['model'] = LGBMClassifier\n",
    "        config['objective'] = 'binary'\n",
    "        config['eval_metric'] = ['auc', 'logloss']\n",
    "        config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "        config['device_type'] = 'cuda' if (gpu_available and colab) else 'cpu' # 'gpu' also possible, 'cpu' is default\n",
    "        \n",
    "        # comment out the below for defaults\n",
    "        config['n_estimators'] = 1286\n",
    "        config['learning_rate'] = 0.03221\n",
    "        config['max_depth'] = 2\n",
    "        config['reg_alpha'] = 0.4687\n",
    "        config['reg_lambda'] = 0.1763\n",
    "        config['subsample'] = 0.6621\n",
    "        \n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "    if library == 'catboost':\n",
    "#         config['model'] = CatBoostClassifier\n",
    "        config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "        config['custom_metrics'] = ['Logloss', 'AUC'] # objective (loss fn) must be singular, defaults to Logloss\n",
    "        config['n_estimators'] = 2000 # logged as \"iterations\" otherwise\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f215-b585-4f7b-afac-36e49ee28c8f",
   "metadata": {},
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a928e1-0a18-4c91-b9bb-a32846e39e5b",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "config_run = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['attempt'],\n",
    "    'notes': \"Attempting sweep-best XGBoost and LightGBM plus defaultish CatBoost on newly preprocessed data (with a column containing NaN counts, median imputation w/indicators, and standard scaling)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f8d1-d303-4420-b671-51fcbff98594",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Scaling has already occurred -- used `StandardScaler` as a precursor to using `KNNImputer(n_neighbors=5)`, on the premise that imputation would proceed more quickly if things were already scaled. I may try different permutations of this later: using `IterativeImputer` instead, before or after scaling, potentially with different scalers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77e37c-8f76-44b2-9e04-7fa02430ce96",
   "metadata": {},
   "source": [
    "# Feature Creation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb77f573-e284-49a7-96a8-bb33b5b44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the polynomialfeatures generated with `PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)`\n",
    "# X_np = np.load(datapath/'X_poly_unscaled.npy')\n",
    "# X = pd.DataFrame(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e905f6-f5e4-4848-98e3-ddc846ab4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e4c99-64d4-4506-b208-397ce736eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2728178c-5214-4c6c-ab86-5d63aeb2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cbdaa47-cab5-441b-885d-d21b33c604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly_names = poly.get_feature_names(X.columns)\n",
    "# # X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f6bd0c-1121-4430-966d-7a318d925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c528d2-2148-409f-9489-254358a4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(X_poly, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f0682b3-1fef-4c54-9a33-99f659a2c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[features[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24391812-dce3-4513-bd38-ee95694730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_valid, y_train, y_valid, model_config, \n",
    "                                              random_state=42,\n",
    "                                              exmodel_config=exmodel_config, \n",
    "                                              config_run=config_run):#, scaler): # passed in via config dict for now\n",
    "    \"\"\"\n",
    "    Basic training function. Note that some of the options passed via the argument are\n",
    "    in fact hard-coded in, to avoid inconveniences.\n",
    "    :param X_train: the training set features\n",
    "    :param X_valid: the validation set features\n",
    "    :param y_train: the training set targets\n",
    "    :param y_valid: the validation set targets\n",
    "    :param random_staKFold: for reproducibility\n",
    "    :param exmodel_config: dict containing configuration details including the library \n",
    "                            (thus model) used, preprocessing, and cross-validation\n",
    "    :param model_config: dict containing hyperparameter specifications for the model\n",
    "    :param config_run: dict containing wandb run configuration (name, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"202109_Kaggle_tabular_playground\",\n",
    "        save_code=True,\n",
    "        tags=config_run['tags'],\n",
    "        name=config_run['name'],\n",
    "        notes=config_run['notes'],\n",
    "        config=exmodel_config)   \n",
    "        \n",
    "    if exmodel_config['library'] == 'xgboost':\n",
    "        model = XGBClassifier(\n",
    "            tree_method=model_config['tree_method'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "            # #             eval_metric=model_config['eval_metric'],\n",
    "\n",
    "            # comment out the below for a fairly default model\n",
    "#             booster=model_config['booster'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            learning_rate=model_config['learning_rate'], \n",
    "            subsample=model_config['subsample'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "\n",
    "\n",
    "    elif exmodel_config['library'] == 'lightgbm':\n",
    "        model = LGBMClassifier(\n",
    "#             boosting_type=model_config['boosting_type'],\n",
    "#             max_depth=model_config['max_depth']\n",
    "            # TODO\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "#             eval_metric=model_config['eval_metric'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=model_config['device_type'],\n",
    "            \n",
    "            # comment out the below for a basically default model\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            learning_rate=model_config['learning_rate'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            subsample=model_config['subsample'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "        \n",
    "    elif exmodel_config['library'] == 'catboost':\n",
    "        print(\"CatBoost, therefore no WandB callback.\")\n",
    "        model = CatBoostClassifier(\n",
    "#             n_estimators=config['n_estimators'],\n",
    "#             learning_rate=config['learning_rate'],\n",
    "#             max_depth=config['max_depth'],\n",
    "            task_type=model_config['task_type'],\n",
    "    #         n_jobs=config['n_jobs'],\n",
    "    #         verbosity=config['verbosity'],\n",
    "    #         subsample=config['subsample'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            random_state=random_state,\n",
    "            # objective='Logloss', # default, accepts only one\n",
    "#             custom_metrics=model_config['custom_metrics'],\n",
    "    #         bootstrap_type=config['bootstrap_type'],\n",
    "    #         device:config['device']\n",
    "        ) \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "#     y_train_pred = model.predict(X_train)\n",
    "    y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "    train_loss = log_loss(y_train, y_train_pred)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "\n",
    "    if exmodel_config['library'] == 'catboost':\n",
    "        print(model.get_all_params())\n",
    "        wandb.log(model.get_all_params())\n",
    "    else:\n",
    "        wandb.log(model.get_params()) # logging model parameters, trying bare-invocation rather than params: model.get_params()\n",
    "    \n",
    "    # trying with predict_proba\n",
    "    y_pred = model.predict_proba(X_valid)[:,1]\n",
    "#     y_pred = model.predict(X_valid)\n",
    "\n",
    "    valid_loss = log_loss(y_valid, y_pred)\n",
    "    valid_auc = roc_auc_score(y_valid, y_pred)\n",
    "    wandb.log({'valid_loss':valid_loss, 'valid_auc':valid_auc})\n",
    "    print(f\"Valid log-loss is {valid_loss}\\nValid AUC is {valid_auc}\")   \n",
    "#     wandb.finish()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_config, X=X, y=y, start_fold=0, exmodel_config=exmodel_config, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1:\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=exmodel_config['test_size'], \n",
    "                                                      random_state=random_state,\n",
    "                                                     )\n",
    "        model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "        wandb.finish()\n",
    "        \n",
    "    else:\n",
    "        X, y = X.to_numpy(), y.to_numpy()\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=random_state)\n",
    "        models = {}\n",
    "        model_path = Path(datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/\")\n",
    "        (model_path).mkdir(exist_ok=True)\n",
    "        for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "            if fold < start_fold:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"FOLD {fold}\")\n",
    "                print(\"---------------------------------------------------\")\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "                model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "                wandb.log({'fold': fold})\n",
    "                models[fold] = model\n",
    "                dump(model, Path(model_path/f\"{exmodel_config['library']}_fold{fold}_model.joblib\"))\n",
    "                wandb.finish()\n",
    "        return models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a437b-f880-4284-8e02-66a398ba6454",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58234814-68d1-4ee4-bedd-d722c18e4fa6",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4085e60e-13cf-4da7-90b9-30306480b4ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1rttuecz\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1rttuecz</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101121-1rttuecz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5109356389636417\n",
      "Valid AUC is 0.8122584973566012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1381262<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.15MB of 0.15MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101121-1rttuecz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101121-1rttuecz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50573</td></tr><tr><td>train_auc</td><td>0.82113</td></tr><tr><td>_runtime</td><td>488</td></tr><tr><td>_timestamp</td><td>1631294369</td></tr><tr><td>_step</td><td>905</td></tr><tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.0304</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>3</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>902</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.863</td></tr><tr><td>reg_lambda</td><td>2.442</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>0.8627</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>valid_loss</td><td>0.51094</td></tr><tr><td>valid_auc</td><td>0.81226</td></tr><tr><td>fold</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1rttuecz\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1rttuecz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/399b68by\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/399b68by</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101947-399b68by</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5084587895255492\n",
      "Valid AUC is 0.8140504514066044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1381421<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.15MB of 0.15MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101947-399b68by/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_101947-399b68by/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.5064</td></tr><tr><td>train_auc</td><td>0.82071</td></tr><tr><td>_runtime</td><td>485</td></tr><tr><td>_timestamp</td><td>1631294872</td></tr><tr><td>_step</td><td>905</td></tr><tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.0304</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>3</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>902</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.863</td></tr><tr><td>reg_lambda</td><td>2.442</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>0.8627</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>valid_loss</td><td>0.50846</td></tr><tr><td>valid_auc</td><td>0.81405</td></tr><tr><td>fold</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/399b68by\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/399b68by</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/38hjlon9\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/38hjlon9</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_102758-38hjlon9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5097983286020547\n",
      "Valid AUC is 0.8128374867961028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1381572<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.16MB of 0.16MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_102758-38hjlon9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_102758-38hjlon9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50606</td></tr><tr><td>train_auc</td><td>0.82094</td></tr><tr><td>_runtime</td><td>529</td></tr><tr><td>_timestamp</td><td>1631295407</td></tr><tr><td>_step</td><td>905</td></tr><tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.0304</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>3</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>902</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.863</td></tr><tr><td>reg_lambda</td><td>2.442</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>0.8627</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>valid_loss</td><td>0.5098</td></tr><tr><td>valid_auc</td><td>0.81284</td></tr><tr><td>fold</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/38hjlon9\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/38hjlon9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1ev2qm2t\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1ev2qm2t</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_103652-1ev2qm2t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.508592728157079\n",
      "Valid AUC is 0.8134012906552728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1381738<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.17MB of 0.17MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_103652-1ev2qm2t/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_103652-1ev2qm2t/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50633</td></tr><tr><td>train_auc</td><td>0.82084</td></tr><tr><td>_runtime</td><td>482</td></tr><tr><td>_timestamp</td><td>1631295894</td></tr><tr><td>_step</td><td>905</td></tr><tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.0304</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>3</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>902</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.863</td></tr><tr><td>reg_lambda</td><td>2.442</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>0.8627</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>valid_loss</td><td>0.50859</td></tr><tr><td>valid_auc</td><td>0.8134</td></tr><tr><td>fold</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1ev2qm2t\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1ev2qm2t</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3m5wrerk\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3m5wrerk</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_104500-3m5wrerk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5078269726162877\n",
      "Valid AUC is 0.8138386718432461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1381936<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.18MB of 0.18MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_104500-3m5wrerk/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_104500-3m5wrerk/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50649</td></tr><tr><td>train_auc</td><td>0.82061</td></tr><tr><td>_runtime</td><td>539</td></tr><tr><td>_timestamp</td><td>1631296439</td></tr><tr><td>_step</td><td>905</td></tr><tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.0304</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>3</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>902</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.863</td></tr><tr><td>reg_lambda</td><td>2.442</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>0.8627</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>valid_loss</td><td>0.50783</td></tr><tr><td>valid_auc</td><td>0.81384</td></tr><tr><td>fold</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3m5wrerk\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3m5wrerk</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library = 'xgboost'\n",
    "exmodel_config['library'] = library\n",
    "model_config = model_configurator(library)\n",
    "xgboost_models = cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b780292-f23c-4a3f-be1e-53038c5ae7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for scaler in [StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler]:\n",
    "#     exmodel_config['scaler'] = scaler\n",
    "#     scaler = scaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "#     exmodel_config['library'] = 'lightgbm'\n",
    "#     model_config = model_configurator('lightgbm')\n",
    "#     cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1106b86c-70c1-4722-a86f-6c53a2e32503",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/mnuvslie\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/mnuvslie</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092143-mnuvslie</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5113911181729013\n",
      "Valid AUC is 0.8114826365905788\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1380166<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.10MB of 0.10MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092143-mnuvslie/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092143-mnuvslie/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50759</td></tr><tr><td>train_auc</td><td>0.81709</td></tr><tr><td>_runtime</td><td>43</td></tr><tr><td>_timestamp</td><td>1631290946</td></tr><tr><td>_step</td><td>1289</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.03221</td></tr><tr><td>max_depth</td><td>2</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>1286</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.4687</td></tr><tr><td>reg_lambda</td><td>0.1763</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>0.6621</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>valid_loss</td><td>0.51139</td></tr><tr><td>valid_auc</td><td>0.81148</td></tr><tr><td>fold</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/mnuvslie\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/mnuvslie</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/39bk6u2i\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/39bk6u2i</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092231-39bk6u2i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5089415144259191\n",
      "Valid AUC is 0.8132048676403175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1380233<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.11MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092231-39bk6u2i/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092231-39bk6u2i/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50828</td></tr><tr><td>train_auc</td><td>0.81655</td></tr><tr><td>_runtime</td><td>44</td></tr><tr><td>_timestamp</td><td>1631290995</td></tr><tr><td>_step</td><td>1289</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.03221</td></tr><tr><td>max_depth</td><td>2</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>1286</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.4687</td></tr><tr><td>reg_lambda</td><td>0.1763</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>0.6621</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>valid_loss</td><td>0.50894</td></tr><tr><td>valid_auc</td><td>0.8132</td></tr><tr><td>fold</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/39bk6u2i\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/39bk6u2i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1km4hyme\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1km4hyme</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092320-1km4hyme</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5102146583888731\n",
      "Valid AUC is 0.812064302187439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1380285<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.11MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092320-1km4hyme/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092320-1km4hyme/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50791</td></tr><tr><td>train_auc</td><td>0.8169</td></tr><tr><td>_runtime</td><td>45</td></tr><tr><td>_timestamp</td><td>1631291045</td></tr><tr><td>_step</td><td>1289</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.03221</td></tr><tr><td>max_depth</td><td>2</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>1286</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.4687</td></tr><tr><td>reg_lambda</td><td>0.1763</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>0.6621</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>valid_loss</td><td>0.51021</td></tr><tr><td>valid_auc</td><td>0.81206</td></tr><tr><td>fold</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1km4hyme\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1km4hyme</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/280662cq\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/280662cq</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092411-280662cq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5090037922697467\n",
      "Valid AUC is 0.812786647498434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1380338<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.12MB of 0.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092411-280662cq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092411-280662cq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.5082</td></tr><tr><td>train_auc</td><td>0.8168</td></tr><tr><td>_runtime</td><td>44</td></tr><tr><td>_timestamp</td><td>1631291095</td></tr><tr><td>_step</td><td>1289</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.03221</td></tr><tr><td>max_depth</td><td>2</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>1286</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.4687</td></tr><tr><td>reg_lambda</td><td>0.1763</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>0.6621</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>valid_loss</td><td>0.509</td></tr><tr><td>valid_auc</td><td>0.81279</td></tr><tr><td>fold</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/280662cq\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/280662cq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2kz1wd79\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2kz1wd79</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092500-2kz1wd79</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 0.5082532843485519\n",
      "Valid AUC is 0.8131253951692738\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1380388<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.12MB of 0.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092500-2kz1wd79/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210910_092500-2kz1wd79/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.50839</td></tr><tr><td>train_auc</td><td>0.81663</td></tr><tr><td>_runtime</td><td>44</td></tr><tr><td>_timestamp</td><td>1631291144</td></tr><tr><td>_step</td><td>1289</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.03221</td></tr><tr><td>max_depth</td><td>2</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>1286</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.4687</td></tr><tr><td>reg_lambda</td><td>0.1763</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>0.6621</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>valid_loss</td><td>0.50825</td></tr><tr><td>valid_auc</td><td>0.81313</td></tr><tr><td>fold</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁██</td></tr><tr><td>_timestamp</td><td>▁▁██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_20210910_092142</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2kz1wd79\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2kz1wd79</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library = 'lightgbm'\n",
    "exmodel_config['library'] = library\n",
    "model_config = model_configurator(library)\n",
    "lightgbm_models = cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542539d-323d-4a4a-b574-d0bf883179b2",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776a94d-01f3-46c0-9c9c-0d162de17e37",
   "metadata": {},
   "source": [
    "## Via `sklearn.ensemble.StackingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ca87f5f-e214-4968-a789-74f83dc7a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e68e3adf-fd9d-4185-87c4-330ecd768679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_estimators = [(f'xgboost_fold{fold}', xgboost_models[fold]) for fold in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed3aa865-fec7-417b-9369-677d3b840760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaving this default for first try\n",
    "# final_estimator = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ac5214d-a3ab-4219-8047-822c4385e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revision below\n",
    "\n",
    "def stacker(estimators:dict, library:str, X=X, y=y): #, load_models:bool=False, load_path:Path=None):\n",
    "    \"\"\"\n",
    "    A wrapper that will take a dict of the form {fold:int : model} and a string representing the library (for file-naming), \n",
    "    then run `sklearn.ensemble.StackingClassifier` with it, and save the stacked model afterward\n",
    "    \"\"\"\n",
    "    estimators_list = [(f'{library}_fold{fold}', estimators[fold]) for fold in range(5)]\n",
    "    blender = StackingClassifier(estimators=estimators_list,\n",
    "                                 cv=5,\n",
    "                                 stack_method='predict_proba',\n",
    "                                 n_jobs=2,\n",
    "                                 passthrough=False,\n",
    "                                 verbose=1\n",
    "                                )\n",
    "    print(f\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    blender.fit(X,y)\n",
    "    print(f\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    dump(blender, filename=datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/{library}_stack.joblib\")\n",
    "    print(f\"Blender model saved at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    return blender\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6926bf5c-f44d-42f7-8328-9ae400a08855",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting at 20210910_093530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting complete at 20210910_095542\n",
      "Blender model saved at 20210910_095543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lightgbm_fold0',\n",
       "                                LGBMClassifier(device_type='cpu',\n",
       "                                               learning_rate=0.03221,\n",
       "                                               max_depth=2, n_estimators=1286,\n",
       "                                               objective='binary',\n",
       "                                               random_state=42,\n",
       "                                               reg_alpha=0.4687,\n",
       "                                               reg_lambda=0.1763,\n",
       "                                               subsample=0.6621)),\n",
       "                               ('lightgbm_fold1',\n",
       "                                LGBMClassifier(device_type='cpu',\n",
       "                                               learning_rate=0.03221,\n",
       "                                               max_depth=2, n_estimators=1286,\n",
       "                                               objective='binary',...\n",
       "                                               max_depth=2, n_estimators=1286,\n",
       "                                               objective='binary',\n",
       "                                               random_state=42,\n",
       "                                               reg_alpha=0.4687,\n",
       "                                               reg_lambda=0.1763,\n",
       "                                               subsample=0.6621)),\n",
       "                               ('lightgbm_fold4',\n",
       "                                LGBMClassifier(device_type='cpu',\n",
       "                                               learning_rate=0.03221,\n",
       "                                               max_depth=2, n_estimators=1286,\n",
       "                                               objective='binary',\n",
       "                                               random_state=42,\n",
       "                                               reg_alpha=0.4687,\n",
       "                                               reg_lambda=0.1763,\n",
       "                                               subsample=0.6621))],\n",
       "                   n_jobs=2, stack_method='predict_proba', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker(lightgbm_models, 'lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42660884-77dd-4cd9-bca9-3ce324615bbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting at 20210910_122952\n",
      "Fitting complete at 20210910_185436\n",
      "Blender model saved at 20210910_185438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('xgboost_fold0',\n",
       "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=1, gamma=0,\n",
       "                                              gpu_id=-1, importance_type='gain',\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.0304,\n",
       "                                              max_delta_step=0, max_depth=3,\n",
       "                                              min_child_weight=1, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=902, n...\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.0304,\n",
       "                                              max_delta_step=0, max_depth=3,\n",
       "                                              min_child_weight=1, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=902, n_jobs=-1,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              random_state=42, reg_alpha=0.863,\n",
       "                                              reg_lambda=2.442,\n",
       "                                              scale_pos_weight=1,\n",
       "                                              subsample=0.8627,\n",
       "                                              tree_method='auto',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=1))],\n",
       "                   n_jobs=2, stack_method='predict_proba', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker(xgboost_models, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1f2d37f-8089-43b1-b796-97a731a70317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1579, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1715, in _on_finish\n",
      "    self.history._flush()\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
      "    self._callback(row=self._data, step=self._step)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 902, in _history_callback\n",
      "    self._backend.interface.publish_history(\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 223, in publish_history\n",
      "    item.value_json = json_dumps_safer_history(v)  # type: ignore\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\", line 749, in json_dumps_safer_history\n",
      "    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\", line 716, in default\n",
      "    return json.JSONEncoder.default(self, obj)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type StackingClassifier is not JSON serializable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1579, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 1715, in _on_finish\n",
      "    self.history._flush()\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
      "    self._callback(row=self._data, step=self._step)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 902, in _history_callback\n",
      "    self._backend.interface.publish_history(\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 223, in publish_history\n",
      "    item.value_json = json_dumps_safer_history(v)  # type: ignore\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\", line 749, in json_dumps_safer_history\n",
      "    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/__init__.py\", line 234, in dumps\n",
      "    return cls(\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\", line 716, in default\n",
      "    return json.JSONEncoder.default(self, obj)\n",
      "  File \"/home/sf/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type StackingClassifier is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1157f1b-87c5-4493-9e4a-151e11a7fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting at 20210910_212035\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/cuda/cuda_lib/devices_provider.h:185: Error: device already requested 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-cca6d0b95b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mblender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unsure of this -- given kwarg cv=5, is it producing the splits? Or do I have to somehow?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/{library}_stack.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'final_estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    177\u001b[0m                       \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                       else None)\n\u001b[0;32m--> 179\u001b[0;31m         predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    180\u001b[0m             delayed(cross_val_predict)(clone(est), X, y, cv=deepcopy(cv),\n\u001b[1;32m    181\u001b[0m                                        \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/cuda/cuda_lib/devices_provider.h:185: Error: device already requested 0"
     ]
    }
   ],
   "source": [
    "# might encapsulate this in a new version of the above train function later\n",
    "exmodel_config['ensemble'] = True\n",
    "\n",
    "# wandb.init(\n",
    "#         project=\"202109_Kaggle_tabular_playground\",\n",
    "#         save_code=True,\n",
    "#         tags=config_run['tags'],\n",
    "#         name=config_run['name'],\n",
    "#         notes=config_run['notes'],\n",
    "#         config=exmodel_config)   \n",
    "\n",
    "random_state = exmodel_config['random_state'] # 42\n",
    "\n",
    "model_config = model_configurator('xgboost')\n",
    "xgboost_model = XGBClassifier(\n",
    "            tree_method=model_config['tree_method'],\n",
    "            random_state=random_state,\n",
    "#             n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "            # #             eval_metric=model_config['eval_metric'],\n",
    "\n",
    "            # comment out the below for a fairly default model\n",
    "#             booster=model_config['booster'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            learning_rate=model_config['learning_rate'], \n",
    "            subsample=model_config['subsample'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "        )\n",
    "\n",
    "model_config = model_configurator('lightgbm')\n",
    "lightgbm_model = LGBMClassifier(\n",
    "            random_state=random_state,\n",
    "#             n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=model_config['device_type'],\n",
    "            \n",
    "            # comment out the below for a basically default model\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            learning_rate=model_config['learning_rate'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            subsample=model_config['subsample'],\n",
    "        )\n",
    "\n",
    "model_config = model_configurator('catboost')\n",
    "catboost_model = CatBoostClassifier(\n",
    "            task_type=model_config['task_type'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            random_state=random_state,\n",
    "        ) \n",
    "\n",
    "\n",
    "\n",
    "estimators_list = [\n",
    "    ('xgboost', xgboost_model),\n",
    "    ('lightgbm', lightgbm_model),\n",
    "    ('catboost', catboost_model)\n",
    "]\n",
    "\n",
    "# wandb.log({'estimators': estimators_list})\n",
    "\n",
    "\n",
    "blender = StackingClassifier(estimators=estimators_list,\n",
    "                                 cv=5,\n",
    "                                 stack_method='predict_proba',\n",
    "                                 n_jobs=2,\n",
    "                                 passthrough=False,\n",
    "                                 verbose=1\n",
    "                            )\n",
    "\n",
    "# wandb.log({'blender': blender})\n",
    "\n",
    "print(f\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "blender.fit(X,y) # unsure of this -- given kwarg cv=5, is it producing the splits? Or do I have to somehow?\n",
    "print(f\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "dump(blender, filename=datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/{library}_stack.joblib\")\n",
    "print(f\"Blender model saved at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41063b9d-5c0c-42d5-994e-641f5e1e3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "?b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e121a47-ca0b-42db-991a-893c7a67b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_stack = StackingClassifier(estimators=xgboost_estimators, \n",
    "#                                    cv=5, \n",
    "#                                    stack_method='predict_proba', \n",
    "#                                    n_jobs=-1, \n",
    "#                                    passthrough=False, \n",
    "#                                    verbose=1)\n",
    "# xgboost_stack.fit(X,y)\n",
    "# dump(xgboost_stack, filename=datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/xgboost_stack.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39bcfde-fe3f-4e22-ab64-76fdb41eef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40b967-a73f-4e0c-b5a9-fbb5303dc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_estimators = [(f'lightgbm_fold{fold}', lightgbm_models[fold]) for fold in range(5)]\n",
    "lightgbm_stack = StackingClassifier(estimators=lightgbm_estimators, \n",
    "                                   cv=5, \n",
    "                                   stack_method='predict_proba', \n",
    "                                   n_jobs=-1, \n",
    "                                   passthrough=False, \n",
    "                                   verbose=1)\n",
    "lightgbm_stack.fit(X,y)\n",
    "dump(xgboost_stack, filename=datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/lightgbm_stack.joblib\")\n",
    "print(datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bb8fe-5b38-4f5c-8c7a-6b70467948ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# library = 'catboost'\n",
    "# gpu_available = True\n",
    "# exmodel_config['library'] = library\n",
    "# model_config = model_configurator(library)\n",
    "# catboost_models = cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b2dc1-71d5-49ce-8aad-5dd03b2a78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this loads models if you need to (or forgot to save them on training above)\n",
    "# xgboost_models = {}\n",
    "# xgboost_models_path = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/baseline_20210905a_152521_5folds/xgboost/')\n",
    "# for fold in range(5):\n",
    "#     xgboost_models[fold] = load(xgboost_models_path/f'xgboost_fold{fold}_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02baf90b-01bc-4945-b64c-5af0c6e309be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e394bc6-29fe-4033-a850-bf6d55883b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(datapath/'test.csv', index_col='id', low_memory=False)\n",
    "# test_df.to_feather(datapath/'test.feather') # issue with index being non-default; fix later\n",
    "# test_df = pd.read_feather(datapath/'test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e85f83d-b5a3-4c9e-b654-dfd743f2966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f109</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957919</th>\n",
       "      <td>0.165850</td>\n",
       "      <td>0.487050</td>\n",
       "      <td>1295.00</td>\n",
       "      <td>0.02310</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.90188</td>\n",
       "      <td>573.29</td>\n",
       "      <td>3743.7</td>\n",
       "      <td>2.705700e+12</td>\n",
       "      <td>6221.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16253</td>\n",
       "      <td>-22.1890</td>\n",
       "      <td>2.0655</td>\n",
       "      <td>0.430880</td>\n",
       "      <td>-10.7410</td>\n",
       "      <td>81606.0</td>\n",
       "      <td>1.1940</td>\n",
       "      <td>1.980400e+14</td>\n",
       "      <td>2017.1</td>\n",
       "      <td>0.46357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957920</th>\n",
       "      <td>0.129650</td>\n",
       "      <td>0.373480</td>\n",
       "      <td>1763.00</td>\n",
       "      <td>0.72884</td>\n",
       "      <td>0.33247</td>\n",
       "      <td>-1.26310</td>\n",
       "      <td>875.55</td>\n",
       "      <td>554370.0</td>\n",
       "      <td>5.955700e+14</td>\n",
       "      <td>934.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81528</td>\n",
       "      <td>-1.6342</td>\n",
       "      <td>1.5736</td>\n",
       "      <td>-1.071200</td>\n",
       "      <td>11.8320</td>\n",
       "      <td>90114.0</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.388000e+16</td>\n",
       "      <td>6638.9</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957921</th>\n",
       "      <td>0.120190</td>\n",
       "      <td>0.445210</td>\n",
       "      <td>736.26</td>\n",
       "      <td>0.04615</td>\n",
       "      <td>0.29605</td>\n",
       "      <td>0.31665</td>\n",
       "      <td>2659.50</td>\n",
       "      <td>317140.0</td>\n",
       "      <td>3.977800e+14</td>\n",
       "      <td>131.810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81831</td>\n",
       "      <td>-32.7800</td>\n",
       "      <td>2.1364</td>\n",
       "      <td>-1.931200</td>\n",
       "      <td>-3.2804</td>\n",
       "      <td>37739.0</td>\n",
       "      <td>1.1548</td>\n",
       "      <td>1.718100e+14</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>0.13797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957922</th>\n",
       "      <td>0.054008</td>\n",
       "      <td>0.395960</td>\n",
       "      <td>996.14</td>\n",
       "      <td>0.85934</td>\n",
       "      <td>0.36678</td>\n",
       "      <td>-0.17060</td>\n",
       "      <td>386.56</td>\n",
       "      <td>325680.0</td>\n",
       "      <td>-3.432200e+13</td>\n",
       "      <td>-26.473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86559</td>\n",
       "      <td>-2.4162</td>\n",
       "      <td>1.5199</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>1.3840</td>\n",
       "      <td>26849.0</td>\n",
       "      <td>1.1490</td>\n",
       "      <td>2.138800e+17</td>\n",
       "      <td>6173.3</td>\n",
       "      <td>0.32910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957923</th>\n",
       "      <td>0.079947</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>10574.00</td>\n",
       "      <td>0.34845</td>\n",
       "      <td>0.45008</td>\n",
       "      <td>-1.84200</td>\n",
       "      <td>3027.00</td>\n",
       "      <td>428150.0</td>\n",
       "      <td>9.291500e+11</td>\n",
       "      <td>5999.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25190</td>\n",
       "      <td>-18.6300</td>\n",
       "      <td>3.7387</td>\n",
       "      <td>0.757080</td>\n",
       "      <td>-4.9405</td>\n",
       "      <td>50336.0</td>\n",
       "      <td>1.2488</td>\n",
       "      <td>2.151300e+17</td>\n",
       "      <td>2250.1</td>\n",
       "      <td>0.33796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1        f2        f3       f4       f5       f6       f7  \\\n",
       "id                                                                         \n",
       "957919  0.165850  0.487050   1295.00  0.02310  0.31900  0.90188   573.29   \n",
       "957920  0.129650  0.373480   1763.00  0.72884  0.33247 -1.26310   875.55   \n",
       "957921  0.120190  0.445210    736.26  0.04615  0.29605  0.31665  2659.50   \n",
       "957922  0.054008  0.395960    996.14  0.85934  0.36678 -0.17060   386.56   \n",
       "957923  0.079947 -0.006919  10574.00  0.34845  0.45008 -1.84200  3027.00   \n",
       "\n",
       "              f8            f9       f10  ...     f109     f110    f111  \\\n",
       "id                                        ...                             \n",
       "957919    3743.7  2.705700e+12  6221.000  ...  0.16253 -22.1890  2.0655   \n",
       "957920  554370.0  5.955700e+14   934.430  ...  0.81528  -1.6342  1.5736   \n",
       "957921  317140.0  3.977800e+14   131.810  ...  0.81831 -32.7800  2.1364   \n",
       "957922  325680.0 -3.432200e+13   -26.473  ...  0.86559  -2.4162  1.5199   \n",
       "957923  428150.0  9.291500e+11  5999.400  ...  0.25190 -18.6300  3.7387   \n",
       "\n",
       "            f112     f113     f114    f115          f116    f117     f118  \n",
       "id                                                                         \n",
       "957919  0.430880 -10.7410  81606.0  1.1940  1.980400e+14  2017.1  0.46357  \n",
       "957920 -1.071200  11.8320  90114.0  1.1507  4.388000e+16  6638.9  0.28125  \n",
       "957921 -1.931200  -3.2804  37739.0  1.1548  1.718100e+14  5844.0  0.13797  \n",
       "957922 -0.011633   1.3840  26849.0  1.1490  2.138800e+17  6173.3  0.32910  \n",
       "957923  0.757080  -4.9405  50336.0  1.2488  2.151300e+17  2250.1  0.33796  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c226e-1ef7-4e03-91a1-06fbb73139f0",
   "metadata": {},
   "source": [
    "# Test set preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ec520-259f-44d2-ad33-7b8c22621132",
   "metadata": {},
   "source": [
    "(Here's where encapsulating the transformations in a pipeline would come in handy. But I'll do it manually for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ec74e4-ccb8-43b4-b910-3df1542aaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in test_df.columns if x != 'claim']\n",
    "X_test = test_df[features] # this is just for naming consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725cd3e-f883-4d20-837a-9f557b2122a9",
   "metadata": {},
   "source": [
    "Now, let's get the features the model was trained on and subset the test set's features accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66e579-7f01-46e5-a47c-580c8f5d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1817e3a-7d90-4bc2-8c47-e97806f7dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_poly_names = poly.get_feature_names(X_test.columns)\n",
    "# X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6bc49-d478-4f59-84d2-5e23e3e236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_test_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68187e-271a-4df1-ae02-a2bb5d62c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = pd.DataFrame(X_test_poly, columns=X_test_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020ad9b-1b05-49b8-b89b-c90362c256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = X_test_final[features[1:]]\n",
    "# X_test_final = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07699efa-37df-4ed9-aaf2-1b77a73f9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['nan_count'] = X_test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd0c2d-7f9a-4fb6-8b4d-c3c51a9ef8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median', add_indicator=True)\n",
    "X_test_imputed_np = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ef600-e3cd-44ef-ae66-e1d1663ec4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=[str(x) for x in range(X_test_imputed.shape[1])])\n",
    "X_test_imputed.to_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da840a-caa6-4d76-a542-c1315a593346",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = exmodel_config['scaler']()\n",
    "X_test_imputed_scaled_np = scaler.fit_transform(X_test_imputed)\n",
    "X_test_imputed_scaled = pd.DataFrame(X_test_imputed_scaled_np, columns=X_test_imputed.columns)\n",
    "X_test_imputed_scaled.to_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a99cf5b-3477-47f4-9391-73e2ff93c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f347f-872f-4011-9f13-78fad542f36a",
   "metadata": {},
   "source": [
    "## Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa072384-5154-4d54-8ddf-5452e9323882",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds = {}\n",
    "for fold in xgboost_models.keys():\n",
    "    xgboost_preds[fold] = xgboost_models[fold].predict_proba(X_test_imputed_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a766fdfe-3990-4177-ab5a-1343575ce258",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_preds = {}\n",
    "for fold in lightgbm_models.keys():\n",
    "    lightgbm_preds[fold] = lightgbm_models[fold].predict_proba(X_test_imputed_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbf1a7-17be-4eb5-8917-1e9697d67569",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = {}\n",
    "for fold in catboost_models.keys():\n",
    "    catboost_preds[fold] = catboost_models[fold].predict_proba(X_test_imputed_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c7e4520-a24a-435f-93d6-f94b822b4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_path = Path(datapath/f\"preds/{config_run['name']}_{exmodel_config['kfolds']}folds_probs/\")\n",
    "preds_path.mkdir(exist_ok=True)\n",
    "\n",
    "for library in ['xgboost', 'lightgbm', 'catboost']:\n",
    "    (preds_path/library).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9303c7-f903-43b3-88c9-b7a889ec6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(xgboost_preds, Path(preds_path/'xgboost/xgboost_preds_dict.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0d79c3c-deaa-4f8a-a852-05012ccfaf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/preds/stacking_20210910_092142_5folds_probs/lightgbm/lightgbm_preds_dict.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lightgbm_preds, Path(preds_path/'lightgbm/lightgbm_preds_dict.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea5f0e-317a-40ca-b519-c1b0850ed3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(catboost_preds, Path(preds_path/'catboost/catboost_preds_dict.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a464a1c-9ca8-4a07-9cdb-18af399cf95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc067fb9-ae8e-4b33-9d75-e5405043aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_xgboost_preds = (xgboost_preds[0] + xgboost_preds[1] + xgboost_preds[2] + xgboost_preds[3] + xgboost_preds[4]) / 5\n",
    "final_lightgbm_preds = (lightgbm_preds[0] + lightgbm_preds[1] + lightgbm_preds[2] + lightgbm_preds[3] + lightgbm_preds[4]) / 5\n",
    "# final_catboost_preds = (catboost_preds[0] + catboost_preds[1] + catboost_preds[2] + catboost_preds[3] + catboost_preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca32f6-2267-4c98-9aa9-c4a31d69bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_xgboost_preds[:10])\n",
    "print(final_lightgbm_preds[:10])\n",
    "print(final_catboost_preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2f4b8-2356-4916-a091-45793db784ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = final_xgboost_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957ce26-bbf5-4aee-bccd-988f2471db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "519f6d45-6b2a-4fe8-be77-ecc70cec6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = datapath/'submissions'\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc6d50-92bc-4295-9acc-5d345eb96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_{exmodel_config['kfolds']}folds_prob_xgboost-mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d8dca3b-41f9-4c6d-965d-ffe1c3095be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = final_lightgbm_preds\n",
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_{exmodel_config['kfolds']}folds_prob_lightgbm-mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f3cb76b-ce4e-4405-b887-a210641d2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_stack = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/stacking_20210910_092142_5folds/lightgbm_stack.joblib')\n",
    "lightgbm_stack_preds = lightgbm_stack.predict_proba(X_test_imputed_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d240818-567d-42f9-acad-53fc962fa558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = lightgbm_stack_preds\n",
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_lightgbm_stack_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906419c-5dbc-46a7-a1d3-83c374cea6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = final_catboost_preds\n",
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_{exmodel_config['kfolds']}folds_prob_catboost-mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efa394-3d8a-47d1-9073-8fcebd7ce85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = (final_xgboost_preds + final_lightgbm_preds + final_catboost_preds) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189975be-25cb-45c7-8910-f093e78103bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = ensemble_preds\n",
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_{exmodel_config['kfolds']}folds_prob_ensemble-equal_model_and_fold_weight_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8fd63-c96d-4725-81b2-1ccc004c922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = 0.4*final_xgboost_preds + 0.3*final_lightgbm_preds + 0.3*final_catboost_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fded70f-add3-43c1-87af-1e2cb994c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = ensemble_preds\n",
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_{exmodel_config['kfolds']}folds_prob_ensemble-0.4xgboost_0.3lightgbm_0.3catboost-equal_fold_weight_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afb61b-8022-4f0f-8996-2adfb3ec640c",
   "metadata": {},
   "source": [
    "## Manual Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1524723c-87c3-410f-863b-9387ef5b59e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       227       228       229       230  \\\n",
       "id                                ...                                           \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "\n",
       "         231       232       233      234       235      236  \n",
       "id                                                            \n",
       "0  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "1  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "2  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "3  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "4  -0.127119 -0.127985 -0.128494 -0.12862  7.821398 -0.12703  \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe341d69-270a-445e-9a05-287cd9f12c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a114476-71cb-4ef2-8f1f-2d8b2c837d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(957919, 237)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8dd525a7-3254-4e0c-8295-8871ffadd39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# generate probability predictions for the XGBoost model's folds\n",
    "for fold in xgboost_models.keys():\n",
    "#     X1[f\"xgboost_fold{fold}_pred\"] = xgboost_models[fold].predict(X)\n",
    "    X1[f\"xgboost_fold{fold}_pred\"] = xgboost_models[fold].predict_proba(X)[:,1]\n",
    "#     xgboost_preds[fold] = xgboost_models[fold].predict(X_test_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eff33be8-e342-42e8-843c-75e1acd96120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>xgboost_fold0_pred</th>\n",
       "      <th>xgboost_fold1_pred</th>\n",
       "      <th>xgboost_fold2_pred</th>\n",
       "      <th>xgboost_fold3_pred</th>\n",
       "      <th>xgboost_fold4_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.582566</td>\n",
       "      <td>0.580950</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>0.569523</td>\n",
       "      <td>0.595877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.152252</td>\n",
       "      <td>0.150803</td>\n",
       "      <td>0.148316</td>\n",
       "      <td>0.155218</td>\n",
       "      <td>0.147297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.794083</td>\n",
       "      <td>0.789945</td>\n",
       "      <td>0.788326</td>\n",
       "      <td>0.787177</td>\n",
       "      <td>0.797979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.774001</td>\n",
       "      <td>0.768510</td>\n",
       "      <td>0.774555</td>\n",
       "      <td>0.782187</td>\n",
       "      <td>0.773245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.759366</td>\n",
       "      <td>0.755764</td>\n",
       "      <td>0.763769</td>\n",
       "      <td>0.758034</td>\n",
       "      <td>0.758038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       232       233      234       235  \\\n",
       "id                                ...                                          \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.127985 -0.128494 -0.12862  7.821398   \n",
       "\n",
       "        236  xgboost_fold0_pred  xgboost_fold1_pred  xgboost_fold2_pred  \\\n",
       "id                                                                        \n",
       "0  -0.12703            0.582566            0.580950            0.576743   \n",
       "1  -0.12703            0.152252            0.150803            0.148316   \n",
       "2  -0.12703            0.794083            0.789945            0.788326   \n",
       "3  -0.12703            0.774001            0.768510            0.774555   \n",
       "4  -0.12703            0.759366            0.755764            0.763769   \n",
       "\n",
       "    xgboost_fold3_pred  xgboost_fold4_pred  \n",
       "id                                          \n",
       "0             0.569523            0.595877  \n",
       "1             0.155218            0.147297  \n",
       "2             0.787177            0.797979  \n",
       "3             0.782187            0.773245  \n",
       "4             0.758034            0.758038  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac245be1-3a2d-4c84-b83e-7224e4b13194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
