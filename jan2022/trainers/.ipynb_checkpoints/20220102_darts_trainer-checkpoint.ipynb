{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "20220102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9e1948-4853-42ea-8cd9-f7a2539fe3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "if '/sf/' in pwd:\n",
    "    COLAB, SAGE = False, False\n",
    "elif 'google.colab' in str(get_ipython()):\n",
    "    COLAB, SAGE = True, False # do colab-specific installs later\n",
    "else:\n",
    "    COLAB, SAGE = False, True\n",
    "    \n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a1b04-72db-4d9f-abae-b9c3bd5a3587",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "# from sklearn.metrics import accuracy_score#, log_loss, roc_auc_score\n",
    "\n",
    "# eda\n",
    "import missingno\n",
    "# import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import cleanlab\n",
    "\n",
    "# normalization\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# widedeep\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac89757f-d88c-47d6-a47d-c4bb14150520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series\n",
    "import tsfresh\n",
    "\n",
    "import darts\n",
    "from darts import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74b7aa4-38ea-4594-a180-e90fcbaed335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef8a92-b59f-4ef4-914f-5dce28bb8c8c",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880b9f33-b517-40ef-a3e6-049dcc52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9e0d-1301-4ade-a63d-9f3d298c2255",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba521a1a-8c41-4b9b-becd-36eb62739ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3f6bf0-8338-4cde-8ab7-5bfd9c6ff317",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19caf9af-5eee-4b85-a7de-91deff989364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-François Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc27764-fd0b-4781-81c5-6887f81b55f7",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d0d675-f5cd-4751-93b0-d07d8679c4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "    'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "train = pd.read_csv(datapath/'train.csv')\n",
    "test = pd.read_csv(datapath/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "579988a3-f394-420e-98b8-3d93eb98d792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>26293</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>26294</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>26295</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>26296</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>26297</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id        date  country       store         product  num_sold\n",
       "0           0  2015-01-01  Finland  KaggleMart      Kaggle Mug       329\n",
       "1           1  2015-01-01  Finland  KaggleMart      Kaggle Hat       520\n",
       "2           2  2015-01-01  Finland  KaggleMart  Kaggle Sticker       146\n",
       "3           3  2015-01-01  Finland  KaggleRama      Kaggle Mug       572\n",
       "4           4  2015-01-01  Finland  KaggleRama      Kaggle Hat       911\n",
       "...       ...         ...      ...         ...             ...       ...\n",
       "26293   26293  2018-12-31   Sweden  KaggleMart      Kaggle Hat       823\n",
       "26294   26294  2018-12-31   Sweden  KaggleMart  Kaggle Sticker       250\n",
       "26295   26295  2018-12-31   Sweden  KaggleRama      Kaggle Mug      1004\n",
       "26296   26296  2018-12-31   Sweden  KaggleRama      Kaggle Hat      1441\n",
       "26297   26297  2018-12-31   Sweden  KaggleRama  Kaggle Sticker       388\n",
       "\n",
       "[26298 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0607fca-0b39-4d58-9446-4641147c4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['row_id','date', 'country', 'store', 'product']]\n",
    "y = train['num_sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4eec0d-745f-4ed2-a270-4cf28980c8e8",
   "metadata": {},
   "source": [
    "I may need to change the presentation from narrow/long/tall/stacked (with the date as the key and the country, store, and product as values) to wide/unstacked (with each day getting a single row, and a lot more features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1051f38-3c06-45ce-b01e-aafb75c267fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>26293</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>26294</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>26295</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>26296</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>26297</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id        date  country       store         product\n",
       "0           0  2015-01-01  Finland  KaggleMart      Kaggle Mug\n",
       "1           1  2015-01-01  Finland  KaggleMart      Kaggle Hat\n",
       "2           2  2015-01-01  Finland  KaggleMart  Kaggle Sticker\n",
       "3           3  2015-01-01  Finland  KaggleRama      Kaggle Mug\n",
       "4           4  2015-01-01  Finland  KaggleRama      Kaggle Hat\n",
       "...       ...         ...      ...         ...             ...\n",
       "26293   26293  2018-12-31   Sweden  KaggleMart      Kaggle Hat\n",
       "26294   26294  2018-12-31   Sweden  KaggleMart  Kaggle Sticker\n",
       "26295   26295  2018-12-31   Sweden  KaggleRama      Kaggle Mug\n",
       "26296   26296  2018-12-31   Sweden  KaggleRama      Kaggle Hat\n",
       "26297   26297  2018-12-31   Sweden  KaggleRama  Kaggle Sticker\n",
       "\n",
       "[26298 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975f6895-51c0-415d-b72d-b5d38f2299cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/time/lib/python3.8/site-packages/darts/timeseries.py:317: FutureWarning: Conversion of the second argument of issubdtype from `object` to `np.generic` is deprecated. In future, it will be treated as `np.object_ == np.dtype(object).type`.\n",
      "  if np.issubdtype(df[time_col].dtype, object):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cf877d9a0768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/darts/timeseries.py\u001b[0m in \u001b[0;36mfrom_dataframe\u001b[0;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[1;32m    346\u001b[0m                           coords={time_index.name: time_index, DIMS[1]: series_df.columns})\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_missing_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_missing_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/darts/timeseries.py\u001b[0m in \u001b[0;36mfrom_xarray\u001b[0;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# The provided index does not have a freq; using the provided freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhas_datetime_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_frequency\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mxa_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_xarray_from_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mxa_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/darts/timeseries.py\u001b[0m in \u001b[0;36m_restore_xarray_from_frequency\u001b[0;34m(xa, freq)\u001b[0m\n\u001b[1;32m   2220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0mtime_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_xa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2222\u001b[0;31m         \u001b[0mresampled_time_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2224\u001b[0m         \u001b[0;31m# check if new time index with inferred frequency contains all input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36masfreq\u001b[0;34m(self, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[1;32m   7828\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7830\u001b[0;31m         return asfreq(\n\u001b[0m\u001b[1;32m   7831\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7832\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36masfreq\u001b[0;34m(obj, freq, method, how, normalize, fill_value)\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0mdti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m         \u001b[0mdti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m         \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m             \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     )\n\u001b[1;32m   4344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m     def drop(\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   4812\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4831\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4832\u001b[0;31m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   4833\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4834\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   4878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "series = TimeSeries.from_dataframe(df=X, time_col='date', value_cols=['country', 'store', 'product'], freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20adc730-0b49-4468-9a8e-9bd31c883772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = load(dataset_params['train_source'])\n",
    "# X = pd.read_feather(dataset_params['train_source'])\n",
    "# y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "# X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "X = \n",
    "\n",
    "# reduce memory usage\n",
    "X = reduce_memory_usage(X)\n",
    "X_test = reduce_memory_usage(X)\n",
    "\n",
    "# metadata logging\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f909078-91fe-4d50-8640-d18207455f22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params['feature_count'] = X.shape[1]\n",
    "# dataset_params['instance_count'] = X.shape[0]\n",
    "\n",
    "# # might eventually shift from dict to tuple\n",
    "\n",
    "# # simplest approach: k-v where key is new feature, v is string with the operation to get it\n",
    "# # sacrifices sortability, but could recover that through regexes, and it's much quicker to input\n",
    "# dataset_params['feature_combinations'] = {\n",
    "#     'EHiElv': \"df['Horizontal_Distance_To_Roadways'] * df['Elevation']\",\n",
    "#     'EViElv': \"df['Vertical_Distance_To_Hydrology'] * df['Elevation']\",\n",
    "#     'EVDtH': \"df.Elevation - df.Vertical_Distance_To_Hydrology\",\n",
    "#     'EHDtH': \"df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\",\n",
    "#     'Euclidean_Distance_to_Hydrology': \"(df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\",\n",
    "#     'Manhattan_Distance_to_Hydrology': \"df['Horizontal_Distance_To_Hydrology'] + df['Vertical_Distance_To_Hydrology']\",\n",
    "#     'Hydro_Fire_1': \"df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\",\n",
    "#     'Hydro_Fire_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\",\n",
    "#     'Hydro_Road_1': \"abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Hydro_Road_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Fire_Road_1': \"abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Fire_Road_2': \"abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\"\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_clipping'] = [\n",
    "#     {\n",
    "#         'features': ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'],\n",
    "#         'range': range(0,256)\n",
    "#     },\n",
    "#     {\n",
    "#         'features': ['Aspect'],\n",
    "#         'range': range(0,360)\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # the features that are just getting the one-hots counted\n",
    "# dataset_params['feature_counts'] = ['Soil_Type*', 'Wilderness_Area*']\n",
    "# dataset_params['feature_complements'] = [\n",
    "#     {\n",
    "#         'old': 'Aspect', \n",
    "#         'new': 'Aspect2',\n",
    "#         'operation': 'If x < 180 return x-180, else return x + 180'\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# dataset_params['feature_indicators'] = {\n",
    "#     'Hillshade_3pm_is_zero': \"(df.Hillshade_3pm == 0).astype(int)\",\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_typecasting'] = {\n",
    "#     'Highwater': \"(df.Vertical_Distance_To_Hydrology < 0).astype(int)\"\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_encodings'] = \"Soil_Type* features concatenated into single 40-bit integers and then five 8-bit integers, and finally to five decimals; see gbms_20211223.ipynb and the section 'Encoding the `Soil_Type` Features'.\"\n",
    "# dataset_params['feature_removals'] = \"Soil_Type* features removed after being encoded\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c715c1-6ffe-49f9-93bc-5f7e9250d4e0",
   "metadata": {},
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8427fb-4e31-413a-816b-b666892a9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params = {\n",
    "#     'general_random_state': SEED,\n",
    "# }\n",
    "\n",
    "# folds = 5\n",
    "# training_params['cross_val_strategy'] = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e198900-4fe5-488d-94f0-2d447f63d11d",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7504bca-4119-4499-aa25-b7f3a8d25ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c789d994-1ae1-4d36-80a4-455d8398db50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d647e8af-e065-4ea8-aa6c-5d158791904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- alter as needed later\n",
    "exmodel_config = {\n",
    "    'general_random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    **dataset_params,\n",
    "    **training_params,\n",
    "    **model_params # perhaps do later\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ecd637-4515-4e9e-9682-53144abed8e4",
   "metadata": {},
   "source": [
    "## WandB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10ae3e-280f-4bed-8d0b-745991fbcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['experiment'],\n",
    "    'notes': \"Trying the encoded Soil_Type* features with the other feature engineering measures (see 'meta_202112231058.joblib') on vanilla GBM models for comparison\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58285e3-b122-4c1e-8173-c92ecbeb19e7",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04cadbd7-3010-4f4d-a20e-fb2cbd294ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, model_params:dict={}, training_params=training_params, dataset_params=dataset_params,\n",
    "                         folds=list(range(folds)), exmodel_config=exmodel_config, wandb_config=wandb_config,  telegram=True, random_state=42, \n",
    "                         wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    # if exmodel_config['kfolds'] == 1: # holdout case\n",
    "    #     print(\"Proceeding with holdout\")\n",
    "    #     X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "    #                                                           random_state=SEED)                 \n",
    "    # else: # k-fold cross validation case\n",
    "    #     # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    #     # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    #     if shuffle_kfolds:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    #     else:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    kfold = training_params['cross_val_strategy']\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    # test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **model_params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **model_params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **model_params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)[:,1] # this would only take one of 7 cols\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test).flatten()\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        # fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       # f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        if telegram:\n",
    "            send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) \n",
    "    # model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    if telegram:\n",
    "        send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   # f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    # test_probs /= exmodel_config['kfolds']\n",
    "    # test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds#, model_confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc97e7d-779f-4f2a-bdf0-be4f16ff7aaa",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df551a93-3ffd-49c2-81be-3338d9df2450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/ruwy6z3t\" target=\"_blank\">gbms_20211223_110024</a></strong> to <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbms_20211223.ipynb\n",
      "Metrics for fold 0 are: \n",
      "Accuracy: 0.96209875\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbms_20211223.ipynb\n",
      "Metrics for fold 1 are: \n",
      "Accuracy: 0.96262\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbms_20211223.ipynb\n",
      "Metrics for fold 2 are: \n",
      "Accuracy: 0.96191875\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbms_20211223.ipynb\n",
      "Metrics for fold 3 are: \n",
      "Accuracy: 0.96230375\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbms_20211223.ipynb\n",
      "Metrics for fold 4 are: \n",
      "Accuracy: 0.96194375\n",
      "gbms_20211223.ipynb\n",
      "Metrics for model xgboost are: \n",
      "Accuracy: 0.962177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 218996... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.34MB of 0.34MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>▁</td></tr><tr><td>fold1_accuracy</td><td>▁</td></tr><tr><td>fold2_accuracy</td><td>▁</td></tr><tr><td>fold3_accuracy</td><td>▁</td></tr><tr><td>fold4_accuracy</td><td>▁</td></tr><tr><td>model_accuracy</td><td>▁</td></tr><tr><td>model_seed</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>0.9621</td></tr><tr><td>fold1_accuracy</td><td>0.96262</td></tr><tr><td>fold2_accuracy</td><td>0.96192</td></tr><tr><td>fold3_accuracy</td><td>0.9623</td></tr><tr><td>fold4_accuracy</td><td>0.96194</td></tr><tr><td>model_accuracy</td><td>0.96194</td></tr><tr><td>model_params</td><td>{'objective': 'multi...</td></tr><tr><td>model_seed</td><td>42</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gbms_20211223_110024</strong>: <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/ruwy6z3t\" target=\"_blank\">https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/ruwy6z3t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211223_110135-ruwy6z3t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost_oof_preds, xgboost_test_preds = cross_validate_model('xgboost', telegram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b61dbde-e87d-4c7f-b3c5-0854c319f6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3c2wk17d\" target=\"_blank\">gbms_20211223_110024</a></strong> to <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 0 are: \n",
      "Accuracy: 0.93337875\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 1 are: \n",
      "Accuracy: 0.9322075\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 2 are: \n",
      "Accuracy: 0.94882125\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 3 are: \n",
      "Accuracy: 0.95228625\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 4 are: \n",
      "Accuracy: 0.94496\n",
      "gbms_20211223.ipynb\n",
      "Metrics for model lightgbm are: \n",
      "Accuracy: 0.94233075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 219325... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.35MB of 0.35MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>▁</td></tr><tr><td>fold1_accuracy</td><td>▁</td></tr><tr><td>fold2_accuracy</td><td>▁</td></tr><tr><td>fold3_accuracy</td><td>▁</td></tr><tr><td>fold4_accuracy</td><td>▁</td></tr><tr><td>model_accuracy</td><td>▁</td></tr><tr><td>model_seed</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>0.93338</td></tr><tr><td>fold1_accuracy</td><td>0.93221</td></tr><tr><td>fold2_accuracy</td><td>0.94882</td></tr><tr><td>fold3_accuracy</td><td>0.95229</td></tr><tr><td>fold4_accuracy</td><td>0.94496</td></tr><tr><td>model_accuracy</td><td>0.94496</td></tr><tr><td>model_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>model_seed</td><td>42</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gbms_20211223_110024</strong>: <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3c2wk17d\" target=\"_blank\">https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3c2wk17d</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211223_110333-3c2wk17d/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lightgbm_oof_preds, lightgbm_test_preds = cross_validate_model('lightgbm', telegram=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "209e1f52-b792-4386-87b6-37c107b60b89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/2hx3sb41\" target=\"_blank\">gbms_20211223_110024</a></strong> to <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 0 are: \n",
      "Accuracy: 0.9621775\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 1 are: \n",
      "Accuracy: 0.96228875\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 2 are: \n",
      "Accuracy: 0.96179875\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 3 are: \n",
      "Accuracy: 0.9620025\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "gbms_20211223.ipynb\n",
      "Metrics for fold 4 are: \n",
      "Accuracy: 0.96153875\n",
      "gbms_20211223.ipynb\n",
      "Metrics for model catboost are: \n",
      "Accuracy: 0.96196125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 219902... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.35MB of 0.35MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>▁</td></tr><tr><td>fold1_accuracy</td><td>▁</td></tr><tr><td>fold2_accuracy</td><td>▁</td></tr><tr><td>fold3_accuracy</td><td>▁</td></tr><tr><td>fold4_accuracy</td><td>▁</td></tr><tr><td>model_accuracy</td><td>▁</td></tr><tr><td>model_seed</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>0.96218</td></tr><tr><td>fold1_accuracy</td><td>0.96229</td></tr><tr><td>fold2_accuracy</td><td>0.9618</td></tr><tr><td>fold3_accuracy</td><td>0.962</td></tr><tr><td>fold4_accuracy</td><td>0.96154</td></tr><tr><td>model_accuracy</td><td>0.96154</td></tr><tr><td>model_params</td><td>{'silent': True, 'ta...</td></tr><tr><td>model_seed</td><td>42</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gbms_20211223_110024</strong>: <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/2hx3sb41\" target=\"_blank\">https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/2hx3sb41</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211223_110826-2hx3sb41/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catboost_oof_preds, catboost_test_preds = cross_validate_model('catboost', telegram=True)\n",
    "# except:\n",
    "    # send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9aad5-478b-4a37-8f10-d176b3a37c7d",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "648f1c7b-d8c4-4070-990c-4f3f37213990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "wrapper = {\n",
    "    'metadata': {\n",
    "        'dataset_params': dataset_params,\n",
    "        'training_params': training_params,\n",
    "        'model_params': 'defaults, all on GPU'\n",
    "    },\n",
    "    'preds': {\n",
    "        'oof_preds': {\n",
    "            'xgb42': xgboost_oof_preds,\n",
    "            'lgb42': lightgbm_oof_preds,\n",
    "            'cat42': catboost_oof_preds,\n",
    "        },\n",
    "        'test_preds': {\n",
    "            'xgb42': xgboost_test_preds,\n",
    "            'lgb42': lightgbm_test_preds,\n",
    "            'cat42': catboost_test_preds\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38427214-22bb-4ff3-9a27-86c5b9bebd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/dec2021/preds/gbms_20211209-default_model_params__manual_feature_engineering__strat5fold.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(wrapper, predpath/'gbms_20211209-default_model_params__manual_feature_engineering__strat5fold.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1d01f8d-d60f-4046-8219-ac14f73d9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = load(predpath/'gbms_20211209-default_model_params__manual_feature_engineering__strat5fold.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05cf7938-2391-4788-bdf0-9c5e90414b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = pd.DataFrame({key: check['preds']['oof_preds'][key] for key in check['preds']['oof_preds'].keys()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
