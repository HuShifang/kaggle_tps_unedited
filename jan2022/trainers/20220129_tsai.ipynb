{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa68fe7-8591-4ea3-a5cf-d2547c9b5c49",
   "metadata": {},
   "source": [
    "# tsai\n",
    "Trying fastai-based library for some quick & dirty NN implementations, for variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853e0cad-277b-4672-8932-00043098c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "# if '/sf/' in pwd:\n",
    "#     COLAB, SAGE = False, False\n",
    "# elif 'google.colab' in str(get_ipython()):\n",
    "#     COLAB, SAGE = True, False # do colab-specific installs later\n",
    "# else:\n",
    "#     COLAB, SAGE = False, True\n",
    "    \n",
    "CONTEXT = 'local' # or 'colab', 'sage', 'kaggle'\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139e8f0-6387-4fb5-a095-f6bbbb67ce28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f92b26f-9097-4dfc-b570-9501aab4e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392bc7f-da5d-4ff0-866f-184ee342ad49",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3602ce7e-5d45-406e-85f4-587a749a5a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# normalization\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250d37f7-8c08-468c-b29e-e7df26bd1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time series\n",
    "# import tsfresh\n",
    "\n",
    "# import darts\n",
    "# from darts import TimeSeries\n",
    "# from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel\n",
    "import holidays\n",
    "import dateutil.easter as easter\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "from tsai.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465787a5-af5f-4871-9e53-a5854f4774fd",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb8882-dc8a-482e-a1fa-2c264932b220",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5deced-4235-46ee-a06e-d0e7a5a08064",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONTEXT == 'colab':\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    root = Path('') # TODO\n",
    "\n",
    "elif CONTEXT == 'sage':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "elif CONTEXT == 'kaggle':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "else: # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath, modelpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449a96a-d63e-4add-9577-987bf9911616",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbb71d9-e4ea-4a2e-a3b5-686442df3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a439da1-41c5-4094-8c90-74a0997b9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc37fac-1397-4afb-b935-2c35cc58cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a663de45-2da6-4db3-9f38-bc80baac37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-François Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372674e6-6280-4ab0-a5b6-f19b4444448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/282735\n",
    "def better_than_median(inputs, axis):\n",
    "    \"\"\"Compute the mean of the predictions if there are no outliers,\n",
    "    or the median if there are outliers.\n",
    "\n",
    "    Parameter: inputs = ndarray of shape (n_samples, n_folds)\"\"\"\n",
    "    spread = inputs.max(axis=axis) - inputs.min(axis=axis) \n",
    "    spread_lim = 0.45\n",
    "    print(f\"Inliers:  {(spread < spread_lim).sum():7} -> compute mean\")\n",
    "    print(f\"Outliers: {(spread >= spread_lim).sum():7} -> compute median\")\n",
    "    print(f\"Total:    {len(inputs):7}\")\n",
    "    return np.where(spread < spread_lim,\n",
    "                    np.mean(inputs, axis=axis),\n",
    "                    np.median(inputs, axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f50d0f-6057-444e-ab5c-72fd91f72fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def plot_periodogram(ts, detrend='linear', ax=None):\n",
    "    from scipy.signal import periodogram\n",
    "    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n",
    "    freqencies, spectrum = periodogram(\n",
    "        ts,\n",
    "        fs=fs,\n",
    "        detrend=detrend,\n",
    "        window=\"boxcar\",\n",
    "        scaling='spectrum',\n",
    "    )\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.step(freqencies, spectrum, color=\"purple\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"Annual (1)\",\n",
    "            \"Semiannual (2)\",\n",
    "            \"Quarterly (4)\",\n",
    "            \"Bimonthly (6)\",\n",
    "            \"Monthly (12)\",\n",
    "            \"Biweekly (26)\",\n",
    "            \"Weekly (52)\",\n",
    "            \"Semiweekly (104)\",\n",
    "        ],\n",
    "        rotation=30,\n",
    "    )\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Periodogram\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81fb6805-b4d5-41fc-a842-376c08fb1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def fourier_features(index, freq, order):\n",
    "    time = np.arange(len(index), dtype=np.float32)\n",
    "    k = 2 * np.pi * (1 / freq) * time\n",
    "    features = {}\n",
    "    for i in range(1, order + 1):\n",
    "        features.update({\n",
    "            f\"sin_{freq}_{i}\": np.sin(i * k),\n",
    "            f\"cos_{freq}_{i}\": np.cos(i * k),\n",
    "        })\n",
    "    return pd.DataFrame(features, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da19663-3814-44d6-ab45-2929d022e370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac483f-9be5-4ba7-bf3d-f7fb9a215355",
   "metadata": {},
   "source": [
    "### Original Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02a3fe1-e98f-49fb-baa7-2fedc384160f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "    'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "test_df = pd.read_csv(datapath/'test.csv')\n",
    "orig_train_df = train_df.copy()\n",
    "orig_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0abf4a-32dd-435a-9551-172f1c110b64",
   "metadata": {},
   "source": [
    "Since the dates are natively `Object` dtype (i.e. strings), we have to convert them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acd956b7-823b-4f3d-ae43-81d73349508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model\n",
    "for df in [train_df, test_df]:\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "# for convenience later\n",
    "countries = ['Sweden', 'Finland', 'Norway']\n",
    "stores = ['KaggleMart', 'KaggleRama']\n",
    "products = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ae630-74dd-40fe-87dc-179f1c4ae6ea",
   "metadata": {},
   "source": [
    "Provisionally, I'm going to concatenate together the `train_df` and `test_df` for preprocessing, to avoid having to constantly apply transforms twice (since I don't anticipate doing any transforms that might allow data leakage to occur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a88789a-e9dc-479a-bdc5-3404e0b82385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "# all_df.columns\n",
    "print(len(all_df) == len(train_df) + len(test_df))\n",
    "del train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83e050-8476-4b03-9141-76547a5b2ab8",
   "metadata": {},
   "source": [
    "### GDP Data\n",
    "Here's data from Carl McBride Ellis ([notebook](https://www.kaggle.com/carlmcbrideellis/gdp-of-finland-norway-and-sweden-2015-2019) and [dataset](https://www.kaggle.com/carlmcbrideellis/gdp-20152019-finland-norway-and-sweden) for doing GDP comparisons. They're frequently used in other entries. I've created a function to add them on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ecb693-a4f9-4834-8733-1124a1b2110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gdp_data(df):\n",
    "    gdp_df = pd.read_csv(datapath/'GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df.set_index('year', inplace=True)\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country]\n",
    "\n",
    "    df['gdp'] = np.log1p(df.apply(get_gdp, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea0d4e-1a00-4598-9d66-f7e5d09f034a",
   "metadata": {},
   "source": [
    "I'll also define here (but perhaps move later) the GDP exponent, which will be used to transform the targets before inference (dividing num_sold by the $GDP^{1.212}$ and then taking the logarithm (after @ambrosm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e21a8d45-49c0-41d7-9dd0-641bee6ba01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_exponent = 1.2121103201489674 # see https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model for an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "351cea17-4e3d-4b0f-ac9b-ed2bc261fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = add_gdp_data(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce44724-6d3e-4a11-9dd7-d30a6d1197b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp  \n",
       "0     5.461456  \n",
       "1     5.461456  \n",
       "2     5.461456  \n",
       "3     5.461456  \n",
       "4     5.461456  \n",
       "...        ...  \n",
       "6565  6.282042  \n",
       "6566  6.282042  \n",
       "6567  6.282042  \n",
       "6568  6.282042  \n",
       "6569  6.282042  \n",
       "\n",
       "[32868 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac430c-1f44-4cab-9f60-591938496422",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001db50-b826-438e-b2a4-2e978348fb28",
   "metadata": {},
   "source": [
    "### Time Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcaf542-5bd7-4c06-8e6b-d07255b27976",
   "metadata": {},
   "source": [
    "The goal of this function is to create features that will capture seasonalities -- but **not** trends. The trends will (hopefully) be captured by the deployment of linear forecasting algorithms on raw time series data (consisting exclusively of dates and targets); we want to have seasonalities that the residual models can learn, however -- holidays, weekly patterns, climactic season patterns, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc192ce-81e6-4a63-a284-4d454e66cb6a",
   "metadata": {},
   "source": [
    "The cell below will generate the `holidays` library's entries for the three countries. I may want to follow the template of @teckmengwong's code below, and add more holidays -- then, do some feature importance checking, and perhaps whittle down the features accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b86a61-63ec-42c9-bbdd-6d762df291b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in [holidays.Finland, holidays.Sweden, holidays.Norway]:\n",
    "#     print(c)\n",
    "    for h in c(years = [2019], observed=True).items():\n",
    "#         print(h)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a1b6e-1d18-4d03-8484-da80e51746a3",
   "metadata": {},
   "source": [
    "Here are the new FE techniques and helper techniques proposed by Teck Meng Wong (added as alt on 20220129, from [here](https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series#Data/Feature-Engineering))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b12695-6f92-4524-b9e3-0fd64900282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor, sqrt\n",
    "# from https://www.kaggle.com/fergusfindley/ensembling-and-rounding-techniques-comparison\n",
    "def geometric_round(arr):\n",
    "    result_array = arr\n",
    "    result_array = np.where(result_array < np.sqrt(np.floor(arr)*np.ceil(arr)), np.floor(arr), result_array)\n",
    "    result_array = np.where(result_array >= np.sqrt(np.floor(arr)*np.ceil(arr)), np.ceil(arr), result_array)\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4a4d157-dbd0-4e6f-8a98-14a2ed464978",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"date\"\n",
    "YEAR = \"year\"\n",
    "QUARTER = \"quarter\"\n",
    "MONTH = \"month\"\n",
    "WEEK = \"week\"\n",
    "DAY = \"day\"\n",
    "DAYOFYEAR = \"dayofyear\"\n",
    "WEEKOFYEAR = \"weekofyear\"\n",
    "DAYOFMONTH = \"dayofMonth\"\n",
    "DAYOFWEEK = \"dayofweek\"\n",
    "WEEKDAY = \"weekday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114c7650-509f-4deb-a4af-0eb1ade65fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "\n",
    "def periodic_spline_transformer(period, n_splines=None, degree=3):\n",
    "    if n_splines is None:\n",
    "        n_splines = period\n",
    "    n_knots = n_splines + 1  # periodic and include_bias is True\n",
    "    return SplineTransformer(\n",
    "        degree=degree,\n",
    "        n_knots=n_knots,\n",
    "        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n",
    "        extrapolation=\"periodic\",\n",
    "        include_bias=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3272bde0-c9aa-4a9d-bba2-405b762bac88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "year_df = pd.DataFrame(\n",
    "    np.linspace(0, 365, 1000).reshape(-1, 1),\n",
    "    columns=[DAYOFYEAR],\n",
    ")\n",
    "splines = periodic_spline_transformer(365, n_splines=12, degree=2).fit_transform(year_df)\n",
    "splines_df = pd.DataFrame(\n",
    "    splines,\n",
    "    columns=[f\"spline_{i}\" for i in range(splines.shape[1])],\n",
    ")\n",
    "pd.concat([year_df, splines_df], axis=\"columns\").plot(x=DAYOFYEAR, cmap=plt.cm.tab20b)\n",
    "_ = plt.title(f\"Periodic spline-based encoding for the {DAYOFYEAR} feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a91ecc4-7810-4d21-a455-beb78a322e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/samuelcortinhas/tps-jan-22-quick-eda-hybrid-model/notebook\n",
    "def unofficial_holiday(df):\n",
    "    countries = {'Finland': 1, 'Norway': 2, 'Sweden': 3}\n",
    "    stores = {'KaggleMart': 1, 'KaggleRama': 2}\n",
    "    products = {'Kaggle Mug': 1,'Kaggle Hat': 2, 'Kaggle Sticker': 3}\n",
    "    \n",
    "    # load holiday info.\n",
    "#     hol_path = '../input/public-and-unofficial-holidays-nor-fin-swe-201519/holidays.csv'\n",
    "    hol_path = datapath/'holidays.csv'\n",
    "    holiday = pd.read_csv(hol_path)\n",
    "    \n",
    "    fin_holiday = holiday.loc[holiday.country == 'Finland']\n",
    "    swe_holiday = holiday.loc[holiday.country == 'Sweden']\n",
    "    nor_holiday = holiday.loc[holiday.country == 'Norway']\n",
    "    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n",
    "    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n",
    "    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n",
    "    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n",
    "    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n",
    "    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n",
    "    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n",
    "    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1405a5ee-2f98-47c4-b9c5-d8815bfa3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUID calendar columns\n",
    "MONTH_COLUMNS = []\n",
    "WEEKOFYEAR_COLUMNS = []\n",
    "DAYOFYEAR_COLUMNS = []\n",
    "WEEKDAY_COLUMNS = []\n",
    "\n",
    "for x in [MONTH,WEEKOFYEAR,DAYOFYEAR,WEEKDAY]:\n",
    "    for y in [f'mug_{x}', f'hat_{x}', f'stick_{x}']:\n",
    "        if x == MONTH:\n",
    "            MONTH_COLUMNS.append(y)\n",
    "        if x == WEEKOFYEAR:\n",
    "            WEEKOFYEAR_COLUMNS.append(y)\n",
    "        if x == DAYOFYEAR:\n",
    "            DAYOFYEAR_COLUMNS.append(y)\n",
    "        if x == WEEKDAY:\n",
    "            WEEKDAY_COLUMNS.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a61e0d2f-aecb-448f-abb4-20f3862656ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(index, freq, order):\n",
    "    time = np.arange(len(index), dtype=np.float32)\n",
    "    k = 2 * np.pi * (1 / freq) * time\n",
    "    features = {}\n",
    "    for i in range(1, order + 1):\n",
    "        features.update({\n",
    "            f\"sin_{freq}_{i}\": np.sin(i * k),\n",
    "            f\"cos_{freq}_{i}\": np.cos(i * k),\n",
    "        })\n",
    "    return pd.DataFrame(features, index=index)\n",
    "\n",
    "def get_basic_ts_features(df):\n",
    "#     gdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df = pd.read_csv(datapath/'GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df.set_index('year', inplace=True)\n",
    "#     gdp_exponent = 1.2121103201489674 # see https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model for an explanation\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country] #**gdp_exponent\n",
    "\n",
    "    # Apply GDP log\n",
    "    df['gdp'] = np.log1p(df.apply(get_gdp, axis=1))\n",
    "    \n",
    "#     # Split GDP by country (for linear model)\n",
    "#     df['fin_gdp']=np.where(df['country'] == 'Finland', df['gdp'], 0)\n",
    "#     df['nor_gdp']=np.where(df['country'] == 'Norway', df['gdp'], 0)\n",
    "#     df['swe_gdp']=np.where(df['country'] == 'Sweden', df['gdp'], 0)\n",
    "    \n",
    "#     # Drop column\n",
    "#     df=df.drop(['gdp'],axis=1)\n",
    "    \n",
    "    # one-hot encoding should be used. linear model should not learn this as numeric value\n",
    "#     df[YEAR] = df[DATE].dt.year\n",
    "#     df[MONTH] = df[DATE].dt.month\n",
    "#     df[WEEKOFYEAR] = df[DATE].dt.isocalendar().week\n",
    "#     df[DAYOFYEAR] = df[DATE].dt.dayofyear\n",
    "#     df[WEEKDAY] = df[DATE].dt.weekday\n",
    "#     df[DAY] = df[DATE].dt.day # day in month\n",
    "#     df[DAYOFMONTH] = df[DATE].dt.days_in_month\n",
    "#     df[DAYOFWEEK] = df[DATE].dt.dayofweek\n",
    "#     df[MONTH] = df[DATE].dt.month # Min SMAPE: 4.005319478790032\n",
    "#     df[QUARTER] = df.date.dt.quarter\n",
    "\n",
    "    df['wd0'] = df[DATE].dt.weekday == 0 # + Monday\n",
    "    df['wd1'] = df[DATE].dt.weekday == 1 # Tuesday\n",
    "    df['wd2'] = df[DATE].dt.weekday == 2\n",
    "    df['wd3'] = df[DATE].dt.weekday == 3\n",
    "    df['wd4'] = df[DATE].dt.weekday == 4 # + Friday\n",
    "    df['wd56'] = df[DATE].dt.weekday >= 5 # + Weekend\n",
    "\n",
    "#     df[f'mug_wd4'] = np.where(df['product'] == 'Kaggle Mug', df[f'wd4'], False)\n",
    "#     df[f'mug_wd56'] = np.where(df['product'] == 'Kaggle Mug', df[f'wd56'], False)\n",
    "#     df[f'hat_wd4'] = np.where(df['product'] == 'Kaggle Hat', df[f'wd4'], False)\n",
    "#     df[f'hat_wd56'] = np.where(df['product'] == 'Kaggle Hat', df[f'wd56'], False)\n",
    "#     df[f'stick_wd4'] = np.where(df['product'] == 'Kaggle Sticker', df[f'wd4'], False)\n",
    "#     df[f'stick_wd56'] = np.where(df['product'] == 'Kaggle Sticker', df[f'wd56'], False)\n",
    "#     df = df.drop(columns=[f'wd4', f'wd56'])\n",
    "    # 4 seasons\n",
    "#     df['season'] = ((df[DATE].dt.month % 12 + 3) // 3).map({1:'DJF', 2: 'MAM', 3:'JJA', 4:'SON'})\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_splines(df):\n",
    "    # one-hot encoding should be used. linear model should not learn this as numeric value\n",
    "#     df[MONTH] = df[DATE].dt.month\n",
    "#     df[WEEKOFYEAR] = df[DATE].dt.isocalendar().week\n",
    "    df[WEEKDAY] = df[DATE].dt.weekday\n",
    "#     df[DAYOFYEAR] = df[DATE].dt.dayofyear\n",
    "    \n",
    "    dayofyear_splines = periodic_spline_transformer(365, n_splines=9, degree=2).fit_transform(df[DATE].dt.dayofyear.values.reshape(-1, 1))\n",
    "    splines_df = pd.DataFrame(\n",
    "        dayofyear_splines,\n",
    "        columns=[f\"spline_{i}\" for i in range(dayofyear_splines.shape[1])],\n",
    "    )\n",
    "    for i in range(dayofyear_splines.shape[1]):\n",
    "        df[f'mug_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Mug', splines_df[f\"spline_{i}\"], 0.)\n",
    "        df[f'hat_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Hat', splines_df[f\"spline_{i}\"], 0.)\n",
    "        df[f'stick_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Sticker', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'fin_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Finland', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'nor_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Norway', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'swe_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Sweden', splines_df[f\"spline_{i}\"], 0.)\n",
    "\n",
    "#     weekofyear_splines = periodic_spline_transformer(52, n_splines=2, degree=2).fit_transform(df[DATE].dt.isocalendar().week.values.astype(np.float64).reshape(-1,1))\n",
    "#     splines_df = pd.DataFrame(\n",
    "#         weekofyear_splines,\n",
    "#         columns=[f\"spline_{i}\" for i in range(weekofyear_splines.shape[1])],\n",
    "#     )\n",
    "#     for i in range(weekofyear_splines.shape[1]):\n",
    "#         df[f'weekofyear_{WEEKOFYEAR}{i}'] = splines_df[f\"spline_{i}\"]\n",
    "#         df[f'hat_{WEEKOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Hat', splines_df[f\"spline_{i}\"], 0)\n",
    "#         df[f'stick_{WEEKOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Sticker', splines_df[f\"spline_{i}\"], 0)\n",
    "#     df[f'mug_{MONTH}'] = np.where(df['product'] == 'Kaggle Mug', df[MONTH], 0)\n",
    "#     df[f'mug_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Mug', df[WEEKOFYEAR], 0)\n",
    "#     df[f'mug_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Mug', df[DAYOFYEAR], 0)\n",
    "#     df[f'mug_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Mug', df[WEEKDAY], 0)\n",
    "#     df[f'hat_{MONTH}'] = np.where(df['product'] == 'Kaggle Hat', df[MONTH], 0)\n",
    "#     df[f'hat_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Hat', df[WEEKOFYEAR], 0)\n",
    "#     df[f'hat_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Hat', df[DAYOFYEAR], 0)\n",
    "#     df[f'hat_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Hat', df[WEEKDAY], 0)\n",
    "#     df[f'stick_{MONTH}'] = np.where(df['product'] == 'Kaggle Sticker', df[MONTH], 0)\n",
    "#     df[f'stick_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Sticker', df[WEEKOFYEAR], 0)\n",
    "#     df[f'stick_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Sticker', df[DAYOFYEAR], 0)\n",
    "#     df[f'stick_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Sticker', df[WEEKDAY], 0)\n",
    "\n",
    "#     df = df.drop(columns=[DAYOFYEAR]) #MONTH, WEEKOFYEAR, WEEKDAY\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_periodic(df):\n",
    "    # 21 days cyclic for lunar\n",
    "    # 21 4.244872419046287 31 4.23870 37 4.2359085545955875 47 4.24590382934362 39 4.236812122257115 \n",
    "    # 35 4.2358561209794665 33 4.237682217183017 36 4.230652791910613 3 4.241000488616227 4.23833321067532\n",
    "    #[7, 14, 21, 28, 30, 31, 91] range(1, 32, 4) range(1,3,1)[1,2,4]\n",
    "    # Long term periodic\n",
    "    dayofyear = df.date.dt.dayofyear\n",
    "    j=-36\n",
    "    for k in [2]:\n",
    "        df = pd.concat([df,\n",
    "                        pd.DataFrame({\n",
    "                            f\"sin{k}\": np.sin((dayofyear+j) / 365 * 1 * math.pi * k),\n",
    "                            f\"cos{k}\": np.cos((dayofyear+j) / 365 * 1 * math.pi * k),\n",
    "                                     })], axis=1)\n",
    "        # Products\n",
    "        df[f'mug_sin{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'sin{k}'], 0)\n",
    "        df[f'mug_cos{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'cos{k}'], 0)\n",
    "        df[f'hat_sin{k}'] = np.where(df['product'] == 'Kaggle Hat', df[f'sin{k}'], 0)\n",
    "        df[f'hat_cos{k}'] = np.where(df['product'] == 'Kaggle Hat', df[f'cos{k}'], 0)\n",
    "        df[f'stick_sin{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'sin{k}'], 0)\n",
    "        df[f'stick_cos{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'cos{k}'], 0)\n",
    "        df = df.drop(columns=[f'sin{k}', f'cos{k}'])\n",
    "\n",
    "    # Short term Periodic\n",
    "    weekday = df.date.dt.weekday\n",
    "    df[f'weekly_sin'] = np.sin((1 / 7) * 2 * math.pi*(weekday+1)) #+\n",
    "    df[f'weekly_cos'] = np.cos((1 / 7) * 2 * math.pi*(weekday+1)) #+\n",
    "    df[f'semiweekly_sin'] = np.sin((1 / 7) * 4 * math.pi*(dayofyear-1.5)) #+ ⁅sin(1/7 𝜋⋅4(𝑥−2))⁆\n",
    "    df[f'semiweekly_cos'] = np.cos((1 / 7) * 4 * math.pi*(dayofyear-1.5)) #+ ⁅cos(1/7 𝜋⋅4𝑥)⁆\n",
    "    \n",
    "    df[f'fin_weekly_sin'] = np.where(df['country'] == 'Finland', df[f'weekly_sin'], 0)\n",
    "    df[f'fin_weekly_cos'] = np.where(df['country'] == 'Finland', df[f'weekly_cos'], 0)\n",
    "    df[f'nor_weekly_sin'] = np.where(df['country'] == 'Norway', df[f'weekly_sin'], 0)\n",
    "    df[f'nor_weekly_cos'] = np.where(df['country'] == 'Norway', df[f'weekly_cos'], 0)\n",
    "    df[f'swe_weekly_sin'] = np.where(df['country'] == 'Sweden', df[f'weekly_sin'], 0)\n",
    "    df[f'swe_weekly_cos'] = np.where(df['country'] == 'Sweden', df[f'weekly_cos'], 0)\n",
    "    \n",
    "    df[f'mug_weekly_sin'] = np.where(df['product'] == 'Kaggle Mug', df[f'weekly_sin'], 0)\n",
    "    df[f'mug_weekly_cos'] = np.where(df['product'] == 'Kaggle Mug', df[f'weekly_cos'], 0)\n",
    "    df[f'hat_weekly_sin'] = np.where(df['product'] == 'Kaggle Hat', df[f'weekly_sin'], 0)\n",
    "    df[f'hat_weekly_cos'] = np.where(df['product'] == 'Kaggle Hat', df[f'weekly_cos'], 0)\n",
    "    df[f'stick_weekly_sin'] = np.where(df['product'] == 'Kaggle Sticker', df[f'weekly_sin'], 0)\n",
    "    df[f'stick_weekly_cos'] = np.where(df['product'] == 'Kaggle Sticker', df[f'weekly_cos'], 0)\n",
    "    \n",
    "    df[f'mug_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Mug', df[f'semiweekly_sin'], 0)\n",
    "    df[f'mug_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Mug', df[f'semiweekly_cos'], 0)\n",
    "    df[f'hat_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Hat', df[f'semiweekly_sin'], 0)\n",
    "    df[f'hat_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Hat', df[f'semiweekly_cos'], 0)\n",
    "    df[f'stick_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Sticker', df[f'semiweekly_sin'], 0)\n",
    "    df[f'stick_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Sticker', df[f'semiweekly_cos'], 0)\n",
    "    \n",
    "    df = df.drop(columns=['weekly_sin', 'weekly_cos', 'semiweekly_sin', 'semiweekly_cos'])\n",
    "    \n",
    "#     df[f'semiannual_sin'] = np.sin(dayofyear / 182.5 * 2 * math.pi)\n",
    "#     df[f'semiannual_cos'] = np.cos(dayofyear / 182.5 * 2 * math.pi)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def feature_holiday(df):\n",
    "# Dec Jan\n",
    "    # End of year\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"f-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"n-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"s-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"f-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in range(1, 14)}),\n",
    "                        pd.DataFrame({f\"n-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "                                      for d in range(1, 10)}),\n",
    "                        pd.DataFrame({f\"s-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "                                      for d in range(1, 15)})\n",
    "                       ], axis=1)\n",
    "        \n",
    "    # May\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"may{d}\":\n",
    "                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n",
    "                                      for d in list(range(1, 10))}),\n",
    "                        pd.DataFrame({f\"may{d}\":\n",
    "                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & \n",
    "                                      (df.country == 'Norway')\n",
    "                                      for d in list(range(18, 28))})\n",
    "                        ], axis=1)\n",
    "    \n",
    "    # June and July 8, 14\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"june{d}\":\n",
    "                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & \n",
    "                                      (df.country == 'Sweden')\n",
    "                                      for d in list(range(8, 14))}),\n",
    "                       ], axis=1)\n",
    "    # Last Wednesday of June\n",
    "    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "                                         2016: pd.Timestamp(('2016-06-29')),\n",
    "                                         2017: pd.Timestamp(('2017-06-28')),\n",
    "                                         2018: pd.Timestamp(('2018-06-27')),\n",
    "                                         2019: pd.Timestamp(('2019-06-26'))})\n",
    "    df = pd.concat([df, pd.DataFrame({f\"wed_june{d}\": \n",
    "                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & \n",
    "                                      (df.country != 'Norway')\n",
    "                                      for d in list(range(-4, 6))})], axis=1)\n",
    "\n",
    "    # First Sunday of November\n",
    "    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "                                         2016: pd.Timestamp(('2016-11-6')),\n",
    "                                         2017: pd.Timestamp(('2017-11-5')),\n",
    "                                         2018: pd.Timestamp(('2018-11-4')),\n",
    "                                         2019: pd.Timestamp(('2019-11-3'))})\n",
    "    df = pd.concat([df, pd.DataFrame({f\"sun_nov{d}\":\n",
    "                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n",
    "                                      for d in list(range(0, 9))})], axis=1)\n",
    "    # First half of December (Independence Day of Finland, 6th of December)\n",
    "    df = pd.concat([df, pd.DataFrame({f\"dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in list(range(6, 14))})], axis=1)\n",
    "    # Easter April\n",
    "    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "    df = pd.concat([df, pd.DataFrame({f\"easter{d}\":\n",
    "                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n",
    "                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118c76c6-85fd-42ce-99d5-32f0aa5a7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_engineering(df):\n",
    "    df = get_basic_ts_features(df)\n",
    "    df = feature_splines(df)\n",
    "    df = feature_periodic(df)\n",
    "    df = feature_holiday(df)\n",
    "    df = unofficial_holiday(df)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "782e4912-fd39-4f15-a440-47ed10fd80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Old feature engineering function\n",
    "\n",
    "# def temporal_engineering(df):\n",
    "#     '''\n",
    "#     Function inspired by / borrowing from @teckmengwong and @ambrosm to create time features that will\n",
    "#     capture seasonality.\n",
    "#     '''\n",
    "    \n",
    "# #     df[YEAR] = df[DATE].dt.year\n",
    "#     df['month'] = df['date'].dt.month\n",
    "# #     df['week'] = df['date'].dt.week # not used by Teck Meng Wong\n",
    "# #     df['day'] = df['date'].dt.day # not used by Teck Meng Wong\n",
    "# #     df['day_of_year'] = df['date'].dt.dayofyear # not used by Teck Meng Wong\n",
    "# #     df['day_of_month'] = df['date'].dt.days_in_month # not used by Teck Meng Wong\n",
    "# #     df['day_of_week'] = df['date'].dt.dayofweek # not used by Teck Meng Wong\n",
    "# #    df['weekday'] = df['date'].dt.weekday # not used by Teck Meng Wong\n",
    "#     # Teck Meng Wong mapped the integers to first-letters in triplets\n",
    "#     # I'm leaving it as integers, where winter=1, spring=2, summer=3, fall=4\n",
    "#     df['season'] = ((df['date'].dt.month % 12 + 3) // 3) #.map({1:'DJF', 2: 'MAM', 3:'JJA', 4:'SON'})\n",
    "# #     df['month'] = df['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "#     df['wd4'] = df['date'].dt.weekday == 4\n",
    "#     df['wd56'] = df['date'].dt.weekday >= 5\n",
    "# #     df['wd6'] = df['date'].dt.weekday >= 6\n",
    "# #     df.loc[(df.date.dt.year != 2016) & (df.date.dt.month >=3), 'day_of_year'] += 1 # fix for leap years\n",
    "    \n",
    "#     # 21 days cyclic for lunar\n",
    "#     dayofyear = df.date.dt.dayofyear # for convenience\n",
    "    \n",
    "#     # here he's creating Fourier features\n",
    "#     for k in range(1, 32, 4):\n",
    "#         df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n",
    "#         df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n",
    "#         df[f'finland_sin{k}'] = np.where(df['country'] == 'Finland', df[f'sin{k}'], 0)\n",
    "#         df[f'finland_cos{k}'] = np.where(df['country'] == 'Finland', df[f'cos{k}'], 0)\n",
    "#         df[f'norway_sin{k}'] = np.where(df['country'] == 'Norway', df[f'sin{k}'], 0)\n",
    "#         df[f'norway_cos{k}'] = np.where(df['country'] == 'Norway', df[f'cos{k}'], 0)\n",
    "#         df[f'store_sin{k}'] = np.where(df['store'] == 'KaggleMart', df[f'sin{k}'], 0)\n",
    "#         df[f'store_cos{k}'] = np.where(df['store'] == 'KaggleMart', df[f'cos{k}'], 0)\n",
    "#         df[f'mug_sin{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'sin{k}'], 0)\n",
    "#         df[f'mug_cos{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'cos{k}'], 0)\n",
    "#         df[f'sticker_sin{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'sin{k}'], 0)\n",
    "#         df[f'sticker_cos{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'cos{k}'], 0)\n",
    "    \n",
    "# #     df[f'semiweekly_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 14)\n",
    "# #     df[f'semiweekly_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 14)\n",
    "# #     df[f'lunar_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 21)\n",
    "# #     df[f'lunar_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 21)\n",
    "#     df[f'season_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 91.5)\n",
    "#     df[f'season_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 91.5)\n",
    "# #     df = pd.concat([df, pd.DataFrame({f'fin{ptr[1]}':\n",
    "# #                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Finland')\n",
    "# #                                       for ptr in holidays.Finland(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "# #     df = pd.concat([df, pd.DataFrame({f'nor{ptr[1]}':\n",
    "# #                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Norway')\n",
    "# #                                       for ptr in holidays.Norway(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "# #     df = pd.concat([df, pd.DataFrame({f'swe{ptr[1]}':\n",
    "# #                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Sweden')\n",
    "# #                                       for ptr in holidays.Sweden(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "\n",
    "#     # End of year\n",
    "#     # Dec - teckmengwong\n",
    "#     for d in range(24, 32):\n",
    "#         df[f\"dec{d}\"] = (df.date.dt.month == 12) & (df.date.dt.day == d)\n",
    "#     # I'm unsure of the logic of only doing this for Norway\n",
    "#     for d in range(24, 32):\n",
    "#         df[f\"n-dec{d}\"] = (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "    \n",
    "#     # not sure why he's using different date ranges for each country here\n",
    "#     # Jan - teckmengwong\n",
    "#     for d in range(1, 14):\n",
    "#         df[f\"f-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "#     for d in range(1, 10):\n",
    "#         df[f\"n-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "#     for d in range(1, 15):\n",
    "#         df[f\"s-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "    \n",
    "    \n",
    "#     # May - tekcmengwong\n",
    "#     for d in list(range(1, 10)): # May Day and after, I guess\n",
    "#         df[f\"may{d}\"] = (df.date.dt.month == 5) & (df.date.dt.day == d)\n",
    "#     for d in list(range(19, 26)):\n",
    "#         df[f\"may{d}\"] = (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "#     # June \n",
    "#     for d in list(range(8, 14)):\n",
    "#         df[f\"june{d}\"] = (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "    \n",
    "#     #Swedish Rock Concert - teckmengwong\n",
    "#     #Jun 3, 2015 – Jun 6, 2015\n",
    "#     #Jun 8, 2016 – Jun 11, 2016\n",
    "#     #Jun 7, 2017 – Jun 10, 2017\n",
    "#     #Jun 6, 2018 – Jun 10, 2018\n",
    "#     #Jun 5, 2019 – Jun 8, 2019\n",
    "#     swed_rock_fest  = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-6')),\n",
    "#                                          2016: pd.Timestamp(('2016-06-11')),\n",
    "#                                          2017: pd.Timestamp(('2017-06-10')),\n",
    "#                                          2018: pd.Timestamp(('2018-06-10')),\n",
    "#                                          2019: pd.Timestamp(('2019-06-8'))})\n",
    "\n",
    "#     df = pd.concat([df, pd.DataFrame({f\"swed_rock_fest{d}\":\n",
    "#                                       (df.date - swed_rock_fest == np.timedelta64(d, \"D\")) & (df.country == 'Sweden')\n",
    "#                                       for d in list(range(-3, 3))})], axis=1)\n",
    "\n",
    "    \n",
    "#     # Last Wednesday of June - teckmengwong\n",
    "#     wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "#                                          2016: pd.Timestamp(('2016-06-29')),\n",
    "#                                          2017: pd.Timestamp(('2017-06-28')),\n",
    "#                                          2018: pd.Timestamp(('2018-06-27')),\n",
    "#                                          2019: pd.Timestamp(('2019-06-26'))})\n",
    "#     for d in list(range(-4, 6)):\n",
    "#         df[f\"wed_june{d}\"] = (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n",
    "        \n",
    "#     # First Sunday of November - teckmengwong\n",
    "#     sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "#                                          2016: pd.Timestamp(('2016-11-6')),\n",
    "#                                          2017: pd.Timestamp(('2017-11-5')),\n",
    "#                                          2018: pd.Timestamp(('2018-11-4')),\n",
    "#                                          2019: pd.Timestamp(('2019-11-3'))})\n",
    "#     df = pd.concat([df, pd.DataFrame({f\"sun_nov{d}\":\n",
    "#                                       (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n",
    "#                                       for d in list(range(0, 9))})], axis=1)\n",
    "    \n",
    "#     # First half of December (Independence Day of Finland, 6th of December) -teckmengwong\n",
    "#     df = pd.concat([df, pd.DataFrame({f\"dec{d}\":\n",
    "#                                       (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "#                                       for d in list(range(6, 14))})], axis=1)\n",
    "    \n",
    "#     # Easter -teckmengwong\n",
    "#     easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "#     df = pd.concat([df, pd.DataFrame({f\"easter{d}\":\n",
    "#                                       (df.date - easter_date == np.timedelta64(d, \"D\"))\n",
    "#                                       for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})], axis=1)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0fb99a9-079a-4248-9d21-958813626510",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_all_df = temporal_engineering(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e43b0b9-6388-4237-a7f4-7ae8db65d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>wd0</th>\n",
       "      <th>wd1</th>\n",
       "      <th>wd2</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp    wd0    wd1    wd2  ...  easter50  easter51  easter52  \\\n",
       "0     5.461456  False  False  False  ...     False     False     False   \n",
       "1     5.461456  False  False  False  ...     False     False     False   \n",
       "2     5.461456  False  False  False  ...     False     False     False   \n",
       "3     5.461456  False  False  False  ...     False     False     False   \n",
       "4     5.461456  False  False  False  ...     False     False     False   \n",
       "...        ...    ...    ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042  False   True  False  ...     False     False     False   \n",
       "6566  6.282042  False   True  False  ...     False     False     False   \n",
       "6567  6.282042  False   True  False  ...     False     False     False   \n",
       "6568  6.282042  False   True  False  ...     False     False     False   \n",
       "6569  6.282042  False   True  False  ...     False     False     False   \n",
       "\n",
       "      easter53  easter54  easter55  easter56  easter57  easter58  holiday  \n",
       "0        False     False     False     False     False     False        1  \n",
       "1        False     False     False     False     False     False        1  \n",
       "2        False     False     False     False     False     False        1  \n",
       "3        False     False     False     False     False     False        1  \n",
       "4        False     False     False     False     False     False        1  \n",
       "...        ...       ...       ...       ...       ...       ...      ...  \n",
       "6565     False     False     False     False     False     False        0  \n",
       "6566     False     False     False     False     False     False        0  \n",
       "6567     False     False     False     False     False     False        0  \n",
       "6568     False     False     False     False     False     False        0  \n",
       "6569     False     False     False     False     False     False        0  \n",
       "\n",
       "[32868 rows x 208 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4077ce-11b3-4536-947b-cb464653dde3",
   "metadata": {},
   "source": [
    "At this point, the `temporal_all_df` DataFrame contains all the time features for both the training and testing sets.\n",
    "* **Todo**: consider not only adding in holidays from `holidays`, but also borrowing ideas from the AmbrosM Linear notebook too (which creates fewer features, populating them instead with temporal distances from the selected holidays)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d96649-8a40-44d4-a449-2cd1ec31121f",
   "metadata": {},
   "source": [
    "### Target Transformation\n",
    "Now, I'll do the target transformation proposed by @AmbrosM. (I'll do it to the non-encoded DataFrame too, for testing with Prophet and NeuralProphet later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa4deae1-898f-4bcb-a35c-60b55eeb9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [temporal_all_df]:\n",
    "    df['target'] = np.log(df['num_sold'] / df['gdp']**gdp_exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f60614b6-d87b-4630-960c-f469ac4b000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df['target'] = np.log(encoded_all_df['num_sold'] / (encoded_all_df['gdp']**gdp_exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85f623aa-d9bb-4cf4-8975-5598721a32aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>wd0</th>\n",
       "      <th>wd1</th>\n",
       "      <th>wd2</th>\n",
       "      <th>...</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>holiday</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.925788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.291321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp    wd0    wd1    wd2  ...  easter51  easter52  easter53  \\\n",
       "0     5.461456  False  False  False  ...     False     False     False   \n",
       "1     5.461456  False  False  False  ...     False     False     False   \n",
       "2     5.461456  False  False  False  ...     False     False     False   \n",
       "3     5.461456  False  False  False  ...     False     False     False   \n",
       "4     5.461456  False  False  False  ...     False     False     False   \n",
       "...        ...    ...    ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042  False   True  False  ...     False     False     False   \n",
       "6566  6.282042  False   True  False  ...     False     False     False   \n",
       "6567  6.282042  False   True  False  ...     False     False     False   \n",
       "6568  6.282042  False   True  False  ...     False     False     False   \n",
       "6569  6.282042  False   True  False  ...     False     False     False   \n",
       "\n",
       "      easter54  easter55  easter56  easter57  easter58  holiday    target  \n",
       "0        False     False     False     False     False        1  3.738239  \n",
       "1        False     False     False     False     False        1  4.196010  \n",
       "2        False     False     False     False     False        1  2.925788  \n",
       "3        False     False     False     False     False        1  4.291321  \n",
       "4        False     False     False     False     False        1  4.756724  \n",
       "...        ...       ...       ...       ...       ...      ...       ...  \n",
       "6565     False     False     False     False     False        0       NaN  \n",
       "6566     False     False     False     False     False        0       NaN  \n",
       "6567     False     False     False     False     False        0       NaN  \n",
       "6568     False     False     False     False     False        0       NaN  \n",
       "6569     False     False     False     False     False        0       NaN  \n",
       "\n",
       "[32868 rows x 209 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eadb9e-0f04-4243-80b7-3f710e5542e2",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474675c-3b84-4aed-a5f7-319a312d9954",
   "metadata": {},
   "source": [
    "I'm going to encapsulate this in a function so that it can be invoked just-in-time, in the hopes of avoiding confusions with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10cec107-6ed6-4013-bd86-83287b73e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    features = ['country', 'product', 'store']\n",
    "    le_dict = {feature: LabelEncoder().fit(orig_train_df[feature]) for feature in features}\n",
    "    enc_df = df.copy()\n",
    "    for feature in features:\n",
    "        enc_df[feature] = le_dict[feature].transform(df[feature])\n",
    "    return le_dict, enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d057ff46-10a1-4a74-a049-49b1705d02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in le_dict.keys():\n",
    "#     print(f\"Values for key {key} are {le_dict[key].inverse_transform(range(len(le_dict[key].values())))}\")#\"\n",
    "# print(le_dict['country'].inverse_transform([0,1,2]))\n",
    "# print(le_dict['product'].inverse_transform([0,1,2]))\n",
    "# print(le_dict['store'].inverse_transform([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65156ef4-a429-46b2-8ff0-f98ca651611a",
   "metadata": {},
   "source": [
    "```\n",
    "['Finland' 'Norway' 'Sweden']\n",
    "['Kaggle Hat' 'Kaggle Mug' 'Kaggle Sticker']\n",
    "['KaggleMart' 'KaggleRama']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ca0e8-1ee8-462d-945b-c00f9958409b",
   "metadata": {},
   "source": [
    "Now, we'll do the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72b123-f8a8-4f90-820e-0da7772fe4a2",
   "metadata": {},
   "source": [
    "At this point, the `encoded_all_df` can be used -- perhaps with a call to `LabelEncoder.inverse_transform` -- to recover the \"original\" data when necessary (e.g. for feeding it into Prophet and NeuralProphet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f57733c-7b91-4925-85dd-7b967cb56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df = label_encoder(temporal_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f4e48-b234-4cf5-8421-f2af145426e9",
   "metadata": {},
   "source": [
    "### Pseudolabeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca8eb6-a11a-4a33-9ac2-e10c1df48845",
   "metadata": {},
   "source": [
    "I'm not going to try this right now, but I may return to it later -- I note that Teck Meng Wong had some good results with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11ce23a5-1c47-4a1d-9c6b-0684f90c5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here's teck meng wong's implementation -- see the notebook for the constants\n",
    "# df_pseudolabels = pd.read_csv(PSEUDO_DIR, index_col=ID)\n",
    "# df_pseudolabels[DATE] = pd.to_datetime(test_df[DATE])\n",
    "# df_pseudolabels.to_csv(\"pseudo_labels_v0.csv\", index=True)\n",
    "# # if PSEUDO_LABEL:\n",
    "#     # df_pseudolabels = df_pseudolabels.set_index([DATE]).sort_index()\n",
    "# test_df[column_y] = df_pseudolabels[column_y].astype(np.float64)\n",
    "# train_df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61061e99-d56e-4290-ba18-c89e1a21fdf3",
   "metadata": {},
   "source": [
    "### Data Splitting, Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268dbc9-cf56-49d8-886e-ba34eb1b4499",
   "metadata": {},
   "source": [
    "Now that the preprocessing is done, I'm going to split the data back into the train and test sets; then, I'll create a view on the dataframes that omits the year. The year-less dataframes will be suitable for residual learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "447607ba-81cf-4125-9a1d-2d551da05fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = encoded_all_df.drop(columns=['num_sold', 'row_id'])\n",
    "all_df = temporal_all_df.drop(columns=['row_id']) # writing over the previous version of `all_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f3b3b51-4cfa-46f5-a32e-3e5c7497d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df = all_df[:len(orig_train_df)] # training and validation sets -- still not encoded\n",
    "test_df = all_df[len(orig_train_df):] # still not encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3120d77c-00bb-4345-b897-4d5d1105fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = encoded_all_df.iloc[np.where(encoded_all_df['date'] < '2019-01-01'), :]\n",
    "# test_df = encoded_all_df[[np.where(encoded_all_df['date'] > '2018-12-31')]]\n",
    "\n",
    "# encoded_tv_df = encoded_all_df.drop(columns=['row_id'])[:len(orig_train_df)]\n",
    "# encoded_test_df = encoded_all_df.drop(columns=['row_id'])[len(orig_train_df):]\n",
    "\n",
    "# valid_df = tv_df[tv_df['date'] > '2017-12-31']\n",
    "# train_df = tv_df[tv_df['date'] <= '2017-12-31']\n",
    "\n",
    "# train_and_valid_residual_df = train_and_valid_df.drop(columns=['date'])\n",
    "# test_residual_df = test_df.drop(columns=['date'])\n",
    "\n",
    "# len(valid_df) + len(train_df) == len(tv_df)\n",
    "\n",
    "# encoded_tv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59f277-f5c5-4e78-ae1e-74c6cb485017",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faed153-18af-4f8d-8008-0e1133c7934d",
   "metadata": {},
   "source": [
    "### Forecasting Models Prep\n",
    "First, we'll set up functions to handle the training of forecasting models which will discern trends, and which may -- or may not -- yield insights concerning seasonality. While the Scikit-Learn models will be able to share a single trainer function, the Prophet and NeuralProphet models have subtly different expectations of their data, and as such will require separate handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2943f6c-0ea8-4686-8915-ea0e3148898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, HuberRegressor, LinearRegression, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "# earth? wouldn't install via pip on my machine at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1be7ac75-d9e8-4cb4-849e-351d651b4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from skorch import NeuralNetRegressor\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc7c88-1d32-4731-b159-34d35aef250c",
   "metadata": {},
   "source": [
    "#### (Preprepared Preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb719de-dd9d-4a44-8a46-59ce92091555",
   "metadata": {},
   "source": [
    "The next cell contains code to import already-existing predictions -- but I think it's better to centralize the code that produces them here, and will comment out the import code for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d07e728-55cd-4526-bd02-14fedb302f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_trainset = load(predpath/'20220121_prophet_baseline_trainset.joblib')\n",
    "\n",
    "# neural_trainset = load(predpath/'20220121_neuralprophet_baseline_trainset.joblib')\n",
    "# neural_test_preds = load(predpath/'20220121_neuralprophet_baseline_testset.joblib')\n",
    "\n",
    "# ridge_tv_preds = load(predpath/'20210121_ridge_baseline_trainset_preds.joblib')\n",
    "# ridge_test_preds = load(predpath/'20220121_ridge_testset_preds.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb101a-dc0a-4aef-8846-a49bf40221e8",
   "metadata": {},
   "source": [
    "And this cell would handle the parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5d9d647-4838-4336-9958-898c0a55eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_tv_preds = neural_trainset['prophet_forecast']\n",
    "# prophet_tv_preds = prophet_trainset['prophet_forecast']\n",
    "\n",
    "# neural_train_preds = neural_tv_preds[:train_length]\n",
    "# neural_valid_preds = neural_tv_preds[train_length:]\n",
    "\n",
    "# prophet_train_preds = prophet_tv_preds[:train_length]\n",
    "# prophet_valid_preds = prophet_tv_preds[train_length:]\n",
    "\n",
    "# train_length = len(neural_trainset[neural_trainset['date'] <= '2017-12-31'])\n",
    "\n",
    "# ridge_train_preds = ridge_tv_preds[:train_length]\n",
    "# ridge_valid_preds = ridge_tv_preds[train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ce80e-1d5b-4f07-8381-8fe6339bbb1d",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Linear Models Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f765ff-e4f9-487d-b271-b852add5c0c6",
   "metadata": {},
   "source": [
    "Linear models from Scikit-Learn seemingly require that datetime data be converted to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df2215-385f-44c7-a18d-1368f81ff6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70752c1d-06cd-4b7c-b2e0-5f097bd1563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_linear_df = train_df.copy()\n",
    "# valid_linear_df = valid_df.copy()\n",
    "# test_linear_df = test_df.copy()\n",
    "# tv_linear_df = tv_df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba467720-1d42-496b-b3da-5de3bb8a49ce",
   "metadata": {},
   "source": [
    "### Forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43861d3a-3563-44c3-beda-b5845e37a2b2",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "I'll hard-code them for now, but in the future may Optuna them. May want to create a dict of all the kwargs to be used for all the models, with the model names as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb09c068-f227-4f7b-bdf3-1ea5250c4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "#     'holidays':holidays_train, # will add this in-function\n",
    "    'n_changepoints':10,\n",
    "    'changepoint_range':0.4,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_prior_scale':25,\n",
    "    'holidays_prior_scale':100,\n",
    "    'changepoint_prior_scale':0.01,\n",
    "    'interval_width':0.5,\n",
    "    'uncertainty_samples':False\n",
    "}\n",
    "\n",
    "neuralprophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "    'n_changepoints':10,\n",
    "    'changepoints_range':0.4,\n",
    "    'trend_reg':1,\n",
    "    'trend_reg_threshold':False,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_reg':1,\n",
    "    'n_forecasts':365,\n",
    "    'normalize':'off'\n",
    "}\n",
    "\n",
    "# for pytorch / skorch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tcn_kwargs = {\n",
    "#     'module': estimator, # will be handled at-call\n",
    "#     'criterion': nn.MSELoss, # consider enhancement here\n",
    "#     \"lr\": 0.01, # default is 0.01\n",
    "#     'optimizer':Adam,\n",
    "#     'max_epochs':10, # default is 10\n",
    "#     'device': 'cpu'#device,\n",
    "    \n",
    "}\n",
    "\n",
    "tcn_skorch_kwargs = {\n",
    "    'module__num_inputs':1,\n",
    "    'module__num_channels':[10] * 11,\n",
    "    'module__output_sz':1, #2 * samples_per_hour,\n",
    "    'module__kernel_size':5,\n",
    "    'module__dropout':0.0,\n",
    "    'max_epochs':60, # 60,\n",
    "    'batch_size':256,\n",
    "    'lr':2e-3,\n",
    "    'optimizer':torch.optim.Adam,\n",
    "    'train_split':None,\n",
    "}\n",
    "\n",
    "mlp_skorch_kwargs = {\n",
    "    'module__n_inputs': tv_df.shape[1],\n",
    "    'module__hidden_units': 200, \n",
    "    'module__dropout': 0.2,\n",
    "    'max_epochs':25, # 60,\n",
    "    'batch_size':256,\n",
    "    'lr':2e-3,\n",
    "    'optimizer':torch.optim.Adam,\n",
    "    'train_split':None,\n",
    "}\n",
    "\n",
    "\n",
    "# model_params['hyperparams'] = str(neuralprophet_kwargs)\n",
    "# model_params['holiday_source'] = 'Prophet builtin for each country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e2eed0b-6f99-4ab0-8856-7de608f31e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26298, 208)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ee65f32-a819-4d1e-95f8-b723186618de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4207,\n",
       " 'learning_rate': 0.05378597302351865,\n",
       " 'reg_alpha': 0.0067949392113948815,\n",
       " 'reg_lambda': 0.04865823628931899,\n",
       " 'subsample': 0.212875760245356,\n",
       " 'min_child_weight': 6.997692447967251,\n",
       " 'colsample_bytree': 0.9824893256584818,\n",
       " 'gamma': 0.10395228539921328,\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost_params = load(studypath/'optuna_xgboost_study-20220126213551.joblib').best_trial.params\n",
    "best_xgboost_params['max_depth'] = best_xgboost_params['depth']\n",
    "del best_xgboost_params['depth']\n",
    "best_xgboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d31271cf-143b-4757-8846-332755b60bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 10529,\n",
       " 'learning_rate': 0.07026263205443048,\n",
       " 'random_strength': 44,\n",
       " 'od_wait': 261,\n",
       " 'reg_lambda': 35.672029887566374,\n",
       " 'border_count': 57,\n",
       " 'min_child_samples': 19,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'max_depth': 3}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_catboost_params = load(studypath/'optuna_catboost_study-20220127082356.joblib').best_trial.params\n",
    "best_catboost_params['max_depth'] = best_catboost_params['depth']\n",
    "del best_catboost_params['depth']\n",
    "best_catboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e01a025-a733-47ec-91a8-cad11f790c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 6078,\n",
       " 'learning_rate': 0.03612108919426432,\n",
       " 'reg_alpha': 0.008631524966022684,\n",
       " 'reg_lambda': 0.19537138720003774,\n",
       " 'subsample': 0.9601129223632775,\n",
       " 'min_child_samples': 24,\n",
       " 'num_leaves': 235,\n",
       " 'colsample_bytree': 0.920126987868937,\n",
       " 'max_depth': 3}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lightgbm_params = load(studypath/'optuna_lightgbm_study-20220127171126.joblib').best_trial.params\n",
    "best_lightgbm_params['max_depth'] = best_lightgbm_params['depth']\n",
    "del best_lightgbm_params['depth']\n",
    "best_lightgbm_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "613b0aa9-021e-4a6f-ac7b-c984ec272d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {\n",
    "    # universal\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'eval_metric': ['mae', 'mape', 'rmse'],\n",
    "#     'sampling_method': 'gradient_based',\n",
    "#     'grow_policy': 'lossguide',\n",
    "    \n",
    "    # best of 500 trials on Optuna\n",
    "    **best_xgboost_params\n",
    "}\n",
    "\n",
    "\n",
    "lightgbm_params = {\n",
    "    # universal\n",
    "    'objective': 'mse',\n",
    "#     'random_state': 42,\n",
    "    'device_type': 'cpu',\n",
    "    'n_jobs': -1,\n",
    "#                 eval_metric='auc',\n",
    "#     'device_type': 'gpu',\n",
    "#     'max_bin': 63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     'gpu_use_dp': False,\n",
    "#     'max_depth': 0,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'subsample': .15,\n",
    "#     'n_estimators': 1500,\n",
    "    **best_lightgbm_params\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    # universal\n",
    "#     'task_type':'GPU',\n",
    "#     'silent':True,\n",
    "#     'random_state':42,\n",
    "    \n",
    "    # from trial 4 (of 5) via Optuna\n",
    "    **best_catboost_params\n",
    "}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a1217-bc47-416d-b73e-95aceae3f973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b011357f-a7bd-4317-8a57-d06434cce590",
   "metadata": {},
   "source": [
    "#### Temporal Convolutional Network\n",
    "\n",
    "Implementation from https://www.kaggle.com/ceshine/pytorch-temporal-convolutional-networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40c8569c-05f5-418e-a269-27c5d8e6ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TemporalBlock(nn.Module):\n",
    "#     def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "#         super(TemporalBlock, self).__init__()\n",
    "        \n",
    "#         # this is the first convolutional layer; note that it foregoes padding irrespective of argument\n",
    "#         self.conv1 = weight_norm(nn.Conv2d(n_inputs, n_outputs, (1, kernel_size),\n",
    "#                                            stride=stride, padding=0, dilation=dilation))\n",
    "#         # the padding is then added after the first conv layer\n",
    "#         self.pad = torch.nn.ZeroPad2d((padding, 0, 0, 0))\n",
    "#         # this is a very standard choice\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#         # the second convolutional layer in the block is identical to the first, but now padding has been added to the input\n",
    "#         self.conv2 = weight_norm(nn.Conv2d(n_outputs, n_outputs, (1, kernel_size),\n",
    "#                                            stride=stride, padding=0, dilation=dilation))\n",
    "        \n",
    "#         # this simply strings together the above architectural elements, for convenience I guess\n",
    "#         self.net = nn.Sequential(self.pad, self.conv1, self.relu, self.dropout,\n",
    "#                                  self.pad, self.conv2, self.relu, self.dropout)\n",
    "        \n",
    "#         # if the n_outputs is nonzero, this adds on a final convlutional layer to ensure that we get the desired number of outputs\n",
    "#         self.downsample = nn.Conv1d(\n",
    "#             n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "#         self.relu = nn.ReLU()\n",
    "        \n",
    "#         # this initializes the weights as specified in the separate weight initialization method, below\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         # this method initializes the weights for the Conv1D and Conv2D layers, plus the Downsample layer (if it's used)\n",
    "#         self.conv1.weight.data.normal_(0, 0.01)\n",
    "#         self.conv2.weight.data.normal_(0, 0.01)\n",
    "#         if self.downsample is not None:\n",
    "#             self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # note the nice one-liner here, to add in the requisite number of dimensions both inbound to the NN and outbound\n",
    "#         out = self.net(x.unsqueeze(2)).squeeze(2) # original\n",
    "# #         out = self.net(x.unsqueeze(3)).squeeze(3) # my revision to address RuntimeError: Expected 4-dimensional input for 4-dimensional weight [32, 128, 1, 2], but got 3-dimensional input of size [128, 244, 2] instead\n",
    "# #         out = self.net(x.unsqueeze(3)).squeeze(2) # further revision to address IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)\n",
    "#         # is this a residual, then?\n",
    "#         res = x if self.downsample is None else self.downsample(x)\n",
    "#         return self.relu(out + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d30fb0e2-e39f-4ce8-90d2-7bf89dc20636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TemporalConvNet(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         '''\n",
    "#         What does num_channels mean? See Obsidian 202201270954... It seems that it should be a \n",
    "#         list, with the number of hidden channels (i.e. activation units in each hidden layer), \n",
    "#         repeated the number of hidden layers there are. E.g. [25,25,25,25]. An alternate idea:\n",
    "#         it's [hidden_size]*(level_size-1) + [embedding_size]\n",
    "        \n",
    "#         I think that \n",
    "#         '''\n",
    "        \n",
    "#         super(TemporalConvNet, self).__init__()\n",
    "#         layers = []\n",
    "#         num_levels = len(num_channels)\n",
    "#         for i in range(num_levels):\n",
    "#             dilation_size = 2 ** i\n",
    "#             in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "#             out_channels = num_channels[i]\n",
    "#             layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "#                                      padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "#         self.network = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feae9ef8-7b82-4211-acd1-68ddf7c46369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TCNModel(nn.Module):\n",
    "#     def __init__(self, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         super(TCNModel, self).__init__()\n",
    "#         self.tcn = TemporalConvNet(\n",
    "#             128, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.decoder = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.decoder(self.dropout(self.tcn(x)[:, :, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984bcdd6-241e-4a58-93ed-5f1b6537ceec",
   "metadata": {},
   "source": [
    "Going to use the [original implementation](https://github.com/locuslab/TCN/blob/master/TCN/tcn.py) (via the discussion [here](https://www.ethanrosenthal.com/2019/02/18/time-series-for-scikit-learn-people-part3/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a868a59-9181-4b1a-8456-f545ae191d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs, hidden_units, dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dense0 = nn.Linear(n_inputs, hidden_units)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.dense1 = nn.Linear(hidden_units, hidden_units // 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.dense2 = nn.Linear(hidden_units // 2, (hidden_units // 2) // 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.dense3 = nn.Linear((hidden_units // 2) // 2, ((hidden_units // 2) // 2) // 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.head = nn.Linear(((hidden_units // 2) // 2) // 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout0(self.relu0(self.dense0(x)))\n",
    "        x = self.dropout1(self.relu1(self.dense1(x)))\n",
    "        x = self.dropout2(self.relu2(self.dense2(x)))\n",
    "        x = self.dropout3(self.relu3(self.dense3(x)))\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b0cde14-0da1-4b88-8188-9798cc893805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, output_sz,\n",
    "                 kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
    "                                     dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size,\n",
    "                                     dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_sz)\n",
    "        self.last_activation = nn.ReLU()\n",
    "        self.output_sz = output_sz\n",
    "        # self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_sz = x.shape[0]\n",
    "        out = self.network(x.unsqueeze(1))\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.linear(out).mean(dim=1)\n",
    "        out = out.to(dtype=torch.float32) # my addition\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65016b8f-c72f-4ba7-bc12-0d5d642107af",
   "metadata": {},
   "source": [
    "#### Trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5ffca-0447-4184-ac30-5a2c1eaa07c9",
   "metadata": {},
   "source": [
    "##### NeuralProphet\n",
    "I'm leaving the folds as they are. ~~Label encoding shouldn't matter -- the values are just being iterated over anyway.~~ It does matter because the Prophets use the strings to identify countries' holidays to add. Not sure about doing the target transform -- if you try it, just have the trainer call pass `target='target'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7142a2b-316b-49c7-b6ad-732d79681d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_folds = [\n",
    "    ('2015-01-01', '2018-01-01'),\n",
    "    ('2018-01-01', '2019-01-01'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cfd9ca4-04db-4176-b787-317eb91f544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_tv_df = tv_df_encoded.copy() # encoded_tv_df.copy()\n",
    "# prophet_test_df = test_df_encoded.copy() # encoded_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d618ce1-5b3f-470f-8c46-878f30aa7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in ['country', 'product', 'store']:\n",
    "#     prophet_tv_df[feature] = orig_train_df[feature]\n",
    "#     prophet_test_df[feature] = orig_test_df[feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a9c69c6-7581-4401-9c83-16c1d4ece031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_tv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "308e48c6-ca35-425d-acdb-493ed48e2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_enc = le_dict['country'].transform(countries)\n",
    "# stores_enc = le_dict['store'].transform(stores)\n",
    "# products_enc = le_dict['product'].transform(products)\n",
    "\n",
    "# countries, countries_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "839064d9-a771-4785-a99b-c951404801aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neuralprophet_trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=prophet_folds, \n",
    "                          tv_df=tv_df, test_df=test_df,\n",
    "#                           df_train=tv_df, df_test=test_df, \n",
    "                          target='num_sold', wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    # no label encoding here -- but test it with too\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', target: 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', target: 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'neuralprophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'neuralprophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test['y'] = np.nan\n",
    "                    test_predictions = model.predict(test)['yhat1']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "#     train_\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train['neuralprophet_forecast'], df_test['neuralprophet_forecast']#, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd79c6c-8b25-41fe-bb2e-37b2ba1516ef",
   "metadata": {},
   "source": [
    "##### Prophet Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46a508af-0494-4762-b9bf-f0909a402ad5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prophet_trainer(prophet_kwargs=prophet_kwargs, countries=countries, stores=stores, products=products, folds=prophet_folds, \n",
    "                    tv_df=tv_df, test_df=test_df,\n",
    "#                           df_train=tv_df, df_test=test_df, \n",
    "                    target='num_sold', wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "                    \n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', target]].reset_index(drop=True)\n",
    "#                     print(train.shape)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', target: 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', target: 'y'})\n",
    "\n",
    "                    model = Prophet(**prophet_kwargs)\n",
    "\n",
    "                    model.add_country_holidays(country_name=country) # uses FacebookProphet API to add holidays\n",
    "                    model.fit(train)\n",
    "        \n",
    "                    train_predictions = model.predict(train[['ds']])['yhat']\n",
    "                    val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test_predictions = model.predict(test[['ds']])['yhat']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'prophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train['prophet_forecast'], df_test['prophet_forecast']#, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d6d95-57f2-4634-89a0-5289ed4ca6a2",
   "metadata": {},
   "source": [
    "##### Scikit-Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2ce0522-8e44-4618-ad57-75c4ea4900cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sklearn_trainer(estimator, model_kwargs={}, tv_df=tv_df, test_df=test_df, #X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                    folds=prophet_folds, countries=countries, stores=stores, products=products, target='target',\n",
    "#                     by_combo=True, \n",
    "#                     model_type=None, # None -> fully scikit-learn compatible; alternatives are 'skorch' or 'gbm'\n",
    "                    wandb_tracked=False):\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, tv_df = label_encoder(df_train) # should leave broader scope's tv_df alone\n",
    "    _, test_df = label_encoder(df_test) # should leave broader scope's test_df alone\n",
    "    del df_train, df_test\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    # drop whichever version of the dependent variable is not being used\n",
    "#     for df in [tv_df, test_df]:\n",
    "    if target == 'num_sold': \n",
    "        tv_df = tv_df.drop(columns=['target'])\n",
    "        test_df = test_df.drop(columns=['target'])\n",
    "    else:\n",
    "        tv_df = tv_df.drop(columns=['num_sold'])\n",
    "        test_df = test_df.drop(columns=['num_sold'])\n",
    "            \n",
    "#     print(\"'num_sold' in test_df.columns == \", 'num_sold' in test_df.columns)\n",
    "    \n",
    "    # handling each combination of country, store, and product separately\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (tv_df['date'] >= start) &\\\n",
    "                                (tv_df['date'] < end) &\\\n",
    "                                (tv_df['country'] == country) &\\\n",
    "                                (tv_df['store'] == store) &\\\n",
    "                                (tv_df['product'] == product)\n",
    "\n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = tv_df.loc[train_idx, :].reset_index(drop=True)\n",
    "#                         print(train.shape)\n",
    "\n",
    "                    val_idx = (tv_df['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (tv_df['date'] < folds[fold + 1][1]) &\\\n",
    "                              (tv_df['country'] == country) &\\\n",
    "                              (tv_df['store'] == store) &\\\n",
    "                              (tv_df['product'] == product)\n",
    "\n",
    "                    val = tv_df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    test_idx = (test_df['country'] == country) &\\\n",
    "                               (test_df['store'] == store) &\\\n",
    "                               (test_df['product'] == product)\n",
    "                    test = test_df.loc[test_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    # with the training and validation sets sorted out, make them integers for model fitting\n",
    "                    for df in [train, val, test]:\n",
    "                        df['date'] = df['date'].map(dt.datetime.toordinal)\n",
    "                    if 'model_forecast' in train.columns:\n",
    "                        X = train.drop(columns=[target, 'model_forecast'])\n",
    "                        X_valid = val.drop(columns=[target, 'model_forecast'])\n",
    "                        X_test = test.drop(columns=[target, 'model_forecast'])\n",
    "                    else:\n",
    "                        X = train.drop(columns=[target])\n",
    "                        X_valid = val.drop(columns=[target])\n",
    "                        X_test = test.drop(columns=[target])\n",
    "\n",
    "                    y = train[target]\n",
    "                    y_valid = val[target]\n",
    "\n",
    "\n",
    "#                         print(type(X), type(y))\n",
    "#                         print(f\"X has {X.isna().any().sum()} NaNs\")\n",
    "#                         print(f\"y has {y.isna().sum()} NaNs\")\n",
    "#                     print(X_test.info())\n",
    "#                     print(y_valid.dtype)\n",
    "    \n",
    "#                     if model_type == 'skorch':\n",
    "# #                         for df in [X, X_valid, X_test]:\n",
    "# # #                             df['date'] = df['date'].apply(dt.datetime.toordinal)\n",
    "# #                             df = torch.tensor(df.to_numpy(dtype=np.float32))\n",
    "# #                         for target in [y, y_valid]:\n",
    "# #                             target = torch.tensor(np.array(target))\n",
    "# # #                             target = target.reshape(-1,1)\n",
    "# #                             target = target.unsqueeze(0)\n",
    "#                         X = torch.tensor(X.to_numpy(dtype=np.float32))\n",
    "#                         X_valid = torch.tensor(X_valid.to_numpy(dtype=np.float32))\n",
    "#                         X_test = torch.tensor(X_test.to_numpy(dtype=np.float32))\n",
    "            \n",
    "#                         y = torch.tensor(np.array(y)).reshape(-1,1)\n",
    "#                         y_valid = torch.tensor(np.array(y)).reshape(-1,1)\n",
    "    \n",
    "#                         tcn_kwargs = {\n",
    "#                             'num_channels': [32,32,32,32],\n",
    "#                         }\n",
    "#                         print(type(y), type(y_valid))\n",
    "# #                         y = y.reshape(-1,1)\n",
    "# #                         y_valid = y_valid.reshape(-1,1)\n",
    "#                         # create the Datasets\n",
    "                \n",
    "#                         # create the DataLoaders\n",
    "\n",
    "#                         # instantiate the wrapper\n",
    "#                         model = NeuralNetRegressor(\n",
    "#                             module=estimator(**tcn_kwargs),\n",
    "#                             **model_kwargs\n",
    "#                         )\n",
    "#                     elif model_type=='gbm':\n",
    "                        \n",
    "#                     else:\n",
    "                    model = estimator(**model_kwargs)\n",
    "\n",
    "                    model.fit(X,y)\n",
    "\n",
    "                    model_train_preds = model.predict(X)\n",
    "                    model_valid_preds = model.predict(X_valid)\n",
    "                    model_test_preds = model.predict(X_test)\n",
    "\n",
    "                    tv_df.loc[train_idx, 'model_forecast'] = model_train_preds#.values\n",
    "                    tv_df.loc[val_idx, 'model_forecast'] =  model_valid_preds#.values\n",
    "                    test_df.loc[test_idx, 'model_forecast'] = model_test_preds#.values\n",
    "\n",
    "\n",
    "    # reverse the dependent variable transform if appropriate\n",
    "    if target == 'target':\n",
    "#             model_tv_preds = np.multiply(np.exp(model_tv_preds), tv_df['gdp']**gdp_exponent)\n",
    "        tv_df['model_forecast'] = np.exp(tv_df['model_forecast']) * tv_df['gdp']**gdp_exponent\n",
    "#             output_tv_df['model_forecast'] = np.exp(output_tv_df['model_forecast']) * output_tv_df['gdp']**gdp_exponent\n",
    "\n",
    "#             model_test_preds = np.multiply(np.exp(model_test_preds), test_df['gdp']**gdp_exponent)\n",
    "        test_df['model_forecast'] = np.exp(test_df['model_forecast']) * test_df['gdp']**gdp_exponent\n",
    "#             output_test_df['model_forecast'] = np.exp(output_test_df['model_forecast']) * output_test_df['gdp']**gdp_exponent\n",
    "#             model_test_preds = np.exp(model_test_preds) * test_df['gdp']**gdp_exponent\n",
    "        \n",
    "#         tv_df['model_forecast'] = model_tv_preds\n",
    "#         test_df['model_forecast'] = model_test_preds\n",
    "#     return output_tv_df, output_test_df\n",
    "    return tv_df['model_forecast'], test_df['model_forecast']\n",
    "#     return tv_df['model_forecast'], test_df['model_forecast']\n",
    "#     return model_tv_preds, model_test_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17cdb83-a789-4a40-a45e-550eda42f4f7",
   "metadata": {},
   "source": [
    "##### Skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b9af474-5d20-4906-bde3-5cfaa214daff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def skorch_trainer(model=TemporalConvNet, model_kwargs={}, tv_df=tv_df, test_df=test_df, #X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "#                 countries=countries, stores=stores, products=products, random_seed=SEED,\n",
    "#                 target='target', wandb_tracked=False, forecasting=True):\n",
    "    \n",
    "#     # preprocessing\n",
    "    \n",
    "#     if USE_GPU and torch.cuda.is_available():\n",
    "#         device = 'cuda' \n",
    "#     else:\n",
    "#         device = 'cpu'\n",
    "    \n",
    "#     # start by creating working copies of dataframes to avoid mutation\n",
    "#     working_tv_df = tv_df.copy()\n",
    "#     working_test_df = test_df.copy()\n",
    "    \n",
    "#     # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "#     le_dict, working_tv_df = label_encoder(working_tv_df) # should leave broader scope's tv_df alone\n",
    "#     _, working_test_df = label_encoder(working_test_df) # should leave broader scope's test_df alone\n",
    "# #     del df_train, df_test\n",
    "    \n",
    "#     # encode the lists of countries, stores, and products\n",
    "#     countries = le_dict['country'].transform(countries)\n",
    "#     stores = le_dict['store'].transform(stores)\n",
    "#     products = le_dict['product'].transform(products)\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         exmodel_config['arch'] = arch\n",
    "# #         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "#         wandb.init(\n",
    "#             project=\"202201_Kaggle_tabular_playground\",\n",
    "#             save_code=True,\n",
    "#             tags=wandb_config['tags'],\n",
    "#             name=wandb_config['name'],\n",
    "#             notes=wandb_config['notes'],\n",
    "#             config=exmodel_config\n",
    "#     )\n",
    "    \n",
    "#     if forecasting: # if not, implement GroupKFold\n",
    "#         train_df = working_tv_df[working_tv_df['date'] < '2018-01-01']\n",
    "#         valid_df = working_tv_df[working_tv_df['date'] >= '2018-01-01']\n",
    "    \n",
    "#     # convert the dates to ordinals\n",
    "#     train_df['date'] = train_df['date'].map(dt.datetime.toordinal)\n",
    "#     valid_df['date'] = valid_df['date'].map(dt.datetime.toordinal)\n",
    "#     working_test_df['date'] = working_test_df['date'].map(dt.datetime.toordinal)\n",
    "    \n",
    "#     # typecast to np.float32\n",
    "#     train_df = train_df.astype(np.float32)\n",
    "#     valid_df = valid_df.astype(np.float32)\n",
    "#     working_test_df = working_test_df.astype(np.float32)\n",
    "    \n",
    "#     # clean up features\n",
    "#     X = train_df.drop(columns=['num_sold', 'target'])\n",
    "#     y = train_df[target]\n",
    "    \n",
    "#     X_valid = valid_df.drop(columns=['num_sold', 'target'])\n",
    "#     y_valid = valid_df[target]\n",
    "    \n",
    "#     X_test = working_test_df.drop(columns=['num_sold', 'target'])\n",
    "    \n",
    "#     # tensorify\n",
    "#     X = torch.tensor(X.values, dtype=torch.float32)\n",
    "#     X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "#     X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "#     y = torch.tensor(np.array(y).reshape(-1,1), dtype=torch.float32)\n",
    "#     y_valid = torch.tensor(np.array(y_valid).reshape(-1,1), dtype=torch.float32)\n",
    "    \n",
    "#     print(X.shape, y.shape)\n",
    "#     print(X.dtype, y.dtype)\n",
    "    \n",
    "#     model = NeuralNetRegressor(\n",
    "#         module=model,\n",
    "#         module__num_inputs=1,\n",
    "#         module__num_channels=[10] * 11,\n",
    "#         module__output_sz=1, #2 * samples_per_hour,\n",
    "#         module__kernel_size=5,\n",
    "#         module__dropout=0.0,\n",
    "#         max_epochs=3, # 60,\n",
    "#         batch_size=256,\n",
    "#         lr=2e-3,\n",
    "#         optimizer=torch.optim.Adam,\n",
    "#         device=device,\n",
    "#     #     iterator_train__shuffle=True,\n",
    "#     #     callbacks=[GradientNormClipping(gradient_clip_value=1,\n",
    "#     #                                     gradient_clip_norm_type=2)],\n",
    "#         train_split=None,\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X,y)\n",
    "    \n",
    "#     y_valid_preds = model.predict(X_valid)\n",
    "# #     tv_preds = model.predict()\n",
    "#     test_preds = model.predict(X_test)\n",
    "    \n",
    "# #     print(f\"SMAPE on validation set (2018) is: {SMAPE(y_pred=y_valid_preds, y_true=y_valid)}\")\n",
    "    \n",
    "#     return model, y_valid_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b250930-2bc7-48e7-b401-ddce2a74e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ae685b4-143a-418a-b042-79d3bb7a1553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def skorch_trainer(model, model_kwargs={}, tv_df=tv_df, test_df=test_df, folds=prophet_folds,#X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                countries=countries, stores=stores, products=products, random_seed=SEED,\n",
    "                target='target', wandb_tracked=False, forecasting=True):\n",
    "    \n",
    "    # preprocessing\n",
    "    \n",
    "    if USE_GPU and torch.cuda.is_available():\n",
    "        device = 'cuda' \n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # start by creating working copies of dataframes to avoid mutation\n",
    "#     working_tv_df = tv_df.copy()\n",
    "#     working_test_df = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, tv_df = label_encoder(tv_df) # should leave broader scope's tv_df alone\n",
    "    _, test_df = label_encoder(test_df) # should leave broader scope's test_df alone\n",
    "#     del df_train, df_test\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "#     y_tv = tv_df['num_sold']\n",
    "    tv_preds = pd.Series(0, index=tv_df.index)\n",
    "    test_preds = pd.Series(0, index=test_df.index)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    # handling each combination of country, store, and product separately\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                print(f\"Training {le_dict['country'].inverse_transform([country])}, {le_dict['store'].inverse_transform([store])}, {le_dict['product'].inverse_transform([product])}\")\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (tv_df['date'] >= start) &\\\n",
    "                                (tv_df['date'] < end) &\\\n",
    "                                (tv_df['country'] == country) &\\\n",
    "                                (tv_df['store'] == store) &\\\n",
    "                                (tv_df['product'] == product)\n",
    "\n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = tv_df.loc[train_idx, :].reset_index(drop=True)\n",
    "#                         print(train.shape)\n",
    "\n",
    "                    val_idx = (tv_df['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (tv_df['date'] < folds[fold + 1][1]) &\\\n",
    "                              (tv_df['country'] == country) &\\\n",
    "                              (tv_df['store'] == store) &\\\n",
    "                              (tv_df['product'] == product)\n",
    "\n",
    "                    val = tv_df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    test_idx = (test_df['country'] == country) &\\\n",
    "                               (test_df['store'] == store) &\\\n",
    "                               (test_df['product'] == product)\n",
    "                    test = test_df.loc[test_idx, :].reset_index(drop=True)\n",
    "                    \n",
    "                    y = train[target]\n",
    "                    y_valid = val[target]\n",
    "                    \n",
    "                    # with the training and validation sets sorted out, make them integers for model fitting\n",
    "                    for df in [train, val, test]:\n",
    "                        df['date'] = df['date'].map(dt.datetime.toordinal)\n",
    "                        df = df.drop(columns=['num_sold', 'target'], inplace=True)\n",
    "#                         df = df.astype(np.float32)\n",
    "                    \n",
    "#                     print(train.columns)\n",
    "#                     print(train.dtypes)\n",
    "#                     train_df = train_df.astype(np.float32)\n",
    "                    X, X_valid, X_test = train.astype(np.float32), val.astype(np.float32), test.astype(np.float32)\n",
    "#                         for feature in ['num_sold', 'target', 'model_forecast']:\n",
    "#                             if feature in df.columns:\n",
    "#                                 df = df.drop(columns=feature)\n",
    "#                     if 'model_forecast' in train.columns:\n",
    "#                         X = train.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                         X_valid = val.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                         X_test = test.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                     else:\n",
    "#                         X = train.drop(columns=['num_sold', 'target'])\n",
    "#                         X_valid = val.drop(columns=['num_sold', 'target'])\n",
    "#                         X_test = test.drop(columns=['num_sold', 'target'])\n",
    "\n",
    "                    \n",
    "                    \n",
    "#                     X = train_df.drop(columns=['num_sold', 'target'])\n",
    "#                     y = train_df[target]\n",
    "\n",
    "#                     X_valid = valid_df.drop(columns=['num_sold', 'target'])\n",
    "#                     y_valid = valid_df[target]\n",
    "\n",
    "#                     X_test = working_test_df.drop(columns=['num_sold', 'target'])\n",
    "\n",
    "                    # tensorify\n",
    "#                     print(X.dtypes)\n",
    "#                     print(type(X.values))\n",
    "                    X = torch.tensor(X.values, dtype=torch.float32)\n",
    "                    X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "                    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "                    y = torch.tensor(np.array(y).reshape(-1,1), dtype=torch.float32)\n",
    "                    y_valid = torch.tensor(np.array(y_valid).reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "#                     print(X.shape, y.shape)\n",
    "#                     print(X.dtype, y.dtype)\n",
    "\n",
    "                    net = NeuralNetRegressor(\n",
    "                        module=model,\n",
    "                        device=device,\n",
    "                        **model_kwargs\n",
    "                    #     iterator_train__shuffle=True,\n",
    "#                         callbacks=[Checkpoint(dirname=modelpath/'20220128-TCN-country{country}-store{store}-product{product}/')],\n",
    "                    #     callbacks=[GradientNormClipping(gradient_clip_value=1,\n",
    "                    #                                     gradient_clip_norm_type=2)],\n",
    "                        \n",
    "                    )\n",
    "\n",
    "                    net.fit(X,y)\n",
    "                    \n",
    "                    net.save_params(f_params=modelpath/f'20220128-TCN-country{country}-store{store}-product{product}-model_params.pkl')\n",
    "            \n",
    "                    y_train_preds = np.squeeze(net.predict(X))\n",
    "                    y_valid_preds = np.squeeze(net.predict(X_valid))\n",
    "                    fold_test_preds = np.squeeze(net.predict(X_test))\n",
    "#                     print(f\"Shape of fold test preds is {fold_test_preds.shape}\")\n",
    "\n",
    "                    tv_preds[train_idx] = y_train_preds\n",
    "                    tv_preds[val_idx] = y_valid_preds\n",
    "                    test_preds[test_idx] = fold_test_preds\n",
    "            \n",
    "                    print(f\"Valid SMAPE for {le_dict['country'].inverse_transform([country])}, {le_dict['store'].inverse_transform([store])}, {le_dict['product'].inverse_transform([product])} is {SMAPE(y_true=tv_df.loc[val_idx, 'num_sold'], y_pred=y_valid_preds)}\")\n",
    "                    \n",
    "    # reverse the dependent variable transform if appropriate\n",
    "    if target == 'target':\n",
    "#             model_tv_preds = np.multiply(np.exp(model_tv_preds), tv_df['gdp']**gdp_exponent)\n",
    "#         tv_df['model_forecast'] = np.exp(tv_df['model_forecast']) * tv_df['gdp']**gdp_exponent\n",
    "        tv_preds = np.exp(tv_preds) * tv_df['gdp']**gdp_exponent\n",
    "        test_preds = np.exp(test_preds) * test_df['gdp']**gdp_exponent\n",
    "        \n",
    "    return tv_preds, test_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a1836-4b75-40c1-90e6-08878c6953d3",
   "metadata": {},
   "source": [
    "##### GBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a09550a2-eee0-4fde-a083-c7c644133e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb330ff5-a835-4e03-bd2b-efbc21169df0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gbm_trainer(arch:str, model_kwargs={}, tv_df=tv_df, test_df=test_df,  #X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                countries=countries, stores=stores, products=products, random_seed=SEED,\n",
    "                target='target', wandb_tracked=False):\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    X = tv_df.copy()\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, X = label_encoder(X) # should leave broader scope's tv_df alone\n",
    "    _, X_test = label_encoder(X_test) # should leave broader scope's test_df alone\n",
    "#     del df_train, df_test\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "#     train_smape = 0\n",
    "#     val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "        )\n",
    "    \n",
    "    # drop whichever version of the dependent variable is not being used\n",
    "#     for df in [tv_df, test_df]:\n",
    "    y = X[target]\n",
    "#     for df in [X, X_test]:\n",
    "#         df = df.drop(columns=['num_sold', 'target'])\n",
    "    X = X.drop(columns=['num_sold', 'target'])\n",
    "    X_test = X_test.drop(columns=['num_sold', 'target'])\n",
    "#     X = X.drop(columns)\n",
    "#     if target == 'num_sold': \n",
    "#         y = X['num_sold']\n",
    "#         X = X.drop(columns=['target'])\n",
    "#         X_test = X_test.drop(columns=['target'])\n",
    "#     else:\n",
    "#         X = X.drop(columns=['num_sold'])\n",
    "#         X_test = X_test.drop(columns=['num_sold'])\n",
    "    \n",
    "    kfold = GroupKFold(n_splits=4)\n",
    "    oof_preds = pd.Series(0, index=tv_df.index)\n",
    "#     oof_preds, oof_y = [], []\n",
    "#     test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_preds = pd.Series(0, index=test_df.index)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(tv_df, groups=tv_df.date.dt.year)):\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        # remove dates \n",
    "#         for df in [X, X_test]:\n",
    "#             df = df.drop(columns=['date'])\n",
    "        if 'date' in X.columns:\n",
    "            X = X.drop(columns=['date'])\n",
    "            X_test = X_test.drop(columns=['date'])#, 'num_sold'])\n",
    "        \n",
    "        y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "        X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:]\n",
    "        \n",
    "        if arch == 'xgboost':\n",
    "            model = XGBRegressor(\n",
    "                tree_method= 'gpu_hist',\n",
    "                predictor= 'gpu_predictor',\n",
    "                eval_metric= ['mae', 'mape'],\n",
    "                sampling_method= 'gradient_based',\n",
    "                grow_policy= 'lossguide',\n",
    "                seed=random_seed,\n",
    "                objective='reg:squarederror',\n",
    "                **model_kwargs)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        elif arch == 'lightgbm':\n",
    "            model = LGBMRegressor(\n",
    "                random_state=random_seed,\n",
    "                **model_kwargs)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostRegressor(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_seed,\n",
    "                **model_kwargs)\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_preds = model.predict(X_valid)\n",
    "        \n",
    "        oof_preds[valid_ids] = y_valid_preds\n",
    "#         oof_preds.extend(y_valid_preds)\n",
    "#         oof_y.extend(y_valid)\n",
    "        \n",
    "        if arch == 'catboost':\n",
    "            test_preds += model.predict(X_test).flatten()\n",
    "        else:\n",
    "            test_preds += model.predict(X_test)\n",
    "        \n",
    "#         fold_smape = SMAPE(y_true=y_valid, y_pred=y_valid_preds)\n",
    "#         print(f\"FOLD {fold} OOF SMAPE: {fold_smape}\")\n",
    "    test_preds /= 4 # taking the average of the test preds\n",
    "    \n",
    "    if target == 'target':\n",
    "        oof_preds = np.exp(oof_preds) * tv_df['gdp']**gdp_exponent\n",
    "        test_preds = np.exp(test_preds) * test_df['gdp']**gdp_exponent\n",
    "        \n",
    "    smape = SMAPE(y_pred=oof_preds, y_true=tv_df['num_sold'])\n",
    "#     print(\"Lengths of oof_preds and tv_df[target] are same? \", len(oof_preds) == len(tv_df[target]))\n",
    "#     print(oof_preds[:10])\n",
    "#     print(tv_df[target][:10])\n",
    "    print(f\"SMAPE: {smape}\")\n",
    "    if wandb_tracked:\n",
    "        wandb.log({\n",
    "            'arch': arch,\n",
    "            'SMAPE': smape,\n",
    "            'model_params': str(model_kwargs),\n",
    "            'model_seed': random_state\n",
    "        })\n",
    "        wandb.finish()\n",
    "    return oof_preds, test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a60ac-1593-4e94-be1e-732628d68de3",
   "metadata": {},
   "source": [
    "# TSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3efebcd1-c71b-4f4c-9d19-8e025903cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv_np = np.array(tv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ad39960-fe98-4ff7-a53e-8fdfbda6cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mTSRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Transforms an object dtype to float (vectorized)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/time/lib/python3.8/site-packages/tsai/data/core.py\n",
       "\u001b[0;31mType:\u001b[0m           _TfmMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?TSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8eb24-2d0e-4df7-be7d-ead4ade9d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tv_df.drop(columns=['num_sold', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78b8cace-e826-48e3-97c1-6cb469a2fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AppliancesEnergy',\n",
       " 'AustraliaRainfall',\n",
       " 'BeijingPM10Quality',\n",
       " 'BeijingPM25Quality',\n",
       " 'BenzeneConcentration',\n",
       " 'Covid3Month',\n",
       " 'FloodModeling1',\n",
       " 'FloodModeling2',\n",
       " 'FloodModeling3',\n",
       " 'HouseholdPowerConsumption1',\n",
       " 'HouseholdPowerConsumption2',\n",
       " 'IEEEPPG',\n",
       " 'LiveFuelMoistureContent',\n",
       " 'NewsHeadlineSentiment',\n",
       " 'NewsTitleSentiment']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e89f5b66-46af-49e2-a36c-00b2701c22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'AppliancesEnergy'\n",
    "X, y, splits = get_regression_data(dsid, split_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b97f165-05fd-4d58-9af4-0054e9ef66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 24, 144), (137,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e039eb7e-bcf0-4eb0-bb7b-cf642bc3b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#95) [0,1,2,3,4,5,6,7,8,9...], (#42) [95,96,97,98,99,100,101,102,103,104...])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8814e34a-87b6-4a5b-9fc8-15c659fb481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = L(x for x in range(100)), L(x for x in range(37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6812754b-40c7-44a1-bef1-4d9c36a157e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(samples:100, vars:24, len:144, device=cuda:0),\n",
       " tensor([19.3800, 12.6800,  5.3400, 12.7200, 13.2500, 26.2800, 13.1000, 14.0600,\n",
       "         10.9200, 10.4600, 20.7400, 21.3100, 21.4900, 10.2500, 11.4000, 10.8000,\n",
       "         11.6400, 23.4200, 11.2300, 13.5600, 14.8200, 16.5300, 19.9400, 12.7800,\n",
       "         11.4900,  9.6300, 11.5300, 12.9700, 23.0100, 11.8300, 13.3700, 12.2400,\n",
       "         14.8000, 19.0100, 12.9800, 12.0700, 10.6100, 17.3000,  8.6200,  9.6000,\n",
       "         10.2600,  9.8200, 14.6100,  5.3800, 14.6200, 19.6200, 19.2200, 16.2500,\n",
       "         16.2200,  9.1700, 15.8900, 10.8200, 18.1800, 12.0300, 11.5400, 13.2100,\n",
       "         10.5100,  7.0300, 11.6300, 16.4100, 21.6900, 21.9100, 21.7400, 17.0000,\n",
       "         22.1000, 12.6800, 10.5100, 14.9900, 10.3100, 12.5400, 16.0500, 18.5600,\n",
       "         16.7700, 11.3200, 15.6800, 16.0200, 11.9300, 20.4400, 10.8900, 22.7400,\n",
       "         10.6200, 11.9200, 17.5300, 10.1700, 11.0600, 10.6300,  9.9900, 10.1100,\n",
       "         13.2900, 14.2800, 14.7100, 13.6900, 13.8700, 17.6600,  8.7500, 17.3700,\n",
       "         20.6500, 11.4200, 10.6800, 12.4400], device='cuda:0'))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms  = [None, [TSRegression()]]\n",
    "batch_tfms = TSStandardize(by_sample=True, by_var=True)\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=128)\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fa026e28-f947-4db7-b434-87eabca5801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9aa00b8f-9042-4970-8212-d35b68a8022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        tuple\n",
       "\u001b[0;31mString form:\u001b[0m ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2 <...> , 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136])\n",
       "\u001b[0;31mLength:\u001b[0m      2\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Built-in immutable sequence.\n",
       "\n",
       "If no argument is given, the constructor returns an empty tuple.\n",
       "If iterable is specified the tuple is initialized from iterable's items.\n",
       "\n",
       "If the argument is a tuple, the return value is the same object.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f049799-435b-4532-8ac9-1a3a049c422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#95) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cac2172b-b245-4e97-af92-afdc408ec1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de77c15f-529d-443f-8858-fd5e5741be2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Behaves like a list of `items` but can also index with list of indices or masks\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/foundation.py\n",
       "\u001b[0;31mType:\u001b[0m           _L_Meta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     TfmdLists, MultiCategory, LabeledBBox\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40f11067-3499-41be-b927-52f4fa2c120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26298"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83e88cf6-c3cd-446e-882a-81d55b276f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19728, 6570)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_df[tv_df['date'] < '2018-01-01']), len(tv_df[tv_df['date'] >= '2018-01-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4572541-6df6-4e9c-ae61-207f93e0dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = L(len(tv_df[tv_df['date'] < '2018-01-01']), len(tv_df[tv_df['date'] >= '2018-01-01']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "048ca4b5-1b4a-4b02-bbc5-d558a214abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19728"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "add83675-62f7-440a-94eb-30ad37c14f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19728"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuple(x for x in range(19728)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04186296-5856-4857-a573-473a267ef708",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = L(tuple(x for x in range(19728)), tuple(x for x in range(19728, 26298)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e91ae76-4cb5-4465-a0c4-bcd24676d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = L(x for x in range(19728)), L(x for x in range(19728, 26298))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "027d62e7-dd51-44f5-bbca-8e60fca19d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#19728) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#6570) [19728,19729,19730,19731,19732,19733,19734,19735,19736,19737...])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5718d126-7b68-4b65-b598-3ca7e2413a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#95) [0,1,2,3,4,5,6,7,8,9...], (#42) [95,96,97,98,99,100,101,102,103,104...])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "455332e4-8352-4205-851a-b611e074c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in tv_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ceb08095-4b78-4202-ae00-636ed64f5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tv_df.drop(columns=['target', 'num_sold'])\n",
    "y = tv_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d702761-ac89-49ba-b097-63e580d9fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [None, [TSRegression()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f3d5e69-4cca-4e31-97ce-216fd1ff865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = TSStandardize(by_sample=True, by_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03bf23ad-94f1-40f0-87aa-cb2a4fb9f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date'] = X['date'].map(dt.datetime.toordinal)\n",
    "# X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e2befcc-9152-4d54-9953-24f0350bd274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          int64\n",
       "country      object\n",
       "store        object\n",
       "product      object\n",
       "gdp         float64\n",
       "             ...   \n",
       "easter55       bool\n",
       "easter56       bool\n",
       "easter57       bool\n",
       "easter58       bool\n",
       "holiday       int64\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f2ff40b1-d076-4945-8791-6575c5c2e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict, X = label_encoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5949e610-f13f-4170-815d-dcab94b9a391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          int64\n",
       "country       int64\n",
       "store         int64\n",
       "product       int64\n",
       "gdp         float64\n",
       "             ...   \n",
       "easter55       bool\n",
       "easter56       bool\n",
       "easter57       bool\n",
       "easter58       bool\n",
       "holiday       int64\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e6642def-01ad-4dd7-bc60-5d2adf0af60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ca4c046-e676-4313-ab75-298f206af1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26298,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf74432c-b542-432c-81cd-4fe4b1a32eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26298, 206), (26298,))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ff591150-40a3-4a84-bffe-b06503f5fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e01727bd-43a1-4f31-8dba-5d5920bede70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26298,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fa10fdb9-9852-46b3-b916-4d694eac8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_ts_dls(X_np,y_np,train_val_split, tfms=tfms, batch_tfms=batch_tfms, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "422541a1-d208-43b3-bc2c-d732ff2f5c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-ccb93b9fbe07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'This DataLoader does not contain any batches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_multiproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(x, f, negate, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcompose_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_enc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.name}:\\nencodes: {self.encodes}decodes: {self.decodes}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/dispatch.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/tsai/data/preprocessing.py\u001b[0m in \u001b[0;36mencodes\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_nanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_nanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_nanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/tsai/utils.py\u001b[0m in \u001b[0;36mtorch_nanmean\u001b[0;34m(o, dim, keepdim)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "14f39926-9034-4792-bfeb-4a65e47c7722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26298, 206, 1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unsq = np.expand_dims(X_np, 2)\n",
    "X_unsq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f548c48e-9bef-4c5d-978d-d14c66bdd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_unsq = np.expand_dims(y_np, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "22afd8d5-c7ed-41d5-86ff-ad0f448b33c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 26298, 206), (26298, 1))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_unsq.shape, y_unsq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9304357-2226-4860-bde4-4556d7cf4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_ts_dls(X_unsq,y_np, tfms=tfms, batch_tfms=batch_tfms, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cea590ce-d56a-4040-a5f7-96c40cf0a4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(samples:128, vars:206, len:1, device=cuda:0),\n",
       " tensor([2.9595, 3.7042, 3.3461, 4.2701, 3.1183, 3.3932, 2.8767, 4.8233, 4.6589,\n",
       "         3.8086, 2.4372, 3.3502, 4.5083, 2.8339, 4.3680, 3.0955, 2.5866, 3.4393,\n",
       "         3.9723, 3.4462, 3.8307, 3.7382, 3.7088, 3.5947, 3.6180, 3.4556, 3.4036,\n",
       "         2.6335, 2.9528, 3.3175, 3.6721, 2.8325, 4.1445, 3.5332, 4.1634, 3.6832,\n",
       "         5.3126, 4.0645, 2.3791, 3.1071, 3.7742, 2.8791, 4.0545, 2.8893, 2.7804,\n",
       "         4.5783, 3.9507, 4.3750, 3.1071, 4.3790, 2.3539, 2.3309, 2.5712, 3.8645,\n",
       "         4.6326, 3.6023, 3.1238, 2.8709, 4.3029, 2.6845, 3.0179, 3.4068, 3.5413,\n",
       "         2.9063, 3.8620, 3.5019, 3.9052, 2.8564, 4.0007, 3.8298, 3.5792, 4.2536,\n",
       "         3.1729, 4.0350, 3.8527, 2.3908, 3.7606, 2.9301, 3.0595, 3.7383, 2.6826,\n",
       "         4.0744, 3.7738, 3.9684, 3.1708, 3.9350, 3.9120, 4.4649, 4.8602, 4.5856,\n",
       "         3.0378, 2.9404, 4.3253, 3.2564, 3.6393, 3.8426, 3.0720, 3.0832, 2.9178,\n",
       "         3.5923, 3.4002, 3.6384, 3.6621, 3.5405, 2.4881, 4.4622, 4.9978, 3.7252,\n",
       "         4.5805, 4.8496, 2.9592, 3.1721, 3.1402, 3.5385, 3.7830, 4.1969, 4.5109,\n",
       "         5.0232, 2.8486, 3.6639, 4.9826, 3.4174, 4.2070, 3.2682, 3.6865, 3.1055,\n",
       "         4.0724, 3.7956], device='cuda:0'))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e23dedd9-7b9f-4409-b86f-b2658269c1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "15e4f835-4524-4145-af02-c69a7eff407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "059a5c23-ddf6-43f6-a714-1b3a391d531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ts_learner(dls, TCN, metrics=[mae, rmse])#, cbs=ShowGraph(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6e2db1f9-c1ac-4a51-995b-4410f40be4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.opt_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1996a66c-7aed-44ac-83d5-2d067427d9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tsai.data.core.TSDataLoaders at 0x7f88a445e190>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "34ea6ef8-e89e-4d5d-aba7-4c8d27ea88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.dls = dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d59f9338-5e7b-4b83-8a61-a5c8899ed6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='205' class='' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [205/205 02:28<00:00 nan]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-87baa2fb3360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    114\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    115\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'missing {event_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[1;32m     44\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/callback/progress.py\u001b[0m in \u001b[0;36mbefore_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iter_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iter_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/callback/progress.py\u001b[0m in \u001b[0;36m_launch_pbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_launch_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mbar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gen, total, display, leave, parent, master, comment)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_last\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "802211dd-933b-4ae9-a575-f23397a92b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of MSELoss()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.loss_func\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
