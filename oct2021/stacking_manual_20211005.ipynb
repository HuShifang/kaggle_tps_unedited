{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Setting up a more robust baseline notebook, suitable for use with all of the \"Big Three\" (XGBoost, CatBoost, LightGBM) libraries and on either Google Colab or the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "COLAB = False\n",
    "USE_GPU = True\n",
    "# libraries = ['xgboost', 'lightgbm', 'catboost']\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"stacking_manual_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if COLAB:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "#     !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "#     !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if USE_GPU: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if USE_GPU:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/oct2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad41f0c-4a5c-470a-bda3-98152c30bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912a62f-970a-48b4-b428-d886f2612fc2",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b8603b-68c3-40da-8406-53e143758905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9716ae38-a859-44f1-bf4e-caf0c7a40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y_train = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X_train = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "exmodel_config['feature_count'] = X.shape[1]\n",
    "exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "exmodel_config['train_source'] = str(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9897e600-60ec-4896-97d3-e029f0eee460",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = datapath/'test.feather'\n",
    "exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "# X_test = X_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785d11ff-6ff7-48c4-95ea-a5616eff6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f215-b585-4f7b-afac-36e49ee28c8f",
   "metadata": {},
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a928e1-0a18-4c91-b9bb-a32846e39e5b",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['stacking-manual'],\n",
    "    'notes': \"Using best-to-date params on GBM classifiers from XGBoost, LightGBM, and CatBoost on original, unaltered dataset. Manual stacking ensemble, with two random-state versions of each architecture in first layer, then one in second, then a LogisticRegressor for third.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e9478-2380-4c4d-8641-5daa72049b6c",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc156663-c689-4dfe-a80b-5efaaae1afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 20211004, thru 106 trials on unaltered original dataset\n",
    "best_xgboost_params = {\n",
    "    'n_estimators': 3878,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.024785857161974977,\n",
    "    'reg_alpha': 26.867682044658245,\n",
    "    'reg_lambda': 10.839759074147148,\n",
    "    'subsample': 0.8208581489835881,\n",
    "    'min_child_weight': 8.829122644339664,\n",
    "    'colsample_bytree': 0.906420714280384,\n",
    "    'gamma': 1.472322916021486\n",
    "}\n",
    "\n",
    "# best as of 20211005, thru 65 trials on unaltered original dataset\n",
    "best_lightgbm_params = {\n",
    "    'n_estimators': 6631,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.004677044539666842,\n",
    "    'reg_alpha': 19.334971246299116,\n",
    "    'reg_lambda': 0.024384251140153856,\n",
    "    'subsample': 0.5082183652689569,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_child_samples': 9,\n",
    "    'num_leaves': 233,\n",
    "    'colsample_bytree': 0.5008014086989773\n",
    "}\n",
    "\n",
    "# catboost 20211001 on colab with 100 trials on GPU, unaltered original dataset\n",
    "best_catboost_params = {\n",
    "    'iterations': 29338,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.004769831650275205,\n",
    "    'random_strength': 7,\n",
    "    'od_wait': 1968,\n",
    "    'reg_lambda': 28.435563240493586,\n",
    "    'border_count': 162,\n",
    "    'min_child_samples': 14,\n",
    "    'leaf_estimation_iterations': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(library:str, params:dict={}, X=X, y=y, X_test=X_test, start_fold=0, \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, wandb_tracked=True):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "#     if exmodel_config['kfolds'] == 1:\n",
    "#         print(\"Proceeding with holdout\")\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=0.2, \n",
    "#                                                           random_state=SEED)                 \n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['library'] = library\n",
    "        exmodel_config[f'{library}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202110_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # setup for serialization\n",
    "    runpath = Path(modelpath/f\"{wandb_config['name']}_{library}_{exmodel_config['kfolds']}folds/\")\n",
    "    (runpath).mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold < start_fold: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "    \n",
    "        # define models\n",
    "        if library == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        elif library == 'lightgbm':\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                 n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        elif library == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # take the training set predictions, if desired\n",
    "#         y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "#         train_loss = log_loss(y_train, y_train_pred)\n",
    "#         train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "#         wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "\n",
    "        # log the parameters, if desired\n",
    "#         if exmodel_config['library'] == 'catboost':\n",
    "#             print(model.get_all_params())\n",
    "#             wandb.log(model.get_all_params())\n",
    "#         else:\n",
    "#             wandb.log(model.get_params()) # logging model parameters, trying bare-invocation rather than params: model.get_params()\n",
    "\n",
    "        y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "        \n",
    "        # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "        oof_preds.extend(y_valid_preds)\n",
    "        oof_y.extend(y_valid)\n",
    "        \n",
    "        # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "        test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        dump(model, Path(runpath/f\"{exmodel_config['library']}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for {library} model is {model_valid_auc}\")\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "    dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{library}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "    dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{library}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'model_valid_auc': model_valid_auc,\n",
    "                   'oof_preds': oof_preds,\n",
    "                   'test_preds': test_preds,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096d8438-1639-47ab-9264-aefb21e51872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _, lightgbm_preds = cross_validate_model(library='lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b93f37-272a-4e06-b1e2-12b45d3148a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _, catboost_preds = cross_validate_model(library='catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc332027-f1ab-45c0-8793-45b9bfd76cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_oof_preds, xgboost_test_preds = cross_validate_model(library='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c3564-37f1-4c16-b91f-753667ecb3b0",
   "metadata": {},
   "source": [
    "# Single Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8217efa1-6b59-4c60-bbc7-5bd50c0fee6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c64589fc-0149-4905-b4e0-f110ef9007a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.loc[:, 'target'] = xgboost_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd20a8cd-72a0-47b9-989d-cb65be178967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee4537d0-13b6-46a2-96ac-4ef6ab855007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a8672e-ebc6-4105-94a6-5f6806aea28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_xgboost_{exmodel_config['kfolds']}folds_rs{42}_baseline_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd1e0734-4e26-4944-896b-65c177181cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(blender.estimators[2][1].get_all_params())\n",
    "# blender.estimators[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "765cbb49-a7b4-4564-b26d-3484431935be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log({'leaderboard_auc': 0.81725,\n",
    "# #            'catboost_params': str(best_catboost_params),\n",
    "#           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df020199-86b3-4f67-8088-0646f028b8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8441c1fc-8432-4d24-a65f-eceaae4919d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_y_pd = pd.Series(oof_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994802dc-6ec1-4588-9ee6-b18e7ef01047",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe960b2-6e42-4384-a7de-d2a2464c2ea2",
   "metadata": {},
   "source": [
    "## Level One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cb4c8f6-4712-45a9-9a42-84864ab265bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_lv1, test_lv1 = pd.DataFrame(), pd.DataFrame() # initialize dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f3a89-af13-4f7d-a613-690498292674",
   "metadata": {},
   "source": [
    "### Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "032ca5db-2dd1-4530-8847-1619f85fbf15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/11jahfma\" target=\"_blank\">stacking_manual_20211005_205933</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 0 is 0.8572718743878947\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 1 is 0.8559994877532525\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 2 is 0.8568325308014939\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 3 is 0.8559842308123811\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 4 is 0.8565528831795393\n",
      "Valid AUC score for lightgbm model is 0.8565251751685374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 4000104 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 99077... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.08MB of 0.08MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>model_valid_auc</td><td>0.85653</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stacking_manual_20211005_205933</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/11jahfma\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/11jahfma</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211005_205933-11jahfma/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lv1_lgb42, test_lv1_lgb42 = cross_validate_model(library='lightgbm', X=X, y=y, X_test=X_test, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_lightgbm_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=True\n",
    "                                        )\n",
    "oof_lv1['lgb42'] = oof_lv1_lgb42\n",
    "test_lv1['lgb42'] = test_lv1_lgb42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfb3c21b-9340-490a-a44d-90b21ac8de04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/3cjsoss8\" target=\"_blank\">stacking_manual_20211005_205933</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 0 is 0.8572161841869534\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 1 is 0.8559350043052648\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 2 is 0.8568529019126492\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 3 is 0.8558748673652216\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 4 is 0.8565261379114149\n",
      "Valid AUC score for lightgbm model is 0.8564776078917813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 4000104 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 99760... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.08MB of 0.08MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>model_valid_auc</td><td>0.85648</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stacking_manual_20211005_205933</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/3cjsoss8\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/3cjsoss8</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211005_220415-3cjsoss8/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lv1_lgb1983, test_lv1_lgb1983 = cross_validate_model(library='lightgbm', X=X, y=y, X_test=X_test, \n",
    "                                                 wandb_config=wandb_config,\n",
    "                                                 random_state=1983,\n",
    "                                                 params=best_lightgbm_params,\n",
    "                                                 exmodel_config=exmodel_config, \n",
    "                                                 wandb_tracked=True\n",
    "                                                )\n",
    "oof_lv1['lgb1983'] = oof_lv1_lgb1983\n",
    "test_lv1['lgb1983'] = test_lv1_lgb1983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f80900ce-57d8-45f3-bd23-2a85f223855b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/gidal6lu\" target=\"_blank\">stacking_manual_20211005_205933</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 0 is 0.8572554115376164\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 1 is 0.8561654493709842\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 2 is 0.8572168508119474\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 3 is 0.8560833380957398\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 4 is 0.8567086183230934\n",
      "Valid AUC score for xgboost model is 0.8566841128860819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 4000104 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 100139... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.09MB of 0.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_params</td><td>{'objective': 'binar...</td></tr><tr><td>model_valid_auc</td><td>0.85668</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stacking_manual_20211005_205933</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/gidal6lu\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/gidal6lu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211005_230734-gidal6lu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lv1_xgb42, test_lv1_xgb42 = cross_validate_model(library='xgboost', X=X, y=y, X_test=X_test, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_xgboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=True\n",
    "                                        )\n",
    "\n",
    "oof_lv1['xgb42'] = oof_lv1_xgb42\n",
    "test_lv1['xgb42'] = test_lv1_xgb42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db292889-5a30-45f5-8b7a-436cdeb27771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/v3a2few8\" target=\"_blank\">stacking_manual_20211005_205933</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 0 is 0.8573146071386168\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 1 is 0.8561499733154669\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 2 is 0.8571969682510598\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 3 is 0.8560595010136646\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 4 is 0.8566916357893442\n",
      "Valid AUC score for xgboost model is 0.8566807985789633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 4000104 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 100346... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.10MB of 0.10MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_params</td><td>{'objective': 'binar...</td></tr><tr><td>model_valid_auc</td><td>0.85668</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stacking_manual_20211005_205933</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/v3a2few8\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/v3a2few8</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211005_233859-v3a2few8/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lv1_xgb1983, test_lv1_xgb1983 = cross_validate_model(library='xgboost', X=X, y=y, X_test=X_test, \n",
    "                                                 wandb_config=wandb_config,\n",
    "                                                 random_state=1983,\n",
    "                                                 params=best_xgboost_params,\n",
    "                                                 exmodel_config=exmodel_config, \n",
    "                                                 wandb_tracked=True\n",
    "                                                )\n",
    "oof_lv1['xgb1983'] = oof_lv1_xgb1983\n",
    "test_lv1['xgb1983'] = test_lv1_xgb1983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07b56f4c-c0eb-46a2-a39f-5f161be4ce52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/1zwidjj3\" target=\"_blank\">stacking_manual_20211005_205933</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 0 is 0.8575766033930445\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 1 is 0.8564289538689146\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 2 is 0.8574776355547533\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 3 is 0.856314002656122\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 4 is 0.8570333546927973\n",
      "Valid AUC score for catboost model is 0.8569640294774554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 4000104 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 100559... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.11MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_params</td><td>{'iterations': 29338...</td></tr><tr><td>model_valid_auc</td><td>0.85696</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stacking_manual_20211005_205933</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/1zwidjj3\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/1zwidjj3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211006_001029-1zwidjj3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_lv1_cat42, test_lv1_cat42 = cross_validate_model(library='catboost', X=X, y=y, X_test=X_test, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_catboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=True\n",
    "                                        )\n",
    "oof_lv1['cat42'] = oof_lv1_cat42\n",
    "test_lv1['cat42'] = test_lv1_cat42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4d41632-6d00-4714-81f3-d73e9d219b43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 0 is 0.8575796749930964\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 1 is 0.8564173360521683\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 2 is 0.8575358682866415\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 3 is 0.8563227427678826\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 4 is 0.8570098742696105\n",
      "Valid AUC score for catboost model is 0.856970844007867\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-97d61929b2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                  \u001b[0mwandb_tracked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                 )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moof_lv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat1983'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof_lv1_cat1983\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_lv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat1983'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_lv1_cat1983\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "oof_lv1_cat1983, test_lv1_cat1983 = cross_validate_model(library='catboost', X=X, y=y, X_test=X_test, \n",
    "                                                 wandb_config=wandb_config,\n",
    "                                                 random_state=1983,\n",
    "                                                 params=best_catboost_params,\n",
    "                                                 exmodel_config=exmodel_config, \n",
    "                                                 wandb_tracked=False\n",
    "                                                )\n",
    "oof_lv1['cat1983'] = oof_lv1_cat1983\n",
    "test_lv1['cat1983'] = test_lv1_cat1983"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ea342-3882-498f-a970-108d71d72ded",
   "metadata": {},
   "source": [
    "### Loading Sets of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128656e-dafe-43ec-bbe9-c30734573f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1, test_lv1 = pd.DataFrame(), pd.DataFrame()\n",
    "# preds_path = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/preds/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ef71b-afd2-4a31-848d-f9ca2525ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['xgb42'] = load(predpath/'stacking_manual_20211005_085253_xgboost_5folds_rs42_oof_preds.joblib')\n",
    "# test_lv1['xgb42'] = load(preds_path/'stacking_manual_20210925_212129_xgboost_5folds_rs42_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f493f20-3a8a-40e4-81d7-6107753ac744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv_xgb42_y = load(predpath/'stacking_manual_20211005_085253_xgboost_5folds_rs42_oof_y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed26a0f-9eac-4f43-8160-1c81f06cf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_true=oof_lv_xgb42_y, y_score=oof_lv1['xgb42'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681cec6-4290-429a-991f-0a3305893075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['xgb1983'] = load(preds_path/'validAUC_0.8146252172737458_stacking_manual_20210926_211701_xgboost_5folds_rs1983_oof_preds.joblib')\n",
    "# test_lv1['xgb1983'] = load(preds_path/'stacking_manual_20210926_211701_xgboost_5folds_rs1983_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59039c-2dc1-49f2-9fc5-311977ac1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['lgb42'] = load(preds_path/'validAUC_0.8156810521798477_stacking_manual_20210925_212129_lightgbm_5folds_rs42_oof_preds.joblib')\n",
    "# test_lv1['lgb42'] = load(preds_path/'stacking_manual_20210925_212129_lightgbm_5folds_rs42_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c301c0-35dd-48f2-8719-47c8247c205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['lgb1983'] = load(preds_path/'validAUC_0.8156503194185875_stacking_manual_20210925_212129_lightgbm_5folds_rs1983_oof_preds.joblib')\n",
    "# test_lv1['lgb1983'] = load(preds_path/'stacking_manual_20210925_212129_lightgbm_5folds_rs1983_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b9355-740d-47b9-87ea-e8de0b1e7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['cat42'] = load(preds_path/'validAUC_0.8116727090290558_stacking_manual_20210925_212129_catboost_5folds_rs42_oof_preds.joblib')\n",
    "# test_lv1['cat42'] = load(preds_path/'stacking_manual_20210925_212129_catboost_5folds_rs42_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1542a39-c5d1-4785-a3c8-1a990d535d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1['cat1983'] = load(predpath/'stacking_manual_20211005_085253_catboost_5folds_rs1983_oof_preds.joblib')\n",
    "# oof_cat1983_y = load(predpath/'stacking_manual_20211005_085253_catboost_5folds_rs1983_oof_y.joblib')\n",
    "# roc_auc_score(y_true=oof_cat1983_y, y_score=oof_lv1['cat1983'])\n",
    "# test_lv1['cat1983'] = load(preds_path/'stacking_manual_20210925_212129_catboost_5folds_rs1983_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c927d-bf2f-45b5-8852-1c1fb44d690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_cat42_y = load(predpath/'stacking_manual_20211005_085253_catboost_5folds_rs42_oof_y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b2247-a987-4cb1-8f7f-11b74e1fe6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_cat42_y == oof_lv_xgb42_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efac1b-596c-489d-a606-50a55c5d67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eec67d-7891-4ac0-884d-d098577bdf03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# oof_y_pd.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7c3a6-2707-4177-abf8-95992f572852",
   "metadata": {},
   "source": [
    "- Why is it that the random seed seems far more important than the model type in making a prediction???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a964b810-db49-49c0-9deb-999a189e4939",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dc05052-1105-4a9a-8fbe-c3a3b59b2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1.to_csv('oof_lv1.csv', index=False)\n",
    "test_lv1.to_csv('test_lv1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "877cd565-c4ed-436e-b230-1bd4487354da",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1.to_feather(predpath/f\"{wandb_config['name']}_oof_lv1.feather\")\n",
    "test_lv1.to_feather(predpath/f\"{wandb_config['name']}_test_lv1.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc7cef-5989-400f-8524-cf59233d3e4b",
   "metadata": {},
   "source": [
    "### Lv1 Finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b519f691-686f-4035-bb6b-15c17554daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1 = pd.read_feather(predpath/f\"{wandb_config['name']}_oof_lv1.feather\")#, columns=[str(x) for x in range()])\n",
    "test_lv1 = pd.read_feather(predpath/f\"{wandb_config['name']}_oof_lv1.feather\")\n",
    "oof_y = load(predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "\n",
    "# oof_lv1.index.name = 'id'\n",
    "# test_lv1.index.name = 'id'\n",
    "# oof_y.index.name = 'id'\n",
    "oof_lv1 = np.array(oof_lv1)\n",
    "test_lv1 = np.array(test_lv1)\n",
    "oof_y = np.array(oof_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e3ba4-981d-4a86-b181-66a43aed8285",
   "metadata": {},
   "source": [
    "## Level Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ea5ac76-c5ab-4ae7-8e56-2eaf2f52f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2, test_lv2 = pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa61d2f0-a14f-4192-8d75-29899946b686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[05:54:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC for fold 0 is 0.8567673974385948\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:54:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8572241681755651\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:54:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8564677798517564\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:54:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8569590636482101\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:54:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8579641095637536\n",
      "Valid AUC score for xgboost model is 0.8570550391170862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/sf/code/kaggle/tabular_playgrounds/oct2021/preds/stacking_manual_20211005_205933_test_lv2_xgboost42_preds.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv2_xgb42, test_lv2_xgb42 = cross_validate_model(library='xgboost', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_xgboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=False\n",
    "                                        )\n",
    "\n",
    "dump(oof_lv2_xgb42, predpath/f\"{wandb_config['name']}_oof_lv2_xgboost42_preds.joblib\")\n",
    "dump(test_lv2_xgb42, predpath/f\"{wandb_config['name']}_test_lv2_xgboost42_preds.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db765d-db36-4c90-858b-bc8708cf9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_xgb_f0_rs1983 = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/stacking_manual_20210926_211701_xgboost_5folds/xgboost_fold0_model.joblib')\n",
    "# oof_xgb_f0_rs42 = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/stacking_manual_20210925_212129_xgboost_5folds/xgboost_fold0_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf9ac76c-cafa-4831-b856-37663b4ec276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 0 is 0.8561112140085647\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 1 is 0.8566038972798236\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 2 is 0.8558367995062315\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 3 is 0.8563649950153741\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "Valid AUC for fold 4 is 0.8573670243744347\n",
      "Valid AUC score for catboost model is 0.8564461628301947\n"
     ]
    }
   ],
   "source": [
    "oof_lv2_cat42, test_lv2_cat42 = cross_validate_model(library='catboost', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_catboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b9ca079-d826-4991-8377-3bd3988b3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sf/code/kaggle/tabular_playgrounds/oct2021/preds/stacking_manual_20211005_205933_test_lv2_catboost42_preds.jobli']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(oof_lv2_cat42, predpath/f\"{wandb_config['name']}_oof_lv2_catboost42_preds.joblib\")\n",
    "dump(test_lv2_cat42, predpath/f\"{wandb_config['name']}_test_lv2_catboost42_preds.jobli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf17be39-6ef1-4387-b1d2-e1ffa677093f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (best_split_info.left_count) > (0) at /home/sf/Software/LightGBM/src/treelearner/serial_tree_learner.cpp, line 653 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6a455f00e067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m oof_lv2_lgb42, test_lv2_lgb42 = cross_validate_model(library='lightgbm', X=oof_lv1, y=oof_y, X_test=test_lv1, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                          \u001b[0mwandb_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                          \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_lightgbm_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          \u001b[0mexmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-4addbed35183>\u001b[0m in \u001b[0;36mcross_validate_model\u001b[0;34m(library, params, X, y, X_test, start_fold, exmodel_config, wandb_config, random_state, wandb_tracked)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/LightGBM/python-package/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    962\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    965\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/LightGBM/python-package/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/LightGBM/python-package/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    291\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/LightGBM/python-package/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3014\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3015\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3017\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;32m~/Software/LightGBM/python-package/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (best_split_info.left_count) > (0) at /home/sf/Software/LightGBM/src/treelearner/serial_tree_learner.cpp, line 653 .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oof_lv2_lgb42, test_lv2_lgb42 = cross_validate_model(library='lightgbm', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=best_lightgbm_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ef2ec-4539-4aaa-8a87-ce76eb8be564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(oof_lv2_lgb42, predpath/f\"{wandb_config['name']}_oof_lv2_lightgbm42_preds.joblib\")\n",
    "dump(test_lv2_lgb42, predpath/f\"{wandb_config['name']}_test_lv2_lightgbm42_preds.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f14d99-2917-4624-8e58-78818820750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2['xgboost'] = oof_lv2_xgb42\n",
    "oof_lv2['catboost'] = oof_lv2_cat42\n",
    "oof_lv2['lightgbm'] = oof_lv2_lgb42\n",
    "\n",
    "test_lv2['xgboost'] = test_lv2_xgb42\n",
    "test_lv2['catboost'] = test_lv2_cat42\n",
    "test_lv2['lightgbm'] = test_lv2_lgb42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf889a0-175d-4564-a80c-4a3476aeffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970e9c3-b3de-42b5-8d8b-c17832ecd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1_df = pd.read_feather(predpath/'oof_lv1.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debcf3f-872c-42fb-9945-3b6b54eb9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a241171-9b43-4205-9156-320687251c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2_full = oof_lv2.join(oof_lv1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a3d8c-4684-4f40-84f7-940a6a485d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lv2_full = test_lv2.join(pd.read_feather(preds_path/'test_lv1.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f442a2e-6b37-49cb-9f0a-57c4073dabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1effd1-435f-470e-af6b-acae64a175b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lv2_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f55d89-4ae1-4397-83ad-388e3d8e697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2_np = oof_lv2_full.to_numpy()\n",
    "test_lv2_np = test_lv2_full.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411948c7-bc26-4722-962d-23f56857a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_y_np = oof_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c6aac-1344-4ee0-b2a2-1580d6c5356d",
   "metadata": {},
   "source": [
    "## Level Three (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1db0b1-26d9-440b-864b-63df8aa6fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa300d-2e9b-4fcd-8553-cf3885228bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = model_selection.StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad51e38-ca0f-4e6c-9879-7993a8bd40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds, oof_y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820c69a-13f3-4ace-a26f-d6e1fb097ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.zeros((X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5b2ec-8f29-471a-ab7d-d6be861a803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = oof_lv2_np\n",
    "y = oof_y_np\n",
    "X_test = test_lv2_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581a349-a22b-4383-b109-ec87ec9eed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = 'sklearn (LogisticRegressor(max_iter=1000))'\n",
    "exmodel_config['library'] = library\n",
    "# wandb.init(\n",
    "#     project=\"202110_Kaggle_tabular_playground\",\n",
    "#     save_code=True,\n",
    "#     tags=wandb_config['tags'],\n",
    "#     name=wandb_config['name'],\n",
    "#     notes=wandb_config['notes'],\n",
    "#     config=exmodel_config\n",
    "# )   \n",
    "\n",
    "# # prepare for k-fold cross-validation\n",
    "# kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=random_state)\n",
    "\n",
    "# setup for serialization\n",
    "# model_path = Path(datapath/f\"models/{wandb_config['name']}_{library}_{exmodel_config['kfolds']}folds/\")\n",
    "# (model_path).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405ab94-9fe2-4d95-b966-ad02de6f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(kfolds.split(X,y)):\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    oof_preds.extend(preds)\n",
    "    oof_y.extend(y_valid)\n",
    "    \n",
    "    test_preds += model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f\"ROC AUC of fold {fold} is {valid_auc}\")\n",
    "    \n",
    "#     dump(preds, /'lv_3)\n",
    "\n",
    "valid_auc_total = roc_auc_score(oof_y, oof_preds)\n",
    "print(f\"Overall ROC_AUC is {valid_auc_total}\")\n",
    "\n",
    "dump(oof_preds, predpath/'oof_lv3_preds.joblib')\n",
    "dump(oof_y, predpath/'oof_lv3_y.joblib')\n",
    "\n",
    "test_preds /= 5\n",
    "\n",
    "dump(test_preds, predpath/'test_lv3_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99cf5b-3477-47f4-9391-73e2ff93c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')\n",
    "# X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_SummaryStats_imputed-Median-wIndicators-StandardScaled.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f347f-872f-4011-9f13-78fad542f36a",
   "metadata": {},
   "source": [
    "## Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773d286-257d-4776-add5-0f724944befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_path = Path(datapath/\"preds/\")\n",
    "\n",
    "# blender_preds = blender.predict_proba(X_test_imputed_scaled)[:,1]\n",
    "# dump(blender_preds, preds_path/f\"{config_run['name']}_stack.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f63005-4b50-40e9-9af4-d858b9b73576",
   "metadata": {},
   "source": [
    "# Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193a028-ea7f-4635-8c36-5cd517894784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecede81-21ca-414d-8e1a-57baa3e5be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9fc8c-45ab-4ea6-b40b-15149ad43751",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d80568-780e-4798-a26b-e2907825f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e653c-a3de-4e25-a22f-4d7d0e1d49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-ensemble_{exmodel_config['kfolds']}folds_rs{42}_baseline_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5c8dfd-4282-45fb-bd1b-cebccbaea68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'leaderboard_auc': ,\n",
    "#            'catboost_params': str(best_catboost_params),\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9a1cda7-ee10-4db7-9d99-2748be655a3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2477425<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.23MB of 0.23MB uploaded (0.06MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210922_213427-2nalm78k/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210922_213427-2nalm78k/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>blender-cv</td><td>5</td></tr><tr><td>blender-final_estimator</td><td>LogisticRegression(m...</td></tr><tr><td>blender-stack_mdethod</td><td>predict_proba</td></tr><tr><td>leaderboard_auc</td><td>0.81725</td></tr><tr><td>lightgbm_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>test_set</td><td>/media/sf/easystore/...</td></tr><tr><td>train_auc</td><td>0.8414</td></tr><tr><td>train_loss</td><td>0.494</td></tr><tr><td>xgboost_params</td><td>{'objective': 'binar...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>blender-cv</td><td>▁</td></tr><tr><td>leaderboard_auc</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_off-shelf_20210922_213426</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2nalm78k\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/2nalm78k</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
