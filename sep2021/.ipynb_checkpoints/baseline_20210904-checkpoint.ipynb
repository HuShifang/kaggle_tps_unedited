{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Setting up a more robust baseline notebook, suitable for use with all of the \"Big Three\" (XGBoost, CatBoost, LightGBM) libraries and on either Google Colab or the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"baseline_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    !pip install category_encoders\n",
    "    !pip install catboost\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    !pip install cmake --upgrade\n",
    "    # !pip install sklearn --upgrade\n",
    "    !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    %cd /content/xgboost\n",
    "    !mkdir build\n",
    "    %cd build\n",
    "    !cmake .. -DUSE_CUDA=ON\n",
    "    !make -j4\n",
    "    %cd /content/xgboost/python-package\n",
    "    !python setup.py install --use-cuda --use-nccl\n",
    "    !/opt/bin/nvidia-smi\n",
    "    !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08408fca-654d-4f30-87c0-b8f31cb1717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')    \n",
    "    \n",
    "# load the version of the dataset with imputations; X and y were stored separately, as feather and joblib respectively\n",
    "X = pd.read_feather(datapath/'X_StandardScaled_KNNImputed_5NN.feather') \n",
    "y = load(datapath/'y.joblib')    \n",
    "X.index.name = 'id'\n",
    "y.index.name = 'id'\n",
    "\n",
    "# # here's how to load the original, unaltered dataset and separate features from targets\n",
    "# df = pd.read_feather(path=dataset_path/'dataset_df.feather') # this is the unaltered original dataset\n",
    "# features = [x for x in df.columns if x != 'claim']\n",
    "# X = df[features]\n",
    "# y = df.claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59020939-0ca1-4e0d-9af3-9fb122646ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f109</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>-2.336057</td>\n",
       "      <td>-0.640028</td>\n",
       "      <td>-0.865135</td>\n",
       "      <td>-0.108153</td>\n",
       "      <td>-4.793134</td>\n",
       "      <td>-1.164104</td>\n",
       "      <td>-0.602909</td>\n",
       "      <td>-0.602437</td>\n",
       "      <td>-0.520139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965180</td>\n",
       "      <td>0.414373</td>\n",
       "      <td>-0.364292</td>\n",
       "      <td>-0.482119</td>\n",
       "      <td>-0.878642</td>\n",
       "      <td>-0.635844</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-1.210113</td>\n",
       "      <td>1.122438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245597</td>\n",
       "      <td>-0.316947</td>\n",
       "      <td>1.208458</td>\n",
       "      <td>0.354270</td>\n",
       "      <td>1.065282</td>\n",
       "      <td>-0.360618</td>\n",
       "      <td>0.079180</td>\n",
       "      <td>-0.745021</td>\n",
       "      <td>0.885596</td>\n",
       "      <td>0.459871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939498</td>\n",
       "      <td>-1.982493</td>\n",
       "      <td>2.337448</td>\n",
       "      <td>-0.516377</td>\n",
       "      <td>0.237215</td>\n",
       "      <td>-0.673335</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>-0.522752</td>\n",
       "      <td>-0.664832</td>\n",
       "      <td>-0.674975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.016108</td>\n",
       "      <td>-2.413280</td>\n",
       "      <td>-0.492762</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>1.063769</td>\n",
       "      <td>0.115233</td>\n",
       "      <td>0.530570</td>\n",
       "      <td>-0.047807</td>\n",
       "      <td>-0.768160</td>\n",
       "      <td>1.043223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662936</td>\n",
       "      <td>0.762045</td>\n",
       "      <td>-0.971575</td>\n",
       "      <td>-0.518246</td>\n",
       "      <td>0.632622</td>\n",
       "      <td>-0.195099</td>\n",
       "      <td>-0.282497</td>\n",
       "      <td>-0.630488</td>\n",
       "      <td>-0.038341</td>\n",
       "      <td>-0.373060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.426856</td>\n",
       "      <td>-2.315919</td>\n",
       "      <td>-0.512583</td>\n",
       "      <td>-0.828360</td>\n",
       "      <td>1.476518</td>\n",
       "      <td>3.561044</td>\n",
       "      <td>-1.181820</td>\n",
       "      <td>-0.340658</td>\n",
       "      <td>-0.740081</td>\n",
       "      <td>-0.532388</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.376995</td>\n",
       "      <td>-0.803706</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.506544</td>\n",
       "      <td>-1.792552</td>\n",
       "      <td>-0.629638</td>\n",
       "      <td>-0.265100</td>\n",
       "      <td>-0.635201</td>\n",
       "      <td>0.294645</td>\n",
       "      <td>-0.108728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.597496</td>\n",
       "      <td>1.073064</td>\n",
       "      <td>-0.651186</td>\n",
       "      <td>0.455018</td>\n",
       "      <td>0.275424</td>\n",
       "      <td>-0.159085</td>\n",
       "      <td>0.719322</td>\n",
       "      <td>-0.902730</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>-0.514415</td>\n",
       "      <td>...</td>\n",
       "      <td>1.773967</td>\n",
       "      <td>0.338317</td>\n",
       "      <td>-0.608098</td>\n",
       "      <td>-0.498863</td>\n",
       "      <td>-0.216082</td>\n",
       "      <td>-0.641494</td>\n",
       "      <td>2.384546</td>\n",
       "      <td>-0.635402</td>\n",
       "      <td>0.477433</td>\n",
       "      <td>-0.804986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3        f4        f5        f6        f7  \\\n",
       "id                                                                         \n",
       "0   0.422121 -2.336057 -0.640028 -0.865135 -0.108153 -4.793134 -1.164104   \n",
       "1   0.245597 -0.316947  1.208458  0.354270  1.065282 -0.360618  0.079180   \n",
       "2   2.016108 -2.413280 -0.492762  0.333754  1.063769  0.115233  0.530570   \n",
       "3   1.426856 -2.315919 -0.512583 -0.828360  1.476518  3.561044 -1.181820   \n",
       "4   0.597496  1.073064 -0.651186  0.455018  0.275424 -0.159085  0.719322   \n",
       "\n",
       "          f8        f9       f10  ...      f109      f110      f111      f112  \\\n",
       "id                                ...                                           \n",
       "0  -0.602909 -0.602437 -0.520139  ... -0.965180  0.414373 -0.364292 -0.482119   \n",
       "1  -0.745021  0.885596  0.459871  ...  1.939498 -1.982493  2.337448 -0.516377   \n",
       "2  -0.047807 -0.768160  1.043223  ... -0.662936  0.762045 -0.971575 -0.518246   \n",
       "3  -0.340658 -0.740081 -0.532388  ... -1.376995 -0.803706 -0.005727 -0.506544   \n",
       "4  -0.902730  0.043314 -0.514415  ...  1.773967  0.338317 -0.608098 -0.498863   \n",
       "\n",
       "        f113      f114      f115      f116      f117      f118  \n",
       "id                                                              \n",
       "0  -0.878642 -0.635844  0.006302 -0.622475 -1.210113  1.122438  \n",
       "1   0.237215 -0.673335  0.326417 -0.522752 -0.664832 -0.674975  \n",
       "2   0.632622 -0.195099 -0.282497 -0.630488 -0.038341 -0.373060  \n",
       "3  -1.792552 -0.629638 -0.265100 -0.635201  0.294645 -0.108728  \n",
       "4  -0.216082 -0.641494  2.384546 -0.635402  0.477433 -0.804986  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08bd3364-0f44-45fb-bdbb-0748fe2d68e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4940261-a267-4f16-af3d-5bbc56958459",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "### General and Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "    \"scaler\": StandardScaler, # TODO: experiment with others (but imputation may be slow)\n",
    "    \"scale_b4_impute\": True,\n",
    "    \"imputer\": KNNImputer,\n",
    "    \"knn_imputer_n_neighbors\": 5, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': 42,\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7341ba-22c1-4887-bbda-ff2c7504bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configurator(library, gpu_available=True):#, config=universal_config):\n",
    "    \"\"\"\n",
    "    Function that provide task-specific or general preference arguments for the various models. \n",
    "    \n",
    "    At first, will rely largely on defaults for hyperparameters, but later this function \n",
    "    can be supplemented later with optimal values, as they're learned in sweeps.\n",
    "    .\n",
    "    \n",
    "    Rationale: creating a helper function will allow more experimentation later, and also\n",
    "    composite runs that cycle through a series of models.\n",
    "    \n",
    "    :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "    :return config: A dict that supplements default hyperparameter values with 1) \n",
    "                    task-appropriate ones, and perhaps later 2) optimal hyperparameter values.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    config['library'] = library\n",
    "#     if library == 'xgboost':\n",
    "#         config['model'] = XGBClassifier()\n",
    "#     elif library == 'lightgbm':\n",
    "#         config['model'] = LGBMClassifier()\n",
    "#     elif library == 'catboost':\n",
    "#         config['model'] = CatBoostClassifier()\n",
    "#     else:\n",
    "#         print(\"Invalid library\")\n",
    "#         return None\n",
    "    \n",
    "    # library-specific config\n",
    "#     if config['model'] in [XGBClassfier, LGBMClassifier]:\n",
    "    if library in ['xgboost', 'lightgbm']:\n",
    "#         config['reg_alpha'] = None\n",
    "        config['n_jobs'] = -1\n",
    "\n",
    "#     if config['model'] == XGBClassifier:\n",
    "    if library == 'xgboost':\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "        config['verbosity'] = 1\n",
    "        config['objective'] = 'binary:logistic'\n",
    "        config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "        config['tree_method'] = 'gpu_hist' if (gpu_available and colab) else 'auto' \n",
    "#         config['reg_alpha'] = \n",
    "\n",
    "#     if config['model'] == LGBMClassifier:\n",
    "    if library == 'lightgbm':\n",
    "        config['objective'] = 'binary'\n",
    "        config['eval_metric'] = ['auc', 'logloss']\n",
    "        config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "        config['device_type'] = 'cuda' if (gpu_available and colab) else 'cpu' # 'gpu' also possible, 'cpu' is default\n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "    if library == 'catboost':\n",
    "        config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "        config['custom_metrics'] = ['Logloss', 'AUC'] # objective (loss fn) must be singular, defaults to Logloss\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9b4dd2-f63c-47df-979e-cb372b57e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_config(model, config=universal_config):\n",
    "#     \"\"\"\n",
    "#     Function that will take a dict containing universal defaults and then flesh them out\n",
    "#     based on the model specified via argument, and return a new, completed configuration \n",
    "#     dict.\n",
    "    \n",
    "#     Rationale: creating a helper function will allow more experimentation later, and also\n",
    "#     composite runs that cycle through a series of models.\n",
    "    \n",
    "#     :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "#     :return config: A dict that fleshes out the basic, universal default config dict with\n",
    "#                     additional, model-specific values.\n",
    "#     \"\"\"\n",
    "#     config['model'] = model\n",
    "    \n",
    "#     # library-specific config\n",
    "#     if config['model'] in [XGBClassfier, LGBMClassifier]:\n",
    "#         config['reg_alpha'] = None\n",
    "#         config['n_jobs'] = -1\n",
    "\n",
    "#     if config['model'] == XGBClassifier:\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "#         config['verbosity'] = 1\n",
    "#         config['objective'] = 'binary:logistic'\n",
    "#         config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "#         config['reg_alpha'] = \n",
    "\n",
    "#     if config['model'] == LGBMClassifier:\n",
    "#         config['objective'] = 'binary'\n",
    "#         config['metric'] = 'auc'\n",
    "#         config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "#         config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "#         config['eval_metrics'] = ['Logloss', 'AUC']\n",
    "\n",
    "#     return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb91d4-1b4c-45f8-93f7-c9397521edda",
   "metadata": {},
   "source": [
    "### Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bec548-7cba-4a42-bacf-02f7b71c0065",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48006b30-619f-42f4-b653-4b859b3fb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_run = {\n",
    "    # wandb config:\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['baseline'],\n",
    "    'notes': \"Initial runs of each model-type, with sane defaults.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f8d1-d303-4420-b671-51fcbff98594",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Scaling has already occurred -- used `StandardScaler` as a precursor to using `KNNImputer(n_neighbors=5)`, on the premise that imputation would proceed more quickly if things were already scaled. I may try different permutations of this later: using `IterativeImputer` instead, before or after scaling, potentially with different scalers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77e37c-8f76-44b2-9e04-7fa02430ce96",
   "metadata": {},
   "source": [
    "# Feature Creation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb77f573-e284-49a7-96a8-bb33b5b44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the polynomialfeatures generated with `PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)`\n",
    "# X_np = np.load(datapath/'X_poly_unscaled.npy')\n",
    "# X = pd.DataFrame(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e905f6-f5e4-4848-98e3-ddc846ab4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e4c99-64d4-4506-b208-397ce736eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2728178c-5214-4c6c-ab86-5d63aeb2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cbdaa47-cab5-441b-885d-d21b33c604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly_names = poly.get_feature_names(X.columns)\n",
    "# # X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f6bd0c-1121-4430-966d-7a318d925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c528d2-2148-409f-9489-254358a4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(X_poly, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0682b3-1fef-4c54-9a33-99f659a2c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[features[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24391812-dce3-4513-bd38-ee95694730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_valid, y_train, y_valid, model_config, \n",
    "                                              random_state=42,\n",
    "                                              exmodel_config=exmodel_config, \n",
    "                                              config_run=config_run):#, scaler): # passed in via config dict for now\n",
    "    \"\"\"\n",
    "    Basic training function. Note that some of the options passed via the argument are\n",
    "    in fact hard-coded in, to avoid inconveniences.\n",
    "    :param X_train: the training set features\n",
    "    :param X_valid: the validation set features\n",
    "    :param y_train: the training set targets\n",
    "    :param y_valid: the validation set targets\n",
    "    :param random_state: for reproducibility\n",
    "    :param exmodel_config: dict containing configuration details including the library \n",
    "                            (thus model) used, preprocessing, and cross-validation\n",
    "    :param model_config: dict containing hyperparameter specifications for the model\n",
    "    :param config_run: dict containing wandb run configuration (name, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"202109_Kaggle_tabular_playground\",\n",
    "        save_code=True,\n",
    "        tags=config_run['tags'],\n",
    "        name=config_run['name'],\n",
    "        notes=config_run['notes'],\n",
    "        config=exmodel_config)   \n",
    "        \n",
    "    # applying hold-out before scaling\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=config['test_size'], \n",
    "#                                                           random_state=config['random_state']\n",
    "#                                                          )\n",
    "    \n",
    "    # strictly speaking should do the below, but doing beforehand faster and fine in this context\n",
    "    # scaling (i.e. normalizing)\n",
    "#     scaler = config['scaler']()\n",
    "#     X_train_s = scaler.fit_transform(X_train)\n",
    "#     X_valid_s = scaler.fit_transform(X_valid)\n",
    "    \n",
    "    # selecting features\n",
    "#     selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                           k=config['k_best'])\n",
    "#     X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "#     X_valid_fs = X_valid_s[:, selector.get_support()] # ensures same features are used in validation\n",
    "\n",
    "    if model_config['library'] == 'xgboost':\n",
    "        model = XGBClassifier(\n",
    "#             tree_method=config['tree_method'],\n",
    "#             booster=config['booster'],\n",
    "#             n_estimators=config['n_estimators'], \n",
    "#             max_depth=config['max_depth'],\n",
    "#             learning_rate=config['learning_rate'], \n",
    "#             subsample=config['subsample'],\n",
    "#             reg_alpha=config['reg_alpha'],\n",
    "#             reg_lambda=config['reg_lambda'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "            eval_metric=model_config['eval_metric'],\n",
    "            tree_method=model_config['tree_method'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "\n",
    "\n",
    "    elif config['library'] == 'lightgbm':\n",
    "        model = LGBMClassifier(\n",
    "#             boosting_type=model_config['boosting_type'],\n",
    "#             max_depth=model_config['max_depth']\n",
    "            # TODO\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "            eval_metric=model_config['eval_metric'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=mdoel_config['device_type'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()])\n",
    "        \n",
    "    elif config['library'] == 'catboost':\n",
    "        print(\"CatBoost, therefore no WandB callback.\")\n",
    "        model = CatBoostClassifier(\n",
    "#             n_estimators=config['n_estimators'],\n",
    "#             learning_rate=config['learning_rate'],\n",
    "#             max_depth=config['max_depth'],\n",
    "            task_type=config['task_type'],\n",
    "    #         n_jobs=config['n_jobs'],\n",
    "    #         verbosity=config['verbosity'],\n",
    "    #         subsample=config['subsample'],\n",
    "            random_state=random_state,\n",
    "            # objective='Logloss', # default, accepts only one\n",
    "            custom_metrics=config['custom_metrics'],\n",
    "    #         bootstrap_type=config['bootstrap_type'],\n",
    "    #         device:config['device']\n",
    "        ) \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_loss = log_loss(y_train, y_train_pred)\n",
    "        train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "        wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "\n",
    "    wandb.log(model.get_params()) # logging model parameters, trying bare-invocation rather than params: model.get_params()\n",
    "    y_pred = model.predict(X_valid)\n",
    "#     mse = mean_squared_error(y_valid, y_pred)\n",
    "#     rmse = math.sqrt(abs(mse))\n",
    "    valid_loss = log_loss(y_valid, y_pred)\n",
    "    valid_auc = roc_auc_score(y_valid, y_pred)\n",
    "    wandb.log({'valid_loss':valid_loss, 'valid_auc':valid_auc})\n",
    "    print(f\"Valid log-loss is {log_loss}\\nValid AUC is {valid_auc}\")   \n",
    "#     wandb.finish()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_config, X=X, y=y, start_fold=0, exmodel_config=exmodel_config, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1:\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=exmodel_config['test_size'], \n",
    "                                                      random_state=random_state,\n",
    "                                                     )\n",
    "        model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "        wandb.finish()\n",
    "        \n",
    "    else:\n",
    "        kfold = config['kfold_strategy'](n_splits=kfolds, shuffle=True, random_state=random_state)\n",
    "        models = {}\n",
    "        model_path = Path(datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/\")\n",
    "        (model_path).mkdir(exist_ok=True)\n",
    "        for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "            if fold < start_fold:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"FOLD {fold}\")\n",
    "                print(\"---------------------------------------------------\")\n",
    "                X, y = X.to_numpy(), y.to_numpy()\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "                model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "                wandb.log({'fold': fold})\n",
    "                models[fold] = model\n",
    "                dump(model, Path(model_path/f\"{exmodel_config['library']}_fold{fold}_model.joblib\"))\n",
    "                wandb.finish()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92835afb-3ff2-42c6-964c-cfeede2c5990",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edc7d8-76db-4e2e-8517-c7b5a24f8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, let's do the initial baseline for each of the Big Three libraries, largely using their own defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314eca54-a032-44dc-b6cf-39eed84f77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with holdout\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4b3fe26bcc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configurator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-924f9e2ac9f3>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model_config, X, y, start_fold, exmodel_config, random_state)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Proceeding with holdout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n\u001b[0;32m---> 12\u001b[0;31m                                                       \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                                                       \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                      )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_size'"
     ]
    }
   ],
   "source": [
    "model_config = model_configurator('xgboost')\n",
    "cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f545d2-1fef-460f-89e0-304c91761860",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = model_configurator('lightgbm')\n",
    "cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7f7e8-31d2-419e-b3df-e9503d561040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = model_configurator('catboost')\n",
    "cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0333a-b1cb-45bd-adc2-e6563ae31770",
   "metadata": {},
   "source": [
    "# K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a17679c-152f-4aff-a1dd-d09ab727ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUALLY probably better to save those as pickles or .npy files; I'll generate them later, regardless\n",
    "# results = {} # for storing k-fold models' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd996d02-2530-4a40-84ec-01f8cde635da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=config['k_folds'], shuffle=True, random_state=config['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e75f832-d012-4021-9628-984209569b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "529afca9-85db-4499-a909-089fb2f10899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(f\"./models/{config_run['name']}_{config['k_folds']}folds/\")\n",
    "(model_path).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81b675b9-3eef-4546-a638-0418ce991653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find XGBoost_ensemble_20210831_no_feature_gen.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.33193748555472\n",
      "RMSE is 7.83147096563313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493223<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.33194</td></tr><tr><td>rmse</td><td>7.83147</td></tr><tr><td>_runtime</td><td>1591</td></tr><tr><td>_timestamp</td><td>1630429873</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 62.24235031226011\n",
      "RMSE is 7.889382124872651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493899<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>62.24235</td></tr><tr><td>rmse</td><td>7.88938</td></tr><tr><td>_runtime</td><td>1539</td></tr><tr><td>_timestamp</td><td>1630431417</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.81231376886642\n",
      "RMSE is 7.862080753138218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494220<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.81231</td></tr><tr><td>rmse</td><td>7.86208</td></tr><tr><td>_runtime</td><td>1551</td></tr><tr><td>_timestamp</td><td>1630432972</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.666720656537805\n",
      "RMSE is 7.852816097206008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494521<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.66672</td></tr><tr><td>rmse</td><td>7.85282</td></tr><tr><td>_runtime</td><td>1548</td></tr><tr><td>_timestamp</td><td>1630434524</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.61926325055153\n",
      "RMSE is 7.849793834907484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494841<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.61926</td></tr><tr><td>rmse</td><td>7.84979</td></tr><tr><td>_runtime</td><td>1533</td></tr><tr><td>_timestamp</td><td>1630436061</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#     if fold == 0:\n",
    "#         continue\n",
    "#     else:\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    X_train, X_valid = X_scaled[train_ids], X_scaled[valid_ids] # requires X to be a numpy.ndarray\n",
    "    y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "    model = train(X_train, X_valid, y_train, y_valid, config)\n",
    "    wandb.log({'fold': fold})\n",
    "    models[fold] = model\n",
    "    dump(model, Path(model_path/f\"xgboost_fold{fold}_model.joblib\"))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e972a4-67b9-4fd8-96b1-6525e805f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     dump(preds, f\"./preds/{config_rn['name']}/xgboost_fold{fold}_preds.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02baf90b-01bc-4945-b64c-5af0c6e309be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e394bc6-29fe-4033-a850-bf6d55883b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(datapath/'test.csv', index_col='id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e85f83d-b5a3-4c9e-b654-dfd743f2966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250000</th>\n",
       "      <td>0.812665</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.239120</td>\n",
       "      <td>-0.893251</td>\n",
       "      <td>295.5770</td>\n",
       "      <td>15.87120</td>\n",
       "      <td>23.04360</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>29.898000</td>\n",
       "      <td>1.11394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>-422.332</td>\n",
       "      <td>-1.44630</td>\n",
       "      <td>1.69075</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>-3.010570</td>\n",
       "      <td>1.94664</td>\n",
       "      <td>0.529470</td>\n",
       "      <td>1.386950</td>\n",
       "      <td>8.78767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250001</th>\n",
       "      <td>0.190344</td>\n",
       "      <td>131</td>\n",
       "      <td>-0.501361</td>\n",
       "      <td>0.801921</td>\n",
       "      <td>64.8866</td>\n",
       "      <td>3.09703</td>\n",
       "      <td>344.80500</td>\n",
       "      <td>0.807194</td>\n",
       "      <td>38.421900</td>\n",
       "      <td>1.09695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377179</td>\n",
       "      <td>10352.200</td>\n",
       "      <td>21.06270</td>\n",
       "      <td>1.84351</td>\n",
       "      <td>0.251895</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>11.79390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250002</th>\n",
       "      <td>0.919671</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.057382</td>\n",
       "      <td>0.901419</td>\n",
       "      <td>11961.2000</td>\n",
       "      <td>16.39650</td>\n",
       "      <td>273.24000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>1.15222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>3224.020</td>\n",
       "      <td>-2.25287</td>\n",
       "      <td>1.55100</td>\n",
       "      <td>-0.559157</td>\n",
       "      <td>17.838600</td>\n",
       "      <td>1.83385</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>2.336870</td>\n",
       "      <td>9.05400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250003</th>\n",
       "      <td>0.860985</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.549509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>7501.6000</td>\n",
       "      <td>2.80698</td>\n",
       "      <td>71.08170</td>\n",
       "      <td>0.792136</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>1.20157</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>9689.760</td>\n",
       "      <td>14.77150</td>\n",
       "      <td>1.41390</td>\n",
       "      <td>0.329272</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>2.23251</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>1.359470</td>\n",
       "      <td>4.84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250004</th>\n",
       "      <td>0.313229</td>\n",
       "      <td>89</td>\n",
       "      <td>0.588509</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>2931.2600</td>\n",
       "      <td>4.34986</td>\n",
       "      <td>1.57187</td>\n",
       "      <td>1.118300</td>\n",
       "      <td>7.754630</td>\n",
       "      <td>1.16807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>2693.350</td>\n",
       "      <td>44.18050</td>\n",
       "      <td>1.58020</td>\n",
       "      <td>-0.191021</td>\n",
       "      <td>26.253000</td>\n",
       "      <td>2.68238</td>\n",
       "      <td>0.361923</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>3.70660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0   f1        f2        f3          f4        f5         f6  \\\n",
       "id                                                                           \n",
       "250000  0.812665   15 -1.239120 -0.893251    295.5770  15.87120   23.04360   \n",
       "250001  0.190344  131 -0.501361  0.801921     64.8866   3.09703  344.80500   \n",
       "250002  0.919671   19 -0.057382  0.901419  11961.2000  16.39650  273.24000   \n",
       "250003  0.860985   19 -0.549509  0.471799   7501.6000   2.80698   71.08170   \n",
       "250004  0.313229   89  0.588509  0.167705   2931.2600   4.34986    1.57187   \n",
       "\n",
       "              f7         f8       f9  ...       f90        f91       f92  \\\n",
       "id                                    ...                                  \n",
       "250000  0.942256  29.898000  1.11394  ...  0.446389   -422.332  -1.44630   \n",
       "250001  0.807194  38.421900  1.09695  ...  0.377179  10352.200  21.06270   \n",
       "250002 -0.003300  37.940000  1.15222  ...  0.990140   3224.020  -2.25287   \n",
       "250003  0.792136   0.395235  1.20157  ...  1.396880   9689.760  14.77150   \n",
       "250004  1.118300   7.754630  1.16807  ...  0.862502   2693.350  44.18050   \n",
       "\n",
       "            f93       f94        f95      f96       f97       f98       f99  \n",
       "id                                                                           \n",
       "250000  1.69075  1.059300  -3.010570  1.94664  0.529470  1.386950   8.78767  \n",
       "250001  1.84351  0.251895   4.440570  1.90309  0.248534  0.863881  11.79390  \n",
       "250002  1.55100 -0.559157  17.838600  1.83385  0.931796  2.336870   9.05400  \n",
       "250003  1.41390  0.329272   0.802437  2.23251  0.893348  1.359470   4.84833  \n",
       "250004  1.58020 -0.191021  26.253000  2.68238  0.361923  1.532800   3.70660  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ec520-259f-44d2-ad33-7b8c22621132",
   "metadata": {},
   "source": [
    "(Here's where encapsulating the transformations in a pipeline would come in handy. But I'll do it manually for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ec74e4-ccb8-43b4-b910-3df1542aaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in test_df.columns if x != 'loss']\n",
    "X_test = test_df[features] # this is just for naming consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725cd3e-f883-4d20-837a-9f557b2122a9",
   "metadata": {},
   "source": [
    "Now, let's get the features the model was trained on and subset the test set's features accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f66e579-7f01-46e5-a47c-580c8f5d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1817e3a-7d90-4bc2-8c47-e97806f7dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_poly_names = poly.get_feature_names(X_test.columns)\n",
    "# X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d6bc49-d478-4f59-84d2-5e23e3e236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_test_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa68187e-271a-4df1-ae02-a2bb5d62c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = pd.DataFrame(X_test_poly, columns=X_test_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1020ad9b-1b05-49b8-b89b-c90362c256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = X_test_final[features[1:]]\n",
    "X_test_final = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c226e-1ef7-4e03-91a1-06fbb73139f0",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "Now, going to scale using `MaxAbsScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21da840a-caa6-4d76-a542-c1315a593346",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = config['scaler']()\n",
    "X_test_scaled = scaler.fit_transform(X_test_final)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3cbac-0995-4015-9940-fe3e8ec94724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8929a3a1-56ca-4f20-a44f-e3877c6dabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# # scaling (i.e. normalizing)\n",
    "# scaler = config['scaler']()\n",
    "# X_train_s = scaler.fit_transform(X_train)\n",
    "# X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# # selecting features\n",
    "# selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                       k=config['k_best'])\n",
    "# X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "# X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "# model = XGBRegressor(\n",
    "#     tree_method=config['tree_method'],\n",
    "#     booster=config['booster'],\n",
    "#     n_estimators=config['n_estimators'], \n",
    "#     max_depth=config['max_depth'],\n",
    "#     learning_rate=config['learning_rate'], \n",
    "#     test_size=config['test_size'],\n",
    "#     subsample=config['subsample'],\n",
    "#     random_state=config['random_state'],\n",
    "#     n_jobs=config['n_jobs'], \n",
    "#     verbosity=config['verbosity'], \n",
    "# )\n",
    "# #     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "# model.fit(X_train_fs, y_train)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b151abea-d9b0-48eb-969f-5c342fc13474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 1: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 2: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 3: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 4: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348db7c-c494-4616-a08f-55016fac5351",
   "metadata": {},
   "source": [
    "Now, iterate over the dict containing the models trained on the 5 folds, and store the predictions in a new dict `preds`\n",
    "**OR**\n",
    "load from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d608ff29-4ceb-43cb-a0bb-e1450c0b8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = {}\n",
    "# saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/inference_ensemble_20210828_204126_5folds/')\n",
    "# for fold in range(5):\n",
    "#     loaded_models[fold] = load(filename=Path(saved_models_path/f'xgboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285899b2-0b2e-4db3-9b1e-a0d8328b84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa072384-5154-4d54-8ddf-5452e9323882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "for fold in models.keys():\n",
    "    preds[fold] = models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a464a1c-9ca8-4a07-9cdb-18af399cf95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d6e6414-5f72-4a48-b5a1-a8d24486bbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc067fb9-ae8e-4b33-9d75-e5405043aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eca32f6-2267-4c98-9aa9-c4a31d69bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "       9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9d2f4b8-2356-4916-a091-45793db784ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c957ce26-bbf5-4aee-bccd-988f2471db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.007940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.532623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.855750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.124434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.444796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.007940\n",
       "1  250001  4.532623\n",
       "2  250002  7.855750\n",
       "3  250003  7.124434\n",
       "4  250004  7.444796"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4cc6d50-92bc-4295-9acc-5d345eb96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b13044-ddb7-4bfb-bdbc-71a42172efc1",
   "metadata": {},
   "source": [
    "# Ensembling with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85c2ffdf-6f70-4fbd-880d-2145c5e13ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_models = {}\n",
    "saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/CatBoost_ensemble_20210831_144245_5folds/')\n",
    "for fold in range(5):\n",
    "    catboost_models[fold] = load(filename=Path(saved_models_path/f'catboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22852978-0c80-413e-900d-363b6055661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <catboost.core.CatBoostRegressor at 0x7f1b154ecfa0>,\n",
       " 1: <catboost.core.CatBoostRegressor at 0x7f1b1548a880>,\n",
       " 2: <catboost.core.CatBoostRegressor at 0x7f1b154ec0a0>,\n",
       " 3: <catboost.core.CatBoostRegressor at 0x7f1b1548ac40>,\n",
       " 4: <catboost.core.CatBoostRegressor at 0x7f1b154ecdf0>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa291c7b-61c6-4ec4-928a-f01225ce68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = {}\n",
    "for fold in catboost_models.keys():\n",
    "    catboost_preds[fold] = catboost_models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e8099a5-b1aa-4aa0-926e-0d493a0dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_catboost_preds = (catboost_preds[0] + catboost_preds[1] + catboost_preds[2] + catboost_preds[3] + catboost_preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b1883aa-4b27-4ae8-bf84-44eef2de90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = 0.6 * final_catboost_preds + 0.4 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30feee22-238b-4807-93df-9c005d91491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.40583658, 4.58774964, 8.32465697, 7.18375788, 7.13135284,\n",
       "        9.67367649, 9.96252577, 5.89393404, 7.22270917, 7.53612671]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f43e0f1-ada2-4299-9b96-10987b073f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_preds = 0.65 * final_catboost_preds + 0.35 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdf4700f-a87a-472a-9228-726c9d76748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.4389943 , 4.5923435 , 8.36373235, 7.18870129, 7.10523255,\n",
       "        9.67708804, 9.96419843, 5.87235472, 7.23656006, 7.52442615]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c04c606-ea73-4744-8b7a-b71deef61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f9f1b0b-9153-4607-b199-28b79d2db7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.438994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.592343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>8.363732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.188701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.105233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.438994\n",
       "1  250001  4.592343\n",
       "2  250002  8.363732\n",
       "3  250003  7.188701\n",
       "4  250004  7.105233"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c9f3ab0-a385-416c-9fd8-be27c4301874",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost0.35-Catboost0.65_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67df4d3-54f8-43fe-9f14-d3751986a58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment - fitting model on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8331118-e7a3-4578-8e43-cf93067c6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:15] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"test_size\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             test_size=0.2, tree_method='auto', validate_parameters=1,\n",
       "             verbosity=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# scaling (i.e. normalizing)\n",
    "scaler = config['scaler']()\n",
    "X_s = scaler.fit_transform(X)\n",
    "X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# selecting features\n",
    "selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "                                      k=config['k_best'])\n",
    "X_fs = selector.fit_transform(X_s, y)\n",
    "X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    tree_method=config['tree_method'],\n",
    "    booster=config['booster'],\n",
    "    n_estimators=config['n_estimators'], \n",
    "    max_depth=config['max_depth'],\n",
    "    learning_rate=config['learning_rate'], \n",
    "    test_size=config['test_size'],\n",
    "    subsample=config['subsample'],\n",
    "    random_state=config['random_state'],\n",
    "    n_jobs=config['n_jobs'], \n",
    "    verbosity=config['verbosity'], \n",
    ")\n",
    "#     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "model.fit(X_fs, y)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90ba24b-75cd-4c2d-a2cf-fe7bf16b3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db93b42-8460-4793-bd0f-60ddb1d7e84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bfc7e54-043d-4abb-818e-503846c0f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50b58c49-59e9-4751-8373-98536c9a121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.027956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.305676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.300106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>6.988875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.316631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.027956\n",
       "1  250001  4.305676\n",
       "2  250002  7.300106\n",
       "3  250003  6.988875\n",
       "4  250004  7.316631"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41d0f44a-2ca7-486f-9197-48534a35043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('202108241211_XGBoost_fullset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
