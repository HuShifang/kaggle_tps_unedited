{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GBM Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7c0bc-ccc7-4454-816a-c1f35bfd6f07",
   "metadata": {},
   "source": [
    "20211202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9149871d-3242-4bb9-81b1-61c0a76a656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "SAGE = False # if notebook will be used on Amazon SageMaker\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797f54a-c512-46e3-b1f3-d7cea8f35c9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b527dd9-23a5-46d5-949c-f6f2d771390b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAGE:\n",
    "    !pip install --upgrade sklearn\n",
    "    !pip install --upgrade wandb\n",
    "    !pip install --upgrade catboost\n",
    "    !pip install --upgrade lightgbm\n",
    "    !pip install --upgrade xgboost\n",
    "    !pip install optuna\n",
    "    !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ab5185-9999-40e3-aba9-b4e6a965b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import requests # for telegram notifications\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b614bc-76c5-43a9-a23f-71ca21e6f0d8",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bbc347-4b2b-428f-8628-07bc0fcf85e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss, f1_score, fbeta_score\n",
    "\n",
    "# eda\n",
    "# import missingno\n",
    "# import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import cleanlab\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"optuna_gbms_{datetime.now().strftime('%Y%m%d')}_sage.ipynb\"\n",
    "\n",
    "# hyperparameter tuning\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0f2234-70b6-48b8-986c-d608f033952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # deep learning\n",
    "# import torch\n",
    "# from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# # widedeep\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97eee37-af6d-4e13-bad5-3109805e7780",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bb6a1-5b53-4caf-8143-6a99509dc0e8",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e426c44-807e-4a93-8a80-01b8471af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    if SAGE:\n",
    "        root = Path('/home/studio-lab-user/sagemaker-studiolab-notebooks')\n",
    "    else:\n",
    "        root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/dec2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd240c-0e91-42da-be87-5bde74e957d1",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6744ad23-307b-4470-ad71-8825b35a22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # if pytorch:\n",
    "    #     torch.manual_seed(seed) # set torch CPU seed\n",
    "    #     if torch.cuda.is_available():\n",
    "    #         torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "    #     if reproducible and torch.backends.cudnn.is_available():\n",
    "    #         torch.backends.cudnn.deterministic = True\n",
    "    #         torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef91eec7-92a7-433c-9d12-18f398ff452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d282d62c-db15-44c4-8af7-02a0756ab634",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7119a9-d04d-43cb-9f17-f60933a4fda3",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd703085-3fb2-4243-a0f7-42376a3ecd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_orig.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "# if SAGE:\n",
    "#     X = load(datapath/'X_orig.joblib')\n",
    "# else:\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "# X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "# reduce memory usage\n",
    "# X = reduce_memory_usage(X)\n",
    "# X_test = reduce_memory_usage(X)\n",
    "\n",
    "# metadata logging\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0d397-1a03-4d54-9178-513837cbe00d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f5f07-b20b-4565-8a24-5147c06aca84",
   "metadata": {},
   "source": [
    "First, going to try some of the basic tweaks suggested [here](https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/293612)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0443c853-c96f-46a3-9a59-31247dfd8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unuseful features\n",
    "# X = X.drop([ 'Soil_Type7', 'Soil_Type15'], axis=1)\n",
    "# X_test = X_test.drop(['Soil_Type7', 'Soil_Type15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954896c4-9474-4ab1-9e23-fe903bb82903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000, 54)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8611034a-0720-4ca0-a454-a2164d9d427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra feature engineering\n",
    "def r(x):\n",
    "    if x+180>360:\n",
    "        return x-180\n",
    "    else:\n",
    "        return x+180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5276dc-1c26-4d3e-95d4-4928ac165da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(df):\n",
    "    df['EHiElv'] = df['Horizontal_Distance_To_Roadways'] * df['Elevation']\n",
    "    df['EViElv'] = df['Vertical_Distance_To_Hydrology'] * df['Elevation']\n",
    "    df['Aspect2'] = df.Aspect.map(r)\n",
    "    ### source: https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/293373\n",
    "    df[\"Aspect\"][df[\"Aspect\"] < 0] += 360\n",
    "    df[\"Aspect\"][df[\"Aspect\"] > 359] -= 360\n",
    "    df.loc[df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n",
    "    df.loc[df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n",
    "    df.loc[df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n",
    "    df.loc[df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n",
    "    df.loc[df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n",
    "    df.loc[df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n",
    "    ########\n",
    "    df['Highwater'] = (df.Vertical_Distance_To_Hydrology < 0).astype(int)\n",
    "    df['EVDtH'] = df.Elevation - df.Vertical_Distance_To_Hydrology\n",
    "    df['EHDtH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\n",
    "    df['Euclidean_Distance_to_Hydrology'] = (df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\n",
    "    df['Manhattan_Distance_to_Hydrology'] = df['Horizontal_Distance_To_Hydrology'] + df['Vertical_Distance_To_Hydrology']\n",
    "    df['Hydro_Fire_1'] = df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    df['Hydro_Fire_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n",
    "    df['Hydro_Road_1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Hydro_Road_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Hillshade_3pm_is_zero'] = (df.Hillshade_3pm == 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2d6241-7a87-4600-a898-3304196bb17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-594eed306287>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Aspect\"][df[\"Aspect\"] < 0] += 360\n",
      "<ipython-input-14-594eed306287>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Aspect\"][df[\"Aspect\"] > 359] -= 360\n"
     ]
    }
   ],
   "source": [
    "X = fe(X)\n",
    "# X_test = fe(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc2048d9-2a68-481d-9e8e-b6f0b9df1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summed features pointed out by @craigmthomas (https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/292823)\n",
    "soil_features = [x for x in X.columns if x.startswith(\"Soil_Type\")]\n",
    "wilderness_features = [x for x in X.columns if x.startswith(\"Wilderness_Area\")]\n",
    "\n",
    "X[\"soil_type_count\"] = X[soil_features].sum(axis=1)\n",
    "# X_test[\"soil_type_count\"] = X_test[soil_features].sum(axis=1)\n",
    "\n",
    "X[\"wilderness_area_count\"] = X[wilderness_features].sum(axis=1)\n",
    "# X_test[\"wilderness_area_count\"] = X_test[wilderness_features].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade18003-d8ba-486a-af54-b463bcb6b72f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40', 'EHiElv', 'EViElv', 'Aspect2',\n",
       "       'Highwater', 'EVDtH', 'EHDtH', 'Euclidean_Distance_to_Hydrology',\n",
       "       'Manhattan_Distance_to_Hydrology', 'Hydro_Fire_1', 'Hydro_Fire_2',\n",
       "       'Hydro_Road_1', 'Hydro_Road_2', 'Fire_Road_1', 'Fire_Road_2',\n",
       "       'Hillshade_3pm_is_zero', 'soil_type_count', 'wilderness_area_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d88cb-84cc-4336-b3f0-954ba4bdbacf",
   "metadata": {},
   "source": [
    "## Dataset Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6742e7c-022d-4e43-bf6d-fd8a3195d2d7",
   "metadata": {},
   "source": [
    "Initialized above, but now records of feature engineering efforts included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b5d80b-8c2b-4cea-8029-29a06f8958fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "\n",
    "# might eventually shift from dict to tuple\n",
    "\n",
    "# simplest approach: k-v where key is new feature, v is string with the operation to get it\n",
    "# sacrifices sortability, but could recover that through regexes, and it's much quicker to input\n",
    "dataset_params['feature_combinations'] = {\n",
    "    'EHiElv': \"df['Horizontal_Distance_To_Roadways'] * df['Elevation']\",\n",
    "    'EViElv': \"df['Vertical_Distance_To_Hydrology'] * df['Elevation']\",\n",
    "    'EVDtH': \"df.Elevation - df.Vertical_Distance_To_Hydrology\",\n",
    "    'EHDtH': \"df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\",\n",
    "    'Euclidean_Distance_to_Hydrology': \"(df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\",\n",
    "    'Manhattan_Distance_to_Hydrology': \"df['Horizontal_Distance_To_Hydrology'] + df['Vertical_Distance_To_Hydrology']\",\n",
    "    'Hydro_Fire_1': \"df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\",\n",
    "    'Hydro_Fire_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\",\n",
    "    'Hydro_Road_1': \"abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "    'Hydro_Road_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\",\n",
    "    'Fire_Road_1': \"abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "    'Fire_Road_2': \"abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\"\n",
    "}\n",
    "\n",
    "dataset_params['feature_clipping'] = [\n",
    "    {\n",
    "        'features': ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'],\n",
    "        'range': range(0,256)\n",
    "    },\n",
    "    {\n",
    "        'features': ['Aspect'],\n",
    "        'range': range(0,360)\n",
    "    }\n",
    "]\n",
    "\n",
    "# the features that are just getting the one-hots counted\n",
    "dataset_params['feature_counts'] = ['Soil_Type*', 'Wilderness_Area*']\n",
    "dataset_params['feature_complements'] = [\n",
    "    {\n",
    "        'old': 'Aspect', \n",
    "        'new': 'Aspect2',\n",
    "        'operation': 'If x < 180 return x-180, else return x + 180'\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_params['feature_indicators'] = {\n",
    "    'Hillshade_3pm_is_zero': \"(df.Hillshade_3pm == 0).astype(int)\",\n",
    "}\n",
    "\n",
    "dataset_params['feature_typecasting'] = {\n",
    "    'Highwater': \"(df.Vertical_Distance_To_Hydrology < 0).astype(int)\"\n",
    "}\n",
    "# dataset_params['feature_combinations'] = [\n",
    "#     {\n",
    "#         'old': ['Horizontal_Distance_To_Roadways', 'Elevation'], \n",
    "#         'new': 'EHiElv',\n",
    "#         'operation': '*'\n",
    "#     },\n",
    "#     {\n",
    "#         'old': ('Vertical_Distance_To_Hydrology', 'Elevation'), \n",
    "#         'new': 'EViElv',\n",
    "#         'operation': '*'\n",
    "#     },\n",
    "#     {\n",
    "#         'old': ['Elevation', 'Vertical_Distance_To_Hydrology'],\n",
    "#         'new': 'EVDtH',\n",
    "#         'operation': '-'\n",
    "#     },\n",
    "#     {\n",
    "#         'old': ['Elevation', 'Horizontal_Distance_To_Hydrology'],\n",
    "#         'new': 'EHDtH',\n",
    "#         'operation': 'df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2'\n",
    "#     },\n",
    "    # {\n",
    "    #     'old': ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology'],\n",
    "    #     'new': 'Euclidean_Distance_to_Hydrology',\n",
    "    #     'operation': \"(df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\"\n",
    "    # },\n",
    "    # {\n",
    "    #     'old': ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology'],\n",
    "    #     'new': 'Manhattan_Distance_to_Hydrology',\n",
    "    #     'operation': '+'\n",
    "    # },\n",
    "    # {\n",
    "    #     'old': ['Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points'],\n",
    "    #     'new': \n",
    "    \n",
    "# dataset_params['feature_crosses'] = [\n",
    "#     {\n",
    "#         'old': ['Horizontal_Distance_To_Roadways', 'Elevation'], \n",
    "#         'new': 'EHiElv',\n",
    "#         'operation': '*'\n",
    "#     },\n",
    "#     {\n",
    "#         'old': ('Vertical_Distance_To_Hydrology', 'Elevation'), \n",
    "#         'new': 'EViElv',\n",
    "#         'operation': '*'\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# dataset_params['feature_additions'] = [\n",
    "#     {\n",
    "#         'old': ['Elevation', 'Vertical_Distance_To_Hydrology'],\n",
    "#         'new': 'EVDtH',\n",
    "#         'operation': '-'\n",
    "#     }\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e9478-2380-4c4d-8641-5daa72049b6c",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc156663-c689-4dfe-a80b-5efaaae1afab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # optuna 20211124, with corrected dataset and RobustScaler\n",
    "# best_xgboost_params = {\n",
    "#     'n_estimators': 9872,\n",
    "#     'max_depth': 3,\n",
    "#     'learning_rate': 0.12943882615104757,\n",
    "#     'reg_alpha': 4.793236314677738,\n",
    "#     'reg_lambda': 0.03427038053813167,\n",
    "#     'subsample': 0.5026684329097286,\n",
    "#     'min_child_weight': 3.2374430610042664,\n",
    "#     'colsample_bytree': 0.9875504456465564,\n",
    "#     'gamma': 4.691772640321729\n",
    "# }\n",
    "\n",
    "# # best as of 20211125, with corrected dataset and RobustScaler\n",
    "# best_lightgbm_params = {\n",
    "#     'n_estimators': 6986,\n",
    "#     'max_depth': 3,\n",
    "#     'learning_rate': 0.09080435106650955,\n",
    "#     'reg_alpha': 19.060739534647425,\n",
    "#     'reg_lambda': 0.12865332700612375,\n",
    "#     'subsample': 0.5612404690403716,\n",
    "#     'boosting_type': 'goss',\n",
    "#     'min_child_samples': 17,\n",
    "#     'num_leaves': 59,\n",
    "#     'colsample_bytree': 0.5125554530181221\n",
    "# }\n",
    "\n",
    "# # best as of 20211126, with corrected dataset and RobustScaler\n",
    "# best_catboost_params = {\n",
    "#     'iterations': 17997,\n",
    "#     'depth': 4,\n",
    "#     'learning_rate': 0.05807421036756052,\n",
    "#     'random_strength': 27,\n",
    "#     'od_wait': 1664,\n",
    "#     'reg_lambda': 57.67864249277457,\n",
    "#     'border_count': 275,\n",
    "#     'min_child_samples': 10,\n",
    "#     'leaf_estimation_iterations': 2\n",
    "# }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_xgboost_params = {\n",
    "# #     'n_estimators': 1534,\n",
    "# #     'max_depth': 4,\n",
    "# #     'learning_rate': 0.0062941159127744535,\n",
    "# #     'reg_alpha': 21.3946930650266,\n",
    "# #     'reg_lambda': 0.021003786013817635,\n",
    "# #     'subsample': 0.5726680367393964,\n",
    "# #     'min_child_weight': 0.07566661785187714,\n",
    "# #     'colsample_bytree': 0.7850419523745037,\n",
    "# #     'gamma': 4.26660233356059\n",
    "# # }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_lightgbm_params = {\n",
    "# #     'n_estimators': 5776,\n",
    "# #     'max_depth': 4,\n",
    "# #     'learning_rate': 0.0010172282832994653,\n",
    "# #     'reg_alpha': 0.013879765609402173,\n",
    "# #     'reg_lambda': 0.002787031048344079,\n",
    "# #     'subsample': 0.800000753298926,\n",
    "# #     'boosting_type': 'gbdt',\n",
    "# #     'min_child_samples': 11,\n",
    "# #     'num_leaves': 190,\n",
    "# #     'colsample_bytree': 0.9976443570341007\n",
    "# # }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_catboost_params = {\n",
    "# #     'iterations': 2000,\n",
    "# #     'depth': 6,\n",
    "# #     'learning_rate': 0.002984126581340097,\n",
    "# #     'random_strength': 0,\n",
    "# #     'od_wait': 334,\n",
    "# #     'reg_lambda': 33.469738674488084,\n",
    "# #     'border_count': 158,\n",
    "# #     'min_child_samples': 8,\n",
    "# #     'leaf_estimation_iterations': 4\n",
    "# # }\n",
    "\n",
    "# # # initial, non-default guess -- need to get optuna working (20211010)\n",
    "# # # basic_widedeep_tabmlp_params = {\n",
    "    \n",
    "# # # }\n",
    "\n",
    "# # # basic_widedeep_trainer_params = {\n",
    "# # #     optimizers=AdamW()\n",
    "# # # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aec7210-135f-402a-af31-330eb0f37276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.basic import LightGBMError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930047e-a9fd-419b-a1a4-0856e3b3ce37",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb78111b-532c-41ce-b18a-aa2a7d868a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'general_random_state': SEED,\n",
    "}\n",
    "\n",
    "folds = 5\n",
    "training_params['cross_val_strategy'] = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52835a6b-bfe2-4152-a2ee-c6d796b7c614",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69e9346-ec9b-4549-b7d9-9837bcea2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- alter as needed later\n",
    "exmodel_config = {\n",
    "#     'general_random_state': SEED,\n",
    "# #     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'cross_val_strategy': KFold, \n",
    "#     'kfolds': 5, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    **training_params,\n",
    "    **dataset_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b463481-20bb-451f-bda8-051992e75e4c",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b4eaf-277f-40a4-a16b-9da08f218556",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca3847-48f7-4d3f-8f86-5e6706d3cd64",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['study'],\n",
    "    'notes': \"Optuna study of feature-engineered notebook, using new (more model-, infrastructure-agnostic) code\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827289c5-e0e7-4382-9cbd-d6174a5cd68b",
   "metadata": {},
   "source": [
    "# Cross-Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb083fa8-eb24-4fb0-b812-1cec9214e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params['cross_val_strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70da4cd9-98d8-4f43-afa5-2467800d8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=None, model_params:dict={}, training_params=training_params, dataset_params=dataset_params,\n",
    "                         folds=list(range(folds)), exmodel_config=exmodel_config, wandb_config=wandb_config,  telegram=True, random_state=42, \n",
    "                         wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    # if exmodel_config['kfolds'] == 1: # holdout case\n",
    "    #     print(\"Proceeding with holdout\")\n",
    "    #     X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "    #                                                           random_state=SEED)                 \n",
    "    # else: # k-fold cross validation case\n",
    "    #     # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    #     # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    #     if shuffle_kfolds:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    #     else:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    kfold = training_params['cross_val_strategy']\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    # test_preds = np.zeros((X_test.shape[0]))\n",
    "    # test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            if USE_GPU:\n",
    "                model = XGBClassifier(\n",
    "                    booster='gbtree',\n",
    "                    tree_method='gpu_hist',\n",
    "                    random_state=random_state,\n",
    "                    n_jobs=-1, \n",
    "                    verbosity=1, \n",
    "                    # objective='binary:logistic',\n",
    "                    objective='multi:softmax',\n",
    "                    **model_params)\n",
    "            else:\n",
    "                model = XGBClassifier(\n",
    "                    booster='gbtree',\n",
    "                    tree_method='hist',\n",
    "                    random_state=random_state,\n",
    "                    n_jobs=-1,\n",
    "                    verbosity=1,\n",
    "                    objective='multi:softmax',\n",
    "                    **model_params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            if USE_GPU:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "                    device_type='gpu',\n",
    "                    max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                    gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **model_params)\n",
    "            else:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "                    device_type='cpu',\n",
    "                    n_jobs=-1,\n",
    "                    **model_params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            if USE_GPU:\n",
    "                model = CatBoostClassifier(\n",
    "                    task_type='GPU',\n",
    "                    silent=True,\n",
    "                    random_state=random_state,\n",
    "                    **model_params) \n",
    "            else:\n",
    "                model = CatBoostClassifier(\n",
    "                    task_type='CPU',\n",
    "                    silent=True,\n",
    "                    random_state=random_state,\n",
    "                    **model_params)\n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)[:,1] # this would only take one of 7 cols\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test).flatten()\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        # fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       # f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        if telegram:\n",
    "            send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) \n",
    "    # model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    if telegram:\n",
    "        send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   # f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    # test_probs /= exmodel_config['kfolds']\n",
    "    # test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    # return oof_preds, test_preds#, model_confusion\n",
    "    return model_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2808c8e-2240-4e76-8e6f-a5115d73ed46",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53d18864-92d6-4346-a346-9542b3fd9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fe80e5-a547-495e-9b70-d294dc1b9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial, arch=arch):\n",
    "    \"\"\"\n",
    "    Wrapper around cross_validation_trainer to test different model hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    if arch == 'catboost':\n",
    "        model_params = {\n",
    "            'iterations' : trial.suggest_int('iterations', 2000, 30000),                         \n",
    "            'depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.5),               \n",
    "            'random_strength': trial.suggest_int('random_strength', 0, 100), \n",
    "    #         'objective': trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "    #         'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['MVC', 'Bernoulli']),#, 'Poisson']),\n",
    "            'od_wait': trial.suggest_int('od_wait', 20, 2000),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 2, 70), # aka l2_leaf_reg\n",
    "            'border_count': trial.suggest_int('border_count', 50, 275),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20), # aka min_data_in_leaf\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 5),\n",
    "            # 'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "    #         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "    #         'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "            # 'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    #         'max_leaves': trial.suggest_int('max_leaves', 32, 128)\n",
    "        }\n",
    "        \n",
    "    elif arch == 'xgboost':\n",
    "        model_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 500, 10000), # was 900-4500 for CPU\n",
    "            'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.3),               \n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 50),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "    #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "            'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 12),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "            'gamma': trial.suggest_uniform('gamma', 0.1, 10)\n",
    "        } \n",
    "    \n",
    "    return cross_validate_model(arch, model_params=model_params, wandb_tracked=True, telegram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a4e2b9b-6b24-40bd-83e5-9e3f90cb9e1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-500e760c9897>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_config)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/uncategorized/runs/a4bleb59\" target=\"_blank\">optuna_gbms_20211210_sage_200639</a></strong> to <a href=\"https://wandb.ai/hushifang/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69acd63c-e202-4d17-ae83-e4f8c030b490",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-10 20:06:45,373]\u001b[0m A new study created in memory with name: xgboost_study-20211210200645\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"{arch}_study-{start_time}\")\n",
    "\n",
    "# study = load(studypath/f\"optuna_xgboost_study_106trials_20211004.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a585ab8d-37f8-423e-9188-a582eecc8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a1f97-0beb-4598-93c2-b1e8037138e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a734b126-0001-4eb4-809a-beae021637b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost.core.XGBoostError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aad439f-3f4e-4bcc-b031-36be0562a9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.optimize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dba38886-c229-4094-9d06-c5e430eef36d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:a4bleb59) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 347977... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">optuna_gbms_20211210_sage_200639</strong>: <a href=\"https://wandb.ai/hushifang/uncategorized/runs/a4bleb59\" target=\"_blank\">https://wandb.ai/hushifang/uncategorized/runs/a4bleb59</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211210_200639-a4bleb59/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:a4bleb59). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3bieju8o\" target=\"_blank\">optuna_gbms_20211210_sage_200639</a></strong> to <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for fold 0 are: \n",
      "Accuracy: 0.96242375\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for fold 1 are: \n",
      "Accuracy: 0.9626225\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for fold 2 are: \n",
      "Accuracy: 0.96205125\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for fold 3 are: \n",
      "Accuracy: 0.96216625\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for fold 4 are: \n",
      "Accuracy: 0.962005\n",
      "optuna_gbms_20211210_sage.ipynb\n",
      "Metrics for model xgboost are: \n",
      "Accuracy: 0.96225375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 348025... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td></td></tr><tr><td>fold1_accuracy</td><td></td></tr><tr><td>fold2_accuracy</td><td></td></tr><tr><td>fold3_accuracy</td><td></td></tr><tr><td>fold4_accuracy</td><td></td></tr><tr><td>model_accuracy</td><td></td></tr><tr><td>model_seed</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_accuracy</td><td>0.96242</td></tr><tr><td>fold1_accuracy</td><td>0.96262</td></tr><tr><td>fold2_accuracy</td><td>0.96205</td></tr><tr><td>fold3_accuracy</td><td>0.96217</td></tr><tr><td>fold4_accuracy</td><td>0.962</td></tr><tr><td>model_accuracy</td><td>0.962</td></tr><tr><td>model_params</td><td>{'objective': 'multi...</td></tr><tr><td>model_seed</td><td>42</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">optuna_gbms_20211210_sage_200639</strong>: <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3bieju8o\" target=\"_blank\">https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/3bieju8o</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211210_200645-3bieju8o/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-10 23:45:17,079]\u001b[0m Trial 0 finished with value: 0.96225375 and parameters: {'n_estimators': 4058, 'depth': 10, 'learning_rate': 0.06504856968981275, 'reg_alpha': 0.6502468545951017, 'reg_lambda': 0.004994757081068292, 'subsample': 0.5779972601681014, 'min_child_weight': 0.6979452624062253, 'colsample_bytree': 0.9330880728874675, 'gamma': 6.051038616257767}. Best is trial 0 with value: 0.96225375.\u001b[0m\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.config.update",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5f208c98a2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, catch=(xgboost.core.XGBoostError,))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudypath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_{arch}_study-{start_time}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/integration/wandb.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, study, trial)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"direction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             raise wandb.Error(\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;34m\"You must call wandb.init() before {}.{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.config.update"
     ]
    }
   ],
   "source": [
    "for x in range(1, 500):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=False)#, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=studypath/f\"optuna_{arch}_study-{start_time}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738f809-eef0-4354-bf6f-a16f1a793c04",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'best_params': str(study.best_trial.params)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac281d00-4ada-45c2-a413-9e4b22514c3e",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f053d-97c4-4954-97fd-002e10aa2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
