{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6e85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f187210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda6c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"cleanlab_widedeep_{datetime.now().strftime('%Y%m%d')}c.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f470cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "# from BorutaShap import BorutaShap\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2851f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfcf7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauss_rank_scaler import GaussRankScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d047b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dcbdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ad331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0716e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58cd4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dbc24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    # 'train_source': str(datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_orig.joblib'),\n",
    "    # 'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9753a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    \"arch\": 'widedeep-TabMLP',\n",
    "    # \"type\": 'sweep',\n",
    "    # \"denoising\": \"cleanlab\",\n",
    "    \"level\": 1,\n",
    "    'random_state': SEED,\n",
    "    # 'tuner': \"Optuna\",\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    'scaler': str(GaussRankScaler()),\n",
    "    **dataset_params\n",
    "}\n",
    "\n",
    "wandb_config = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['experiment'],\n",
    "    'notes': \"Testing to see if Cleanlab works with WideDeep models sans wrappers; also, comparing a baseline.\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ca655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h/t Laurent Pourchot https://www.kaggle.com/pourchot/in-python-tabular-denoising-residual-network/\n",
    "\n",
    "# 100 bins for the bins head of the NN (i.e. percentiles):\n",
    "X_bins = np.zeros((X.shape[0],X.shape[1])) # he used all available data for the first tuple entry, but I'll start like this\n",
    "X_test_bins = np.zeros((X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9269571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65a4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]): # assumes X is a pd.DataFrame\n",
    "    X_bins[:,i] = pd.qcut(X.iloc[:,i],X.shape[1],labels=False)#,duplicates = 'drop')\n",
    "    \n",
    "for i in range(X_test.shape[1]): # assumes X_test is a pd.DataFrame\n",
    "    X_test_bins[:,i] = pd.qcut(X_test.iloc[:,i],X_test.shape[1], labels=False)#,duplicates = 'drop')\n",
    "# blabeled = X_bins[:X.shape[0],:]\n",
    "# bunlabeled = X_ins[X.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eedfaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_test_bins).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8e90dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_bins = X_bins.astype(np.int8)\n",
    "# X_test_bins = X_test_bins.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6266ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bins = pd.DataFrame(X_bins, index=X.index, columns=[f'rkd_f{col}' for col in range(100)])\n",
    "X_test_bins = pd.DataFrame(X_test_bins, index=X_test.index, columns=[f'rkd_f{col}' for col in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0faf45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GaussRankScaler(n_jobs=-1, epsilon=0.005)\n",
    "X_gauss = scaler.fit_transform(X)\n",
    "X_test_gauss = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d52a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))"
     ]
    }
   ],
   "source": [
    "np.where(np.isnan(X_test_gauss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36498f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gauss = pd.DataFrame(X_gauss, columns=X.columns, index=X.index)\n",
    "X_test_gauss = pd.DataFrame(X_test_gauss, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45fe7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = X_gauss.join(X_bins)\n",
    "X_test_pre = X_test_gauss.join(X_test_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00c82b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = X_pre.iloc[:,:100].columns\n",
    "wide_cols = X_pre.iloc[:, 100:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6d16200",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(X_pre)\n",
    "X_test_wide = wide_preprocessor.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14bceb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols, scale=False, for_transformer=False,embed_cols=wide_cols, already_standard=True)\n",
    "X_tab = tab_preprocessor.fit_transform(X_pre)\n",
    "X_test_tab = tab_preprocessor.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c611353",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f392ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeptabular = TabMlp(continuous_cols=X_gauss.columns, column_idx=tab_preprocessor.column_idx)\n",
    "deeptabular = TabMlp(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4167f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf4cff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_deep_train, X_deep_valid\n",
    "X_wide_train, X_wide_valid, y_train, y_valid = train_test_split(X_wide, y, test_size=0.2, random_state=42)\n",
    "X_tab_train, X_tab_valid, _, _ = train_test_split(X_tab, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dcea01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23ab28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "\n",
    "wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "\n",
    "wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_wide_train.shape[0], epochs=n_epochs)\n",
    "deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_tab_train.shape[0], epochs=n_epochs)\n",
    "\n",
    "optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    LRHistory(n_epochs=n_epochs), \n",
    "]\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model, \n",
    "                  objective='binary', \n",
    "                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                  seed=42, \n",
    "                  optimizers=optimizers,\n",
    "                  callbacks=callbacks\n",
    "                 )\n",
    "\n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "trainer.fit( # this is where problem is beginning\n",
    "    X_wide=X_wide_train,\n",
    "    X_tab=X_tab_train,\n",
    "    target=y_train,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    ")\n",
    "\n",
    "y_valid_preds = trainer.predict_proba(X_wide=X_wide_valid, X_tab=X_tab_valid, batch_size=1024)[:,1]\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90f45257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "dirty_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024,)[:,1]\n",
    "np.isnan(dirty_preds).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80b684aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(y_valid_preds).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17d0ebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_test_wide).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5bb2db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_tab).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c65ddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]): # assumes X is a pd.DataFrame\n",
    "    X_bins[:,i] = pd.qcut(X.iloc[:,i],X.shape[1],labels=False)#,duplicates = 'drop')\n",
    "    \n",
    "for i in range(X_test.shape[1]): # assumes X_test is a pd.DataFrame\n",
    "    X_test_bins[:,i] = pd.qcut(X_test.iloc[:,i],X_test.shape[1], labels=False)#,duplicates = 'drop')\n",
    "# blabeled = X_bins[:X.shape[0],:]\n",
    "# bunlabeled = X_ins[X.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40fb9ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(y_valid_preds).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af1760c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_test_wide).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5afe1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_tab).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ad91dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "np.isnan(X_test_tab).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6bcb7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/preds/cleanlab_widedeep_20211123-TabMLP-dirtydata-holdout-baseline_preds.joblib']"
     ]
    }
   ],
   "source": [
    "dump(dirty_preds, predpath/'cleanlab_widedeep_20211123-TabMLP-dirtydata-holdout-baseline_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d573b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d790b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  target\n",
      "0  600000     0.5\n",
      "1  600001     0.5\n",
      "2  600002     0.5\n",
      "3  600003     0.5\n",
      "4  600004     0.5"
     ]
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06025342",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = dirty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09f8b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id    target\n",
      "0  600000  0.999271\n",
      "1  600001  0.998434\n",
      "2  600002  0.508877\n",
      "3  600003  0.993828\n",
      "4  600004  0.958983"
     ]
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7725c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}-TabMLP-dirtydata-holdout-baseline_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd23c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "\n",
    "wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_wide_train.shape[0], epochs=n_epochs)\n",
    "deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_tab_train.shape[0], epochs=n_epochs)\n",
    "\n",
    "optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    LRHistory(n_epochs=n_epochs), \n",
    "]\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model, \n",
    "                  objective='binary', \n",
    "                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                  seed=42, \n",
    "                  optimizers=optimizers,\n",
    "                  callbacks=callbacks\n",
    "                 )\n",
    "\n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "trainer.fit( # this is where problem is beginning\n",
    "    X_wide=X_wide_train,\n",
    "    X_tab=X_tab_train,\n",
    "    target=y_train,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    ")\n",
    "\n",
    "y_valid_preds = trainer.predict_proba(X_wide=X_wide_valid, X_tab=X_tab_valid, batch_size=1024)[:,1]\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d830a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "dirty_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024,)[:,1]\n",
    "np.isnan(dirty_preds).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1003eb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/preds/cleanlab_widedeep_20211123-TabMLP-dirtydata-holdout-baseline_preds.joblib']"
     ]
    }
   ],
   "source": [
    "dump(dirty_preds, predpath/'cleanlab_widedeep_20211123-TabMLP-dirtydata-holdout-baseline_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dbf32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0753bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  target\n",
      "0  600000     0.5\n",
      "1  600001     0.5\n",
      "2  600002     0.5\n",
      "3  600003     0.5\n",
      "4  600004     0.5"
     ]
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be0563d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = dirty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5828bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id    target\n",
      "0  600000  0.745735\n",
      "1  600001  0.543516\n",
      "2  600002  0.799951\n",
      "3  600003  0.382965\n",
      "4  600004  0.499106"
     ]
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c64b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}-TabMLP-dirtydata-holdout-baseline_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a52072b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [1.5782640417501617,\n",
      "  1.4658180739579678,\n",
      "  1.3636410360905662,\n",
      "  1.2640171056108942,\n",
      "  1.169310306181023,\n",
      "  1.0811104722368692,\n",
      "  0.9988063434039606,\n",
      "  0.9238579072423582,\n",
      "  0.8566404775515802,\n",
      "  0.7971974780310446,\n",
      "  0.7463966960083447,\n",
      "  0.7034459214474855,\n",
      "  0.6698591036837238,\n",
      "  0.6441153502667637,\n",
      "  0.6251680727706534,\n",
      "  0.6110981505816934,\n",
      "  0.6017060001521731,\n",
      "  0.5949167211426855,\n",
      "  0.5902555257018441,\n",
      "  0.5876799241057845,\n",
      "  0.5852626996762209,\n",
      "  0.5839717616912907,\n",
      "  0.5829337349832694,\n",
      "  0.5815511997828859,\n",
      "  0.5811689098252416,\n",
      "  0.5802307953712529,\n",
      "  0.5796380260351625,\n",
      "  0.579643978365957,\n",
      "  0.5785929005283282,\n",
      "  0.5785237953606953,\n",
      "  0.5782156373137859,\n",
      "  0.5775741117595355,\n",
      "  0.5770682386243775,\n",
      "  0.5766099651993465,\n",
      "  0.5763754135510052,\n",
      "  0.5759396197190926,\n",
      "  0.5757148849176191,\n",
      "  0.5756011860711234,\n",
      "  0.5746617186298248,\n",
      "  0.5745866466432746,\n",
      "  0.5743073116995887,\n",
      "  0.5735866446484889,\n",
      "  0.5734975879380444,\n",
      "  0.5732190976264888,\n",
      "  0.5729572251915678,\n",
      "  0.57257795155938,\n",
      "  0.5719377797549722,\n",
      "  0.572131154887966,\n",
      "  0.5716644289142796,\n",
      "  0.5713944175858487],\n",
      " 'train_acc': [0.5911208333333333,\n",
      "  0.5950145833333333,\n",
      "  0.5978541666666667,\n",
      "  0.601725,\n",
      "  0.6057833333333333,\n",
      "  0.6097479166666666,\n",
      "  0.6149854166666666,\n",
      "  0.6197020833333333,\n",
      "  0.6260270833333333,\n",
      "  0.63301875,\n",
      "  0.641125,\n",
      "  0.65136875,\n",
      "  0.6610333333333334,\n",
      "  0.6711166666666667,\n",
      "  0.6801229166666667,\n",
      "  0.6886041666666667,\n",
      "  0.6946708333333333,\n",
      "  0.7003770833333334,\n",
      "  0.7035604166666667,\n",
      "  0.7050479166666667,\n",
      "  0.7074333333333334,\n",
      "  0.7087729166666666,\n",
      "  0.7092895833333334,\n",
      "  0.7102541666666666,\n",
      "  0.71065625,\n",
      "  0.7124229166666667,\n",
      "  0.71228125,\n",
      "  0.7121541666666666,\n",
      "  0.713175,\n",
      "  0.71368125,\n",
      "  0.7135291666666667,\n",
      "  0.71391875,\n",
      "  0.7139604166666667,\n",
      "  0.7147145833333334,\n",
      "  0.7145479166666666,\n",
      "  0.7150770833333333,\n",
      "  0.7148541666666667,\n",
      "  0.7151979166666667,\n",
      "  0.7154104166666667,\n",
      "  0.7157375,\n",
      "  0.7157145833333334,\n",
      "  0.7166625,\n",
      "  0.7163770833333334,\n",
      "  0.71663125,\n",
      "  0.7165541666666667,\n",
      "  0.7172541666666666,\n",
      "  0.7172791666666667,\n",
      "  0.7169083333333334,\n",
      "  0.7177395833333333,\n",
      "  0.7174604166666667]}"
     ]
    }
   ],
   "source": [
    "trainer.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6393b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50"
     ]
    }
   ],
   "source": [
    "len(trainer.history['train_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b35e0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_gauss, X_test_gauss, X_pre, X_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f302277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "clean_trainer = Trainer(model=model, \n",
    "                  objective='binary', \n",
    "                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                  seed=42, \n",
    "                  optimizers=optimizers,\n",
    "                  callbacks=callbacks\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a8fb7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x7f5ad414a850>"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3hezw9hp\" target=\"_blank\">cleanlab_widedeep_20211123c_141600</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"202111_Kaggle_tabular_playground\",\n",
    "    save_code=True,\n",
    "    tags=wandb_config['tags'],\n",
    "    name=wandb_config['name'],\n",
    "    notes=wandb_config['notes'],\n",
    "    config=exmodel_config\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0664a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of WideDeep(\n",
      "  (wide): Wide(\n",
      "    (wide_linear): Embedding(10001, 1, padding_idx=0)\n",
      "  )\n",
      "  (deeptabular): Sequential(\n",
      "    (0): TabMlp(\n",
      "      (cat_embed_and_cont): CatEmbeddingsAndCont(\n",
      "        (cont_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tab_mlp): MLP(\n",
      "        (mlp): Sequential(\n",
      "          (dense_layer_0): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (dense_layer_1): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")>"
     ]
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c96cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f58c6fba660>"
     ]
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6b2b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of WideDeep(\n",
      "  (wide): Wide(\n",
      "    (wide_linear): Embedding(10001, 1, padding_idx=0)\n",
      "  )\n",
      "  (deeptabular): Sequential(\n",
      "    (0): TabMlp(\n",
      "      (cat_embed_and_cont): CatEmbeddingsAndCont(\n",
      "        (cont_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tab_mlp): MLP(\n",
      "        (mlp): Sequential(\n",
      "          (dense_layer_0): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (dense_layer_1): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")>"
     ]
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e0f1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<bound method Module.parameters of WideDeep(\\n  (wide): Wide(\\n    (wide_linear): Embedding(10001, 1, padding_idx=0)\\n  )\\n  (deeptabular): Sequential(\\n    (0): TabMlp(\\n      (cat_embed_and_cont): CatEmbeddingsAndCont(\\n        (cont_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n      (tab_mlp): MLP(\\n        (mlp): Sequential(\\n          (dense_layer_0): Sequential(\\n            (0): Dropout(p=0.1, inplace=False)\\n            (1): Linear(in_features=100, out_features=200, bias=True)\\n            (2): ReLU(inplace=True)\\n          )\\n          (dense_layer_1): Sequential(\\n            (0): Dropout(p=0.1, inplace=False)\\n            (1): Linear(in_features=200, out_features=100, bias=True)\\n            (2): ReLU(inplace=True)\\n          )\\n        )\\n      )\\n    )\\n    (1): Linear(in_features=100, out_features=1, bias=True)\\n  )\\n)>'"
     ]
    }
   ],
   "source": [
    "str(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8cf2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of WideDeep(\n",
      "  (wide): Wide(\n",
      "    (wide_linear): Embedding(10001, 1, padding_idx=0)\n",
      "  )\n",
      "  (deeptabular): Sequential(\n",
      "    (0): TabMlp(\n",
      "      (cat_embed_and_cont): CatEmbeddingsAndCont(\n",
      "        (cont_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tab_mlp): MLP(\n",
      "        (mlp): Sequential(\n",
      "          (dense_layer_0): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (dense_layer_1): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")>"
     ]
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96fba55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f58c6fbac10>"
     ]
    }
   ],
   "source": [
    "model.parameters(recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "998672bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of WideDeep(\n",
      "  (wide): Wide(\n",
      "    (wide_linear): Embedding(10001, 1, padding_idx=0)\n",
      "  )\n",
      "  (deeptabular): Sequential(\n",
      "    (0): TabMlp(\n",
      "      (cat_embed_and_cont): CatEmbeddingsAndCont(\n",
      "        (cont_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tab_mlp): MLP(\n",
      "        (mlp): Sequential(\n",
      "          (dense_layer_0): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (dense_layer_1): Sequential(\n",
      "            (0): Dropout(p=0.1, inplace=False)\n",
      "            (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")>"
     ]
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97974cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3dc8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "WideDeep                                      --\n",
      "├─Wide: 1-1                                   --\n",
      "│    └─Embedding: 2-1                         10,001\n",
      "├─Sequential: 1-2                             --\n",
      "│    └─TabMlp: 2-2                            --\n",
      "│    │    └─CatEmbeddingsAndCont: 3-1         200\n",
      "│    │    └─MLP: 3-2                          40,300\n",
      "│    └─Linear: 2-3                            101\n",
      "======================================================================\n",
      "Total params: 50,602\n",
      "Trainable params: 50,602\n",
      "Non-trainable params: 0\n",
      "======================================================================"
     ]
    }
   ],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ece923f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ce9c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "?summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bfd44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'======================================================================\\nLayer (type:depth-idx)                        Param #\\n======================================================================\\nWideDeep                                      --\\n├─Wide: 1-1                                   --\\n│    └─Embedding: 2-1                         10,001\\n├─Sequential: 1-2                             --\\n│    └─TabMlp: 2-2                            --\\n│    │    └─CatEmbeddingsAndCont: 3-1         200\\n│    │    └─MLP: 3-2                          40,300\\n│    └─Linear: 2-3                            101\\n======================================================================\\nTotal params: 50,602\\nTrainable params: 50,602\\nNon-trainable params: 0\\n======================================================================'"
     ]
    }
   ],
   "source": [
    "str(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80091daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'overall_valid_auc': roc_auc_score(y_true=y_valid, y_score=y_valid_preds),\n",
    "           'model_params': model.parameters,\n",
    "           'model_summary': torchinfo.summary(model),\n",
    "           'model_seed': 42,\n",
    "           'leadboard_auc': 0.72913,\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1f6231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'overall_valid_auc': roc_auc_score(y_true=y_valid, y_score=y_valid_preds),\n",
    "           'model_params': model.parameters,\n",
    "           'model_summary': str(torchinfo.summary(model)),\n",
    "           'model_seed': 42,\n",
    "           'leadboard_auc': 0.72913,\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76bb88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
