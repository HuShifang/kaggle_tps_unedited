{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing Sweep\n",
    "Trying to set up a new template for a notebook that will run a simple 5-fold cross-validation XGBoost model on a variety of dataset permutations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "COLAB = False\n",
    "USE_GPU = True\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost', 'widedeep-SAINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d99557a-45cc-404f-9ade-862ae78bcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"dataset_sweep_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if COLAB:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "#     !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "#     !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if USE_GPU: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if USE_GPU:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.preprocessing import StandardScaler MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/oct2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    altdatapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/')\n",
    "    studypath = root/'optuna_studies'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad41f0c-4a5c-470a-bda3-98152c30bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ca5f75-d4f8-43cd-b23a-46c87a4c9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the full training data set to get the feature correlations to target, for K-means clustering later\n",
    "df = pd.read_feather(datapath/'train.feather')\n",
    "# df_corr = df.corr() # getting the correlations of the features\n",
    "# corr_target = df_corr.loc['target':'target'] # pulling out just the correlation of features with the target, as a 1-row df (for Series, it'd be df_corr.loc['target'])\n",
    "corr_target = load(altdatapath/'corr_target.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4b3642-38c5-434f-b029-0023d5d33467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.004067</td>\n",
       "      <td>-0.029324</td>\n",
       "      <td>-0.015663</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>-0.043557</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.003869</td>\n",
       "      <td>-0.004477</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0        f1        f2        f3        f4        f5        f6  \\\n",
       "target  0.004067 -0.029324 -0.015663  0.036279  0.019811 -0.012301 -0.012332   \n",
       "\n",
       "              f7        f8        f9  ...     f276      f277      f278  \\\n",
       "target  0.013528 -0.043557 -0.002662  ... -0.00329 -0.003869 -0.004477   \n",
       "\n",
       "            f279      f280      f281      f282      f283    f284  target  \n",
       "target -0.004503 -0.004319 -0.004587 -0.002426 -0.005901 -0.0037     1.0  \n",
       "\n",
       "[1 rows x 286 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812a21a9-ad34-40a2-9aa9-f06c1d68e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target_x = corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "corr_target_abs = abs(corr_target_x) # just interested in magnitudes here\n",
    "corr_sorted = corr_target_abs.sort_values(by='target', axis=1, ascending=False) # df columns of useful values by correlation with target, will be modified later\n",
    "y = df.target # pulling out the dependent variable\n",
    "X = df.drop('target', axis=1) # isolating the independent variables\n",
    "del df # cleaning up memory\n",
    "categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # not touching already binary encoded vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a30a0-786e-4d24-8a48-aeaefecc3a10",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f5ba3e-7883-4d96-9220-6dfc063a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 20211004, thru 106 trials on unaltered original dataset\n",
    "params = {\n",
    "    'n_estimators': 3878,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.024785857161974977,\n",
    "    'reg_alpha': 26.867682044658245,\n",
    "    'reg_lambda': 10.839759074147148,\n",
    "    'subsample': 0.8208581489835881,\n",
    "    'min_child_weight': 8.829122644339664,\n",
    "    'colsample_bytree': 0.906420714280384,\n",
    "    'gamma': 1.472322916021486\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0c5eba-c314-47ae-8bbe-7da26af02276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = load(altdatapath/'X_boruta_200iter_filtered_green.joblib')\n",
    "# type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac21ce42-a882-4e2c-a8c4-c1b1438fcff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bdf = pd.DataFrame(b, index=X.index).join(y)\n",
    "# bdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b19679-1488-437e-9140-d300c83fcf24",
   "metadata": {},
   "source": [
    "(Following cells generate the correlations for the different feature selections, so that the process need not be repeated each iteration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7781d7-daf3-4376-9018-f5687687ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = load(altdatapath/'X_boruta_200iter_filtered_green.joblib')\n",
    "# bdf = pd.DataFrame(b, index=X.index).join(y)\n",
    "# bdf.head()\n",
    "# bdf_corr = bdf.corr()\n",
    "# bdf_corr_target = bdf_corr.loc['target':'target']\n",
    "# bdf_corr_target_x = bdf_corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "# bdf_corr_target_abs = abs(bdf_corr_target_x) # just interested in magnitudes here\n",
    "# bdf_corr_sorted = bdf_corr_target_abs.sort_values(by='target', axis=1, ascending=False)\n",
    "# dump(bdf_corr_sorted, altdatapath/'X_boruta_200iter_filtered_green_corr_sorted.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92e8b38-e735-4d16-9cef-c2fd52cdbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del b, bdf, bdf_corr_target, bdf_corr_target_x, bdf_corr_target_abs, bdf_corr_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108991f2-9ec7-4217-b1c0-936c848fc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = pd.read_feather(altdatapath/'X_boruta_shap_200trials.feather')\n",
    "# bdf = b.join(y)\n",
    "# # bdf.head()\n",
    "# bdf_corr = bdf.corr()\n",
    "# bdf_corr_target = bdf_corr.loc['target':'target']\n",
    "# bdf_corr_target_x = bdf_corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "# bdf_corr_target_abs = abs(bdf_corr_target_x) # just interested in magnitudes here\n",
    "# bdf_corr_sorted = bdf_corr_target_abs.sort_values(by='target', axis=1, ascending=False)\n",
    "# dump(bdf_corr_sorted, altdatapath/'X_boruta_shap_200trials_corr_sorted.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e3dc59-21bb-49c5-9535-83ee0edb3506",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial, X=X, y=y, categoricals=categoricals, corr_sorted=corr_sorted):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "    \n",
    "\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "\n",
    "    # use the original 286-feature dataset, or the 136-feature BorutaShap selected one\n",
    "#     dataset = trial.suggest_categorical('dataset', ['X_orig.feather', 'X_boruta_shap_200trials.feather']) \n",
    "#     train_source = altdatapath/'X_orig.feather'\n",
    "    # train_source = altdatapath/'train-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' #'X_boruta_shap_200trials.feather'\n",
    "#     X = pd.read_feather(path=train_source)\n",
    "#     y = load(datapath/'y.joblib')\n",
    "    \n",
    "#     # decides whether binary-encoded categoricals are encoded or not\n",
    "#     cardinality_min = trial.suggest_categorical('cardinality_min', [0, 2]) \n",
    "        \n",
    "    encoder_name = trial.suggest_categorical('encoder_name', ['woe', 'catboost', 'james-stein', 'loo', 'mestimate', 'target', 'hashing', None])\n",
    "    if encoder_name:\n",
    "        encode_before_kmeans = trial.suggest_categorical('encode_before_kmeans', [True, False]) # determines order\n",
    "    \n",
    "    # feature selection setup -- applied before preprocessing\n",
    "    feature_selection = trial.suggest_categorical('feature_selection', ['BorutaShap', 'Boruta', None])\n",
    "    k_means_method = trial.suggest_categorical('k_means_method', [25, 50, 100, 'k-means++', None]) # K-Means initialization method\n",
    "\n",
    "    # now, switch datasets if feature selection is implemented; regardless, prepare appropriate K-Means setup (to be implemented later, in folds)\n",
    "    if feature_selection: # create a subset of features if appropriate\n",
    "        if feature_selection == 'BorutaShap':\n",
    "            X = pd.read_feather(altdatapath/'X_boruta_shap_200trials.feather') # :: pd.DataFrame\n",
    "            categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # not touching already binary encoded vars\n",
    "            # k-means cluster feature generation setup \n",
    "            if k_means_method:\n",
    "                corr_sorted = load(altdatapath/'X_boruta_shap_200trials_corr_sorted.joblib') # load prepared correlations\n",
    "                k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "                useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "        elif feature_selection == 'Boruta':\n",
    "            X = pd.DataFrame(load(altdatapath/'X_boruta_200iter_filtered_green.joblib'), index=X.index)\n",
    "            if k_means_method:\n",
    "                corr_sorted = load(altdatapath/'X_boruta_200iter_filtered_green_corr_sorted.joblib') # load prepared correlations\n",
    "                k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "                useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "            categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # not touching already binary encoded vars\n",
    "    else:\n",
    "        if k_means_method:\n",
    "            k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "            useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "    \n",
    "    # define dict of encoders, with names as keys and implementations as values\n",
    "    encoders = {\n",
    "        'woe': ce.WOEEncoder(cols=categoricals),\n",
    "        'catboost': ce.CatBoostEncoder(cols=categoricals),\n",
    "        'james-stein': ce.JamesSteinEncoder(cols=categoricals),\n",
    "        'loo': ce.LeaveOneOutEncoder(cols=categoricals),\n",
    "        'mestimate': ce.MEstimateEncoder(cols=categoricals),\n",
    "        'target': ce.TargetEncoder(cols=categoricals),\n",
    "        'hashing': ce.HashingEncoder(cols=categoricals),\n",
    "    }\n",
    "    \n",
    "    # PCA dimensionality reduction setup -- applied at end of preprocessing\n",
    "    pca_components = trial.suggest_categorical('pca_components', [50, 75, 'mle', None, 'NO'])\n",
    "    \n",
    "    # define k-fold splitter\n",
    "    kfold = KFold(n_splits=5, shuffle=False)\n",
    "        \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "            \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "        \n",
    "        y_train, y_valid = y[train_ids], y[valid_ids] # slicing syntax works on both pandas.Series and numpy.ndarray\n",
    "        # category_encoders expects pandas.DataFrames\n",
    "        X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for slicing\n",
    "        \n",
    "        # now, apply preprocessing\n",
    "        if encoder_name: # if categorical encoding to be applied to high cardinality (2<x<100,000) categoricals...\n",
    "            if k_means_method: # if k-means proceeding\n",
    "                if encode_before_kmeans: # do category encoding, then clustering\n",
    "                    # category encoding for high-cardinality categoricals\n",
    "                    encoder = encoders[encoder_name]\n",
    "                    X_train = encoder.fit_transform(X_train, y_train)\n",
    "                    X_valid = encoder.transform(X_valid)\n",
    "\n",
    "                    # k-means cluster feature generation\n",
    "                    cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "                    if k_means_method == 'k-means++':\n",
    "                        kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "                    else:\n",
    "                        kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "                    # fit on the training set only\n",
    "                    X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "                    X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "                    # convert numpy.ndarrays back to properly-labeled pandas.DataFrames\n",
    "                    X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "                    X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "                    # join the cluster-distance features to the training and validation sets\n",
    "                    X_train = X_train.join(X_train_clusters)\n",
    "                    X_valid = X_valid.join(X_valid_clusters)\n",
    "\n",
    "                else: # do k-means clustering, then do category encoding\n",
    "                    cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "                    if k_means_method == 'k-means++':\n",
    "                        kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "                    else:\n",
    "                        kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "                    X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "                    X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "                    X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "                    X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "                    X_train = X_train.join(X_train_clusters)\n",
    "                    X_valid = X_valid.join(X_valid_clusters)\n",
    "\n",
    "                    encoder = encoders[encoder_name]\n",
    "                    X_train = encoder.fit_transform(X_train, y_train)\n",
    "                    X_valid = encoder.transform(X_valid)\n",
    "            \n",
    "            else: # category encoding, but no k-means\n",
    "                encoder = encoders[encoder_name]\n",
    "                X_train = encoder.fit_transform(X_train, y_train)\n",
    "                X_valid = encoder.transform(X_valid)\n",
    "                \n",
    "        else: # no category encoding\n",
    "            if k_means_method: # if still doing k-means\n",
    "                # k-means cluster feature generation\n",
    "                cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "                if k_means_method == 'k-means++':\n",
    "                    kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "                else:\n",
    "                    kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "                # fit on the training set only\n",
    "                X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "                X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "                # convert numpy.ndarrays back to properly-labeled pandas.DataFrames\n",
    "                X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "                X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "                # join the cluster-distance features to the training and validation sets\n",
    "                X_train = X_train.join(X_train_clusters)\n",
    "                X_valid = X_valid.join(X_valid_clusters)\n",
    "            \n",
    "        \n",
    "        # now, PCA dimensionality reduction\n",
    "        if pca_components != 'NO':\n",
    "            pca = PCA(n_components=pca_components, random_state=42)\n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_valid = pca.transform(X_valid)\n",
    "            \n",
    "        # define models\n",
    "        model = XGBClassifier(\n",
    "            booster='gbtree',\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=42,\n",
    "            n_jobs=-1, \n",
    "            verbosity=1, \n",
    "            objective='binary:logistic',\n",
    "            **params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "        # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "        oof_preds.extend(y_valid_preds)\n",
    "        oof_y.extend(y_valid)\n",
    "\n",
    "\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "#         dump(model, Path(runpath/f\"{library}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for is {model_valid_auc}\")\n",
    "    \n",
    "    return model_valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac6b1dd-5c9d-4f95-985c-4250d78d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for preprocessing techniques on dataset\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b0ce509-11c3-4c1e-847b-89a50dc4ade7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "4e88b8c2-11ec-493d-8fdb-f97cd2f0243a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find dataset_sweep_20211026.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/m2erlqe9\" target=\"_blank\">dataset_sweep_20211026_124444</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5124950-57e7-45e0-842a-a6eb01b2383d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "outputId": "05b7ce12-dc98-4d38-fd83-a0578ec37531",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 12:44:50,241]\u001b[0m A new study created in memory with name: dataset_20211026\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed=int(SEED)), study_name='dataset_20211026')\n",
    "study = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ee181bd-8c5b-4468-bc76-22c5dacd7142",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXQWM6Otmxma",
    "outputId": "d4b74ae6-6552-4b2f-a4e0-d9999874ab06",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[16:22:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.7517760922401533\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[16:28:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.7539213843954606\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[16:34:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.7590118210311512\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[16:39:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.7539179052878628\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[16:44:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.7523735217328041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 16:48:30,187]\u001b[0m Trial 12 finished with value: 0.7542908472902581 and parameters: {'encoder_name': 'target', 'encode_before_kmeans': False, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7542908472902581\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[16:49:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8460498790948396\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[16:53:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8487617952918354\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[16:57:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8490002113547026\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[17:02:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8448842279545304\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[17:06:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8438420555278117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 17:10:11,751]\u001b[0m Trial 13 finished with value: 0.846609851097209 and parameters: {'encoder_name': 'loo', 'encode_before_kmeans': False, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.846609851097209\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[17:10:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[17:14:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[17:19:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[17:23:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[17:27:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 17:31:29,665]\u001b[0m Trial 14 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[17:32:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8463829433197478\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[17:36:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8486140766450826\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[17:41:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8488299945892275\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[17:45:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8447333654639602\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[17:50:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8437706457144185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 17:54:21,197]\u001b[0m Trial 15 finished with value: 0.8465627881689273 and parameters: {'encoder_name': 'catboost', 'encode_before_kmeans': False, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8465627881689273\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[17:54:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[17:58:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:02:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:07:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:11:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 18:15:04,499]\u001b[0m Trial 16 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:16:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8461843758043033\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:22:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8487207689546775\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:27:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8489651958254386\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:32:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8449334972530584\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:38:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8439892698546787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 18:42:14,352]\u001b[0m Trial 17 finished with value: 0.8466567050492937 and parameters: {'encoder_name': 'hashing', 'encode_before_kmeans': False, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8466567050492937\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:42:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:46:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:50:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:54:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:59:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 19:03:00,407]\u001b[0m Trial 18 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[19:03:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[19:07:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[19:11:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[19:15:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[19:19:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 19:23:47,289]\u001b[0m Trial 19 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[19:24:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[19:28:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[19:32:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[19:36:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[19:40:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 19:44:33,812]\u001b[0m Trial 20 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[19:44:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[19:49:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[19:53:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[19:57:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[20:01:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 20:05:18,953]\u001b[0m Trial 21 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[20:05:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[20:09:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[20:13:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[20:18:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[20:22:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 20:26:01,234]\u001b[0m Trial 22 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[20:26:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[20:30:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[20:34:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[20:38:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[20:42:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 20:46:43,532]\u001b[0m Trial 23 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[20:47:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[20:51:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[20:55:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[20:59:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[21:03:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 21:07:59,564]\u001b[0m Trial 24 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[21:08:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[21:12:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[21:17:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[21:21:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[21:25:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 21:29:39,342]\u001b[0m Trial 25 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[21:30:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8463829433197478\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[21:35:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8486140766450826\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[21:39:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8488299945892275\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[21:44:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8447333654639602\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[21:49:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8437706457144185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 21:53:05,025]\u001b[0m Trial 26 finished with value: 0.8465627881689273 and parameters: {'encoder_name': 'catboost', 'encode_before_kmeans': False, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8465627881689273\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[21:53:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[21:57:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[22:01:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[22:06:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[22:10:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 22:14:16,630]\u001b[0m Trial 27 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[22:14:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[22:18:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[22:22:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[22:26:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[22:31:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 22:34:54,607]\u001b[0m Trial 28 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[22:35:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[22:39:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[22:43:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[22:47:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[22:51:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 22:55:33,227]\u001b[0m Trial 29 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[22:55:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[22:59:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[23:04:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[23:08:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[23:12:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 23:16:10,713]\u001b[0m Trial 30 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[23:16:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[23:20:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[23:24:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[23:28:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[23:32:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 23:36:47,343]\u001b[0m Trial 31 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[23:37:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[23:41:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[23:45:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[23:49:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[23:53:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-26 23:57:25,473]\u001b[0m Trial 32 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[23:57:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[00:01:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[00:05:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[00:10:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[00:14:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 00:18:03,317]\u001b[0m Trial 33 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[00:18:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[00:22:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[00:26:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[00:31:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[00:35:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 00:39:05,279]\u001b[0m Trial 34 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[00:39:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[00:43:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[00:47:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[00:52:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[00:56:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 01:00:05,868]\u001b[0m Trial 35 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[01:00:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[01:04:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[01:08:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[01:13:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[01:17:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 01:21:08,197]\u001b[0m Trial 36 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[01:21:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[01:25:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[01:29:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[01:33:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[01:37:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 01:41:44,437]\u001b[0m Trial 37 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[01:42:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[01:46:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[01:50:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[01:54:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[01:58:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 02:02:21,316]\u001b[0m Trial 38 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[02:02:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[02:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[02:10:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[02:15:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[02:19:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 02:22:58,997]\u001b[0m Trial 39 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[02:23:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[02:27:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[02:31:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[02:35:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[02:39:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 02:43:36,490]\u001b[0m Trial 40 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[02:43:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[02:48:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[02:52:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[02:56:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[03:00:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 03:04:13,629]\u001b[0m Trial 41 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[03:04:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[03:08:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[03:12:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[03:16:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[03:20:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 03:24:50,885]\u001b[0m Trial 42 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[03:25:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[03:29:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[03:33:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[03:37:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[03:41:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 03:45:27,189]\u001b[0m Trial 43 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[03:45:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[03:50:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[03:54:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[03:58:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[04:02:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 04:06:29,938]\u001b[0m Trial 44 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[04:06:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8468150822382937\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[04:11:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8491576487090565\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[04:15:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.849561538223476\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[04:19:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8453452025717385\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[04:23:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8444498070703212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 04:27:32,069]\u001b[0m Trial 45 finished with value: 0.8471726725487676 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': 'mle'}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.8471726725487676\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[04:27:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[04:31:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[04:36:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[04:40:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[04:44:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 04:48:10,197]\u001b[0m Trial 46 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[04:48:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[04:52:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[04:56:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[05:00:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[05:04:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 05:08:46,144]\u001b[0m Trial 47 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[05:09:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[05:13:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[05:17:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[05:21:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[05:25:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 05:29:25,541]\u001b[0m Trial 48 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[05:29:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[05:33:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[05:37:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[05:42:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[05:46:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 05:50:04,653]\u001b[0m Trial 49 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[05:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8467395508145958\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[05:54:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8490648949947982\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[05:58:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8495268213689964\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[06:02:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8452497867521451\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[06:06:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8443698607826702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 06:10:48,434]\u001b[0m Trial 50 finished with value: 0.847097402563946 and parameters: {'encoder_name': None, 'feature_selection': None, 'k_means_method': None, 'pca_components': None}. Best is trial 6 with value: 0.8529520938646249.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.847097402563946\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[06:11:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8460498790948396\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[06:15:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8487617952918354\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[06:19:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.8490002113547026\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[06:24:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3cdcaafa4222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_jobs = multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudypath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'optuna_dataset_study_trial{x}_20211026.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-06cfcc9a6012>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, X, y, categoricals, corr_sorted)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             **params)\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0my_valid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         )\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(11,100):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc]) #n_jobs = multiprocessing.cpu_count())\n",
    "    dump(study, filename=studypath/f'optuna_dataset_study_trial{x}_20211026.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35c0b945-2e29-48f0-9cf9-7de44f5b0afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_name': 'loo',\n",
       " 'encode_before_kmeans': True,\n",
       " 'feature_selection': 'Boruta',\n",
       " 'k_means_method': 100,\n",
       " 'k_means_clusters': 7,\n",
       " 'pca_components': 'NO'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf062650-04df-4d32-a443-9e5e9c198b93",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 783650... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>encode_before_kmeans</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–</td></tr><tr><td>k_means_clusters</td><td>â–„â–‚â–â–â–ˆâ–„â–ˆ</td></tr><tr><td>k_means_method</td><td>â–ˆâ–ƒâ–ˆâ–ˆâ–â–ƒ</td></tr><tr><td>pca_components</td><td>â–ˆâ–ˆâ–â–ˆ</td></tr><tr><td>value</td><td>â–ˆâ–ƒâ–‚â–†â–ˆâ–„â–‡â–‡â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>encode_before_kmeans</td><td>False</td></tr><tr><td>k_means_clusters</td><td>12</td></tr><tr><td>value</td><td>0.8471</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dataset_sweep_20211026_124444</strong>: <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/m2erlqe9\" target=\"_blank\">https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/m2erlqe9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211026_124444-m2erlqe9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'best_dataset_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fe247-3521-4f74-9363-b901c205d113",
   "metadata": {},
   "source": [
    "Now, the baseline for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7ab11a8-0e63-4d0e-a82d-015646d93fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[07:59:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8562083823462339\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[08:06:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8583507447326876\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[08:12:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.858679604843354\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[08:18:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8546676893529576\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[08:24:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8548239360305142\n",
      "Valid AUC score for is 0.8566651115202035\n"
     ]
    }
   ],
   "source": [
    "# define k-fold splitter\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# initialize lists for out-of-fold preds and ground truth\n",
    "oof_preds, oof_y = [], []\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    y_train, y_valid = y[train_ids], y[valid_ids] # slicing syntax works on both pandas.Series and numpy.ndarray\n",
    "    # category_encoders expects pandas.DataFrames\n",
    "    X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for slicing\n",
    "\n",
    "\n",
    "    # define models\n",
    "    model = XGBClassifier(\n",
    "        booster='gbtree',\n",
    "        tree_method='gpu_hist',\n",
    "        random_state=42,\n",
    "        n_jobs=-1, \n",
    "        verbosity=1, \n",
    "        objective='binary:logistic',\n",
    "        **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "    # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "    oof_preds.extend(y_valid_preds)\n",
    "    oof_y.extend(y_valid)\n",
    "\n",
    "\n",
    "    fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "    print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "#         dump(model, Path(runpath/f\"{library}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "print(f\"Valid AUC score for is {model_valid_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa0381-a9e3-483f-a9bc-b41ad6d04468",
   "metadata": {},
   "source": [
    "So, the best of the sweep was trial 6 with AUC of 0.8529520938646249, but the straight-up analysis without any bells and whistles gets 0.8566651115202035. \n",
    "\n",
    "Conclusion: best to forget about preprocessing. $\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
