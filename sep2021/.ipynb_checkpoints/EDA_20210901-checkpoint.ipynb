{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Notebook is intended for preliminary EDA -- getting to know the dataset. Using code from `../aug2021/20210823_XGBRegressor_feature_selection.ipynb` as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685773d0-dfe2-431e-8462-0e5880a61599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "# import timm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7827296-9c74-4b2e-b7e3-fac198991c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '20210901_EDA.ipynb'\n",
    "# config = {\n",
    "#     # model config\n",
    "#     \"model\":None,\n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'dart', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 400, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1522,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"scaler\": MaxAbsScaler,\n",
    "# #     \"task_type\": \"GPU\", # for CatBoost only\n",
    "# #     \"reg_alpha\": 2.8,\n",
    "# #     \"reg_lambda\": 3.987,\n",
    "# #     \"feature_selector\": SelectKBest,\n",
    "# #     \"k_best\": 80,\n",
    "# #     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': 42,\n",
    "#     'subsample': 1,\n",
    "#     'n_jobs': -1,\n",
    "#     'verbosity': 1,\n",
    "#     'k_folds': 5,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "# }\n",
    "\n",
    "# config_run = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'tags': ['XGBoost', 'kfold', 'scaling'],\n",
    "#     'notes': \"A straight-up replication of previous best mdoel -- a 400 estimator Dart-boosted one -- with k-fold ensembling. No feature generation or selection.\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1c0a51-fa76-46d8-a7eb-277a0b5fb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ffaac-ffe0-4698-a076-13ae9a1449bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b5532f-0fef-49af-aa4b-d8b7cc801d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unaltered dataset\n",
    "df = pd.read_feather(path='dataset_df.feather')\n",
    "df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1386ddc6-4049-4483-b262-89b3a21d0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       ...\n",
       "       'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118',\n",
       "       'claim'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf58181-fc3c-4d48-b0e6-12bb8c097ad7",
   "metadata": {},
   "source": [
    "So 119 features this time, with the dependent variable being `'claim'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78944561-1fe5-4a29-9967-4bb87227fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15697e7c-c1f6-4bab-9961-30a9b9a0eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in df.columns if x != 'claim']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128efad-c6d4-41c3-98db-f9c1984dd8f0",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "## Data Description\n",
    "From [here](https://www.kaggle.com/c/tabular-playground-series-sep-2021/data):\n",
    "> For this competition, you will predict whether a customer made a claim upon an insurance policy. The ground truth claim is binary valued, but a prediction may be any number from 0.0 to 1.0, representing the probability of a claim. The features in this dataset have been anonymized and may contain missing values.\n",
    "\n",
    "So this is closer to the SETI Breakthrough Listen competition in the sense that you're doing binary classification, and expected to output a probability rather than a hard-and-fast prediction.\n",
    "\n",
    "## Evaluation\n",
    "> Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
    "> For each id in the test set, you must predict a probability for the claim variable. The file should contain a header and have the following format:\n",
    "```\n",
    "id,claim\n",
    "957919,0.5\n",
    "957920,0.5\n",
    "957921,0.5\n",
    "etc.\n",
    "```\n",
    "\n",
    "Consistent with SETI Breakthrough Listen, you're judged on AUC_ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c6898-1df3-4e3a-81f5-3ce43b9d890a",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f80b9f25-1f8e-410b-97a2-2ab0affd0472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10859</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>-37.566</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.28915</td>\n",
       "      <td>-10.25100</td>\n",
       "      <td>135.12</td>\n",
       "      <td>168900.0</td>\n",
       "      <td>3.992400e+14</td>\n",
       "      <td>86.489</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.2280</td>\n",
       "      <td>1.7482</td>\n",
       "      <td>1.90960</td>\n",
       "      <td>-7.11570</td>\n",
       "      <td>4378.80</td>\n",
       "      <td>1.2096</td>\n",
       "      <td>8.613400e+14</td>\n",
       "      <td>140.1</td>\n",
       "      <td>1.01770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.299610</td>\n",
       "      <td>11822.000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.45970</td>\n",
       "      <td>-0.83733</td>\n",
       "      <td>1721.90</td>\n",
       "      <td>119810.0</td>\n",
       "      <td>3.874100e+15</td>\n",
       "      <td>9953.600</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.7580</td>\n",
       "      <td>4.1684</td>\n",
       "      <td>0.34808</td>\n",
       "      <td>4.14200</td>\n",
       "      <td>913.23</td>\n",
       "      <td>1.2464</td>\n",
       "      <td>7.575100e+15</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.17803</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>907.270</td>\n",
       "      <td>0.272140</td>\n",
       "      <td>0.45948</td>\n",
       "      <td>0.17327</td>\n",
       "      <td>2298.00</td>\n",
       "      <td>360650.0</td>\n",
       "      <td>1.224500e+13</td>\n",
       "      <td>15827.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.7688</td>\n",
       "      <td>1.2042</td>\n",
       "      <td>0.26290</td>\n",
       "      <td>8.13120</td>\n",
       "      <td>45119.00</td>\n",
       "      <td>1.1764</td>\n",
       "      <td>3.218100e+14</td>\n",
       "      <td>3838.2</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15236</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>780.100</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.51947</td>\n",
       "      <td>7.49140</td>\n",
       "      <td>112.51</td>\n",
       "      <td>259490.0</td>\n",
       "      <td>7.781400e+13</td>\n",
       "      <td>-36.837</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.8580</td>\n",
       "      <td>2.0694</td>\n",
       "      <td>0.79631</td>\n",
       "      <td>-16.33600</td>\n",
       "      <td>4952.40</td>\n",
       "      <td>1.1784</td>\n",
       "      <td>4.533000e+12</td>\n",
       "      <td>4889.1</td>\n",
       "      <td>0.51486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11623</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>-109.150</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>0.34490</td>\n",
       "      <td>-0.40932</td>\n",
       "      <td>2538.90</td>\n",
       "      <td>65332.0</td>\n",
       "      <td>1.907200e+15</td>\n",
       "      <td>144.120</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.6410</td>\n",
       "      <td>1.5298</td>\n",
       "      <td>1.14640</td>\n",
       "      <td>-0.43124</td>\n",
       "      <td>3856.50</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-8.991300e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2         f3        f4       f5        f6       f7  \\\n",
       "id                                                                       \n",
       "0   0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n",
       "1   0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n",
       "2   0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n",
       "3   0.15236  0.007259    780.100  0.025179  0.51947   7.49140   112.51   \n",
       "4   0.11623  0.502900   -109.150  0.297910  0.34490  -0.40932  2538.90   \n",
       "\n",
       "          f8            f9        f10  ...     f110    f111     f112  \\\n",
       "id                                     ...                             \n",
       "0   168900.0  3.992400e+14     86.489  ... -12.2280  1.7482  1.90960   \n",
       "1   119810.0  3.874100e+15   9953.600  ... -56.7580  4.1684  0.34808   \n",
       "2   360650.0  1.224500e+13  15827.000  ...  -5.7688  1.2042  0.26290   \n",
       "3   259490.0  7.781400e+13    -36.837  ... -34.8580  2.0694  0.79631   \n",
       "4    65332.0  1.907200e+15    144.120  ... -13.6410  1.5298  1.14640   \n",
       "\n",
       "        f113      f114    f115          f116    f117     f118  claim  \n",
       "id                                                                    \n",
       "0   -7.11570   4378.80  1.2096  8.613400e+14   140.1  1.01770      1  \n",
       "1    4.14200    913.23  1.2464  7.575100e+15  1861.0  0.28359      0  \n",
       "2    8.13120  45119.00  1.1764  3.218100e+14  3838.2  0.40690      1  \n",
       "3  -16.33600   4952.40  1.1784  4.533000e+12  4889.1  0.51486      1  \n",
       "4   -0.43124   3856.50  1.4830 -8.991300e+12     NaN  0.23049      1  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45a7c23-474f-4c2a-9652-40d8aa6aa4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957919"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4b8b0-d70d-4bb4-b49b-a042d9eeffc8",
   "metadata": {},
   "source": [
    "- So there are more datapoints this time around than in August (where there were just 250000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb0b49-c46b-4eb4-ab17-e929b6b4de0f",
   "metadata": {},
   "source": [
    "Do we have any categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c594ea10-b2c0-4651-86a8-d8ed33cf5fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=X.columns, y=[len(X[f].unique()) for f in X.columns])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea79fb-4ae4-4c00-b62a-c1a325f16f8e",
   "metadata": {},
   "source": [
    "- Here, `len(X[f].unique()) for f in X.columns` represents the number of unique values in each feature. We do have a fair amount of variance here, and it seems that there are quite a few repeated values (bearing in mind the dataset has a total of 957919 values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a2e8622-b799-4761-9f1e-7a5fe2284443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f17': 77995},\n",
       " {'f22': 83439},\n",
       " {'f38': 38268},\n",
       " {'f43': 81541},\n",
       " {'f46': 84045},\n",
       " {'f48': 87460},\n",
       " {'f54': 7460},\n",
       " {'f59': 76379},\n",
       " {'f69': 14050},\n",
       " {'f71': 30981},\n",
       " {'f76': 78698},\n",
       " {'f81': 33487},\n",
       " {'f97': 430},\n",
       " {'f99': 41906},\n",
       " {'f111': 44839},\n",
       " {'f115': 12971}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) < 100000]\n",
    "low_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "050ebe03-342a-4462-bbef-5efe27265696",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f1': 147966},\n",
       " {'f2': 117428},\n",
       " {'f3': 274625},\n",
       " {'f4': 265619},\n",
       " {'f5': 125415},\n",
       " {'f6': 286474},\n",
       " {'f7': 201976},\n",
       " {'f8': 209766},\n",
       " {'f9': 368026},\n",
       " {'f10': 370267},\n",
       " {'f11': 157266},\n",
       " {'f12': 325096},\n",
       " {'f13': 117374},\n",
       " {'f14': 231414},\n",
       " {'f15': 308573},\n",
       " {'f16': 313090},\n",
       " {'f18': 172560},\n",
       " {'f19': 160074},\n",
       " {'f20': 318318},\n",
       " {'f21': 313906},\n",
       " {'f23': 148461},\n",
       " {'f24': 176989},\n",
       " {'f25': 208330},\n",
       " {'f26': 333768},\n",
       " {'f27': 291000},\n",
       " {'f28': 269917},\n",
       " {'f29': 233936},\n",
       " {'f30': 135073},\n",
       " {'f31': 263379},\n",
       " {'f32': 297892},\n",
       " {'f33': 281104},\n",
       " {'f34': 245722},\n",
       " {'f35': 357009},\n",
       " {'f36': 316293},\n",
       " {'f37': 210949},\n",
       " {'f39': 229894},\n",
       " {'f40': 223438},\n",
       " {'f41': 307517},\n",
       " {'f42': 264544},\n",
       " {'f44': 213950},\n",
       " {'f45': 245352},\n",
       " {'f47': 212672},\n",
       " {'f49': 245197},\n",
       " {'f50': 127051},\n",
       " {'f51': 305729},\n",
       " {'f52': 212596},\n",
       " {'f53': 342518},\n",
       " {'f55': 117102},\n",
       " {'f56': 240291},\n",
       " {'f57': 246959},\n",
       " {'f58': 163485},\n",
       " {'f60': 158583},\n",
       " {'f61': 245797},\n",
       " {'f62': 266662},\n",
       " {'f63': 194154},\n",
       " {'f64': 267356},\n",
       " {'f65': 142379},\n",
       " {'f66': 149028},\n",
       " {'f67': 213420},\n",
       " {'f68': 209320},\n",
       " {'f70': 210463},\n",
       " {'f72': 203072},\n",
       " {'f73': 357059},\n",
       " {'f74': 346324},\n",
       " {'f75': 227089},\n",
       " {'f77': 292412},\n",
       " {'f78': 183952},\n",
       " {'f79': 292607},\n",
       " {'f80': 212279},\n",
       " {'f82': 214663},\n",
       " {'f83': 306522},\n",
       " {'f84': 339636},\n",
       " {'f85': 218334},\n",
       " {'f86': 285558},\n",
       " {'f87': 213306},\n",
       " {'f88': 193833},\n",
       " {'f89': 205001},\n",
       " {'f90': 107020},\n",
       " {'f91': 117597},\n",
       " {'f92': 362663},\n",
       " {'f93': 199922},\n",
       " {'f94': 203995},\n",
       " {'f95': 222503},\n",
       " {'f96': 306484},\n",
       " {'f98': 335222},\n",
       " {'f100': 190384},\n",
       " {'f101': 223051},\n",
       " {'f102': 261001},\n",
       " {'f103': 312860},\n",
       " {'f104': 318263},\n",
       " {'f105': 155297},\n",
       " {'f106': 223839},\n",
       " {'f107': 252277},\n",
       " {'f108': 305687},\n",
       " {'f109': 207141},\n",
       " {'f110': 206038},\n",
       " {'f112': 328338},\n",
       " {'f113': 291842},\n",
       " {'f114': 316129},\n",
       " {'f116': 336137},\n",
       " {'f117': 200081},\n",
       " {'f118': 164264}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) > 100000]\n",
    "higher_cardinality_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876a9bc-c636-49e2-80c9-e09bec644eec",
   "metadata": {},
   "source": [
    "Probably best of all to just list them all out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2847ab58-94fc-4132-9bef-37260a1f719b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f97        430\n",
       "f54       7460\n",
       "f115     12971\n",
       "f69      14050\n",
       "f71      30981\n",
       "         ...  \n",
       "f35     357009\n",
       "f73     357059\n",
       "f92     362663\n",
       "f9      368026\n",
       "f10     370267\n",
       "Length: 118, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinalities = pd.Series([len(X[f].unique()) for f in X.columns], index=X.columns).sort_values()\n",
    "cardinalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f43fe-c474-41bb-81d2-03e8ae1e5f20",
   "metadata": {},
   "source": [
    "- So f97 and f54 are the real outliers and best prospects for categorical variables, though I think there are plenty more. (And it's striking that the highest cardinality features still have only 1/3 the unique values as the number of values period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b98ebf6-06df-4416-a045-94cdb544b437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    0.99662\n",
       "1    0.99815\n",
       "2        NaN\n",
       "3    0.99898\n",
       "4        NaN\n",
       "Name: f97, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f97'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc407dd-b805-481c-91ba-e6cbb478e786",
   "metadata": {},
   "source": [
    "**Note** that we do have `NaN`s here. I wonder if that accounts for the lower-than-expected cardinalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a0f32f5-b891-4f22-9664-a985ac34cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 957919 entries, 0 to 957918\n",
      "Data columns (total 119 columns):\n",
      " #    Column  Non-Null Count   Dtype  \n",
      "---   ------  --------------   -----  \n",
      " 0    f1      942672 non-null  float64\n",
      " 1    f2      942729 non-null  float64\n",
      " 2    f3      942428 non-null  float64\n",
      " 3    f4      942359 non-null  float64\n",
      " 4    f5      942514 non-null  float64\n",
      " 5    f6      942398 non-null  float64\n",
      " 6    f7      942415 non-null  float64\n",
      " 7    f8      942546 non-null  float64\n",
      " 8    f9      942670 non-null  float64\n",
      " 9    f10     942696 non-null  float64\n",
      " 10   f11     942494 non-null  float64\n",
      " 11   f12     942326 non-null  float64\n",
      " 12   f13     942455 non-null  float64\n",
      " 13   f14     942697 non-null  float64\n",
      " 14   f15     942410 non-null  float64\n",
      " 15   f16     942475 non-null  float64\n",
      " 16   f17     942492 non-null  float64\n",
      " 17   f18     942594 non-null  float64\n",
      " 18   f19     942445 non-null  float64\n",
      " 19   f20     942464 non-null  float64\n",
      " 20   f21     942465 non-null  float64\n",
      " 21   f22     942641 non-null  float64\n",
      " 22   f23     942563 non-null  float64\n",
      " 23   f24     942289 non-null  float64\n",
      " 24   f25     942413 non-null  float64\n",
      " 25   f26     942561 non-null  float64\n",
      " 26   f27     942475 non-null  float64\n",
      " 27   f28     942654 non-null  float64\n",
      " 28   f29     942504 non-null  float64\n",
      " 29   f30     942527 non-null  float64\n",
      " 30   f31     942241 non-null  float64\n",
      " 31   f32     942390 non-null  float64\n",
      " 32   f33     942427 non-null  float64\n",
      " 33   f34     942671 non-null  float64\n",
      " 34   f35     942585 non-null  float64\n",
      " 35   f36     942556 non-null  float64\n",
      " 36   f37     942607 non-null  float64\n",
      " 37   f38     942485 non-null  float64\n",
      " 38   f39     942360 non-null  float64\n",
      " 39   f40     942551 non-null  float64\n",
      " 40   f41     942523 non-null  float64\n",
      " 41   f42     942503 non-null  float64\n",
      " 42   f43     942464 non-null  float64\n",
      " 43   f44     942456 non-null  float64\n",
      " 44   f45     942436 non-null  float64\n",
      " 45   f46     942286 non-null  float64\n",
      " 46   f47     942396 non-null  float64\n",
      " 47   f48     942473 non-null  float64\n",
      " 48   f49     942539 non-null  float64\n",
      " 49   f50     942357 non-null  float64\n",
      " 50   f51     942487 non-null  float64\n",
      " 51   f52     942604 non-null  float64\n",
      " 52   f53     942457 non-null  float64\n",
      " 53   f54     942494 non-null  float64\n",
      " 54   f55     942497 non-null  float64\n",
      " 55   f56     942452 non-null  float64\n",
      " 56   f57     942346 non-null  float64\n",
      " 57   f58     942464 non-null  float64\n",
      " 58   f59     942519 non-null  float64\n",
      " 59   f60     942359 non-null  float64\n",
      " 60   f61     942488 non-null  float64\n",
      " 61   f62     942401 non-null  float64\n",
      " 62   f63     942509 non-null  float64\n",
      " 63   f64     942341 non-null  float64\n",
      " 64   f65     942505 non-null  float64\n",
      " 65   f66     942505 non-null  float64\n",
      " 66   f67     942433 non-null  float64\n",
      " 67   f68     942300 non-null  float64\n",
      " 68   f69     942367 non-null  float64\n",
      " 69   f70     942657 non-null  float64\n",
      " 70   f71     942437 non-null  float64\n",
      " 71   f72     942700 non-null  float64\n",
      " 72   f73     942382 non-null  float64\n",
      " 73   f74     942349 non-null  float64\n",
      " 74   f75     942463 non-null  float64\n",
      " 75   f76     942350 non-null  float64\n",
      " 76   f77     942668 non-null  float64\n",
      " 77   f78     942470 non-null  float64\n",
      " 78   f79     942541 non-null  float64\n",
      " 79   f80     942599 non-null  float64\n",
      " 80   f81     942573 non-null  float64\n",
      " 81   f82     942434 non-null  float64\n",
      " 82   f83     942292 non-null  float64\n",
      " 83   f84     942534 non-null  float64\n",
      " 84   f85     942470 non-null  float64\n",
      " 85   f86     942396 non-null  float64\n",
      " 86   f87     942603 non-null  float64\n",
      " 87   f88     942371 non-null  float64\n",
      " 88   f89     942474 non-null  float64\n",
      " 89   f90     942437 non-null  float64\n",
      " 90   f91     942412 non-null  float64\n",
      " 91   f92     942427 non-null  float64\n",
      " 92   f93     942462 non-null  float64\n",
      " 93   f94     942505 non-null  float64\n",
      " 94   f95     942320 non-null  float64\n",
      " 95   f96     942634 non-null  float64\n",
      " 96   f97     942654 non-null  float64\n",
      " 97   f98     942631 non-null  float64\n",
      " 98   f99     942485 non-null  float64\n",
      " 99   f100    942393 non-null  float64\n",
      " 100  f101    942570 non-null  float64\n",
      " 101  f102    942751 non-null  float64\n",
      " 102  f103    942319 non-null  float64\n",
      " 103  f104    942721 non-null  float64\n",
      " 104  f105    942533 non-null  float64\n",
      " 105  f106    942375 non-null  float64\n",
      " 106  f107    942535 non-null  float64\n",
      " 107  f108    942579 non-null  float64\n",
      " 108  f109    942390 non-null  float64\n",
      " 109  f110    942554 non-null  float64\n",
      " 110  f111    942420 non-null  float64\n",
      " 111  f112    942509 non-null  float64\n",
      " 112  f113    942686 non-null  float64\n",
      " 113  f114    942481 non-null  float64\n",
      " 114  f115    942360 non-null  float64\n",
      " 115  f116    942330 non-null  float64\n",
      " 116  f117    942512 non-null  float64\n",
      " 117  f118    942707 non-null  float64\n",
      " 118  claim   957919 non-null  int64  \n",
      "dtypes: float64(118), int64(1)\n",
      "memory usage: 869.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-6ac79f7ef903>:1: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  df.info(verbose=True, null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0c266-e112-4e48-bc26-474952bdfb5a",
   "metadata": {},
   "source": [
    "- So we have a lot of null values -- seemingly usually about 15k per feature (though almost never the precise same number). Are these null rows, plus a sprinkling of other missing bits, or are they smoothly distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31adc42-97fa-42e8-94a0-3bbe883b407e",
   "metadata": {},
   "source": [
    "# Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b042a010-6fb2-494a-b3d1-b9fd58bb67a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1\n",
      "-----------\n",
      "f1 max is 0.41517\n",
      "f1 min is -0.14991\n",
      "f2\n",
      "-----------\n",
      "f2 max is 0.51899\n",
      "f2 min is -0.019044\n",
      "f3\n",
      "-----------\n",
      "f3 max is 39544.0\n",
      "f3 min is -9421.7\n",
      "f4\n",
      "-----------\n",
      "f4 max is 1.3199\n",
      "f4 min is -0.082122\n",
      "f5\n",
      "-----------\n",
      "f5 max is 0.55475\n",
      "f5 min is -0.0069898\n",
      "f6\n",
      "-----------\n",
      "f6 max is 11.202\n",
      "f6 min is -12.791\n",
      "f7\n",
      "-----------\n",
      "f7 max is 5426.6\n",
      "f7 min is -224.8\n",
      "f8\n",
      "-----------\n",
      "f8 max is 1913700.0\n",
      "f8 min is -29843.0\n",
      "f9\n",
      "-----------\n",
      "f9 max is 1.0424e+16\n",
      "f9 min is -1153300000000000.0\n",
      "f10\n",
      "-----------\n",
      "f10 max is 85622.0\n",
      "f10 min is -26404.0\n",
      "f11\n",
      "-----------\n",
      "f11 max is 8.6505\n",
      "f11 min is -8.0863\n",
      "f12\n",
      "-----------\n",
      "f12 max is 8473600000.0\n",
      "f12 min is -408100000.0\n",
      "f13\n",
      "-----------\n",
      "f13 max is 0.58977\n",
      "f13 min is -0.1038\n",
      "f14\n",
      "-----------\n",
      "f14 max is 36.951\n",
      "f14 min is -0.85376\n",
      "f15\n",
      "-----------\n",
      "f15 max is 0.50963\n",
      "f15 min is -0.33566\n",
      "f16\n",
      "-----------\n",
      "f16 max is 2335.4\n",
      "f16 min is -116.88\n",
      "f17\n",
      "-----------\n",
      "f17 max is 19.189\n",
      "f17 min is -3.6645\n",
      "f18\n",
      "-----------\n",
      "f18 max is 25.458\n",
      "f18 min is -0.066527\n",
      "f19\n",
      "-----------\n",
      "f19 max is 80.154\n",
      "f19 min is -4.4225\n",
      "f20\n",
      "-----------\n",
      "f20 max is 1032.2\n",
      "f20 min is -58.834\n",
      "f21\n",
      "-----------\n",
      "f21 max is 523590.0\n",
      "f21 min is -84079.0\n",
      "f22\n",
      "-----------\n",
      "f22 max is 11.306\n",
      "f22 min is -6.0094\n",
      "f23\n",
      "-----------\n",
      "f23 max is 160.45\n",
      "f23 min is -20.514\n",
      "f24\n",
      "-----------\n",
      "f24 max is 6.96\n",
      "f24 min is -5.7352\n",
      "f25\n",
      "-----------\n",
      "f25 max is 1220.8\n",
      "f25 min is -71.502\n",
      "f26\n",
      "-----------\n",
      "f26 max is 25805000000000.0\n",
      "f26 min is -695670000000.0\n",
      "f27\n",
      "-----------\n",
      "f27 max is 5447100000000.0\n",
      "f27 min is -938420000000.0\n",
      "f28\n",
      "-----------\n",
      "f28 max is 8960600.0\n",
      "f28 min is -470600.0\n",
      "f29\n",
      "-----------\n",
      "f29 max is 1.0958\n",
      "f29 min is -0.0056592\n",
      "f30\n",
      "-----------\n",
      "f30 max is 36.744\n",
      "f30 min is -0.52999\n",
      "f31\n",
      "-----------\n",
      "f31 max is 3.7531\n",
      "f31 min is -3.8135\n",
      "f32\n",
      "-----------\n",
      "f32 max is 1154000.0\n",
      "f32 min is -349650.0\n",
      "f33\n",
      "-----------\n",
      "f33 max is 2873200.0\n",
      "f33 min is -605590.0\n",
      "f34\n",
      "-----------\n",
      "f34 max is 0.0039186\n",
      "f34 min is -0.0038813\n",
      "f35\n",
      "-----------\n",
      "f35 max is 1.5905e+17\n",
      "f35 min is -2.0689e+16\n",
      "f36\n",
      "-----------\n",
      "f36 max is 3728.5\n",
      "f36 min is -2414.3\n",
      "f37\n",
      "-----------\n",
      "f37 max is 1218.0\n",
      "f37 min is -40.881\n",
      "f38\n",
      "-----------\n",
      "f38 max is 4.084\n",
      "f38 min is 0.5461\n",
      "f39\n",
      "-----------\n",
      "f39 max is 11195.0\n",
      "f39 min is -433.7\n",
      "f40\n",
      "-----------\n",
      "f40 max is 1.0435\n",
      "f40 min is -0.007641\n",
      "f41\n",
      "-----------\n",
      "f41 max is 2335.4\n",
      "f41 min is -107.38\n",
      "f42\n",
      "-----------\n",
      "f42 max is 1.0287\n",
      "f42 min is -0.05771\n",
      "f43\n",
      "-----------\n",
      "f43 max is 19.978\n",
      "f43 min is -4.4214\n",
      "f44\n",
      "-----------\n",
      "f44 max is 180.97\n",
      "f44 min is -8.1892\n",
      "f45\n",
      "-----------\n",
      "f45 max is 0.066794\n",
      "f45 min is -0.01026\n",
      "f46\n",
      "-----------\n",
      "f46 max is 10.066\n",
      "f46 min is -3.5615\n",
      "f47\n",
      "-----------\n",
      "f47 max is 3.0153\n",
      "f47 min is -2.6172\n",
      "f48\n",
      "-----------\n",
      "f48 max is 16.87\n",
      "f48 min is 1.0564\n",
      "f49\n",
      "-----------\n",
      "f49 max is 1.799\n",
      "f49 min is -1.7306\n",
      "f50\n",
      "-----------\n",
      "f50 max is 0.54832\n",
      "f50 min is -0.006924\n",
      "f51\n",
      "-----------\n",
      "f51 max is nan\n",
      "f51 min is nan\n",
      "f52\n",
      "-----------\n",
      "f52 max is 14553.0\n",
      "f52 min is -721.61\n",
      "f53\n",
      "-----------\n",
      "f53 max is 131.75\n",
      "f53 min is -26.637\n",
      "f54\n",
      "-----------\n",
      "f54 max is 175.16\n",
      "f54 min is 98.868\n",
      "f55\n",
      "-----------\n",
      "f55 max is 0.49607\n",
      "f55 min is -0.033956\n",
      "f56\n",
      "-----------\n",
      "f56 max is 1.1866\n",
      "f56 min is -0.052052\n",
      "f57\n",
      "-----------\n",
      "f57 max is 0.0039055\n",
      "f57 min is -0.003899\n",
      "f58\n",
      "-----------\n",
      "f58 max is 0.071947\n",
      "f58 min is -1.179\n",
      "f59\n",
      "-----------\n",
      "f59 max is 7.7346\n",
      "f59 min is 0.68364\n",
      "f60\n",
      "-----------\n",
      "f60 max is 1.0141\n",
      "f60 min is -0.15099\n",
      "f61\n",
      "-----------\n",
      "f61 max is 1.0751\n",
      "f61 min is -0.19692\n",
      "f62\n",
      "-----------\n",
      "f62 max is 18289000000.0\n",
      "f62 min is -1825600000.0\n",
      "f63\n",
      "-----------\n",
      "f63 max is 210.43\n",
      "f63 min is -11.941\n",
      "f64\n",
      "-----------\n",
      "f64 max is 1.352\n",
      "f64 min is -0.13478\n",
      "f65\n",
      "-----------\n",
      "f65 max is 91871.0\n",
      "f65 min is -3302.6\n",
      "f66\n",
      "-----------\n",
      "f66 max is 161.75\n",
      "f66 min is -22.021\n",
      "f67\n",
      "-----------\n",
      "f67 max is 1996.7\n",
      "f67 min is -68.682\n",
      "f68\n",
      "-----------\n",
      "f68 max is 167.66\n",
      "f68 min is -2.1598\n",
      "f69\n",
      "-----------\n",
      "f69 max is 1.8917\n",
      "f69 min is 0.84922\n",
      "f70\n",
      "-----------\n",
      "f70 max is 1.0179\n",
      "f70 min is -0.0092006\n",
      "f71\n",
      "-----------\n",
      "f71 max is 3.7999\n",
      "f71 min is 0.7742\n",
      "f72\n",
      "-----------\n",
      "f72 max is 1453.9\n",
      "f72 min is -64.669\n",
      "f73\n",
      "-----------\n",
      "f73 max is 6087900000000000.0\n",
      "f73 min is -280280000000000.0\n",
      "f74\n",
      "-----------\n",
      "f74 max is 6694600000000.0\n",
      "f74 min is -610670000000.0\n",
      "f75\n",
      "-----------\n",
      "f75 max is 1.0304\n",
      "f75 min is -0.013163\n",
      "f76\n",
      "-----------\n",
      "f76 max is 18.366\n",
      "f76 min is -2.9862\n",
      "f77\n",
      "-----------\n",
      "f77 max is 56889.0\n",
      "f77 min is -1546.0\n",
      "f78\n",
      "-----------\n",
      "f78 max is 47503.0\n",
      "f78 min is -1284.2\n",
      "f79\n",
      "-----------\n",
      "f79 max is 43.552\n",
      "f79 min is -24.288\n",
      "f80\n",
      "-----------\n",
      "f80 max is 1.3572\n",
      "f80 min is -0.017615\n",
      "f81\n",
      "-----------\n",
      "f81 max is 7.2883\n",
      "f81 min is 0.9642\n",
      "f82\n",
      "-----------\n",
      "f82 max is 738970000000.0\n",
      "f82 min is -73457000000.0\n",
      "f83\n",
      "-----------\n",
      "f83 max is 950.53\n",
      "f83 min is -28.752\n",
      "f84\n",
      "-----------\n",
      "f84 max is 34511000.0\n",
      "f84 min is -2992000.0\n",
      "f85\n",
      "-----------\n",
      "f85 max is 2307.5\n",
      "f85 min is -74.545\n",
      "f86\n",
      "-----------\n",
      "f86 max is 130970000000.0\n",
      "f86 min is -5949500000.0\n",
      "f87\n",
      "-----------\n",
      "f87 max is 147.08\n",
      "f87 min is -7.6164\n",
      "f88\n",
      "-----------\n",
      "f88 max is 618.13\n",
      "f88 min is -22.576\n",
      "f89\n",
      "-----------\n",
      "f89 max is 20675.0\n",
      "f89 min is -296.78\n",
      "f90\n",
      "-----------\n",
      "f90 max is 21.994\n",
      "f90 min is -0.25757\n",
      "f91\n",
      "-----------\n",
      "f91 max is 0.51629\n",
      "f91 min is -0.012238\n",
      "f92\n",
      "-----------\n",
      "f92 max is 55362.0\n",
      "f92 min is -12829.0\n",
      "f93\n",
      "-----------\n",
      "f93 max is 448.78\n",
      "f93 min is -12.922\n",
      "f94\n",
      "-----------\n",
      "f94 max is 3.9251\n",
      "f94 min is -3.2933\n",
      "f95\n",
      "-----------\n",
      "f95 max is 65.317\n",
      "f95 min is -1.3524\n",
      "f96\n",
      "-----------\n",
      "f96 max is 38704.0\n",
      "f96 min is -7764.3\n",
      "f97\n",
      "-----------\n",
      "f97 max is 1.0039\n",
      "f97 min is 0.9961\n",
      "f98\n",
      "-----------\n",
      "f98 max is 71701000000000.0\n",
      "f98 min is -5714600000000.0\n",
      "f99\n",
      "-----------\n",
      "f99 max is 4.1691\n",
      "f99 min is 0.6082\n",
      "f100\n",
      "-----------\n",
      "f100 max is 1.0613\n",
      "f100 min is -0.034559\n",
      "f101\n",
      "-----------\n",
      "f101 max is 105.62\n",
      "f101 min is -4.2949\n",
      "f102\n",
      "-----------\n",
      "f102 max is 2337900.0\n",
      "f102 min is -227770.0\n",
      "f103\n",
      "-----------\n",
      "f103 max is 3260.9\n",
      "f103 min is -222.21\n",
      "f104\n",
      "-----------\n",
      "f104 max is 46876.0\n",
      "f104 min is -11581.0\n",
      "f105\n",
      "-----------\n",
      "f105 max is 0.49156\n",
      "f105 min is -0.029027\n",
      "f106\n",
      "-----------\n",
      "f106 max is 0.84855\n",
      "f106 min is -0.066726\n",
      "f107\n",
      "-----------\n",
      "f107 max is 0.089019\n",
      "f107 min is -0.0075354\n",
      "f108\n",
      "-----------\n",
      "f108 max is 7556500000.0\n",
      "f108 min is -587700000.0\n",
      "f109\n",
      "-----------\n",
      "f109 max is 1.1236\n",
      "f109 min is -0.042355\n",
      "f110\n",
      "-----------\n",
      "f110 max is 1.6134\n",
      "f110 min is -105.86\n",
      "f111\n",
      "-----------\n",
      "f111 max is 4.5659\n",
      "f111 min is 0.27704\n",
      "f112\n",
      "-----------\n",
      "f112 max is 217.84\n",
      "f112 min is -27.691\n",
      "f113\n",
      "-----------\n",
      "f113 max is 47.757\n",
      "f113 min is -26.589\n",
      "f114\n",
      "-----------\n",
      "f114 max is 526050.0\n",
      "f114 min is -81977.0\n",
      "f115\n",
      "-----------\n",
      "f115 max is 1.8867\n",
      "f115 min is 0.90527\n",
      "f116\n",
      "-----------\n",
      "f116 max is 3.2499e+17\n",
      "f116 min is -8944400000000000.0\n",
      "f117\n",
      "-----------\n",
      "f117 max is 13151.0\n",
      "f117 min is -415.24\n",
      "f118\n",
      "-----------\n",
      "f118 max is 2.7436\n",
      "f118 min is -0.15124\n",
      "claim\n",
      "-----------\n",
      "claim max is 1\n",
      "claim min is 0\n"
     ]
    }
   ],
   "source": [
    "for f in df.columns:\n",
    "    print(f + '\\n-----------')\n",
    "    print(f\"{f} max is {max(df[f])}\")\n",
    "    print(f\"{f} min is {min(df[f])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d550e-d485-49fe-a5aa-b7c3dc2728d3",
   "metadata": {},
   "source": [
    "- So we have some pretty wild variances in values -- everything from features that barely deviate from zero to ones that range from positive to negative 17-digit numbers. Scaling will be absolutely essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ade0d1-2716-4a1e-a2df-3c24580e44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in df.columns:\n",
    "    sns.scatterplot(x=f, y=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f03f1-2a05-4c9f-8e88-c75a9488b280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e77e37c-8f76-44b2-9e04-7fa02430ce96",
   "metadata": {},
   "source": [
    "# Feature Creation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb77f573-e284-49a7-96a8-bb33b5b44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the polynomialfeatures generated with `PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)`\n",
    "# X_np = np.load(datapath/'X_poly_unscaled.npy')\n",
    "# X = pd.DataFrame(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e905f6-f5e4-4848-98e3-ddc846ab4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1e4c99-64d4-4506-b208-397ce736eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep features from unaltered dataset\n",
    "features = [x for x in df.columns if x != 'loss']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2728178c-5214-4c6c-ab86-5d63aeb2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbdaa47-cab5-441b-885d-d21b33c604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly_names = poly.get_feature_names(X.columns)\n",
    "# # X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f6bd0c-1121-4430-966d-7a318d925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c528d2-2148-409f-9489-254358a4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(X_poly, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0682b3-1fef-4c54-9a33-99f659a2c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[features[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c845cbf-334e-432e-9f85-a8b68284580b",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "Now, going to scale using `MaxAbsScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c839fb-0ffc-4f4f-bc90-a73a13afb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = config['scaler']()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0333a-b1cb-45bd-adc2-e6563ae31770",
   "metadata": {},
   "source": [
    "# K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a17679c-152f-4aff-a1dd-d09ab727ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUALLY probably better to save those as pickles or .npy files; I'll generate them later, regardless\n",
    "# results = {} # for storing k-fold models' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd996d02-2530-4a40-84ec-01f8cde635da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=config['k_folds'], shuffle=True, random_state=config['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b57553a-5f07-49a4-94ac-6ca4f49017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_valid, y_train, y_valid, config):#, scaler): # passed in via config dict for now\n",
    "    \"\"\"\n",
    "    Basic training function. Note that some of the options passed via the argument are\n",
    "    in fact hard-coded in, to avoid inconveniences.\n",
    "    :param config: dict with things to be logged in WandB, some to be used in function\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"202108_Kaggle_tabular_playground\",\n",
    "        save_code=True,\n",
    "        tags=config_run['tags'],\n",
    "        name=config_run['name'],\n",
    "        notes=config_run['notes'],\n",
    "        config=config)   \n",
    "        \n",
    "    # applying hold-out before scaling\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=config['test_size'], \n",
    "#                                                           random_state=config['random_state']\n",
    "#                                                          )\n",
    "    \n",
    "    # strictly speaking should do the below, but doing beforehand faster and fine in this context\n",
    "    # scaling (i.e. normalizing)\n",
    "#     scaler = config['scaler']()\n",
    "#     X_train_s = scaler.fit_transform(X_train)\n",
    "#     X_valid_s = scaler.fit_transform(X_valid)\n",
    "    \n",
    "    # selecting features\n",
    "#     selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                           k=config['k_best'])\n",
    "#     X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "#     X_valid_fs = X_valid_s[:, selector.get_support()] # ensures same features are used in validation\n",
    "\n",
    "#     # split the dataset\n",
    "#     model = CatBoostRegressor(\n",
    "#         n_estimators=config['n_estimators'],\n",
    "#         learning_rate=config['learning_rate'],\n",
    "#         max_depth=config['max_depth'],\n",
    "#         task_type=config['task_type'],\n",
    "# #         n_jobs=config['n_jobs'],\n",
    "# #         verbosity=config['verbosity'],\n",
    "# #         subsample=config['subsample'],\n",
    "#         random_state=config['random_state'],\n",
    "# #         bootstrap_type=config['bootstrap_type'],\n",
    "# #         device:config['device']\n",
    "#     ) \n",
    "\n",
    "    model = XGBRegressor(\n",
    "        tree_method=config['tree_method'],\n",
    "        booster=config['booster'],\n",
    "        n_estimators=config['n_estimators'], \n",
    "        max_depth=config['max_depth'],\n",
    "        learning_rate=config['learning_rate'], \n",
    "#         test_size=config['test_size'],\n",
    "        subsample=config['subsample'],\n",
    "#         reg_alpha=config['reg_alpha'],\n",
    "#         reg_lambda=config['reg_lambda'],\n",
    "        random_state=config['random_state'],\n",
    "        n_jobs=config['n_jobs'], \n",
    "        verbosity=config['verbosity'], \n",
    "    )\n",
    "#     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "    model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "    y_preds = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, y_preds)\n",
    "    rmse = math.sqrt(abs(mse))\n",
    "    wandb.log({'mse':mse, 'rmse':rmse})\n",
    "    print(f\"MSE is {mse}\\nRMSE is {rmse}\")   \n",
    "#     wandb.finish()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e75f832-d012-4021-9628-984209569b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "529afca9-85db-4499-a909-089fb2f10899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(f\"./models/{config_run['name']}_{config['k_folds']}folds/\")\n",
    "(model_path).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81b675b9-3eef-4546-a638-0418ce991653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find XGBoost_ensemble_20210831_no_feature_gen.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.33193748555472\n",
      "RMSE is 7.83147096563313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493223<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.33194</td></tr><tr><td>rmse</td><td>7.83147</td></tr><tr><td>_runtime</td><td>1591</td></tr><tr><td>_timestamp</td><td>1630429873</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 62.24235031226011\n",
      "RMSE is 7.889382124872651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493899<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>62.24235</td></tr><tr><td>rmse</td><td>7.88938</td></tr><tr><td>_runtime</td><td>1539</td></tr><tr><td>_timestamp</td><td>1630431417</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.81231376886642\n",
      "RMSE is 7.862080753138218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494220<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.81231</td></tr><tr><td>rmse</td><td>7.86208</td></tr><tr><td>_runtime</td><td>1551</td></tr><tr><td>_timestamp</td><td>1630432972</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.666720656537805\n",
      "RMSE is 7.852816097206008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494521<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.66672</td></tr><tr><td>rmse</td><td>7.85282</td></tr><tr><td>_runtime</td><td>1548</td></tr><tr><td>_timestamp</td><td>1630434524</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.61926325055153\n",
      "RMSE is 7.849793834907484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494841<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.61926</td></tr><tr><td>rmse</td><td>7.84979</td></tr><tr><td>_runtime</td><td>1533</td></tr><tr><td>_timestamp</td><td>1630436061</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#     if fold == 0:\n",
    "#         continue\n",
    "#     else:\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    X_train, X_valid = X_scaled[train_ids], X_scaled[valid_ids] # requires X to be a numpy.ndarray\n",
    "    y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "    model = train(X_train, X_valid, y_train, y_valid, config)\n",
    "    wandb.log({'fold': fold})\n",
    "    models[fold] = model\n",
    "    dump(model, Path(model_path/f\"xgboost_fold{fold}_model.joblib\"))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e972a4-67b9-4fd8-96b1-6525e805f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     dump(preds, f\"./preds/{config_rn['name']}/xgboost_fold{fold}_preds.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02baf90b-01bc-4945-b64c-5af0c6e309be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e394bc6-29fe-4033-a850-bf6d55883b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(datapath/'test.csv', index_col='id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e85f83d-b5a3-4c9e-b654-dfd743f2966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250000</th>\n",
       "      <td>0.812665</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.239120</td>\n",
       "      <td>-0.893251</td>\n",
       "      <td>295.5770</td>\n",
       "      <td>15.87120</td>\n",
       "      <td>23.04360</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>29.898000</td>\n",
       "      <td>1.11394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>-422.332</td>\n",
       "      <td>-1.44630</td>\n",
       "      <td>1.69075</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>-3.010570</td>\n",
       "      <td>1.94664</td>\n",
       "      <td>0.529470</td>\n",
       "      <td>1.386950</td>\n",
       "      <td>8.78767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250001</th>\n",
       "      <td>0.190344</td>\n",
       "      <td>131</td>\n",
       "      <td>-0.501361</td>\n",
       "      <td>0.801921</td>\n",
       "      <td>64.8866</td>\n",
       "      <td>3.09703</td>\n",
       "      <td>344.80500</td>\n",
       "      <td>0.807194</td>\n",
       "      <td>38.421900</td>\n",
       "      <td>1.09695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377179</td>\n",
       "      <td>10352.200</td>\n",
       "      <td>21.06270</td>\n",
       "      <td>1.84351</td>\n",
       "      <td>0.251895</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>11.79390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250002</th>\n",
       "      <td>0.919671</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.057382</td>\n",
       "      <td>0.901419</td>\n",
       "      <td>11961.2000</td>\n",
       "      <td>16.39650</td>\n",
       "      <td>273.24000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>1.15222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>3224.020</td>\n",
       "      <td>-2.25287</td>\n",
       "      <td>1.55100</td>\n",
       "      <td>-0.559157</td>\n",
       "      <td>17.838600</td>\n",
       "      <td>1.83385</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>2.336870</td>\n",
       "      <td>9.05400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250003</th>\n",
       "      <td>0.860985</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.549509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>7501.6000</td>\n",
       "      <td>2.80698</td>\n",
       "      <td>71.08170</td>\n",
       "      <td>0.792136</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>1.20157</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>9689.760</td>\n",
       "      <td>14.77150</td>\n",
       "      <td>1.41390</td>\n",
       "      <td>0.329272</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>2.23251</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>1.359470</td>\n",
       "      <td>4.84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250004</th>\n",
       "      <td>0.313229</td>\n",
       "      <td>89</td>\n",
       "      <td>0.588509</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>2931.2600</td>\n",
       "      <td>4.34986</td>\n",
       "      <td>1.57187</td>\n",
       "      <td>1.118300</td>\n",
       "      <td>7.754630</td>\n",
       "      <td>1.16807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>2693.350</td>\n",
       "      <td>44.18050</td>\n",
       "      <td>1.58020</td>\n",
       "      <td>-0.191021</td>\n",
       "      <td>26.253000</td>\n",
       "      <td>2.68238</td>\n",
       "      <td>0.361923</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>3.70660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0   f1        f2        f3          f4        f5         f6  \\\n",
       "id                                                                           \n",
       "250000  0.812665   15 -1.239120 -0.893251    295.5770  15.87120   23.04360   \n",
       "250001  0.190344  131 -0.501361  0.801921     64.8866   3.09703  344.80500   \n",
       "250002  0.919671   19 -0.057382  0.901419  11961.2000  16.39650  273.24000   \n",
       "250003  0.860985   19 -0.549509  0.471799   7501.6000   2.80698   71.08170   \n",
       "250004  0.313229   89  0.588509  0.167705   2931.2600   4.34986    1.57187   \n",
       "\n",
       "              f7         f8       f9  ...       f90        f91       f92  \\\n",
       "id                                    ...                                  \n",
       "250000  0.942256  29.898000  1.11394  ...  0.446389   -422.332  -1.44630   \n",
       "250001  0.807194  38.421900  1.09695  ...  0.377179  10352.200  21.06270   \n",
       "250002 -0.003300  37.940000  1.15222  ...  0.990140   3224.020  -2.25287   \n",
       "250003  0.792136   0.395235  1.20157  ...  1.396880   9689.760  14.77150   \n",
       "250004  1.118300   7.754630  1.16807  ...  0.862502   2693.350  44.18050   \n",
       "\n",
       "            f93       f94        f95      f96       f97       f98       f99  \n",
       "id                                                                           \n",
       "250000  1.69075  1.059300  -3.010570  1.94664  0.529470  1.386950   8.78767  \n",
       "250001  1.84351  0.251895   4.440570  1.90309  0.248534  0.863881  11.79390  \n",
       "250002  1.55100 -0.559157  17.838600  1.83385  0.931796  2.336870   9.05400  \n",
       "250003  1.41390  0.329272   0.802437  2.23251  0.893348  1.359470   4.84833  \n",
       "250004  1.58020 -0.191021  26.253000  2.68238  0.361923  1.532800   3.70660  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ec520-259f-44d2-ad33-7b8c22621132",
   "metadata": {},
   "source": [
    "(Here's where encapsulating the transformations in a pipeline would come in handy. But I'll do it manually for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ec74e4-ccb8-43b4-b910-3df1542aaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in test_df.columns if x != 'loss']\n",
    "X_test = test_df[features] # this is just for naming consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725cd3e-f883-4d20-837a-9f557b2122a9",
   "metadata": {},
   "source": [
    "Now, let's get the features the model was trained on and subset the test set's features accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f66e579-7f01-46e5-a47c-580c8f5d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1817e3a-7d90-4bc2-8c47-e97806f7dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_poly_names = poly.get_feature_names(X_test.columns)\n",
    "# X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d6bc49-d478-4f59-84d2-5e23e3e236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_test_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa68187e-271a-4df1-ae02-a2bb5d62c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = pd.DataFrame(X_test_poly, columns=X_test_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1020ad9b-1b05-49b8-b89b-c90362c256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = X_test_final[features[1:]]\n",
    "X_test_final = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c226e-1ef7-4e03-91a1-06fbb73139f0",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "Now, going to scale using `MaxAbsScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21da840a-caa6-4d76-a542-c1315a593346",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = config['scaler']()\n",
    "X_test_scaled = scaler.fit_transform(X_test_final)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3cbac-0995-4015-9940-fe3e8ec94724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8929a3a1-56ca-4f20-a44f-e3877c6dabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# # scaling (i.e. normalizing)\n",
    "# scaler = config['scaler']()\n",
    "# X_train_s = scaler.fit_transform(X_train)\n",
    "# X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# # selecting features\n",
    "# selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                       k=config['k_best'])\n",
    "# X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "# X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "# model = XGBRegressor(\n",
    "#     tree_method=config['tree_method'],\n",
    "#     booster=config['booster'],\n",
    "#     n_estimators=config['n_estimators'], \n",
    "#     max_depth=config['max_depth'],\n",
    "#     learning_rate=config['learning_rate'], \n",
    "#     test_size=config['test_size'],\n",
    "#     subsample=config['subsample'],\n",
    "#     random_state=config['random_state'],\n",
    "#     n_jobs=config['n_jobs'], \n",
    "#     verbosity=config['verbosity'], \n",
    "# )\n",
    "# #     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "# model.fit(X_train_fs, y_train)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b151abea-d9b0-48eb-969f-5c342fc13474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 1: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 2: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 3: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 4: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348db7c-c494-4616-a08f-55016fac5351",
   "metadata": {},
   "source": [
    "Now, iterate over the dict containing the models trained on the 5 folds, and store the predictions in a new dict `preds`\n",
    "**OR**\n",
    "load from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d608ff29-4ceb-43cb-a0bb-e1450c0b8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = {}\n",
    "# saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/inference_ensemble_20210828_204126_5folds/')\n",
    "# for fold in range(5):\n",
    "#     loaded_models[fold] = load(filename=Path(saved_models_path/f'xgboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285899b2-0b2e-4db3-9b1e-a0d8328b84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa072384-5154-4d54-8ddf-5452e9323882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "for fold in models.keys():\n",
    "    preds[fold] = models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a464a1c-9ca8-4a07-9cdb-18af399cf95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d6e6414-5f72-4a48-b5a1-a8d24486bbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc067fb9-ae8e-4b33-9d75-e5405043aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eca32f6-2267-4c98-9aa9-c4a31d69bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "       9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9d2f4b8-2356-4916-a091-45793db784ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c957ce26-bbf5-4aee-bccd-988f2471db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.007940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.532623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.855750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.124434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.444796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.007940\n",
       "1  250001  4.532623\n",
       "2  250002  7.855750\n",
       "3  250003  7.124434\n",
       "4  250004  7.444796"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4cc6d50-92bc-4295-9acc-5d345eb96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b13044-ddb7-4bfb-bdbc-71a42172efc1",
   "metadata": {},
   "source": [
    "# Ensembling with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85c2ffdf-6f70-4fbd-880d-2145c5e13ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_models = {}\n",
    "saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/CatBoost_ensemble_20210831_144245_5folds/')\n",
    "for fold in range(5):\n",
    "    catboost_models[fold] = load(filename=Path(saved_models_path/f'catboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22852978-0c80-413e-900d-363b6055661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <catboost.core.CatBoostRegressor at 0x7f1b154ecfa0>,\n",
       " 1: <catboost.core.CatBoostRegressor at 0x7f1b1548a880>,\n",
       " 2: <catboost.core.CatBoostRegressor at 0x7f1b154ec0a0>,\n",
       " 3: <catboost.core.CatBoostRegressor at 0x7f1b1548ac40>,\n",
       " 4: <catboost.core.CatBoostRegressor at 0x7f1b154ecdf0>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa291c7b-61c6-4ec4-928a-f01225ce68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = {}\n",
    "for fold in catboost_models.keys():\n",
    "    catboost_preds[fold] = catboost_models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e8099a5-b1aa-4aa0-926e-0d493a0dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_catboost_preds = (catboost_preds[0] + catboost_preds[1] + catboost_preds[2] + catboost_preds[3] + catboost_preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b1883aa-4b27-4ae8-bf84-44eef2de90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = 0.6 * final_catboost_preds + 0.4 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30feee22-238b-4807-93df-9c005d91491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.40583658, 4.58774964, 8.32465697, 7.18375788, 7.13135284,\n",
       "        9.67367649, 9.96252577, 5.89393404, 7.22270917, 7.53612671]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f43e0f1-ada2-4299-9b96-10987b073f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_preds = 0.65 * final_catboost_preds + 0.35 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdf4700f-a87a-472a-9228-726c9d76748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.4389943 , 4.5923435 , 8.36373235, 7.18870129, 7.10523255,\n",
       "        9.67708804, 9.96419843, 5.87235472, 7.23656006, 7.52442615]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c04c606-ea73-4744-8b7a-b71deef61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f9f1b0b-9153-4607-b199-28b79d2db7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.438994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.592343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>8.363732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.188701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.105233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.438994\n",
       "1  250001  4.592343\n",
       "2  250002  8.363732\n",
       "3  250003  7.188701\n",
       "4  250004  7.105233"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c9f3ab0-a385-416c-9fd8-be27c4301874",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost0.35-Catboost0.65_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67df4d3-54f8-43fe-9f14-d3751986a58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment - fitting model on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8331118-e7a3-4578-8e43-cf93067c6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:15] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"test_size\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             test_size=0.2, tree_method='auto', validate_parameters=1,\n",
       "             verbosity=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# scaling (i.e. normalizing)\n",
    "scaler = config['scaler']()\n",
    "X_s = scaler.fit_transform(X)\n",
    "X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# selecting features\n",
    "selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "                                      k=config['k_best'])\n",
    "X_fs = selector.fit_transform(X_s, y)\n",
    "X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    tree_method=config['tree_method'],\n",
    "    booster=config['booster'],\n",
    "    n_estimators=config['n_estimators'], \n",
    "    max_depth=config['max_depth'],\n",
    "    learning_rate=config['learning_rate'], \n",
    "    test_size=config['test_size'],\n",
    "    subsample=config['subsample'],\n",
    "    random_state=config['random_state'],\n",
    "    n_jobs=config['n_jobs'], \n",
    "    verbosity=config['verbosity'], \n",
    ")\n",
    "#     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "model.fit(X_fs, y)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90ba24b-75cd-4c2d-a2cf-fe7bf16b3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db93b42-8460-4793-bd0f-60ddb1d7e84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bfc7e54-043d-4abb-818e-503846c0f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50b58c49-59e9-4751-8373-98536c9a121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.027956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.305676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.300106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>6.988875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.316631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.027956\n",
       "1  250001  4.305676\n",
       "2  250002  7.300106\n",
       "3  250003  6.988875\n",
       "4  250004  7.316631"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41d0f44a-2ca7-486f-9197-48534a35043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('202108241211_XGBoost_fullset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
