{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eeee413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3fc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2894a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss, f1_score, fbeta_score\n",
    "\n",
    "# eda\n",
    "import missingno\n",
    "import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "import cleanlab\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70cccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# widedeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e031f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/dec2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25aa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99710bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d6d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf4df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_orig.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "# reduce memory usage\n",
    "X = reduce_memory_usage(X)\n",
    "# X_test = reduce_memory_usage(X)\n",
    "\n",
    "# metadata logging\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3178bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- alter as needed later\n",
    "exmodel_config = {\n",
    "    'general_random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "    'cross_val_strategy': KFold, \n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    **dataset_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595607fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['baseline'],\n",
    "    'notes': \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c451c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optuna 20211124, with corrected dataset and RobustScaler\n",
    "# best_xgboost_params = {\n",
    "#     'n_estimators': 9872,\n",
    "#     'max_depth': 3,\n",
    "#     'learning_rate': 0.12943882615104757,\n",
    "#     'reg_alpha': 4.793236314677738,\n",
    "#     'reg_lambda': 0.03427038053813167,\n",
    "#     'subsample': 0.5026684329097286,\n",
    "#     'min_child_weight': 3.2374430610042664,\n",
    "#     'colsample_bytree': 0.9875504456465564,\n",
    "#     'gamma': 4.691772640321729\n",
    "# }\n",
    "\n",
    "# # best as of 20211125, with corrected dataset and RobustScaler\n",
    "# best_lightgbm_params = {\n",
    "#     'n_estimators': 6986,\n",
    "#     'max_depth': 3,\n",
    "#     'learning_rate': 0.09080435106650955,\n",
    "#     'reg_alpha': 19.060739534647425,\n",
    "#     'reg_lambda': 0.12865332700612375,\n",
    "#     'subsample': 0.5612404690403716,\n",
    "#     'boosting_type': 'goss',\n",
    "#     'min_child_samples': 17,\n",
    "#     'num_leaves': 59,\n",
    "#     'colsample_bytree': 0.5125554530181221\n",
    "# }\n",
    "\n",
    "# # best as of 20211126, with corrected dataset and RobustScaler\n",
    "# best_catboost_params = {\n",
    "#     'iterations': 17997,\n",
    "#     'depth': 4,\n",
    "#     'learning_rate': 0.05807421036756052,\n",
    "#     'random_strength': 27,\n",
    "#     'od_wait': 1664,\n",
    "#     'reg_lambda': 57.67864249277457,\n",
    "#     'border_count': 275,\n",
    "#     'min_child_samples': 10,\n",
    "#     'leaf_estimation_iterations': 2\n",
    "# }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_xgboost_params = {\n",
    "# #     'n_estimators': 1534,\n",
    "# #     'max_depth': 4,\n",
    "# #     'learning_rate': 0.0062941159127744535,\n",
    "# #     'reg_alpha': 21.3946930650266,\n",
    "# #     'reg_lambda': 0.021003786013817635,\n",
    "# #     'subsample': 0.5726680367393964,\n",
    "# #     'min_child_weight': 0.07566661785187714,\n",
    "# #     'colsample_bytree': 0.7850419523745037,\n",
    "# #     'gamma': 4.26660233356059\n",
    "# # }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_lightgbm_params = {\n",
    "# #     'n_estimators': 5776,\n",
    "# #     'max_depth': 4,\n",
    "# #     'learning_rate': 0.0010172282832994653,\n",
    "# #     'reg_alpha': 0.013879765609402173,\n",
    "# #     'reg_lambda': 0.002787031048344079,\n",
    "# #     'subsample': 0.800000753298926,\n",
    "# #     'boosting_type': 'gbdt',\n",
    "# #     'min_child_samples': 11,\n",
    "# #     'num_leaves': 190,\n",
    "# #     'colsample_bytree': 0.9976443570341007\n",
    "# # }\n",
    "\n",
    "# # # 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "# # lv2_catboost_params = {\n",
    "# #     'iterations': 2000,\n",
    "# #     'depth': 6,\n",
    "# #     'learning_rate': 0.002984126581340097,\n",
    "# #     'random_strength': 0,\n",
    "# #     'od_wait': 334,\n",
    "# #     'reg_lambda': 33.469738674488084,\n",
    "# #     'border_count': 158,\n",
    "# #     'min_child_samples': 8,\n",
    "# #     'leaf_estimation_iterations': 4\n",
    "# # }\n",
    "\n",
    "# # # initial, non-default guess -- need to get optuna working (20211010)\n",
    "# # # basic_widedeep_tabmlp_params = {\n",
    "    \n",
    "# # # }\n",
    "\n",
    "# # # basic_widedeep_trainer_params = {\n",
    "# # #     optimizers=AdamW()\n",
    "# # # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a02a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.basic import LightGBMError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "042a3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_probs) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds, labels=list(range(7)))\n",
    "        fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,labels=list(range(7)))\n",
    "        fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy},\\nLog Loss: {fold_log_loss},\\nROC AUC: {fold_roc_auc}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_probs) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy},\\nLog Loss: {model_log_loss},\\nROC AUC: {model_roc_auc}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   f'model_log_loss': fold_log_loss,\n",
    "                   f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bd8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs, oof_preds, test_probs, test_preds = cross_validate_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b48715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds, labels=list(range(7)))\n",
    "        fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,labels=list(range(7)))\n",
    "        fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy},\\nLog Loss: {fold_log_loss},\\nROC AUC: {fold_roc_auc}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy},\\nLog Loss: {model_log_loss},\\nROC AUC: {model_roc_auc}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   f'model_log_loss': fold_log_loss,\n",
    "                   f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b4fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs, oof_preds, test_probs, test_preds = cross_validate_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a250e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy},\\nLog Loss: {fold_log_loss},\\nROC AUC: {fold_roc_auc}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy},\\nLog Loss: {model_log_loss},\\nROC AUC: {model_roc_auc}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   f'model_log_loss': fold_log_loss,\n",
    "                   f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05d943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs, oof_preds, test_probs, test_preds = cross_validate_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c64a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy},\\nLog Loss: {fold_log_loss},\\nROC AUC: {fold_roc_auc}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy},\\nLog Loss: {model_log_loss},\\nROC AUC: {model_roc_auc}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   f'model_log_loss': fold_log_loss,\n",
    "                   f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a014097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs, oof_preds, test_probs, test_preds = cross_validate_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbea7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds, confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "442f8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c9d6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"Metrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"Metrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds, confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b09741",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model('xgboost')\n",
    "except:\n",
    "    send_tg_message(text=f\"{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e971a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'lightgbm'\n",
    "try:\n",
    "    oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model(arch)\n",
    "except:\n",
    "    send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45e72864",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'catboost'\n",
    "try:\n",
    "    oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model(arch)\n",
    "except:\n",
    "    send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2abb12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'lightgbm'\n",
    "# try:\n",
    "oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model(arch)\n",
    "# except:\n",
    "#     send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83017021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds, model_confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769577f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'catboost'\n",
    "try:\n",
    "    oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model(arch)\n",
    "except:\n",
    "    send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97f5b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'catboost'\n",
    "# try:\n",
    "oof_probs, oof_preds, test_probs, test_preds, confusion = cross_validate_model(arch)\n",
    "# except:\n",
    "    # send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a28a677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_probs /= exmodel_config['kfolds']\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds#, model_confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69a37358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:95e6ieed) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 86024... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d84b3a90d9e49089b6537dcf16b04ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xgboost_20211204_120612</strong>: <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/95e6ieed\" target=\"_blank\">https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/95e6ieed</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211204_155002-95e6ieed/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:95e6ieed). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground/runs/2sezaqln\" target=\"_blank\">xgboost_20211204_120612</a></strong> to <a href=\"https://wandb.ai/hushifang/202112_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arch = 'catboost'\n",
    "# try:\n",
    "oof_probs, oof_preds, _, _ = cross_validate_model(arch)\n",
    "# except:\n",
    "    # send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03943c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, params:dict={}, folds=list(range(5)), \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1: # holdout case\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                              random_state=SEED)                 \n",
    "    else: # k-fold cross validation case\n",
    "        # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "        # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "        if shuffle_kfolds:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "        else:\n",
    "            kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_probs, oof_y = [], [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    # test_preds = np.zeros((X_test.shape[0]))\n",
    "    # test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            y_valid_probs = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            # test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) # or should be preds?\n",
    "    model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    # test_probs /= exmodel_config['kfolds']\n",
    "    # test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_probs, oof_preds, test_probs, test_preds#, model_confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1de6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'catboost'\n",
    "# try:\n",
    "oof_probs, oof_preds, _, _ = cross_validate_model(arch)\n",
    "# except:\n",
    "    # send_tg_message(text=f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\n{arch} model training crashed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
