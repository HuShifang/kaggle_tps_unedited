{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Setting up a more robust baseline notebook, suitable for use with all of the \"Big Three\" (XGBoost, CatBoost, LightGBM) libraries and on either Google Colab or the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = False\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"stacking_off-shelf_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if gpu_available: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if gpu_available:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "    \"library\": libraries,\n",
    "    \"scaler\": StandardScaler, # TODO: experiment with others (but imputation may be slow)\n",
    "    \"scale_b4_impute\": False,\n",
    "    \"imputer\": SimpleImputer(strategy='median', add_indicator=True),\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': 42,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 5, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912a62f-970a-48b4-b428-d886f2612fc2",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b8603b-68c3-40da-8406-53e143758905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9716ae38-a859-44f1-bf4e-caf0c7a40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here's how to load the original, unaltered dataset and separate features from targets\n",
    "# df = pd.read_feather(path=datapath/'dataset_df.feather') # this is the unaltered original dataset\n",
    "# features = [x for x in df.columns if x != 'claim']\n",
    "# X = df[features]\n",
    "# y = df.claim\n",
    "\n",
    "\n",
    "\n",
    "# load the version of the dataset with imputations; X and y were stored separately, as feather and joblib respectively\n",
    "X = pd.read_feather(datapath/'X_NaNcounts_imputed-Median-wIndicators-StandardScaled.feather') \n",
    "y = load(datapath/'y.joblib')    \n",
    "X.index.name = 'id'\n",
    "y.index.name = 'id'\n",
    "\n",
    "exmodel_config['feature_count'] = len(X.columns)\n",
    "exmodel_config['feature_generator'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe60f69-2f22-403c-a13f-8ea8af4ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = exmodel_config['scaler']()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59020939-0ca1-4e0d-9af3-9fb122646ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       227       228       229       230  \\\n",
       "id                                ...                                           \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "\n",
       "         231       232       233      234       235      236  \n",
       "id                                                            \n",
       "0  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "1  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "2  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "3  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "4  -0.127119 -0.127985 -0.128494 -0.12862  7.821398 -0.12703  \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bd3364-0f44-45fb-bdbb-0748fe2d68e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47647b-3652-4f7e-ae62-6972d25f1a74",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7341ba-22c1-4887-bbda-ff2c7504bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configurator(library, gpu_available=True):#, config=universal_config):\n",
    "    \"\"\"\n",
    "    Function that provide task-specific or general preference arguments for the various models. \n",
    "    \n",
    "    At first, will rely largely on defaults for hyperparameters, but later this function \n",
    "    can be supplemented later with optimal values, as they're learned in sweeps.\n",
    "    .\n",
    "    \n",
    "    Rationale: creating a helper function will allow more experimentation later, and also\n",
    "    composite runs that cycle through a series of models.\n",
    "    \n",
    "    :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "    :return config: A dict that supplements default hyperparameter values with 1) \n",
    "                    task-appropriate ones, and perhaps later 2) optimal hyperparameter values.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    \n",
    "    # library-specific config\n",
    "    if library in ['xgboost', 'lightgbm']:\n",
    "        config['n_jobs'] = -1\n",
    "        \n",
    "    # best params per sweep `icac24c5`, generated from notebook `sweep_20210905.ipynb`\n",
    "    # runtime per fold should be around 12m 38s\n",
    "    # should get auc of 0.7434 on the random_state=42 holdout\n",
    "    # haven't yet tried dart\n",
    "    if library == 'xgboost':\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "#         config['model'] = XGBClassifier\n",
    "        config['verbosity'] = 1\n",
    "        config['objective'] = 'binary:logistic'\n",
    "#         config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "        config['tree_method'] = 'gpu_hist' if (gpu_available and colab) else 'auto' \n",
    "        \n",
    "        # comment out the below to get defaults\n",
    "        config['n_estimators'] = 902\n",
    "        config['learning_rate'] = 0.0304\n",
    "        config['max_depth'] = 3\n",
    "        config['reg_alpha'] = 0.863\n",
    "        config['reg_lambda'] = 2.442\n",
    "        config['subsample'] = 0.8627\n",
    "\n",
    "    # best params per sweep `sjghewf0`, generated from notebook `sweep_lightgbm_20210907`\n",
    "    # run name `sweep_lightgbm_20210907_195641`\n",
    "    # runtime per fold should be around 39s\n",
    "    # should get an auc of 0.7435 on random_state=42 holdout\n",
    "    if library == 'lightgbm':\n",
    "#         config['model'] = LGBMClassifier\n",
    "        config['objective'] = 'binary'\n",
    "        config['eval_metric'] = ['auc', 'logloss']\n",
    "        config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "        config['device_type'] = 'cuda' if (gpu_available and colab) else 'cpu' # 'gpu' also possible, 'cpu' is default\n",
    "        \n",
    "        # comment out the below for defaults\n",
    "        config['n_estimators'] = 1286\n",
    "        config['learning_rate'] = 0.03221\n",
    "        config['max_depth'] = 2\n",
    "        config['reg_alpha'] = 0.4687\n",
    "        config['reg_lambda'] = 0.1763\n",
    "        config['subsample'] = 0.6621\n",
    "        \n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "    if library == 'catboost':\n",
    "#         config['model'] = CatBoostClassifier\n",
    "        config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "        config['custom_metrics'] = ['Logloss', 'AUC'] # objective (loss fn) must be singular, defaults to Logloss\n",
    "        config['n_estimators'] = 2000 # logged as \"iterations\" otherwise\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f215-b585-4f7b-afac-36e49ee28c8f",
   "metadata": {},
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a928e1-0a18-4c91-b9bb-a32846e39e5b",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "config_run = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['stacking-sklearn', 'experiment', 'attempt'],\n",
    "    'notes': \"Another stacking run using Scikit-Learn's StackingClassifier API using best-to-date models for XGBoost and LightGBM (plus the default CatBoost). This time using RandomForestRegressor for final esimator.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f8d1-d303-4420-b671-51fcbff98594",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Scaling has already occurred -- used `StandardScaler` as a precursor to using `KNNImputer(n_neighbors=5)`, on the premise that imputation would proceed more quickly if things were already scaled. I may try different permutations of this later: using `IterativeImputer` instead, before or after scaling, potentially with different scalers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77e37c-8f76-44b2-9e04-7fa02430ce96",
   "metadata": {},
   "source": [
    "# Feature Creation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb77f573-e284-49a7-96a8-bb33b5b44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the polynomialfeatures generated with `PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)`\n",
    "# X_np = np.load(datapath/'X_poly_unscaled.npy')\n",
    "# X = pd.DataFrame(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e905f6-f5e4-4848-98e3-ddc846ab4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e4c99-64d4-4506-b208-397ce736eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2728178c-5214-4c6c-ab86-5d63aeb2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cbdaa47-cab5-441b-885d-d21b33c604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly_names = poly.get_feature_names(X.columns)\n",
    "# # X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f6bd0c-1121-4430-966d-7a318d925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c528d2-2148-409f-9489-254358a4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(X_poly, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f0682b3-1fef-4c54-9a33-99f659a2c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[features[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24391812-dce3-4513-bd38-ee95694730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_valid, y_train, y_valid, model_config, \n",
    "                                              random_state=42,\n",
    "                                              exmodel_config=exmodel_config, \n",
    "                                              config_run=config_run):#, scaler): # passed in via config dict for now\n",
    "    \"\"\"\n",
    "    Basic training function. Note that some of the options passed via the argument are\n",
    "    in fact hard-coded in, to avoid inconveniences.\n",
    "    :param X_train: the training set features\n",
    "    :param X_valid: the validation set features\n",
    "    :param y_train: the training set targets\n",
    "    :param y_valid: the validation set targets\n",
    "    :param random_staKFold: for reproducibility\n",
    "    :param exmodel_config: dict containing configuration details including the library \n",
    "                            (thus model) used, preprocessing, and cross-validation\n",
    "    :param model_config: dict containing hyperparameter specifications for the model\n",
    "    :param config_run: dict containing wandb run configuration (name, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"202109_Kaggle_tabular_playground\",\n",
    "        save_code=True,\n",
    "        tags=config_run['tags'],\n",
    "        name=config_run['name'],\n",
    "        notes=config_run['notes'],\n",
    "        config=exmodel_config)   \n",
    "        \n",
    "    if exmodel_config['library'] == 'xgboost':\n",
    "        model = XGBClassifier(\n",
    "            tree_method=model_config['tree_method'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "            # #             eval_metric=model_config['eval_metric'],\n",
    "\n",
    "            # comment out the below for a fairly default model\n",
    "#             booster=model_config['booster'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            learning_rate=model_config['learning_rate'], \n",
    "            subsample=model_config['subsample'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "\n",
    "\n",
    "    elif exmodel_config['library'] == 'lightgbm':\n",
    "        model = LGBMClassifier(\n",
    "#             boosting_type=model_config['boosting_type'],\n",
    "#             max_depth=model_config['max_depth']\n",
    "            # TODO\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "#             eval_metric=model_config['eval_metric'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=model_config['device_type'],\n",
    "            \n",
    "            # comment out the below for a basically default model\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            learning_rate=model_config['learning_rate'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            subsample=model_config['subsample'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "        \n",
    "    elif exmodel_config['library'] == 'catboost':\n",
    "        print(\"CatBoost, therefore no WandB callback.\")\n",
    "        model = CatBoostClassifier(\n",
    "#             n_estimators=config['n_estimators'],\n",
    "#             learning_rate=config['learning_rate'],\n",
    "#             max_depth=config['max_depth'],\n",
    "            task_type=model_config['task_type'],\n",
    "    #         n_jobs=config['n_jobs'],\n",
    "    #         verbosity=config['verbosity'],\n",
    "    #         subsample=config['subsample'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            random_state=random_state,\n",
    "            # objective='Logloss', # default, accepts only one\n",
    "#             custom_metrics=model_config['custom_metrics'],\n",
    "    #         bootstrap_type=config['bootstrap_type'],\n",
    "    #         device:config['device']\n",
    "        ) \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "#     y_train_pred = model.predict(X_train)\n",
    "    y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "    train_loss = log_loss(y_train, y_train_pred)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "\n",
    "    if exmodel_config['library'] == 'catboost':\n",
    "        print(model.get_all_params())\n",
    "        wandb.log(model.get_all_params())\n",
    "    else:\n",
    "        wandb.log(model.get_params()) # logging model parameters, trying bare-invocation rather than params: model.get_params()\n",
    "    \n",
    "    # trying with predict_proba\n",
    "    y_pred = model.predict_proba(X_valid)[:,1]\n",
    "#     y_pred = model.predict(X_valid)\n",
    "\n",
    "    valid_loss = log_loss(y_valid, y_pred)\n",
    "    valid_auc = roc_auc_score(y_valid, y_pred)\n",
    "    wandb.log({'valid_loss':valid_loss, 'valid_auc':valid_auc})\n",
    "    print(f\"Valid log-loss is {valid_loss}\\nValid AUC is {valid_auc}\")   \n",
    "#     wandb.finish()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_config, X=X, y=y, start_fold=0, exmodel_config=exmodel_config, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1:\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=exmodel_config['test_size'], \n",
    "                                                      random_state=random_state,\n",
    "                                                     )\n",
    "        model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "        wandb.finish()\n",
    "        \n",
    "    else:\n",
    "        X, y = X.to_numpy(), y.to_numpy()\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=random_state)\n",
    "        models = {}\n",
    "        model_path = Path(datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/\")\n",
    "        (model_path).mkdir(exist_ok=True)\n",
    "        for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "            if fold < start_fold:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"FOLD {fold}\")\n",
    "                print(\"---------------------------------------------------\")\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "                model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "                wandb.log({'fold': fold})\n",
    "                models[fold] = model\n",
    "                dump(model, Path(model_path/f\"{exmodel_config['library']}_fold{fold}_model.joblib\"))\n",
    "                wandb.finish()\n",
    "        return models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a437b-f880-4284-8e02-66a398ba6454",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58234814-68d1-4ee4-bedd-d722c18e4fa6",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4085e60e-13cf-4da7-90b9-30306480b4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# library = 'xgboost'\n",
    "# exmodel_config['library'] = library\n",
    "# model_config = model_configurator(library)\n",
    "# xgboost_models = cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b780292-f23c-4a3f-be1e-53038c5ae7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for scaler in [StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler]:\n",
    "#     exmodel_config['scaler'] = scaler\n",
    "#     scaler = scaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "#     X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "#     exmodel_config['library'] = 'lightgbm'\n",
    "#     model_config = model_configurator('lightgbm')\n",
    "#     cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1106b86c-70c1-4722-a86f-6c53a2e32503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# library = 'lightgbm'\n",
    "# exmodel_config['library'] = library\n",
    "# model_config = model_configurator(library)\n",
    "# lightgbm_models = cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542539d-323d-4a4a-b574-d0bf883179b2",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776a94d-01f3-46c0-9c9c-0d162de17e37",
   "metadata": {},
   "source": [
    "## Via `sklearn.ensemble.StackingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ca87f5f-e214-4968-a789-74f83dc7a656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e68e3adf-fd9d-4185-87c4-330ecd768679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_estimators = [(f'xgboost_fold{fold}', xgboost_models[fold]) for fold in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed3aa865-fec7-417b-9369-677d3b840760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaving this default for first try\n",
    "# final_estimator = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ac5214d-a3ab-4219-8047-822c4385e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacker(estimators:dict, library:str, X=X, y=y): #, load_models:bool=False, load_path:Path=None):\n",
    "    \"\"\"\n",
    "    A wrapper that will take a dict of the form {fold:int : model} and a string representing the library (for file-naming), \n",
    "    then run `sklearn.ensemble.StackingClassifier` with it, and save the stacked model afterward\n",
    "    \"\"\"\n",
    "    estimators_list = [(f'{library}_fold{fold}', estimators[fold]) for fold in range(5)]\n",
    "    blender = StackingClassifier(estimators=estimators_list,\n",
    "                                 cv=5,\n",
    "                                 stack_method='predict_proba',\n",
    "                                 n_jobs=2,\n",
    "                                 passthrough=False,\n",
    "                                 verbose=1\n",
    "                                )\n",
    "    print(f\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    blender.fit(X,y)\n",
    "    print(f\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    dump(blender, filename=datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/{library}_stack.joblib\")\n",
    "    print(f\"Blender model saved at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    return blender\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6926bf5c-f44d-42f7-8328-9ae400a08855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stacker(lightgbm_models, 'lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42660884-77dd-4cd9-bca9-3ce324615bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stacker(xgboost_models, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1f2d37f-8089-43b1-b796-97a731a70317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39f08073-4061-4f03-be9c-1c1fa601b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might encapsulate this in a new version of the above train function later\n",
    "exmodel_config['ensemble'] = 'stacking'\n",
    "\n",
    "# wandb.init(\n",
    "#         project=\"202109_Kaggle_tabular_playground\",\n",
    "#         save_code=True,\n",
    "#         tags=config_run['tags'],\n",
    "#         name=config_run['name'],\n",
    "#         notes=config_run['notes'],\n",
    "#         config=exmodel_config)   \n",
    "\n",
    "random_state = exmodel_config['random_state'] # 42\n",
    "\n",
    "model_config = model_configurator('xgboost')\n",
    "xgboost_model = XGBClassifier(\n",
    "            tree_method=model_config['tree_method'],\n",
    "            random_state=random_state,\n",
    "#             n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "            # #             eval_metric=model_config['eval_metric'],\n",
    "\n",
    "            # comment out the below for a fairly default model\n",
    "#             booster=model_config['booster'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            learning_rate=model_config['learning_rate'], \n",
    "            subsample=model_config['subsample'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "        )\n",
    "\n",
    "model_config = model_configurator('lightgbm')\n",
    "lightgbm_model = LGBMClassifier(\n",
    "            random_state=random_state,\n",
    "#             n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=model_config['device_type'],\n",
    "            \n",
    "            # comment out the below for a basically default model\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            learning_rate=model_config['learning_rate'],\n",
    "            max_depth=model_config['max_depth'],\n",
    "            reg_alpha=model_config['reg_alpha'],\n",
    "            reg_lambda=model_config['reg_lambda'],\n",
    "            subsample=model_config['subsample'],\n",
    "        )\n",
    "\n",
    "model_config = model_configurator('catboost', gpu_available=False) # set GPU false to avoid parallel threads blocking GPU\n",
    "catboost_model = CatBoostClassifier(\n",
    "            task_type=model_config['task_type'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            random_state=random_state,\n",
    "        ) \n",
    "\n",
    "\n",
    "\n",
    "estimators_list = [\n",
    "    ('xgboost', xgboost_model),\n",
    "    ('lightgbm', lightgbm_model),\n",
    "    ('catboost', catboost_model)\n",
    "]\n",
    "\n",
    "# wandb.log({'estimators': estimators_list})\n",
    "\n",
    "\n",
    "blender = StackingClassifier(estimators=estimators_list,\n",
    "                             final_estimator=RandomForestRegressor(),\n",
    "                             cv=5,\n",
    "                             stack_method='predict_proba',\n",
    "                             n_jobs=3,\n",
    "                             passthrough=False,\n",
    "                             verbose=1\n",
    "                            )\n",
    "exmodel_config['blender-passthrough'] = False\n",
    "# exmodel_config['blender_final_estimator'] = \n",
    "\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aca21cef-74f4-4b23-a82e-8c35419dd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params':str(blender.estimators_[0].get_params()),\n",
    "           'lightgbm_params':str(blender.estimators_[1].get_params()),\n",
    "           'catboost_params':str(blender.estimators_[2].get_all_params()),\n",
    "           'blender-final_estimator': str(blender.final_estimator),\n",
    "           'blender-final_estimator_params': str(blender.final_estimator.get_params()),\n",
    "           'blender-stack_mdethod': 'predict_proba',\n",
    "           'blender-cv': 5\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2e1ce80-d95e-4266-96c7-51390a7a8fea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting at 20210911_092732\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type XGBClassifier is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0e53b9abdab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mblender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unsure of this -- given kwarg cv=5, is it producing the splits? Or do I have to somehow?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'blender_params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mblender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcommit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_row_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_row_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_history.py\u001b[0m in \u001b[0;36m_row_add\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_row_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_history.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_history_callback\u001b[0;34m(self, row, step)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mnot_using_tensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tensorboard\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             self._backend.interface.publish_history(\n\u001b[0m\u001b[1;32m    903\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublish_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_using_tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_history\u001b[0;34m(self, data, step, run, publish_step)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_dumps_safer_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\u001b[0m in \u001b[0;36mjson_dumps_safer_history\u001b[0;34m(obj, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjson_dumps_safer_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;34m\"\"\"Convert obj to json, with some extra encodable types, including histograms\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWandBHistoryJSONEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     return cls(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mskipkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ascii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/wandb/util.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type XGBClassifier is not JSON serializable"
     ]
    }
   ],
   "source": [
    "print(f\"Starting fitting at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "blender.fit(X,y) # unsure of this -- given kwarg cv=5, is it producing the splits? Or do I have to somehow?\n",
    "print(f\"Fitting complete at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d8076f3-d1dc-4bd1-80ad-0eb29cc5bd00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blender model saved at 20210911_112017\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(datapath/f\"models/{config_run['name']}/\")\n",
    "(model_path).mkdir(exist_ok=True)\n",
    "dump(blender, filename=model_path/f\"{config_run['name']}_stack.joblib\")\n",
    "print(f\"Blender model saved at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da2b57e6-e4d7-4cb2-aa5d-7757a8d6d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss is 0.48896614392690346, train_auc is 0.8524474372578484\n"
     ]
    }
   ],
   "source": [
    "train_preds = blender.predict_proba(X)[:,1]\n",
    "train_loss = log_loss(y_pred=train_preds, y_true=y)\n",
    "train_auc = roc_auc_score(y, train_preds)\n",
    "wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "print(f\"train_loss is {train_loss}, train_auc is {train_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c226e-1ef7-4e03-91a1-06fbb73139f0",
   "metadata": {},
   "source": [
    "# Test set preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ec520-259f-44d2-ad33-7b8c22621132",
   "metadata": {},
   "source": [
    "(Here's where encapsulating the transformations in a pipeline would come in handy. But I'll do it manually for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ec74e4-ccb8-43b4-b910-3df1542aaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [x for x in test_df.columns if x != 'claim']\n",
    "# X_test = test_df[features] # this is just for naming consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725cd3e-f883-4d20-837a-9f557b2122a9",
   "metadata": {},
   "source": [
    "Now, let's get the features the model was trained on and subset the test set's features accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66e579-7f01-46e5-a47c-580c8f5d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1817e3a-7d90-4bc2-8c47-e97806f7dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_poly_names = poly.get_feature_names(X_test.columns)\n",
    "# X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6bc49-d478-4f59-84d2-5e23e3e236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_test_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68187e-271a-4df1-ae02-a2bb5d62c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = pd.DataFrame(X_test_poly, columns=X_test_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020ad9b-1b05-49b8-b89b-c90362c256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = X_test_final[features[1:]]\n",
    "# X_test_final = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07699efa-37df-4ed9-aaf2-1b77a73f9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['nan_count'] = X_test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd0c2d-7f9a-4fb6-8b4d-c3c51a9ef8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer = SimpleImputer(strategy='median', add_indicator=True)\n",
    "# X_test_imputed_np = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ef600-e3cd-44ef-ae66-e1d1663ec4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_imputed = pd.DataFrame(X_test_imputed, columns=[str(x) for x in range(X_test_imputed.shape[1])])\n",
    "# X_test_imputed.to_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da840a-caa6-4d76-a542-c1315a593346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = exmodel_config['scaler']()\n",
    "# X_test_imputed_scaled_np = scaler.fit_transform(X_test_imputed)\n",
    "# X_test_imputed_scaled = pd.DataFrame(X_test_imputed_scaled_np, columns=X_test_imputed.columns)\n",
    "# X_test_imputed_scaled.to_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a99cf5b-3477-47f4-9391-73e2ff93c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f347f-872f-4011-9f13-78fad542f36a",
   "metadata": {},
   "source": [
    "## Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0773d286-257d-4776-add5-0f724944befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/preds/stacking_off-shelf_20210911_092713_stack.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_path = Path(datapath/\"preds/\")\n",
    "\n",
    "blender_preds = blender.predict_proba(X_test_imputed_scaled)[:,1]\n",
    "dump(blender_preds, preds_path/f\"{config_run['name']}_stack.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719290c6-a10f-4506-8eeb-6a4bbf281b3d",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a464a1c-9ca8-4a07-9cdb-18af399cf95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9d2f4b8-2356-4916-a091-45793db784ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'claim'] = blender_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c957ce26-bbf5-4aee-bccd-988f2471db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>957919</td>\n",
       "      <td>0.578844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>957920</td>\n",
       "      <td>0.123754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>957921</td>\n",
       "      <td>0.642735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>957922</td>\n",
       "      <td>0.121587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>957923</td>\n",
       "      <td>0.148302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     claim\n",
       "0  957919  0.578844\n",
       "1  957920  0.123754\n",
       "2  957921  0.642735\n",
       "3  957922  0.121587\n",
       "4  957923  0.148302"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "519f6d45-6b2a-4fe8-be77-ecc70cec6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = datapath/'submissions'\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ae726f8-0c8e-46ab-bba1-cff095978d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(submission_path/f\"{config_run['name']}_blended.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4e34083-9f47-4583-b4f3-c10b4f3311d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'leaderboard_auc': 0.81630})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b08b089-292e-43a1-87f1-9d46ac917ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1440594<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.61MB of 0.61MB uploaded (0.09MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210911_114258-1aqlpp1g/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210911_114258-1aqlpp1g/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>estimators</td><td>[XGBClassifier(base_...</td></tr><tr><td>_runtime</td><td>521</td></tr><tr><td>_timestamp</td><td>1631386299</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>xgboost_params</td><td>{'objective': 'binar...</td></tr><tr><td>lightgbm_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>catboost_params</td><td>{'nan_mode': 'Min', ...</td></tr><tr><td>blender-final_estimator</td><td>LogisticRegression</td></tr><tr><td>blender-stack_mdethod</td><td>predict_proba</td></tr><tr><td>blender-cv</td><td>5</td></tr><tr><td>train_loss</td><td>0.48897</td></tr><tr><td>train_auc</td><td>0.85245</td></tr><tr><td>leaderboard_auc</td><td>0.8163</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▃▅▇██</td></tr><tr><td>_timestamp</td><td>▁▃▅▇██</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr><tr><td>blender-cv</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>leaderboard_auc</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stacking_off-shelf_20210911_092713</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1aqlpp1g\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1aqlpp1g</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afb61b-8022-4f0f-8996-2adfb3ec640c",
   "metadata": {},
   "source": [
    "## Manual Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1524723c-87c3-410f-863b-9387ef5b59e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>-0.127677</td>\n",
       "      <td>-0.128242</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.127119</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       227       228       229       230  \\\n",
       "id                                ...                                           \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.128368 -0.127677 -0.128242 -0.127867   \n",
       "\n",
       "         231       232       233      234       235      236  \n",
       "id                                                            \n",
       "0  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "1  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "2  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "3  -0.127119 -0.127985 -0.128494 -0.12862 -0.127854 -0.12703  \n",
       "4  -0.127119 -0.127985 -0.128494 -0.12862  7.821398 -0.12703  \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe341d69-270a-445e-9a05-287cd9f12c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a114476-71cb-4ef2-8f1f-2d8b2c837d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(957919, 237)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8dd525a7-3254-4e0c-8295-8871ffadd39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# generate probability predictions for the XGBoost model's folds\n",
    "for fold in xgboost_models.keys():\n",
    "#     X1[f\"xgboost_fold{fold}_pred\"] = xgboost_models[fold].predict(X)\n",
    "    X1[f\"xgboost_fold{fold}_pred\"] = xgboost_models[fold].predict_proba(X)[:,1]\n",
    "#     xgboost_preds[fold] = xgboost_models[fold].predict(X_test_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eff33be8-e342-42e8-843c-75e1acd96120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>xgboost_fold0_pred</th>\n",
       "      <th>xgboost_fold1_pred</th>\n",
       "      <th>xgboost_fold2_pred</th>\n",
       "      <th>xgboost_fold3_pred</th>\n",
       "      <th>xgboost_fold4_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425545</td>\n",
       "      <td>-2.357891</td>\n",
       "      <td>-0.637206</td>\n",
       "      <td>-0.866657</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-4.829243</td>\n",
       "      <td>-1.171229</td>\n",
       "      <td>-0.603397</td>\n",
       "      <td>-0.596871</td>\n",
       "      <td>-0.516828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.582566</td>\n",
       "      <td>0.580950</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>0.569523</td>\n",
       "      <td>0.595877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247600</td>\n",
       "      <td>-0.323982</td>\n",
       "      <td>1.223569</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>1.071182</td>\n",
       "      <td>-0.361140</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>-0.746590</td>\n",
       "      <td>0.899454</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.152252</td>\n",
       "      <td>0.150803</td>\n",
       "      <td>0.148316</td>\n",
       "      <td>0.155218</td>\n",
       "      <td>0.147297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032371</td>\n",
       "      <td>-2.435680</td>\n",
       "      <td>-0.488960</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>1.069656</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>-0.763516</td>\n",
       "      <td>1.056879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.794083</td>\n",
       "      <td>0.789945</td>\n",
       "      <td>0.788326</td>\n",
       "      <td>0.787177</td>\n",
       "      <td>0.797979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438373</td>\n",
       "      <td>-2.337605</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-0.829607</td>\n",
       "      <td>1.485682</td>\n",
       "      <td>3.592008</td>\n",
       "      <td>-1.189087</td>\n",
       "      <td>-0.339152</td>\n",
       "      <td>-0.735281</td>\n",
       "      <td>-0.529158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.774001</td>\n",
       "      <td>0.768510</td>\n",
       "      <td>0.774555</td>\n",
       "      <td>0.782187</td>\n",
       "      <td>0.773245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602333</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.648438</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.511066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.128494</td>\n",
       "      <td>-0.12862</td>\n",
       "      <td>7.821398</td>\n",
       "      <td>-0.12703</td>\n",
       "      <td>0.759366</td>\n",
       "      <td>0.755764</td>\n",
       "      <td>0.763769</td>\n",
       "      <td>0.758034</td>\n",
       "      <td>0.758038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "id                                                                         \n",
       "0   0.425545 -2.357891 -0.637206 -0.866657 -0.111568 -4.829243 -1.171229   \n",
       "1   0.247600 -0.323982  1.223569  0.361863  1.071182 -0.361140  0.082051   \n",
       "2   2.032371 -2.435680 -0.488960  0.341193  1.069656  0.118532  0.537069   \n",
       "3   1.438373 -2.337605 -0.508914 -0.829607  1.485682  3.592008 -1.189087   \n",
       "4   0.602333  1.076218 -0.648438  0.463365  0.275053 -0.157989  0.727338   \n",
       "\n",
       "           7         8         9  ...       232       233      234       235  \\\n",
       "id                                ...                                          \n",
       "0  -0.603397 -0.596871 -0.516828  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "1  -0.746590  0.899454  0.469668  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "2  -0.044075 -0.763516  1.056879  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "3  -0.339152 -0.735281 -0.529158  ... -0.127985 -0.128494 -0.12862 -0.127854   \n",
       "4  -0.905498  0.052478 -0.511066  ... -0.127985 -0.128494 -0.12862  7.821398   \n",
       "\n",
       "        236  xgboost_fold0_pred  xgboost_fold1_pred  xgboost_fold2_pred  \\\n",
       "id                                                                        \n",
       "0  -0.12703            0.582566            0.580950            0.576743   \n",
       "1  -0.12703            0.152252            0.150803            0.148316   \n",
       "2  -0.12703            0.794083            0.789945            0.788326   \n",
       "3  -0.12703            0.774001            0.768510            0.774555   \n",
       "4  -0.12703            0.759366            0.755764            0.763769   \n",
       "\n",
       "    xgboost_fold3_pred  xgboost_fold4_pred  \n",
       "id                                          \n",
       "0             0.569523            0.595877  \n",
       "1             0.155218            0.147297  \n",
       "2             0.787177            0.797979  \n",
       "3             0.782187            0.773245  \n",
       "4             0.758034            0.758038  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac245be1-3a2d-4c84-b83e-7224e4b13194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
