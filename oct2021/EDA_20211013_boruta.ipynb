{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# Dataset Sweep usign XGBoost on GPU\n",
    "Trying different variations on the dataset using PCA, other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_qtimPUchWD",
   "metadata": {
    "id": "U_qtimPUchWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {
    "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {
    "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb"
   },
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {
    "id": "16849bd2-428c-497b-ba3b-675002f8d041"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
    "outputId": "6bd53922-c4d7-43ce-c04f-ac1079087966"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
    "outputId": "5483656e-2943-4d97-b5d4-65cfb9795430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    # !pip install category_encoders\n",
    "    # !pip install catboost\n",
    "#     !pip install --upgrade -q lightgbm\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    # !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    # ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    # !pip install cmake --upgrade\n",
    "    # # !pip install sklearn --upgrade\n",
    "    # !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    # %cd /content/xgboost\n",
    "    # !mkdir build\n",
    "    # %cd build\n",
    "    # !cmake .. -DUSE_CUDA=ON\n",
    "    # !make -j4\n",
    "    # %cd /content/xgboost/python-package\n",
    "    # !python setup.py install --use-cuda --use-nccl\n",
    "    # !/opt/bin/nvidia-smi\n",
    "    # !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {
    "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd"
   },
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {
    "id": "a01e85f7-d602-4dde-bef9-611683cd74c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "# import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accfe297-1d47-41bd-9c84-a819d5e565f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {
    "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe"
   },
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {
    "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351"
   },
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67530ca9-6317-48be-bf6c-8621158b0020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
    "outputId": "76d62b41-4171-40fa-936c-4481a9fdab36"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "#     datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'optuna_studies'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {
    "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {
    "id": "fbec2e77-2081-4815-ac6d-39f2a2616386"
   },
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f08480-1725-4520-8995-92b76b8f2cea",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for preprocessing techniques on dataset\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {
    "id": "a52d9012-34f1-435a-ba16-4416e0d4a286"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ca14-2718-49d9-89e2-91d55f72d706",
   "metadata": {
    "id": "c912a62f-970a-48b4-b428-d886f2612fc2"
   },
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6919aac1-15d6-4b41-9871-f547602a91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {
    "id": "69ff4abf-560b-450e-a7a5-040878b66565"
   },
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "993947ab-fae6-4d7e-b73a-eb4e171ea61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 285)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82cb1b5b-73c9-45d2-943a-5361328f07df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 285)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b055e2b-ebbb-4d36-b995-7a50d4adbc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178216</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>0.390170</td>\n",
       "      <td>0.324221</td>\n",
       "      <td>0.221722</td>\n",
       "      <td>0.738894</td>\n",
       "      <td>0.582588</td>\n",
       "      <td>0.343770</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.476455</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.283146</td>\n",
       "      <td>0.598020</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.283467</td>\n",
       "      <td>0.721575</td>\n",
       "      <td>0.268990</td>\n",
       "      <td>0.208373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159721</td>\n",
       "      <td>0.451202</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.365274</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.413502</td>\n",
       "      <td>0.249318</td>\n",
       "      <td>0.642339</td>\n",
       "      <td>0.411104</td>\n",
       "      <td>0.246891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182424</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.095344</td>\n",
       "      <td>0.327742</td>\n",
       "      <td>0.741830</td>\n",
       "      <td>0.358711</td>\n",
       "      <td>0.270077</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>0.297742</td>\n",
       "      <td>0.252829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229329</td>\n",
       "      <td>0.336513</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>0.300913</td>\n",
       "      <td>0.668738</td>\n",
       "      <td>0.481586</td>\n",
       "      <td>0.545660</td>\n",
       "      <td>0.667849</td>\n",
       "      <td>0.546045</td>\n",
       "      <td>0.202731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.178216  0.435617  0.010230  0.202074  0.390170  0.324221  0.221722   \n",
       "1  0.181250  0.476455  0.022413  0.283146  0.598020  0.349508  0.283467   \n",
       "2  0.159721  0.451202  0.259649  0.365274  0.594634  0.413502  0.249318   \n",
       "3  0.182424  0.520976  0.095344  0.327742  0.741830  0.358711  0.270077   \n",
       "4  0.229329  0.336513  0.023511  0.300913  0.668738  0.481586  0.545660   \n",
       "\n",
       "         f7        f8        f9  ...  f275  f276  f277  f278  f279  f280  \\\n",
       "0  0.738894  0.582588  0.343770  ...     1     0     0     0     0     0   \n",
       "1  0.721575  0.268990  0.208373  ...     0     0     0     0     0     0   \n",
       "2  0.642339  0.411104  0.246891  ...     0     0     0     0     0     0   \n",
       "3  0.601662  0.297742  0.252829  ...     0     0     0     0     0     1   \n",
       "4  0.667849  0.546045  0.202731  ...     0     0     0     0     1     0   \n",
       "\n",
       "   f281  f282  f283  f284  \n",
       "0     1     1     1     0  \n",
       "1     0     0     0     0  \n",
       "2     1     0     0     0  \n",
       "3     1     0     0     0  \n",
       "4     0     1     0     0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "033581df-5813-448e-b3bb-1ba418585142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31df1af-7057-4167-8561-c9947c27b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eca68f8-930e-4c4f-9d0f-767ebe561d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_picker = XGBClassifier(\n",
    "    verbosity = 1,\n",
    "    tree_method = 'gpu_hist',\n",
    "    booster = 'gbtree',\n",
    "    random_state = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6230e00-931d-4e25-b4a4-1f2305fdbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta = BorutaPy(\n",
    "    verbose=2,\n",
    "    random_state=SEED,\n",
    "    estimator=feature_picker,\n",
    "    n_estimators='auto',\n",
    "    max_iter=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5ea27b-53a5-4c4c-a45a-2528c86349c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t1 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:48:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t2 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:51:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t3 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:53:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t4 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:55:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t5 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:57:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t6 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[15:59:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t7 / 200\n",
      "Confirmed: \t0\n",
      "Tentative: \t285\n",
      "Rejected: \t0\n",
      "[16:02:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t8 / 200\n",
      "Confirmed: \t51\n",
      "Tentative: \t67\n",
      "Rejected: \t167\n",
      "[16:04:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t9 / 200\n",
      "Confirmed: \t51\n",
      "Tentative: \t67\n",
      "Rejected: \t167\n",
      "[16:04:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t10 / 200\n",
      "Confirmed: \t51\n",
      "Tentative: \t67\n",
      "Rejected: \t167\n",
      "[16:05:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t11 / 200\n",
      "Confirmed: \t51\n",
      "Tentative: \t67\n",
      "Rejected: \t167\n",
      "[16:06:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t12 / 200\n",
      "Confirmed: \t59\n",
      "Tentative: \t59\n",
      "Rejected: \t167\n",
      "[16:06:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t13 / 200\n",
      "Confirmed: \t59\n",
      "Tentative: \t59\n",
      "Rejected: \t167\n",
      "[16:07:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t14 / 200\n",
      "Confirmed: \t59\n",
      "Tentative: \t59\n",
      "Rejected: \t167\n",
      "[16:08:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t15 / 200\n",
      "Confirmed: \t59\n",
      "Tentative: \t59\n",
      "Rejected: \t167\n",
      "[16:08:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t16 / 200\n",
      "Confirmed: \t69\n",
      "Tentative: \t48\n",
      "Rejected: \t168\n",
      "[16:09:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t17 / 200\n",
      "Confirmed: \t69\n",
      "Tentative: \t48\n",
      "Rejected: \t168\n",
      "[16:10:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t18 / 200\n",
      "Confirmed: \t69\n",
      "Tentative: \t48\n",
      "Rejected: \t168\n",
      "[16:10:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t19 / 200\n",
      "Confirmed: \t75\n",
      "Tentative: \t42\n",
      "Rejected: \t168\n",
      "[16:11:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t20 / 200\n",
      "Confirmed: \t75\n",
      "Tentative: \t42\n",
      "Rejected: \t168\n",
      "[16:12:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t21 / 200\n",
      "Confirmed: \t75\n",
      "Tentative: \t42\n",
      "Rejected: \t168\n",
      "[16:12:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t22 / 200\n",
      "Confirmed: \t76\n",
      "Tentative: \t41\n",
      "Rejected: \t168\n",
      "[16:13:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t23 / 200\n",
      "Confirmed: \t76\n",
      "Tentative: \t41\n",
      "Rejected: \t168\n",
      "[16:14:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t24 / 200\n",
      "Confirmed: \t76\n",
      "Tentative: \t41\n",
      "Rejected: \t168\n",
      "[16:14:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t25 / 200\n",
      "Confirmed: \t76\n",
      "Tentative: \t41\n",
      "Rejected: \t168\n",
      "[16:15:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t26 / 200\n",
      "Confirmed: \t80\n",
      "Tentative: \t37\n",
      "Rejected: \t168\n",
      "[16:16:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t27 / 200\n",
      "Confirmed: \t80\n",
      "Tentative: \t37\n",
      "Rejected: \t168\n",
      "[16:16:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t28 / 200\n",
      "Confirmed: \t80\n",
      "Tentative: \t37\n",
      "Rejected: \t168\n",
      "[16:17:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t29 / 200\n",
      "Confirmed: \t82\n",
      "Tentative: \t35\n",
      "Rejected: \t168\n",
      "[16:18:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t30 / 200\n",
      "Confirmed: \t82\n",
      "Tentative: \t35\n",
      "Rejected: \t168\n",
      "[16:18:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t31 / 200\n",
      "Confirmed: \t82\n",
      "Tentative: \t35\n",
      "Rejected: \t168\n",
      "[16:19:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t32 / 200\n",
      "Confirmed: \t85\n",
      "Tentative: \t31\n",
      "Rejected: \t169\n",
      "[16:20:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t33 / 200\n",
      "Confirmed: \t85\n",
      "Tentative: \t31\n",
      "Rejected: \t169\n",
      "[16:20:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t34 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:21:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t35 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:22:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t36 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:22:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t37 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:23:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t38 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:24:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t39 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:24:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t40 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:25:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t41 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:26:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t42 / 200\n",
      "Confirmed: \t86\n",
      "Tentative: \t30\n",
      "Rejected: \t169\n",
      "[16:26:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t43 / 200\n",
      "Confirmed: \t87\n",
      "Tentative: \t29\n",
      "Rejected: \t169\n",
      "[16:27:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t44 / 200\n",
      "Confirmed: \t87\n",
      "Tentative: \t29\n",
      "Rejected: \t169\n",
      "[16:28:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t45 / 200\n",
      "Confirmed: \t87\n",
      "Tentative: \t29\n",
      "Rejected: \t169\n",
      "[16:28:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t46 / 200\n",
      "Confirmed: \t89\n",
      "Tentative: \t27\n",
      "Rejected: \t169\n",
      "[16:29:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t47 / 200\n",
      "Confirmed: \t89\n",
      "Tentative: \t27\n",
      "Rejected: \t169\n",
      "[16:30:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t48 / 200\n",
      "Confirmed: \t89\n",
      "Tentative: \t27\n",
      "Rejected: \t169\n",
      "[16:30:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t49 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:31:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t50 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:32:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t51 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:32:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t52 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:33:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t53 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:34:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t54 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:34:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t55 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:35:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t56 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:36:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t57 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:36:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t58 / 200\n",
      "Confirmed: \t90\n",
      "Tentative: \t26\n",
      "Rejected: \t169\n",
      "[16:37:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t59 / 200\n",
      "Confirmed: \t92\n",
      "Tentative: \t24\n",
      "Rejected: \t169\n",
      "[16:38:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t60 / 200\n",
      "Confirmed: \t92\n",
      "Tentative: \t24\n",
      "Rejected: \t169\n",
      "[16:38:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t61 / 200\n",
      "Confirmed: \t92\n",
      "Tentative: \t24\n",
      "Rejected: \t169\n",
      "[16:39:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t62 / 200\n",
      "Confirmed: \t95\n",
      "Tentative: \t21\n",
      "Rejected: \t169\n",
      "[16:40:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t63 / 200\n",
      "Confirmed: \t95\n",
      "Tentative: \t21\n",
      "Rejected: \t169\n",
      "[16:40:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t64 / 200\n",
      "Confirmed: \t95\n",
      "Tentative: \t21\n",
      "Rejected: \t169\n",
      "[16:41:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t65 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:42:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t66 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:42:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t67 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:43:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t68 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:44:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t69 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:44:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t70 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:45:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t71 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:45:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t72 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:46:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t73 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:47:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t74 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:47:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t75 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:48:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t76 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:49:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t77 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:49:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t78 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:50:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t79 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:51:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t80 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:51:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t81 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:52:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t82 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:53:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t83 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:53:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t84 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:54:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t85 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:55:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t86 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:55:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t87 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:56:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t88 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:57:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t89 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:57:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t90 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:58:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t91 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:59:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t92 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[16:59:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t93 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:00:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t94 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:01:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t95 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:01:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t96 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:02:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t97 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:03:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t98 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:03:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t99 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:04:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t100 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:05:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t101 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:05:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t102 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:06:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t103 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:07:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t104 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:07:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t105 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:08:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t106 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:09:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t107 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:09:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t108 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:10:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t109 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:11:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t110 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:11:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t111 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:12:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t112 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:13:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t113 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:13:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t114 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:14:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t115 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:15:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t116 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:15:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t117 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:16:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t118 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:17:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t119 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:17:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t120 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:18:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t121 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:18:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t122 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:19:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t123 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:20:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t124 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:20:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t125 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:21:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t126 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:22:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t127 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:22:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t128 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:23:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t129 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:24:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t130 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:24:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t131 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:25:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t132 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:26:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t133 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:26:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t134 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:27:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t135 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:28:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t136 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t20\n",
      "Rejected: \t169\n",
      "[17:28:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t137 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:29:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t138 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:30:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t139 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:30:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t140 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:31:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t141 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:32:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t142 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:32:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t143 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:33:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t144 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:34:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t145 / 200\n",
      "Confirmed: \t96\n",
      "Tentative: \t19\n",
      "Rejected: \t170\n",
      "[17:34:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t146 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:35:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t147 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:36:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t148 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:36:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t149 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:37:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t150 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:38:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t151 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:38:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t152 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t18\n",
      "Rejected: \t170\n",
      "[17:39:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t153 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t17\n",
      "Rejected: \t171\n",
      "[17:39:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t154 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t17\n",
      "Rejected: \t171\n",
      "[17:40:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t155 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t17\n",
      "Rejected: \t171\n",
      "[17:41:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t156 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t17\n",
      "Rejected: \t171\n",
      "[17:41:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t157 / 200\n",
      "Confirmed: \t97\n",
      "Tentative: \t17\n",
      "Rejected: \t171\n",
      "[17:42:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t158 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:43:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t159 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:43:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t160 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:44:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t161 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:45:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t162 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:45:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t163 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:46:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t164 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:47:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t165 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:47:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t166 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:48:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t167 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:49:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t168 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:49:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t169 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:50:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t170 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:50:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t171 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t16\n",
      "Rejected: \t171\n",
      "[17:51:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t172 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:52:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t173 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:52:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t174 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:53:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t175 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:54:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t176 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:54:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t177 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:55:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t178 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:56:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t179 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:56:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t180 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:57:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t181 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:58:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t182 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:58:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t183 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:59:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t184 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[17:59:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t185 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:00:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t186 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:01:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t187 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:01:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t188 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:02:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t189 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:03:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t190 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:03:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t191 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:04:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t192 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:05:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t193 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:05:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t194 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:06:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t195 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:07:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t196 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:07:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t197 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:08:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t198 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "[18:08:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration: \t199 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t15\n",
      "Rejected: \t172\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t200 / 200\n",
      "Confirmed: \t98\n",
      "Tentative: \t11\n",
      "Rejected: \t172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                 colsample_bylevel=1, colsample_bynode=1,\n",
       "                                 colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "                                 importance_type='gain',\n",
       "                                 interaction_constraints='',\n",
       "                                 learning_rate=0.300000012, max_delta_step=0,\n",
       "                                 max_depth=6, min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints='()', n_estimators=250,\n",
       "                                 n_jobs=16, num_parallel_tree=1,\n",
       "                                 random_state=1807573427, reg_alpha=0,\n",
       "                                 reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                                 tree_method='gpu_hist', validate_parameters=1,\n",
       "                                 verbosity=1),\n",
       "         max_iter=200, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x7F83E407DC40, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boruta.fit(np.array(X), np.array(y))\n",
    "boruta = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0cb568c-130f-490b-8032-a365774c7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_zone = X.columns[boruta.support_].to_list()\n",
    "blue_zone = X.columns[boruta.support_weak_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff3f9ae9-71fc-4c53-b611-a9e47cac9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks = boruta.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eae4c65-54e1-4663-8205-59891154d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = boruta.transform(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc719a0a-2e9e-4954-a098-ecf70c5d3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/X_boruta_200iter_filtered.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X_filtered, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/X_boruta_200iter_filtered.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "645beb05-411a-4f71-8ad3-3e355a502bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(boruta, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cf8c5ca-20b2-4b6c-8ac5-97054c6c1c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(green_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d377b4a2-dcf7-4139-8d0f-6e8d98a658e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blue_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54976834-33a4-48f5-9df8-27e42c786864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 98)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efed15bc-0223-41af-a506-b9395ff8907b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79,   1,   1,   1,   1,   1,   1,   1,   1,  19,  87,  17,   1,\n",
       "         1,   1,  54,   1,   1,   1,   1,   1, 145,   1, 110,  94,  55,\n",
       "         1,  29, 131,   1,  72, 103,  73,   2,  59,  29,  69, 132,  89,\n",
       "        60,   1, 108,   1,   1,   1, 151,  61,  49,   1, 141,  96, 120,\n",
       "         1,   1,  42,   2,   1,  36,   1, 161,  50,  25,   8,   1,   2,\n",
       "         1,  81,  70, 138,   1,  16,   1,   1,   1,   1,   1,   2,   1,\n",
       "         1,  20,  25,  38,   1,   8,  97,   1,   1,   2,  98,   2,   1,\n",
       "       125,   1,   1,  58,   1,   1, 154,  14,   1,  90,  52, 157,   1,\n",
       "        66, 105,  94,   1,   2,  85, 129, 129,   1,  11,   3,  62,  56,\n",
       "        18,   2,   1, 127,  76, 115,  83, 115,   1, 138,   1,  25,   2,\n",
       "         1,  36, 101,   5,   1, 150,   1, 117,   1,   1,   1,   3, 118,\n",
       "         1,   5, 142,  32,  27,  86, 147,   1, 104,   1,  44,   1, 112,\n",
       "         1,   1, 162,  43,  79,  46,   1,   1,  22, 112, 112,  96, 116,\n",
       "         1, 103, 153, 108,   1,   1,  72, 140,  48,  82,   1, 125,  41,\n",
       "       134,  80,   1, 119,  77,  13,  57, 136,  67,   1,   1,  33, 140,\n",
       "         1, 159, 106, 147,   1,   1,   1, 158, 121,  75, 148,   1,  99,\n",
       "        22, 155,  40,   1,   9,   1,   1, 100, 133,  74, 125,  34, 145,\n",
       "       150,   2,  92, 123,   5,  31,   1,  91,  30,  88,   2,  45,  39,\n",
       "       110, 152, 143,  65,  16,   1,  36,   1, 172,   1,  64,   1, 175,\n",
       "         1, 173, 169,   1, 165,   1, 169, 170,   1,   1, 161,   1,  23,\n",
       "         1, 129, 136,  64, 176,   1,   1,  84, 177,   1, 172,  69,  13,\n",
       "       167,   1, 164, 175, 166, 122,  10,  47,  51, 163,  53, 157])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e0f79d4-336b-4d0b-88c3-39c7195b9fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3ad7ead-566b-4e6d-a882-61f849ff7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "# instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    verbosity=1,\n",
    "    tree_method='gpu_hist',\n",
    "    booster='gbtree', # not bothering with dart for time reasons\n",
    "    random_state=SEED,\n",
    "    **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e3000f1-35e5-4bf7-8cac-ce351fc498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4e3eb45-bc64-4375-a533-dba7760033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "080b7113-4389-484b-85b0-1206d99861d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_filtered), type(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b68e1908-a301-4939-8b01-3635133e5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:14:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_filtered, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ec43ce0-12e4-44c3-86a4-1b1125250a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8553163413048461\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) # was 0.7783978025549229 for pca_poly; 0.8572984856383443 for vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a56c16-13f3-4e44-b6b4-fe32d587ee73",
   "metadata": {},
   "source": [
    "So, it gets 0.8553163413048461, vs 0.8572984856383443 for the same model on the vanilla training set. Not bad.\n",
    "\n",
    "Let's try a more conservative take -- the green zone *plus* the blue zone (i.e. the take-it-or-leave-it features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1419c9e3-d0b9-40e2-b53c-de93779e1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3878f19-14e3-4b91-9fb5-78662b01e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_blue_green = np.concatenate((X_filtered, np.array(X[blue_zone])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55114317-dd1e-4521-806c-0e63edfa4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 109)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boruta_blue_green.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5efbff7b-7bca-4d3d-83be-ca2465a9e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8558487581638441\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_boruta_blue_green, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754fe12-1939-4128-9825-78fb3f54f10a",
   "metadata": {},
   "source": [
    "So that gets 0.8558487581638441 -- a bit better than the green-zone only. Now, let's try adding polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6adeaa-0713-40df-9a32-c7abec077807",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_boruta_blue_green_poly = poly.fit_transform(X_boruta_blue_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46b765-584f-4b28-a80d-d76639da9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_boruta_blue_green, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/X_boruta_200iter_green+blue_109features.joblib')\n",
    "del X_boruta_blue_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37893d85-c063-4425-9665-cb5b969c62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da6f7-7573-4aae-b7c8-f90696304bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c16bd622-ec4b-4744-b552-2ec6b869d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_pca_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f10abfc-2f98-4814-ac42-98fab0eab6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b81d1498-77b6-4a04-bc77-db6e40a705ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd3d5544-df0e-4af5-9096-3e3e821dcaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8572984856383443\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "    \n",
    "#     pca_components = trial.suggest_int('pca_components', 50, 285)\n",
    "    pca = PCA(n_components=pca_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "    \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 900, 6000), # was 900-4500 for CPU\n",
    "#         'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "#         'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 30),\n",
    "#         'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "# #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "#         'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 10),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "#         'gamma': trial.suggest_uniform('gamma', 0.1, 30)\n",
    "#     }  \n",
    "\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    "    )    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "              })\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_xgboost_20211010.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/2b286ehp\" target=\"_blank\">sweep_xgboost_20211010_115658</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-10 11:57:06,723]\u001b[0m A new study created in memory with name: pca_20211010\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"pca_{datetime.now().strftime('%Y%m%d')}\")\n",
    "\n",
    "# study = load(studypath/f\"optuna_xgboost_study_106trials_20211004.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02e3b84-ee16-48b9-94db-c738b408a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a454cc8-f135-4d36-8b6c-a964f4b52288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3860cbd2-1d08-4b2e-ac53-92b8a2ce016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Error thrown by xgboost trainer.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.core.XGBoostError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8ad6db-2722-4f04-bd51-4b795bec93c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ed3ac943a45fa8dc339194d2cab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:57:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 1; dropping {'pca_components': 138, 'value': 0.8283967087232865}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8283967087232865\n",
      "\u001b[32m[I 2021-10-10 11:59:12,446]\u001b[0m Trial 0 finished with value: 0.8283967087232865 and parameters: {'pca_components': 138}. Best is trial 0 with value: 0.8283967087232865.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c995da28a1d44a78001aca7668f1bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 2; dropping {'pca_components': 274, 'value': 0.8472107426301871}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472107426301871\n",
      "\u001b[32m[I 2021-10-10 12:02:45,979]\u001b[0m Trial 1 finished with value: 0.8472107426301871 and parameters: {'pca_components': 274}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fccb3fa1d664c2c9182df86e0916f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 3; dropping {'pca_components': 222, 'value': 0.8411313966895685}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8411313966895685\n",
      "\u001b[32m[I 2021-10-10 12:06:07,082]\u001b[0m Trial 2 finished with value: 0.8411313966895685 and parameters: {'pca_components': 222}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa85acfc834a6eb8f4993b66a345d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 4; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:09:03,422]\u001b[0m Trial 3 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeb5cbc6d8f498aaeafbcbd5baf86c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 5; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:10:25,360]\u001b[0m Trial 4 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ed1965573401a893b3bcf5d741830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 6; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:11:46,686]\u001b[0m Trial 5 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5122220c3f24f86abb9c62111e5b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 7; dropping {'pca_components': 63, 'value': 0.7904181686815366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.7904181686815366\n",
      "\u001b[32m[I 2021-10-10 12:12:47,694]\u001b[0m Trial 6 finished with value: 0.7904181686815366 and parameters: {'pca_components': 63}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add254087a4548f8943e78283019acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 8; dropping {'pca_components': 254, 'value': 0.8452885185751505}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8452885185751505\n",
      "\u001b[32m[I 2021-10-10 12:15:43,607]\u001b[0m Trial 7 finished with value: 0.8452885185751505 and parameters: {'pca_components': 254}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa23627f1d4045d888d13dfda8f652fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 9; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:18:38,689]\u001b[0m Trial 8 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5422d08b044f46318acef3ee9a059d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 10; dropping {'pca_components': 217, 'value': 0.8409412517853502}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8409412517853502\n",
      "\u001b[32m[I 2021-10-10 12:21:58,921]\u001b[0m Trial 9 finished with value: 0.8409412517853502 and parameters: {'pca_components': 217}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5828e8c8e4c4e88ada0bcfd0a1e657c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 11; dropping {'pca_components': 281, 'value': 0.8474176983005992}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474176983005992\n",
      "\u001b[32m[I 2021-10-10 12:25:32,672]\u001b[0m Trial 10 finished with value: 0.8474176983005992 and parameters: {'pca_components': 281}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d792ab5b54f7e94cac11539cb2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 12; dropping {'pca_components': 270, 'value': 0.8462401528718595}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8462401528718595\n",
      "\u001b[32m[I 2021-10-10 12:29:05,642]\u001b[0m Trial 11 finished with value: 0.8462401528718595 and parameters: {'pca_components': 270}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ede0e145554dab8b24e39e112f384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 13; dropping {'pca_components': 278, 'value': 0.8472224222376469}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472224222376469\n",
      "\u001b[32m[I 2021-10-10 12:32:39,229]\u001b[0m Trial 12 finished with value: 0.8472224222376469 and parameters: {'pca_components': 278}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c03a5fab942cc8bc82dedea9ea5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 14; dropping {'pca_components': 239, 'value': 0.8446363408619656}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8446363408619656\n",
      "\u001b[32m[I 2021-10-10 12:35:35,341]\u001b[0m Trial 13 finished with value: 0.8446363408619656 and parameters: {'pca_components': 239}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8986b171a6b14e7db312199a0ada6e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 15; dropping {'pca_components': 283, 'value': 0.8474194357944366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474194357944366\n",
      "\u001b[32m[I 2021-10-10 12:39:09,826]\u001b[0m Trial 14 finished with value: 0.8474194357944366 and parameters: {'pca_components': 283}. Best is trial 14 with value: 0.8474194357944366.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5e682ca174a228a244baa13a8c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31be9a9972d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e2748e41b07>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpca_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca_components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m285\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     dump(pca60, edapath/'PCA_60.joblibg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# sign flipping is done inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             U, S, Vt = randomized_svd(X, n_components=n_components,\n\u001b[0m\u001b[1;32m    549\u001b[0m                                       \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                       \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     Q = randomized_range_finder(\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Sample the range of A using by linear projection of Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Extract an orthonormal basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'economic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    162\u001b[0m                       lwork=lwork, overwrite_a=1)\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'economic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         Q, = safecall(gor_un_gqr, \"gorgqr/gungqr\", qr, tau, lwork=lwork,\n\u001b[0m\u001b[1;32m    165\u001b[0m                       overwrite_a=1)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36msafecall\u001b[0;34m(f, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lwork'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ValueError(\"illegal value in %dth argument of internal %s\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(1,200):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=True, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=datapath/f\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d6fb3-b4b3-40bd-8ff9-e2919c234f7d",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "# dump(study, filename=datapath/f\"optuna_xgboost_100trials-complete_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# dump(study.best_trial.params, filename=datapath/f\"optuna_lightgbm_all-500trials-best_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e398cb-f0f4-4400-8fe7-9012b4bc33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
