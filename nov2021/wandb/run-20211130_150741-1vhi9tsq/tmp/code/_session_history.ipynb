{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069e3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82716f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ccb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"deeptrainer_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e97e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "# from BorutaShap import BorutaShap\n",
    "from gauss_rank_scaler import GaussRankScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209ea338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SAINT import TabAttention # from the official SAINT implementation as of 20211118, https://github.com/somepago/saint/blob/main/models/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13f7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3b969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba57eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944ecaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd05c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmodel_config = {'arch': 'widedeep-saint',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2225a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_corrected.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "    'scaler': str(GaussRankScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "X = pd.read_feather(dataset_params['train_source'])# load(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "X_test = pd.read_feather(dataset_params['test_source']) #load(dataset_params['test_source'])\n",
    "\n",
    "# dataset_params['feature_count'] = X.shape[1]\n",
    "# dataset_params['instance_count'] = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743e75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease memory footprint\n",
    "X = reduce_memory_usage(X)\n",
    "X_test = reduce_memory_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a81b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695c7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_params = {\n",
    "    'binning': \"pd.qcut(X.iloc[:,i],X.shape[1],labels=False,duplicates = 'drop')\",\n",
    "    'scaling, normalization': str(GaussRankScaler(epsilon=0.005)),\n",
    "    # 'reduction': str(PCA(n_components='mle', random_state=42)),\n",
    "    'reduction': None,\n",
    "    'manifold': None,\n",
    "    # 'manifold': str(umap.UMAP(n_components=10, n_neighbors=15, random_state=42, transform_seed=42,)),\n",
    "    'clustering': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9ab8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h/t Laurent Pourchot https://www.kaggle.com/pourchot/in-python-tabular-denoising-residual-network/\n",
    "if preprocessing_params['binning']:\n",
    "    # 100 bins for the bins head of the NN (i.e. percentiles):\n",
    "    X_bins = np.zeros((X.shape[0],X.shape[1])) # he used all available data for the first tuple entry, but I'll start like this\n",
    "    X_bins_test = np.zeros((X_test.shape[0], X_test.shape[1]))\n",
    "    for i in range(X.shape[1]): # assumes X is a pd.DataFrame\n",
    "        X_bins[:,i] = pd.qcut(X.iloc[:,i],X.shape[1],labels=False,duplicates = 'drop')\n",
    "        X_bins_test[:,i] = pd.qcut(X_test.iloc[:,i],X.shape[1],labels=False,duplicates = 'drop')\n",
    "    X_bins = X_bins.astype(np.int8)\n",
    "    X_bins_test = X_bins_test.astype(np.int8)\n",
    "    X_bins = pd.DataFrame(X_bins, index=X.index, columns=[f'rkd_f{col}' for col in range(100)])\n",
    "    X_bins_test = pd.DataFrame(X_bins_test, index=X_test.index, columns=[f'rkd_f{col}' for col in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c51ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocessing_params['scaling, normalization']:\n",
    "    scaler = GaussRankScaler(epsilon=0.005)\n",
    "    X_gauss = scaler.fit_transform(X)\n",
    "    X_gauss_test = scaler.transform(X_test)\n",
    "    X_gauss = pd.DataFrame(X_gauss, columns=X.columns, index=X.index)\n",
    "    X_gauss_test = pd.DataFrame(X_gauss_test, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "571f8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if preprocessing_params['reduction']:\n",
    "#     from sklearn.decomposition import PCA\n",
    "#     pca = PCA(n_components='mle', random_state=42)\n",
    "#     X_pca = pca.fit_transform(X_gauss)\n",
    "#     # X_pca = pca.fit_transform(X)\n",
    "#     X_pca = pd.DataFrame(X_pca, index=X.index)\n",
    "#     import umap\n",
    "#     reducer = umap.UMAP(n_components=10, # low end of typical for feature reduction\n",
    "#                     n_neighbors=15, # default value\n",
    "#                     random_state=42,\n",
    "#                     transform_seed=42,\n",
    "#                    )\n",
    "#     umapper = reducer.fit(X_pca)\n",
    "#     embedding = reducer.transform(X_pca)\n",
    "#     embedding_df = pd.DataFrame(embedding,columns=[f'embed_{col}' for col in range(10)])\n",
    "#     X_gauss = X_gauss.join(embedding_df)\n",
    "#     # X = X.join(embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f1bb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = X_gauss.join(X_bins)\n",
    "X_pre_test = X_gauss_test.join(X_bins_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5348f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb4d06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkd_f0     100\n",
      "rkd_f1     100\n",
      "rkd_f2     100\n",
      "rkd_f3     100\n",
      "rkd_f4     100\n",
      "rkd_f5     100\n",
      "rkd_f6     100\n",
      "rkd_f7     100\n",
      "rkd_f8     100\n",
      "rkd_f9     100\n",
      "rkd_f10    100\n",
      "rkd_f11    100\n",
      "rkd_f12    100\n",
      "rkd_f13    100\n",
      "rkd_f14    100\n",
      "rkd_f15    100\n",
      "rkd_f16    100\n",
      "rkd_f17    100\n",
      "rkd_f18    100\n",
      "rkd_f19    100\n",
      "rkd_f20    100\n",
      "rkd_f21    100\n",
      "rkd_f22    100\n",
      "rkd_f23    100\n",
      "rkd_f24    100\n",
      "rkd_f25    100\n",
      "rkd_f26    100\n",
      "rkd_f27    100\n",
      "rkd_f28    100\n",
      "rkd_f29    100\n",
      "rkd_f30    100\n",
      "rkd_f31    100\n",
      "rkd_f32    100\n",
      "rkd_f33    100\n",
      "rkd_f34    100\n",
      "rkd_f35    100\n",
      "rkd_f36    100\n",
      "rkd_f37    100\n",
      "rkd_f38    100\n",
      "rkd_f39    100\n",
      "rkd_f40    100\n",
      "rkd_f41    100\n",
      "rkd_f42    100\n",
      "rkd_f43    100\n",
      "rkd_f44    100\n",
      "rkd_f45    100\n",
      "rkd_f46    100\n",
      "rkd_f47    100\n",
      "rkd_f48    100\n",
      "rkd_f49    100\n",
      "rkd_f50    100\n",
      "rkd_f51    100\n",
      "rkd_f52    100\n",
      "rkd_f53    100\n",
      "rkd_f54    100\n",
      "rkd_f55    100\n",
      "rkd_f56    100\n",
      "rkd_f57    100\n",
      "rkd_f58    100\n",
      "rkd_f59    100\n",
      "rkd_f60    100\n",
      "rkd_f61    100\n",
      "rkd_f62    100\n",
      "rkd_f63    100\n",
      "rkd_f64    100\n",
      "rkd_f65    100\n",
      "rkd_f66    100\n",
      "rkd_f67    100\n",
      "rkd_f68    100\n",
      "rkd_f69    100\n",
      "rkd_f70    100\n",
      "rkd_f71    100\n",
      "rkd_f72    100\n",
      "rkd_f73    100\n",
      "rkd_f74    100\n",
      "rkd_f75    100\n",
      "rkd_f76    100\n",
      "rkd_f77    100\n",
      "rkd_f78    100\n",
      "rkd_f79    100\n",
      "rkd_f80    100\n",
      "rkd_f81    100\n",
      "rkd_f82    100\n",
      "rkd_f83    100\n",
      "rkd_f84    100\n",
      "rkd_f85    100\n",
      "rkd_f86    100\n",
      "rkd_f87    100\n",
      "rkd_f88    100\n",
      "rkd_f89    100\n",
      "rkd_f90    100\n",
      "rkd_f91    100\n",
      "rkd_f92    100\n",
      "rkd_f93    100\n",
      "rkd_f94    100\n",
      "rkd_f95    100\n",
      "rkd_f96    100\n",
      "rkd_f97    100\n",
      "rkd_f98    100\n",
      "rkd_f99    100\n",
      "dtype: int64"
     ]
    }
   ],
   "source": [
    "X_pre.iloc[:, 100:].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fbf2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkd_f0     100\n",
      "rkd_f1     100\n",
      "rkd_f2     100\n",
      "rkd_f3     100\n",
      "rkd_f4     100\n",
      "rkd_f5     100\n",
      "rkd_f6     100\n",
      "rkd_f7     100\n",
      "rkd_f8     100\n",
      "rkd_f9     100\n",
      "rkd_f10    100\n",
      "rkd_f11    100\n",
      "rkd_f12    100\n",
      "rkd_f13    100\n",
      "rkd_f14    100\n",
      "rkd_f15    100\n",
      "rkd_f16    100\n",
      "rkd_f17    100\n",
      "rkd_f18    100\n",
      "rkd_f19    100\n",
      "rkd_f20    100\n",
      "rkd_f21    100\n",
      "rkd_f22    100\n",
      "rkd_f23    100\n",
      "rkd_f24    100\n",
      "rkd_f25    100\n",
      "rkd_f26    100\n",
      "rkd_f27    100\n",
      "rkd_f28    100\n",
      "rkd_f29    100\n",
      "rkd_f30    100\n",
      "rkd_f31    100\n",
      "rkd_f32    100\n",
      "rkd_f33    100\n",
      "rkd_f34    100\n",
      "rkd_f35    100\n",
      "rkd_f36    100\n",
      "rkd_f37    100\n",
      "rkd_f38    100\n",
      "rkd_f39    100\n",
      "rkd_f40    100\n",
      "rkd_f41    100\n",
      "rkd_f42    100\n",
      "rkd_f43    100\n",
      "rkd_f44    100\n",
      "rkd_f45    100\n",
      "rkd_f46    100\n",
      "rkd_f47    100\n",
      "rkd_f48    100\n",
      "rkd_f49    100\n",
      "rkd_f50    100\n",
      "rkd_f51    100\n",
      "rkd_f52    100\n",
      "rkd_f53    100\n",
      "rkd_f54    100\n",
      "rkd_f55    100\n",
      "rkd_f56    100\n",
      "rkd_f57    100\n",
      "rkd_f58    100\n",
      "rkd_f59    100\n",
      "rkd_f60    100\n",
      "rkd_f61    100\n",
      "rkd_f62    100\n",
      "rkd_f63    100\n",
      "rkd_f64    100\n",
      "rkd_f65    100\n",
      "rkd_f66    100\n",
      "rkd_f67    100\n",
      "rkd_f68    100\n",
      "rkd_f69    100\n",
      "rkd_f70    100\n",
      "rkd_f71    100\n",
      "rkd_f72    100\n",
      "rkd_f73    100\n",
      "rkd_f74    100\n",
      "rkd_f75    100\n",
      "rkd_f76    100\n",
      "rkd_f77    100\n",
      "rkd_f78    100\n",
      "rkd_f79    100\n",
      "rkd_f80    100\n",
      "rkd_f81    100\n",
      "rkd_f82    100\n",
      "rkd_f83    100\n",
      "rkd_f84    100\n",
      "rkd_f85    100\n",
      "rkd_f86    100\n",
      "rkd_f87    100\n",
      "rkd_f88    100\n",
      "rkd_f89    100\n",
      "rkd_f90    100\n",
      "rkd_f91    100\n",
      "rkd_f92    100\n",
      "rkd_f93    100\n",
      "rkd_f94    100\n",
      "rkd_f95    100\n",
      "rkd_f96    100\n",
      "rkd_f97    100\n",
      "rkd_f98    100\n",
      "rkd_f99    100\n",
      "dtype: int64"
     ]
    }
   ],
   "source": [
    "X_pre_test.iloc[:, 100:].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87737076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pre = pd.read_feather(datapath/'X_bins+GaussRankScaled+PCA,UMAP.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8d2666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pre_cont = X_pre.iloc[:, :110].join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c2a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corr = X_pre_cont.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5169b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params['feature_count'] = X_pre.shape[1]\n",
    "dataset_params['instance_count'] = X_pre.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4031f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'widedeep' in exmodel_config['arch']:\n",
    "    cont_cols = X_pre.iloc[:,:100].columns # 110 if using PCA-UMAP embedding\n",
    "    wide_cols = X_pre.iloc[:, 100:].columns # 110 if using PCA-UMAP embedding\n",
    "    # # if not preprocessing\n",
    "    # X_wide = X_pre[wide_cols]\n",
    "    # X_tab = X_pre[cont_cols]\n",
    "    \n",
    "    # if preprocessing\n",
    "    wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "    X_wide = wide_preprocessor.fit_transform(X_pre)\n",
    "    X_wide_test = wide_preprocessor.transform(X_pre_test)\n",
    "    # tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols, scale=False, for_transformer=False,embed_cols=wide_cols) # for TabMLP\n",
    "    tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols, scale=False, for_transformer=True,embed_cols=wide_cols) # for SAINT\n",
    "    X_tab = tab_preprocessor.fit_transform(X_pre)\n",
    "    X_tab_test = tab_preprocessor.transform(X_pre_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09c9f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep_preprocessing_params = {\n",
    "        'wide': str(wide_preprocessor),\n",
    "        'deeptabular': str(tab_preprocessor),\n",
    "    }\n",
    "    \n",
    "preprocessing_params.update(widedeep_preprocessing_params)\n",
    "# print(preprocessing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62c61b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/datasets/X_tab_test_FIXED.joblib']"
     ]
    }
   ],
   "source": [
    "dump(X_wide_test, datapath/'X_wide_test_FIXED.joblib')\n",
    "dump(X_tab_test, datapath/'X_tab_test_FIXED.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6f80a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_wide = load(datapath/'X_wide.joblib')\n",
    "# X_tab = load(datapath/'X_tab.joblib')\n",
    "# X_wide_test = load(datapath/'X_wide_test.joblib')\n",
    "# X_tab_test = load(datapath/'X_tab_test.joblib')\n",
    "# dump(cont_cols, datapath/'cont_cols.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c22d5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config.update({\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold(n_splits=5, shuffle=True, random_state=SEED), # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    **dataset_params,\n",
    "    **preprocessing_params\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "882823f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['widedeep', 'deeplearning'],\n",
    "    'notes': \"Attempt using SAINT, default model params.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3449dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pre_np = np.array(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "931b6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeptabular = TabMlp(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx)\n",
    "# deeptabular = TabMlp(continuous_cols=list(range(110)), column_idx={str(x): x for x in range(len(cont_cols))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a5ec3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.ndarray"
     ]
    }
   ],
   "source": [
    "type(X_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bb673d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.ndarray"
     ]
    }
   ],
   "source": [
    "type(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a30d643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_widedeep(arch, X_wide=X_wide, X_tab=X_tab, y=y, X_wide_test=X_wide_test, X_tab_test=X_tab_test, folds=list(range(5)), \n",
    "                            prev_epochs=0, n_epochs=20, exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                            random_state=42, shuffle_kfolds=True, wandb_tracked=True):\n",
    "    \"\"\"\n",
    "    Modification of the `cross_validate_model` function used in my stacking notebooks, customized to the dataset and to deep learning approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    if shuffle_kfolds:\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)#exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = 'widedeep-saint'\n",
    "        # exmodel_config[f'model_params'] = str(model.parameters())\n",
    "        wandb.init(\n",
    "            project=\"202111_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "#     if start_fold == 4:\n",
    "#     # immediately extend to include predictions from the 0 fold, which had a code bug\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold0-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold1-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold2-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-55epochs-fold3-oofpreds.joblib'))\n",
    "        \n",
    "#         oof_y.extend(load(datapath/'y_valid-fold0.joblib'))\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold1-valid_ids.joblib')])\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold2-valid_ids.joblib')])\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold3-valid_ids.joblib')])\n",
    "        \n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold0-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold1-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold2-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-55epochs-fold3-testpreds.joblib')\n",
    "    \n",
    "    # print(f\"Before entering loop, oof_preds is length {len(oof_preds)}, oof_y is {len(oof_y)}, and test_preds is {test_preds.shape}\")\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        torch.cuda.empty_cache()\n",
    "#         print(f\"type(train_ids) = {type(train_ids)} and train_ids.shape = {train_ids.shape}\")\n",
    "#         print(f\"type(valid_ids) = {type(valid_ids)} and train_ids.shape = {valid_ids.shape}\")\n",
    "        if fold not in folds: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            dump(train_ids, datapath/f'kfold42-fold{fold}-train_ids.joblib')\n",
    "            dump(valid_ids, datapath/f'kfold42-fold{fold}-valid_ids.joblib')\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            print(f\"y_train shape is {y_train.shape}, y_valid shape is {y_valid.shape}\")\n",
    "            # dump(y_train, datapath/f'y_train-fold{fold}.joblib')\n",
    "            # dump(y_valid, datapath/f'y_valid-fold{fold}.joblib')\n",
    "            # if isinstance(X, np.ndarray):\n",
    "                # X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            X_train_wide, X_train_tab = X_wide[train_ids], X_tab[train_ids]\n",
    "            X_valid_wide, X_valid_tab = X_wide[valid_ids], X_tab[valid_ids]\n",
    "                \n",
    "                # X_train = pd.DataFrame(X_train, columns=\n",
    "            # else:\n",
    "            #     X_train_wide, X_train_tab = X_wide.iloc[train_ids,:], X_tab[train_ids,:]\n",
    "            #     X_valid_wide, X_valid_tab = X_wide[valid_ids,:], X_tab[valid_ids,:]\n",
    "            \n",
    "            # print(f\"X_train shape is {X_train.shape}\")\n",
    "            # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "            # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "            # scaling\n",
    "            # scaler = GaussRankScaler()\n",
    "            # X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "            # X_valid = pd.DataFrame(scaler.transform(X_valid), columns=X.columns)\n",
    "            # X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "            \n",
    "            # print(\"Scaling complete\")\n",
    "            # print(f\"X_train shape is {X_train.shape}\")\n",
    "            # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "            # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "            # embedding & library-specific preprocessing\n",
    "#             tab_preprocessor = TabPreprocessor(\n",
    "#                 scale=False, # because GaussRank scaling already occurred\n",
    "#                 # scale=True\n",
    "#                 for_transformer=False, # change if using a Transformer-based model\n",
    "#                 continuous_cols=X.columns,\n",
    "#                 # continuous_cols=range(X.shape[1]), # since it'll be working on a numpy.ndarray\n",
    "#                 auto_embed_dim=True, # uses fastai's rule of thumb\n",
    "#             )#, embed_cols=embed_cols, )\n",
    "#             X_train = tab_preprocessor.fit_transform(X_train)   \n",
    "#             X_valid = tab_preprocessor.transform(X_valid)\n",
    "#             X_test = tab_preprocessor.transform(X_test)\n",
    "            \n",
    "#             print(\"Tab preprocessing complete.\")\n",
    "#             print(f\"Type of X_train is {type(X_train)}\")\n",
    "#             # print(f\"X_train shape is {X_train.shape}\")\n",
    "#             # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "#             # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "#             # define model\n",
    "#             deeptabular = TabMlp(\n",
    "#                 mlp_hidden_dims=[64,32],\n",
    "#                 column_idx=tab_preprocessor.column_idx,\n",
    "#             #     embed_input=tab_preprocessor.embeddings_input,\n",
    "#                 # continuous_cols=range(X.shape[1]), # since it'll be working on a numpy.ndarray\n",
    "#                 continuous_cols=X.columns,\n",
    "#             )\n",
    "\n",
    "            if 'saint' in arch:\n",
    "                wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "                deeptabular = SAINT(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx,)\n",
    "                model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "                if prev_epochs > 0:\n",
    "                    model.load_state_dict(torch.load(datapath/f\"{arch}-20211127-weights-{prev_epochs}epochs-fold{fold}/wd_model.pt\"))\n",
    "        \n",
    "                # n_epochs = 55\n",
    "\n",
    "                # model = WideDeep(wide=None, deeptabular=deeptabular)\n",
    "\n",
    "                # pytorch hyperparams\n",
    "                wide_opt = AdamW(model.wide.parameters(),)\n",
    "                deep_opt = SGD(model.deeptabular.parameters(),  lr=0.01, momentum=0.75)\n",
    "\n",
    "                wide_sch = CosineAnnealingWarmRestarts(optimizer=wide_opt, T_0=5) \n",
    "                deep_sch = ReduceLROnPlateau(optimizer=deep_opt, )\n",
    "\n",
    "                # deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "\n",
    "                # optimizers = {'deeptabular': deep_opt }\n",
    "                # lr_schedulers = {'deeptabular': deep_sch }\n",
    "\n",
    "                optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "                lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "                callbacks = [\n",
    "                    LRHistory(n_epochs=n_epochs), \n",
    "                ]\n",
    "\n",
    "                # trainer\n",
    "                trainer = Trainer(model=model, \n",
    "                                  objective='binary', \n",
    "                                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                                  seed=random_state, \n",
    "                                  optimizers=optimizers,\n",
    "                                  callbacks=callbacks\n",
    "                                 )\n",
    "                \n",
    "            else:\n",
    "                wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "                deeptabular = TabMlp(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx)\n",
    "                model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "                \n",
    "                wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "                deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "\n",
    "                wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_wide_train.shape[0], epochs=n_epochs)\n",
    "                deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_tab_train.shape[0], epochs=n_epochs)\n",
    "\n",
    "                optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "                lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "\n",
    "                callbacks = [\n",
    "                    LRHistory(n_epochs=n_epochs), \n",
    "                ]\n",
    "\n",
    "                # trainer\n",
    "                trainer = Trainer(model=model, \n",
    "                                  objective='binary', \n",
    "                                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                                  seed=42, \n",
    "                                  optimizers=optimizers,\n",
    "                                  callbacks=callbacks\n",
    "                                 )\n",
    "    #             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "            trainer.fit( \n",
    "                X_wide=X_train_wide,\n",
    "                X_tab=X_train_tab,# np.array(X_train),\n",
    "                target=np.array(y_train),\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=1048, # default value is 32\n",
    "    #                 val_split=0.2, # no need for this\n",
    "            )\n",
    "        \n",
    "            trainer.save(path=datapath/f'{arch}-20211127-weights-{prev_epochs + n_epochs}epochs-fold{fold}', save_state_dict=True)\n",
    "\n",
    "            y_valid_preds = trainer.predict_proba(X_wide=np.array(X_valid_wide), X_tab=np.array(X_valid_tab), batch_size=1048)[:,1]\n",
    "            dump(y_valid_preds, predpath/f'{arch}-20211127-{prev_epochs + n_epochs}epochs-fold{fold}-oofpreds.joblib')\n",
    "\n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "\n",
    "\n",
    "            # test set inference\n",
    "            fold_test_preds = trainer.predict_proba(X_wide=np.array(X_wide_test), X_tab=np.array(X_tab_test), batch_size=1048)[:,1]\n",
    "            dump(fold_test_preds, predpath/f'{arch}-20211127-{prev_epochs + n_epochs}epochs-fold{fold}-testpreds.joblib')\n",
    "            test_preds += fold_test_preds\n",
    "            \n",
    "            # print(f\"NaNs in y_valid_preds: {np.isnan(y_valid_preds).any()}\")\n",
    "            # print(f\"NaNs in y_valid: {np.isnan(y_valid).any()}\")\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "    #         valid_loss = log_loss(y_valid, y_pred)\n",
    "            # give the valid AUC score, for edification\n",
    "            fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "            if wandb_tracked:\n",
    "                wandb.log({f'fold{fold}_valid_roc_auc': fold_valid_auc})\n",
    "            print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    if len(folds) == 5:\n",
    "        model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "        print(f\"Valid AUC score for {arch} model is {model_valid_auc}\")\n",
    "        if wandb_tracked:\n",
    "            wandb.log({'overall_valid_auc': model_valid_auc,\n",
    "                       'model_params': str(model.parameters()), #if 'widedeep' in arch else str(model.get_params()),\n",
    "                       'model_seed': random_state,\n",
    "                      })\n",
    "            wandb.finish()\n",
    "        # finalize test preds\n",
    "        test_preds /= exmodel_config['kfolds']\n",
    "        \n",
    "    else:\n",
    "        if wandb_tracked:\n",
    "                wandb.log({#'overall_valid_auc': model_valid_auc,\n",
    "                           'model_params': str(model.parameters()), #if 'widedeep' in arch else str(model.get_params()),\n",
    "                           'model_seed': random_state,\n",
    "                          })\n",
    "                wandb.finish()\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "        dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d134cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(y_valid, datapath/'y_valid-fold0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de101c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(X_wide, datapath/'X_wide.joblib')\n",
    "# dump(X_tab, datapath/'X_tab.joblib')\n",
    "# dump(X_wide_test, datapath/'X_wide_test.joblib')\n",
    "# dump(X_tab_test, datapath/'X_tab_test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e673de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_gauss, X_bins, X_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2578a947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1vhi9tsq\" target=\"_blank\">deeptrainer_20211130_150740</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_preds, test_preds = cross_validate_widedeep('widedeep-tabmlp', prev_epochs=0, n_epochs=50)\n",
    "# oof_preds, test_preds = cross_validate_widedeep('widedeep-saint', )\n",
    "# dump(oof_preds, predpath/f'widedeep_saint-20211127-{n_epochs}epochs-mean-oofpreds.joblib')\n",
    "# dump(test_preds, predpath/f'widedeep_saint-20211127-{n_epochs}epochs-mean-testpreds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ecc8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_widedeep(arch, X_wide=X_wide, X_tab=X_tab, y=y, X_wide_test=X_wide_test, X_tab_test=X_tab_test, folds=list(range(5)), \n",
    "                            prev_epochs=0, n_epochs=20, exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                            random_state=42, shuffle_kfolds=True, wandb_tracked=True):\n",
    "    \"\"\"\n",
    "    Modification of the `cross_validate_model` function used in my stacking notebooks, customized to the dataset and to deep learning approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    if shuffle_kfolds:\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)#exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = 'widedeep-saint'\n",
    "        # exmodel_config[f'model_params'] = str(model.parameters())\n",
    "        wandb.init(\n",
    "            project=\"202111_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "#     if start_fold == 4:\n",
    "#     # immediately extend to include predictions from the 0 fold, which had a code bug\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold0-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold1-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-50epochs-fold2-oofpreds.joblib'))\n",
    "#         oof_preds.extend(load(predpath/'widedeep_saint-20211127-55epochs-fold3-oofpreds.joblib'))\n",
    "        \n",
    "#         oof_y.extend(load(datapath/'y_valid-fold0.joblib'))\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold1-valid_ids.joblib')])\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold2-valid_ids.joblib')])\n",
    "#         oof_y.extend(y[load(datapath/'kfold42-fold3-valid_ids.joblib')])\n",
    "        \n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold0-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold1-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-50epochs-fold2-testpreds.joblib')\n",
    "#         test_preds += load(predpath/'widedeep_saint-20211127-55epochs-fold3-testpreds.joblib')\n",
    "    \n",
    "    # print(f\"Before entering loop, oof_preds is length {len(oof_preds)}, oof_y is {len(oof_y)}, and test_preds is {test_preds.shape}\")\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        torch.cuda.empty_cache()\n",
    "#         print(f\"type(train_ids) = {type(train_ids)} and train_ids.shape = {train_ids.shape}\")\n",
    "#         print(f\"type(valid_ids) = {type(valid_ids)} and train_ids.shape = {valid_ids.shape}\")\n",
    "        if fold not in folds: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            dump(train_ids, datapath/f'kfold42-fold{fold}-train_ids.joblib')\n",
    "            dump(valid_ids, datapath/f'kfold42-fold{fold}-valid_ids.joblib')\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            print(f\"y_train shape is {y_train.shape}, y_valid shape is {y_valid.shape}\")\n",
    "            # dump(y_train, datapath/f'y_train-fold{fold}.joblib')\n",
    "            # dump(y_valid, datapath/f'y_valid-fold{fold}.joblib')\n",
    "            # if isinstance(X, np.ndarray):\n",
    "                # X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            X_train_wide, X_train_tab = X_wide[train_ids], X_tab[train_ids]\n",
    "            X_valid_wide, X_valid_tab = X_wide[valid_ids], X_tab[valid_ids]\n",
    "                \n",
    "                # X_train = pd.DataFrame(X_train, columns=\n",
    "            # else:\n",
    "            #     X_train_wide, X_train_tab = X_wide.iloc[train_ids,:], X_tab[train_ids,:]\n",
    "            #     X_valid_wide, X_valid_tab = X_wide[valid_ids,:], X_tab[valid_ids,:]\n",
    "            \n",
    "            # print(f\"X_train shape is {X_train.shape}\")\n",
    "            # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "            # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "            # scaling\n",
    "            # scaler = GaussRankScaler()\n",
    "            # X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "            # X_valid = pd.DataFrame(scaler.transform(X_valid), columns=X.columns)\n",
    "            # X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "            \n",
    "            # print(\"Scaling complete\")\n",
    "            # print(f\"X_train shape is {X_train.shape}\")\n",
    "            # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "            # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "            # embedding & library-specific preprocessing\n",
    "#             tab_preprocessor = TabPreprocessor(\n",
    "#                 scale=False, # because GaussRank scaling already occurred\n",
    "#                 # scale=True\n",
    "#                 for_transformer=False, # change if using a Transformer-based model\n",
    "#                 continuous_cols=X.columns,\n",
    "#                 # continuous_cols=range(X.shape[1]), # since it'll be working on a numpy.ndarray\n",
    "#                 auto_embed_dim=True, # uses fastai's rule of thumb\n",
    "#             )#, embed_cols=embed_cols, )\n",
    "#             X_train = tab_preprocessor.fit_transform(X_train)   \n",
    "#             X_valid = tab_preprocessor.transform(X_valid)\n",
    "#             X_test = tab_preprocessor.transform(X_test)\n",
    "            \n",
    "#             print(\"Tab preprocessing complete.\")\n",
    "#             print(f\"Type of X_train is {type(X_train)}\")\n",
    "#             # print(f\"X_train shape is {X_train.shape}\")\n",
    "#             # print(f\"X_valid shape is {X_valid.shape}\")\n",
    "#             # print(f\"X_test shape is {X_test.shape}\")\n",
    "            \n",
    "#             # define model\n",
    "#             deeptabular = TabMlp(\n",
    "#                 mlp_hidden_dims=[64,32],\n",
    "#                 column_idx=tab_preprocessor.column_idx,\n",
    "#             #     embed_input=tab_preprocessor.embeddings_input,\n",
    "#                 # continuous_cols=range(X.shape[1]), # since it'll be working on a numpy.ndarray\n",
    "#                 continuous_cols=X.columns,\n",
    "#             )\n",
    "\n",
    "            if 'saint' in arch:\n",
    "                wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "                deeptabular = SAINT(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx,)\n",
    "                model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "                if prev_epochs > 0:\n",
    "                    model.load_state_dict(torch.load(datapath/f\"{arch}-20211127-weights-{prev_epochs}epochs-fold{fold}/wd_model.pt\"))\n",
    "        \n",
    "                # n_epochs = 55\n",
    "\n",
    "                # model = WideDeep(wide=None, deeptabular=deeptabular)\n",
    "\n",
    "                # pytorch hyperparams\n",
    "                wide_opt = AdamW(model.wide.parameters(),)\n",
    "                deep_opt = SGD(model.deeptabular.parameters(),  lr=0.01, momentum=0.75)\n",
    "\n",
    "                wide_sch = CosineAnnealingWarmRestarts(optimizer=wide_opt, T_0=5) \n",
    "                deep_sch = ReduceLROnPlateau(optimizer=deep_opt, )\n",
    "\n",
    "                # deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "\n",
    "                # optimizers = {'deeptabular': deep_opt }\n",
    "                # lr_schedulers = {'deeptabular': deep_sch }\n",
    "\n",
    "                optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "                lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "                callbacks = [\n",
    "                    LRHistory(n_epochs=n_epochs), \n",
    "                ]\n",
    "\n",
    "                # trainer\n",
    "                trainer = Trainer(model=model, \n",
    "                                  objective='binary', \n",
    "                                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                                  seed=random_state, \n",
    "                                  optimizers=optimizers,\n",
    "                                  callbacks=callbacks\n",
    "                                 )\n",
    "                \n",
    "            else:\n",
    "                wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "                deeptabular = TabMlp(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx)\n",
    "                model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "                \n",
    "                wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "                deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "\n",
    "                wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_train_wide.shape[0], epochs=n_epochs)\n",
    "                deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "\n",
    "                optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "                lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "\n",
    "                callbacks = [\n",
    "                    LRHistory(n_epochs=n_epochs), \n",
    "                ]\n",
    "\n",
    "                # trainer\n",
    "                trainer = Trainer(model=model, \n",
    "                                  objective='binary', \n",
    "                                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                                  seed=42, \n",
    "                                  optimizers=optimizers,\n",
    "                                  callbacks=callbacks\n",
    "                                 )\n",
    "    #             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "            trainer.fit( \n",
    "                X_wide=X_train_wide,\n",
    "                X_tab=X_train_tab,# np.array(X_train),\n",
    "                target=np.array(y_train),\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=1048, # default value is 32\n",
    "    #                 val_split=0.2, # no need for this\n",
    "            )\n",
    "        \n",
    "            trainer.save(path=datapath/f'{arch}-20211127-weights-{prev_epochs + n_epochs}epochs-fold{fold}', save_state_dict=True)\n",
    "\n",
    "            y_valid_preds = trainer.predict_proba(X_wide=np.array(X_valid_wide), X_tab=np.array(X_valid_tab), batch_size=1048)[:,1]\n",
    "            dump(y_valid_preds, predpath/f'{arch}-20211127-{prev_epochs + n_epochs}epochs-fold{fold}-oofpreds.joblib')\n",
    "\n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "\n",
    "\n",
    "            # test set inference\n",
    "            fold_test_preds = trainer.predict_proba(X_wide=np.array(X_wide_test), X_tab=np.array(X_tab_test), batch_size=1048)[:,1]\n",
    "            dump(fold_test_preds, predpath/f'{arch}-20211127-{prev_epochs + n_epochs}epochs-fold{fold}-testpreds.joblib')\n",
    "            test_preds += fold_test_preds\n",
    "            \n",
    "            # print(f\"NaNs in y_valid_preds: {np.isnan(y_valid_preds).any()}\")\n",
    "            # print(f\"NaNs in y_valid: {np.isnan(y_valid).any()}\")\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "    #         valid_loss = log_loss(y_valid, y_pred)\n",
    "            # give the valid AUC score, for edification\n",
    "            fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "            if wandb_tracked:\n",
    "                wandb.log({f'fold{fold}_valid_roc_auc': fold_valid_auc})\n",
    "            print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    if len(folds) == 5:\n",
    "        model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "        print(f\"Valid AUC score for {arch} model is {model_valid_auc}\")\n",
    "        if wandb_tracked:\n",
    "            wandb.log({'overall_valid_auc': model_valid_auc,\n",
    "                       'model_params': str(model.parameters()), #if 'widedeep' in arch else str(model.get_params()),\n",
    "                       'model_seed': random_state,\n",
    "                      })\n",
    "            wandb.finish()\n",
    "        # finalize test preds\n",
    "        test_preds /= exmodel_config['kfolds']\n",
    "        \n",
    "    else:\n",
    "        if wandb_tracked:\n",
    "                wandb.log({#'overall_valid_auc': model_valid_auc,\n",
    "                           'model_params': str(model.parameters()), #if 'widedeep' in arch else str(model.get_params()),\n",
    "                           'model_seed': random_state,\n",
    "                          })\n",
    "                wandb.finish()\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "        dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b5c2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds, test_preds = cross_validate_widedeep('widedeep-tabmlp', prev_epochs=0, n_epochs=50)\n",
    "# oof_preds, test_preds = cross_validate_widedeep('widedeep-saint', )\n",
    "# dump(oof_preds, predpath/f'widedeep_saint-20211127-{n_epochs}epochs-mean-oofpreds.joblib')\n",
    "# dump(test_preds, predpath/f'widedeep_saint-20211127-{n_epochs}epochs-mean-testpreds.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
