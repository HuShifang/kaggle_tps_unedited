{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"stacking_manual_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fee2dc-9908-499b-a6ba-c7cfeaa286fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc50eeb-5833-4421-af80-57f081b849b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n"
     ]
    }
   ],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad41f0c-4a5c-470a-bda3-98152c30bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912a62f-970a-48b4-b428-d886f2612fc2",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b8603b-68c3-40da-8406-53e143758905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db3e37d1-2082-41c6-8693-05c7829e2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = datapath/'test.feather'\n",
    "# # test_source = altdatapath/'test-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' # altdatapath/'X_test_boruta_shap_200trials.feather'\n",
    "exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "# # boruta = load(altdatapath/'boruta_shap.joblib')\n",
    "# # X_test_enc = \n",
    "# # X_test = X_test.iloc[:, 1:] # only if loading the original test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c63eedc-0e9a-4148-a1c1-2de263d85aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a431150a-fcb2-4bb3-a0f9-d35df9406c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = altdatapath/'X_orig.feather'\n",
    "# train_source = altdatapath/'train-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' #'X_boruta_shap_200trials.feather'\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "# X = pd.read_feather(path=train_source)\n",
    "# if 'target' in X.columns:\n",
    "#     X = X.drop(['target'], axis=1)\n",
    "# df.index.name = 'id'\n",
    "# y = np.array(df.target)\n",
    "y = load(datapath/'y.joblib')\n",
    "# features = [x for x in df.columns if x != 'target']\n",
    "# X = df[features] # passing X as a pd.DataFrame to the trainer below, rather than as an np.ndarray\n",
    "# X_train = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f215-b585-4f7b-afac-36e49ee28c8f",
   "metadata": {},
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a928e1-0a18-4c91-b9bb-a32846e39e5b",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['stacking'],\n",
    "    'notes': \"Trying to marginally improve performance by adding in more seeds for the models.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e9478-2380-4c4d-8641-5daa72049b6c",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc156663-c689-4dfe-a80b-5efaaae1afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 20211004, thru 106 trials on unaltered original dataset\n",
    "best_xgboost_params = {\n",
    "    'n_estimators': 3878,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.024785857161974977,\n",
    "    'reg_alpha': 26.867682044658245,\n",
    "    'reg_lambda': 10.839759074147148,\n",
    "    'subsample': 0.8208581489835881,\n",
    "    'min_child_weight': 8.829122644339664,\n",
    "    'colsample_bytree': 0.906420714280384,\n",
    "    'gamma': 1.472322916021486\n",
    "}\n",
    "\n",
    "# best as of 20211005, thru 65 trials on unaltered original dataset\n",
    "best_lightgbm_params = {\n",
    "    'n_estimators': 6631,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.004677044539666842,\n",
    "    'reg_alpha': 19.334971246299116,\n",
    "    'reg_lambda': 0.024384251140153856,\n",
    "    'subsample': 0.5082183652689569,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_child_samples': 9,\n",
    "    'num_leaves': 233,\n",
    "    'colsample_bytree': 0.5008014086989773\n",
    "}\n",
    "\n",
    "# catboost 20211001 on colab with 100 trials on GPU, unaltered original dataset\n",
    "best_catboost_params = {\n",
    "    'iterations': 29338,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.004769831650275205,\n",
    "    'random_strength': 7,\n",
    "    'od_wait': 1968,\n",
    "    'reg_lambda': 28.435563240493586,\n",
    "    'border_count': 162,\n",
    "    'min_child_samples': 14,\n",
    "    'leaf_estimation_iterations': 1\n",
    "}\n",
    "\n",
    "# 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "lv2_xgboost_params = {\n",
    "    'n_estimators': 1534,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.0062941159127744535,\n",
    "    'reg_alpha': 21.3946930650266,\n",
    "    'reg_lambda': 0.021003786013817635,\n",
    "    'subsample': 0.5726680367393964,\n",
    "    'min_child_weight': 0.07566661785187714,\n",
    "    'colsample_bytree': 0.7850419523745037,\n",
    "    'gamma': 4.26660233356059\n",
    "}\n",
    "\n",
    "# 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "lv2_lightgbm_params = {\n",
    "    'n_estimators': 5776,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.0010172282832994653,\n",
    "    'reg_alpha': 0.013879765609402173,\n",
    "    'reg_lambda': 0.002787031048344079,\n",
    "    'subsample': 0.800000753298926,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_child_samples': 11,\n",
    "    'num_leaves': 190,\n",
    "    'colsample_bytree': 0.9976443570341007\n",
    "}\n",
    "\n",
    "# 20211021 lv2 on the K-Means 8-cluster, synth dataset\n",
    "lv2_catboost_params = {\n",
    "    'iterations': 2000,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.002984126581340097,\n",
    "    'random_strength': 0,\n",
    "    'od_wait': 334,\n",
    "    'reg_lambda': 33.469738674488084,\n",
    "    'border_count': 158,\n",
    "    'min_child_samples': 8,\n",
    "    'leaf_estimation_iterations': 4\n",
    "}\n",
    "\n",
    "# initial, non-default guess -- need to get optuna working (20211010)\n",
    "# basic_widedeep_tabmlp_params = {\n",
    "    \n",
    "# }\n",
    "\n",
    "# basic_widedeep_trainer_params = {\n",
    "#     optimizers=AdamW()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aec7210-135f-402a-af31-330eb0f37276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.basic import LightGBMError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827289c5-e0e7-4382-9cbd-d6174a5cd68b",
   "metadata": {},
   "source": [
    "# Cross-Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X, y, X_test, params:dict={}, start_fold=0, \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "#     if exmodel_config['kfolds'] == 1:\n",
    "#         print(\"Proceeding with holdout\")\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=0.2, \n",
    "#                                                           random_state=SEED)                 \n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    if shuffle_kfolds:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202110_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # setup for serialization\n",
    "    runpath = Path(modelpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds/\")\n",
    "    (runpath).mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    # if using deep learning with pytorch-widedeep, do data preprocessing now, before splits\n",
    "    if 'widedeep' in arch:\n",
    "        # NOTE THAT ENCODING NOT DEPLOYED FOR THIS YET\n",
    "        # preprocessing first\n",
    "        wide_cols = [f for f in X.columns if X[f].nunique() == 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() == 2] # binary indicator vars are wide\n",
    "        cont_cols = [f for f in X.columns if X[f].nunique() > 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() > 2] # others are cont\n",
    "\n",
    "        # wide part\n",
    "        wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "        X_wide = wide_preprocessor.fit_transform(X)\n",
    "#         print(f\"X_wide.shape = {X_wide.shape}\")\n",
    "#         X_wide = np.array(X_train[wide_cols])\n",
    "        \n",
    "\n",
    "        # deep part\n",
    "        tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols)#, embed_cols=embed_cols, )\n",
    "        X_tab = tab_preprocessor.fit_transform(X)   \n",
    "#         print(f\"X_tab.shape = {X_tab.shape}\")\n",
    "        \n",
    "        # transforming the test set\n",
    "        X_test_wide = wide_preprocessor.transform(X_test)\n",
    "        X_test_tab = tab_preprocessor.transform(X_test)\n",
    "        \n",
    "        # at this point, X_wide, X_tab, X_test_wide, and X_test_tab will all be np.ndarrays\n",
    "    \n",
    "#     else: # if using a GBM, simply convert the pd.DataFrames to np.ndarrays\n",
    "#         X = np.array(X) # CAN YOU USE CATEGORY_ENCODERS ON NP.NDARRAYS?\n",
    "#         X_test = np.array(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#         print(f\"type(train_ids) = {type(train_ids)} and train_ids.shape = {train_ids.shape}\")\n",
    "#         print(f\"type(valid_ids) = {type(valid_ids)} and train_ids.shape = {valid_ids.shape}\")\n",
    "        if fold < start_fold: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if 'widedeep' in arch: # handle wide and deep tabs in parallel\n",
    "                X_train_wide, X_valid_wide = X_wide[train_ids, :], X_wide[valid_ids, :]\n",
    "                X_train_tab, X_valid_tab = X_tab[train_ids, :], X_tab[valid_ids, :]\n",
    "#                 print(f\"X_train_wide.shape = {X_train_wide.shape}\")\n",
    "#                 print(f\"X_train_tab.shape = {X_train_tab.shape}\")\n",
    "#                 print(f\"X_test_wide.shape = {X_test_wide.shape}\")\n",
    "#                 print(f\"X_test_tab.shape = {X_test_tab.shape}\")\n",
    "            else: # handle datasets for GBMs\n",
    "                if isinstance(X, np.ndarray):\n",
    "                    X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                else:\n",
    "                    X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                if encode_cats:\n",
    "                    encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                    encoder.fit(X_train,y_train)\n",
    "                    X_train = encoder.transform(X_train)\n",
    "                    X_valid = encoder.transform(X_valid)\n",
    "                # exmodel_config['feature_count'] = len(X.columns)\n",
    "                    wandb.log({\n",
    "                        'feature_count': X_train.shape[1],\n",
    "                        'instance_count': X_train.shape[0],\n",
    "                        'encoder': str(encoder)\n",
    "                    })\n",
    "#                 exmodel_config['instance_count'] = X_train.shape[0]\n",
    "#                 exmodel_config['encoder'] = str(encoder)\n",
    "#                     X_test = encoder.transform(X_test)\n",
    "#                 y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "            \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            try:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "                    device_type='gpu',\n",
    "                    max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "    #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            except LightGBMError:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "                    device_type='cpu',\n",
    "                    n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "    #                 device_type='gpu',\n",
    "    #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "    #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "        elif 'widedeep' in arch: # only coding for TabMlp right now\n",
    "#             X_train = pd.DataFrame(X_train, columns=[f\"f{x}\" for x in range(X_train.shape[1])])\n",
    "#             X_valid = pd.DataFrame(X_valid, columns=[f\"f{x}\" for x in range(X_valid.shape[1])])\n",
    "#             X_test = pd.DataFrame(X_test, columns=[f\"f{x}\" for x in range(X_test.shape[1])])\n",
    "            \n",
    "            wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "            deeptabular = TabMlp(\n",
    "                mlp_hidden_dims=[64,32],\n",
    "                column_idx=tab_preprocessor.column_idx,\n",
    "            #     embed_input=tab_preprocessor.embeddings_input,\n",
    "                continuous_cols=cont_cols,\n",
    "            )\n",
    "            \n",
    "            # model instantiation and training\n",
    "            model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "            \n",
    "            \n",
    "            n_epochs = 300\n",
    "\n",
    "            # pytorch hyperparams\n",
    "            wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "            deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "            \n",
    "            wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_train_wide.shape[0], epochs=n_epochs)\n",
    "            deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "            \n",
    "            optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "            lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "            \n",
    "            \n",
    "            callbacks = [\n",
    "                LRHistory(n_epochs=n_epochs), \n",
    "            ]\n",
    "            \n",
    "            # trainer\n",
    "            trainer = Trainer(model=model, \n",
    "                              objective='binary', \n",
    "                              metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                              seed=random_state, \n",
    "                              optimizers=optimizers,\n",
    "                              callbacks=callbacks\n",
    "                             )\n",
    "            \n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "            trainer.fit( # this is where problem is beginning\n",
    "                X_wide=X_train_wide,\n",
    "                X_tab=X_train_tab,\n",
    "                target=y_train,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    "            )\n",
    "            \n",
    "            y_valid_preds = trainer.predict_proba(X_wide=X_valid_wide, X_tab=X_valid_tab, batch_size=1024)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            \n",
    "            # test set inference\n",
    "            fold_test_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024)[:,1]\n",
    "            test_preds += fold_test_preds\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for {arch} model is {model_valid_auc}\")\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # MAYBE PULL THIS OUT OF THE LOOP TO AVOID POINTLESS REPETITION\n",
    "    dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         if 'widedeep' in arch:\n",
    "        wandb.log({'model_valid_auc': model_valid_auc,\n",
    "#                    'oof_preds': oof_preds,\n",
    "#                    'test_preds': test_preds,\n",
    "                   'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "        #                    'model_params': str(model.get_params()),\n",
    "        })\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "#                    'oof_preds': oof_preds,\n",
    "#                    'test_preds': test_preds,\n",
    "# #                    'model_params': str(model.get_params()),\n",
    "#                   })\n",
    "        wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994802dc-6ec1-4588-9ee6-b18e7ef01047",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe960b2-6e42-4384-a7de-d2a2464c2ea2",
   "metadata": {},
   "source": [
    "## Level One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56809b48-4570-4369-9c4b-4a51e22d4818",
   "metadata": {},
   "source": [
    "I'm going to try adding more models to this run -- a third seed for everything -- and also train the TabMLP models deeper -- 300 epochs/fold. I'm not confident that I've found a set of predictions that use the best model hyperparameters on the original dataset, so I'm going to just run this all over again. In the future, I **need** to do better at tracking artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdffb03-04c5-440a-9e56-56e75db5ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = ['xgboost', 'lightgbm', 'catboost', 'widedeep-tabmlp', 'widedeep-saint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac258d-44f9-4b10-a91a-756650746dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seeds = [42, 1983, 550, 1701, 2063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a0375-85f3-4011-b1f7-cbdd0c216d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_params = {\n",
    "    # 'xgboost': #todo,\n",
    "    # 'lightgbm': #todo,\n",
    "    # 'catboost': #todo,\n",
    "    # 'widedeep-tabmlp': #todo,\n",
    "    # 'widedeep-saint': #todo,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb4c8f6-4712-45a9-9a42-84864ab265bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_lv1, test_lv1 = pd.DataFrame(), pd.DataFrame() # initialize dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f3a89-af13-4f7d-a613-690498292674",
   "metadata": {},
   "source": [
    "### Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd37480-62ce-4dd9-af24-11eb85ce2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in architectures:\n",
    "    for model_seed in model_seeds:\n",
    "        # update exmodel_config here\n",
    "        oof_pred, test_pred = cross_validate_model(arch=arch, X=X, y=y, X_test=X_test, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=model_seed,\n",
    "                                         params=lv1_params[arch],\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=True\n",
    "                                        )\n",
    "        oof_lv1[f'{arch}{model_seed}'] = oof_pred\n",
    "        test_lv1[f'{arch}{model_seed}'] = test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51005cff-07e7-4cbb-91da-931fbbf361ee",
   "metadata": {},
   "source": [
    "**FILL IN THE BELOW FILENAME with dataset info, arch info, date info, etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242aa4c6-477b-4486-b682-ffec249ef8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1.to_feather(predpath/f'stacking_oof.feather')\n",
    "# test_lv1.to_feather(predpath/f'stacking_test.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a964b810-db49-49c0-9deb-999a189e4939",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd5828bc-e0d1-4b26-b1ed-33b26116f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1 = pd.read_feather(predpath/f\"stacking_manual_20211027_143755nb-20211028183233run-X_orig-oof-lv1.feather\")#, columns=[str(x) for x in range()])\n",
    "# test_lv1 = pd.read_feather(predpath/f\"stacking_manual_20211027_143755nb-20211028183233run-X_orig-test-lv1.feather\")\n",
    "oof_y = load(predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50588e31-b3a8-4fa5-b53b-9bf8abbb44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1_1701 = pd.read_feather(altdatapath/'oof_lv1_1701_models.feather')\n",
    "# test_lv1_1701 = pd.read_feather(altdatapath/'test_lv1_1701_models.feather')\n",
    "# oof_lv1_2063 = pd.read_feather(altdatapath/'oof_lv1_2063_models.feather')\n",
    "# test_lv1_2063 = pd.read_feather(altdatapath/'test_lv1_2063_models.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be8f8746-5493-4a7e-8102-2707573be0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835053d3-3e25-49bd-9236-3e63bc76925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1_1701.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcd47a2d-026a-41f2-ac8c-4e71e329616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1_2063.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbff7630-5871-4acf-9a93-7e6069263545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1.join(oof_lv1_1701).join(oof_lv1_2063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eb7e8c7-bba7-4b2a-aea1-ace3db01b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lv1.join(test_lv1_1701).join(test_lv1_2063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7fe8775-fb8d-4fe6-9b9f-415c4c9bc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv1.to_feather(altdatapath/'oof_lv1_5rs.feather')\n",
    "# oof_lv1 = pd.read_feather(altdatapath/'oof_lv1_5rs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff464a53-8a61-4ad5-8057-fca5ff916a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lv1.to_feather(altdatapath/'test_lv1_5rs.feather')\n",
    "# test_lv1 = pd.read_feather(altdatapath/'test_lv1_5rs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2921e40-202a-4c1d-a36e-5364fb7e2e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>0.637863</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.528318</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.455730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.965270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.600854</td>\n",
       "      <td>0.755067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.273882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.068461</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.082108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0  0.643063  0.644761  0.651015  0.627152  0.666962  0.658337  0.633626   \n",
       "1  0.979158  0.980269  0.979628  0.975591  0.976313  0.975725  0.978221   \n",
       "2  0.694800  0.735218  0.685842  0.674095  0.670068  0.668585  0.758380   \n",
       "3  0.315001  0.310552  0.317150  0.294775  0.321891  0.326354  0.277934   \n",
       "4  0.086256  0.089822  0.081587  0.069561  0.071851  0.072671  0.060639   \n",
       "\n",
       "    cat1983    cat550  tabmlp42  tabmlp1983  tabmlp550  \n",
       "0  0.637863  0.618124  0.528318    0.551580   0.455730  \n",
       "1  0.978872  0.979702  0.960835    0.958873   0.965270  \n",
       "2  0.695742  0.687652  0.722547    0.600854   0.755067  \n",
       "3  0.281502  0.280313  0.200837    0.214472   0.273882  \n",
       "4  0.061077  0.068461  0.060948    0.034382   0.082108  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aea2e8e2-6fcc-4ede-8bba-ae98f89ad1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "oof_lv1 = oof_lv1.join(pd.read_feather(altdatapath/'oof_lv1_1701_models.feather')).join(pd.read_feather(altdatapath/'oof_lv1_2063_models.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c637dba9-1bde-4234-808c-16c1760267c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>0.637863</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.528318</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.455730</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.965270</td>\n",
       "      <td>0.979586</td>\n",
       "      <td>0.975426</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.600854</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.716650</td>\n",
       "      <td>0.679206</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.273882</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.068461</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0  0.643063  0.644761  0.651015  0.627152  0.666962  0.658337  0.633626   \n",
       "1  0.979158  0.980269  0.979628  0.975591  0.976313  0.975725  0.978221   \n",
       "2  0.694800  0.735218  0.685842  0.674095  0.670068  0.668585  0.758380   \n",
       "3  0.315001  0.310552  0.317150  0.294775  0.321891  0.326354  0.277934   \n",
       "4  0.086256  0.089822  0.081587  0.069561  0.071851  0.072671  0.060639   \n",
       "\n",
       "    cat1983    cat550  tabmlp42  tabmlp1983  tabmlp550   lgb1701   xgb1701  \\\n",
       "0  0.637863  0.618124  0.528318    0.551580   0.455730  0.647845  0.636991   \n",
       "1  0.978872  0.979702  0.960835    0.958873   0.965270  0.979586  0.975426   \n",
       "2  0.695742  0.687652  0.722547    0.600854   0.755067  0.716650  0.679206   \n",
       "3  0.281502  0.280313  0.200837    0.214472   0.273882  0.301760  0.318009   \n",
       "4  0.061077  0.068461  0.060948    0.034382   0.082108  0.094915  0.065146   \n",
       "\n",
       "    cat1701  tablmp1701   lgb2063   xgb2063   cat2063  tablmp2063  \n",
       "0  0.604513    0.550344  0.636336  0.652631  0.630627    0.550438  \n",
       "1  0.977638    0.967344  0.979467  0.973305  0.977416    0.966318  \n",
       "2  0.788293    0.634997  0.642301  0.663404  0.696574    0.747513  \n",
       "3  0.272723    0.223079  0.311523  0.316786  0.280914    0.174859  \n",
       "4  0.066420    0.050387  0.084422  0.068258  0.064579    0.073367  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a7e0a5d-0fc8-4dc0-a57f-73fa2f7a39aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "test_lv1 = test_lv1.join(pd.read_feather(altdatapath/'test_lv1_1701_models.feather')).join(pd.read_feather(altdatapath/'test_lv1_2063_models.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65f6fe35-5fa8-4636-a8a4-a14fb7a58260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>0.637863</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.528318</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.455730</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.965270</td>\n",
       "      <td>0.979586</td>\n",
       "      <td>0.975426</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.600854</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.716650</td>\n",
       "      <td>0.679206</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.273882</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.068461</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.877003</td>\n",
       "      <td>0.866812</td>\n",
       "      <td>0.859368</td>\n",
       "      <td>0.873962</td>\n",
       "      <td>0.876338</td>\n",
       "      <td>0.882213</td>\n",
       "      <td>0.876955</td>\n",
       "      <td>0.876530</td>\n",
       "      <td>0.873538</td>\n",
       "      <td>0.872165</td>\n",
       "      <td>0.898925</td>\n",
       "      <td>0.846161</td>\n",
       "      <td>0.876102</td>\n",
       "      <td>0.867594</td>\n",
       "      <td>0.875290</td>\n",
       "      <td>0.880338</td>\n",
       "      <td>0.863979</td>\n",
       "      <td>0.866435</td>\n",
       "      <td>0.880339</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.735823</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>0.702689</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.785770</td>\n",
       "      <td>0.789151</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.768164</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>0.660141</td>\n",
       "      <td>0.760324</td>\n",
       "      <td>0.758805</td>\n",
       "      <td>0.749080</td>\n",
       "      <td>0.768249</td>\n",
       "      <td>0.743479</td>\n",
       "      <td>0.712077</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.726242</td>\n",
       "      <td>0.661662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.151834</td>\n",
       "      <td>0.155176</td>\n",
       "      <td>0.146293</td>\n",
       "      <td>0.140220</td>\n",
       "      <td>0.146466</td>\n",
       "      <td>0.153901</td>\n",
       "      <td>0.164341</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>0.164354</td>\n",
       "      <td>0.103621</td>\n",
       "      <td>0.129194</td>\n",
       "      <td>0.094390</td>\n",
       "      <td>0.151669</td>\n",
       "      <td>0.151052</td>\n",
       "      <td>0.155469</td>\n",
       "      <td>0.077828</td>\n",
       "      <td>0.143994</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.161125</td>\n",
       "      <td>0.168268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.205738</td>\n",
       "      <td>0.182986</td>\n",
       "      <td>0.196857</td>\n",
       "      <td>0.216337</td>\n",
       "      <td>0.200384</td>\n",
       "      <td>0.197216</td>\n",
       "      <td>0.232795</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>0.229330</td>\n",
       "      <td>0.277918</td>\n",
       "      <td>0.401489</td>\n",
       "      <td>0.343227</td>\n",
       "      <td>0.222530</td>\n",
       "      <td>0.217675</td>\n",
       "      <td>0.229789</td>\n",
       "      <td>0.335021</td>\n",
       "      <td>0.186798</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.226820</td>\n",
       "      <td>0.178284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.124505</td>\n",
       "      <td>0.116093</td>\n",
       "      <td>0.125708</td>\n",
       "      <td>0.127176</td>\n",
       "      <td>0.123510</td>\n",
       "      <td>0.127476</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.114628</td>\n",
       "      <td>0.112860</td>\n",
       "      <td>0.073573</td>\n",
       "      <td>0.066758</td>\n",
       "      <td>0.130796</td>\n",
       "      <td>0.119925</td>\n",
       "      <td>0.120880</td>\n",
       "      <td>0.111866</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.115872</td>\n",
       "      <td>0.120967</td>\n",
       "      <td>0.118960</td>\n",
       "      <td>0.139605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0       0.643063  0.644761  0.651015  0.627152  0.666962  0.658337  0.633626   \n",
       "1       0.979158  0.980269  0.979628  0.975591  0.976313  0.975725  0.978221   \n",
       "2       0.694800  0.735218  0.685842  0.674095  0.670068  0.668585  0.758380   \n",
       "3       0.315001  0.310552  0.317150  0.294775  0.321891  0.326354  0.277934   \n",
       "4       0.086256  0.089822  0.081587  0.069561  0.071851  0.072671  0.060639   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.877003  0.866812  0.859368  0.873962  0.876338  0.882213  0.876955   \n",
       "999996  0.735823  0.732218  0.702689  0.777820  0.785770  0.789151  0.766000   \n",
       "999997  0.151834  0.155176  0.146293  0.140220  0.146466  0.153901  0.164341   \n",
       "999998  0.205738  0.182986  0.196857  0.216337  0.200384  0.197216  0.232795   \n",
       "999999  0.124505  0.116093  0.125708  0.127176  0.123510  0.127476  0.111852   \n",
       "\n",
       "         cat1983    cat550  tabmlp42  tabmlp1983  tabmlp550   lgb1701  \\\n",
       "0       0.637863  0.618124  0.528318    0.551580   0.455730  0.647845   \n",
       "1       0.978872  0.979702  0.960835    0.958873   0.965270  0.979586   \n",
       "2       0.695742  0.687652  0.722547    0.600854   0.755067  0.716650   \n",
       "3       0.281502  0.280313  0.200837    0.214472   0.273882  0.301760   \n",
       "4       0.061077  0.068461  0.060948    0.034382   0.082108  0.094915   \n",
       "...          ...       ...       ...         ...        ...       ...   \n",
       "999995  0.876530  0.873538  0.872165    0.898925   0.846161  0.876102   \n",
       "999996  0.766401  0.768164  0.751403    0.660141   0.760324  0.758805   \n",
       "999997  0.165027  0.164354  0.103621    0.129194   0.094390  0.151669   \n",
       "999998  0.227559  0.229330  0.277918    0.401489   0.343227  0.222530   \n",
       "999999  0.114628  0.112860  0.073573    0.066758   0.130796  0.119925   \n",
       "\n",
       "         xgb1701   cat1701  tablmp1701   lgb2063   xgb2063   cat2063  \\\n",
       "0       0.636991  0.604513    0.550344  0.636336  0.652631  0.630627   \n",
       "1       0.975426  0.977638    0.967344  0.979467  0.973305  0.977416   \n",
       "2       0.679206  0.788293    0.634997  0.642301  0.663404  0.696574   \n",
       "3       0.318009  0.272723    0.223079  0.311523  0.316786  0.280914   \n",
       "4       0.065146  0.066420    0.050387  0.084422  0.068258  0.064579   \n",
       "...          ...       ...         ...       ...       ...       ...   \n",
       "999995  0.867594  0.875290    0.880338  0.863979  0.866435  0.880339   \n",
       "999996  0.749080  0.768249    0.743479  0.712077  0.768061  0.726242   \n",
       "999997  0.151052  0.155469    0.077828  0.143994  0.135747  0.161125   \n",
       "999998  0.217675  0.229789    0.335021  0.186798  0.224917  0.226820   \n",
       "999999  0.120880  0.111866    0.124561  0.115872  0.120967  0.118960   \n",
       "\n",
       "        tablmp2063  \n",
       "0         0.550438  \n",
       "1         0.966318  \n",
       "2         0.747513  \n",
       "3         0.174859  \n",
       "4         0.073367  \n",
       "...            ...  \n",
       "999995    0.894021  \n",
       "999996    0.661662  \n",
       "999997    0.168268  \n",
       "999998    0.178284  \n",
       "999999    0.139605  \n",
       "\n",
       "[1000000 rows x 20 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee532ac-e8ab-4813-85e6-21df0de841b4",
   "metadata": {},
   "source": [
    "Now, I'll quickly do some Optuna for the above lv1 tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e3ba4-981d-4a86-b181-66a43aed8285",
   "metadata": {},
   "source": [
    "## Level Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332a88ad-3033-4763-973e-1ee4a369639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# oof_lv1 = pd.read_feather(predpath/'stacking_manual_20211020_104938_X_orig+KMeans8+synth_oof_lv1.feather')\n",
    "# oof_lv1 = pd.read_feather(predpath/'stacking_manual_20211011_092728_oof_lv1.feather') # basis for best original dataset run as of 20211021\n",
    "# test_lv1 = pd.read_feather(predpath/'stacking_manual_20211020_104938_X_orig+KMeans8+synth_test_lv1.feather')\n",
    "# test_lv1 = pd.read_feather(predpath/'stacking_manual_20211011_092728_test_lv1.feather') # basis for best original dataset run as of 20211021\n",
    "# oof_y = load(predpath/'5folds_rs42_oof_y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4468455-998b-463d-9c8b-c6b6ea6669c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv2_xgboost_params = {\n",
    "    'n_estimators': 8398,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.005152495267590912,\n",
    "    'reg_alpha': 0.003501877866082655,\n",
    "    'reg_lambda': 0.5892650659577978,\n",
    "    'subsample': 0.5321195352481216,\n",
    "    'min_child_weight': 1.7950489828988663,\n",
    "    'colsample_bytree': 0.6100580666401978,\n",
    "    'gamma': 7.836182280294878}\n",
    "\n",
    "# trial 27\n",
    "lv2_lightgbm_params = {\n",
    "    'n_estimators': 5978,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.002972483637079397,\n",
    "    'reg_alpha': 0.0066240595682091315,\n",
    "    'reg_lambda': 0.023021277110080198,\n",
    "    'subsample': 0.762378215816119,\n",
    "    'boosting_type': 'goss',\n",
    "    'min_child_samples': 14,\n",
    "    'num_leaves': 108,\n",
    "    'colsample_bytree': 0.6831809216468459}\n",
    "\n",
    "# trial 62\n",
    "lv2_catboost_params = {\n",
    "    'iterations': 2633, \n",
    "    'depth': 10, \n",
    "    'learning_rate': 0.0023597486442471613, \n",
    "    'random_strength': 2, \n",
    "    'od_wait': 1597, \n",
    "    'reg_lambda': 60.949736178635824, \n",
    "    'border_count': 109, \n",
    "    'min_child_samples': 20, \n",
    "    'leaf_estimation_iterations': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ea5ac76-c5ab-4ae7-8e56-2eaf2f52f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2, test_lv2 = pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3711a52d-fa65-4bd9-996c-789a996f0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_y = pd.Series(oof_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa61d2f0-a14f-4192-8d75-29899946b686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:55:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.8578150664470746\n",
      "FOLD 1\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:55:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.8566466212062318\n",
      "FOLD 2\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:56:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.857639013843124\n",
      "FOLD 3\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.8564849475361453\n",
      "FOLD 4\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.8572123879070284\n",
      "Valid AUC score for xgboost model is 0.8571320078395062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/sf/code/kaggle/tabular_playgrounds/oct2021/preds/stacking_manual_20211031_160241nb-20211031165842run-X_orig_test_lv2_xgboost42_preds.joblib']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv2_xgb42, test_lv2_xgb42 = cross_validate_model(library='xgboost', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=lv2_xgboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         shuffle_kfolds=False,\n",
    "                                         wandb_tracked=False,\n",
    "                                         encode_cats=False\n",
    "                                        )\n",
    "\n",
    "dump(oof_lv2_xgb42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_oof_lv2_xgboost42_preds.joblib\")\n",
    "dump(test_lv2_xgb42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_test_lv2_xgboost42_preds.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "00db765d-db36-4c90-858b-bc8708cf9331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# oof_xgb_f0_rs1983 = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/stacking_manual_20210926_211701_xgboost_5folds/xgboost_fold0_model.joblib')\n",
    "# oof_xgb_f0_rs42 = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/models/stacking_manual_20210925_212129_xgboost_5folds/xgboost_fold0_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf9ac76c-cafa-4831-b856-37663b4ec276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-1150aab84c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m oof_lv2_cat42, test_lv2_cat42 = cross_validate_model(library='catboost', X=oof_lv1, y=oof_y, X_test=test_lv1, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                          \u001b[0mwandb_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                          \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlv2_catboost_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          \u001b[0mexmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4d25d060929e>\u001b[0m in \u001b[0;36mcross_validate_model\u001b[0;34m(library, X, y, X_test, params, start_fold, exmodel_config, wandb_config, random_state, shuffle_kfolds, wandb_tracked, encode_cats)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 **params) \n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0my_valid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   4673\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4675\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   4676\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4677\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   1998\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_lv2_cat42, test_lv2_cat42 = cross_validate_model(library='catboost', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=lv2_catboost_params,\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         shuffle_kfolds=False,\n",
    "                                         wandb_tracked=False,\n",
    "                                         encode_cats=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ca079-d826-4991-8377-3bd3988b3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(oof_lv2_cat42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_oof_lv2_catboost42_preds.joblib\")\n",
    "dump(test_lv2_cat42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_test_lv2_catboost42_preds.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17be39-6ef1-4387-b1d2-e1ffa677093f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "oof_lv2_lgb42, test_lv2_lgb42 = cross_validate_model(library='lightgbm', X=oof_lv1, y=oof_y, X_test=test_lv1, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=42,\n",
    "                                         params=lv2_lightgbm_params,\n",
    "                                         exmodel_config=exmodel_config,\n",
    "                                         shuffle_kfolds=False,\n",
    "                                         wandb_tracked=False,\n",
    "                                         encode_cats=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ef2ec-4539-4aaa-8a87-ce76eb8be564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(oof_lv2_lgb42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_oof_lv2_lightgbm42_preds.joblib\")\n",
    "dump(test_lv2_lgb42, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_test_lv2_lightgbm42_preds.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37f14d99-2917-4624-8e58-78818820750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2['xgboost'] = oof_lv2_xgb42\n",
    "oof_lv2['catboost'] = oof_lv2_cat42\n",
    "oof_lv2['lightgbm'] = oof_lv2_lgb42\n",
    "\n",
    "test_lv2['xgboost'] = test_lv2_xgb42\n",
    "test_lv2['catboost'] = test_lv2_cat42\n",
    "test_lv2['lightgbm'] = test_lv2_lgb42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b970e9c3-b3de-42b5-8d8b-c17832ecd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1_df = pd.read_feather(predpath/f\"{wandb_config['name']}_oof_lv1.feather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a241171-9b43-4205-9156-320687251c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lv2_full = oof_lv2.join(oof_lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9dbae0dc-79e9-421b-a9ea-a37cb5b17b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>...</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603463</td>\n",
       "      <td>0.603793</td>\n",
       "      <td>0.609108</td>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.455730</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.965270</td>\n",
       "      <td>0.979586</td>\n",
       "      <td>0.975426</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.678293</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600854</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.716650</td>\n",
       "      <td>0.679206</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.317473</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.273882</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028643</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    xgboost  catboost  lightgbm     lgb42   lgb1983    lgb550     xgb42  \\\n",
       "0  0.603463  0.603793  0.609108  0.643063  0.644761  0.651015  0.627152   \n",
       "1  0.999806  0.996125  0.988117  0.979158  0.980269  0.979628  0.975591   \n",
       "2  0.678293  0.667067  0.679545  0.694800  0.735218  0.685842  0.674095   \n",
       "3  0.312112  0.317473  0.317336  0.315001  0.310552  0.317150  0.294775   \n",
       "4  0.028643  0.029519  0.038828  0.086256  0.089822  0.081587  0.069561   \n",
       "\n",
       "    xgb1983    xgb550     cat42  ...  tabmlp1983  tabmlp550   lgb1701  \\\n",
       "0  0.666962  0.658337  0.633626  ...    0.551580   0.455730  0.647845   \n",
       "1  0.976313  0.975725  0.978221  ...    0.958873   0.965270  0.979586   \n",
       "2  0.670068  0.668585  0.758380  ...    0.600854   0.755067  0.716650   \n",
       "3  0.321891  0.326354  0.277934  ...    0.214472   0.273882  0.301760   \n",
       "4  0.071851  0.072671  0.060639  ...    0.034382   0.082108  0.094915   \n",
       "\n",
       "    xgb1701   cat1701  tablmp1701   lgb2063   xgb2063   cat2063  tablmp2063  \n",
       "0  0.636991  0.604513    0.550344  0.636336  0.652631  0.630627    0.550438  \n",
       "1  0.975426  0.977638    0.967344  0.979467  0.973305  0.977416    0.966318  \n",
       "2  0.679206  0.788293    0.634997  0.642301  0.663404  0.696574    0.747513  \n",
       "3  0.318009  0.272723    0.223079  0.311523  0.316786  0.280914    0.174859  \n",
       "4  0.065146  0.066420    0.050387  0.084422  0.068258  0.064579    0.073367  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv2_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e641d5b-2750-4e33-90c6-8d8481ca09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# test_lv1 = pd.DataFrame(test_lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "10359662-c105-477e-8c5b-8b82a4d51648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704171</td>\n",
       "      <td>0.719313</td>\n",
       "      <td>0.716673</td>\n",
       "      <td>0.742503</td>\n",
       "      <td>0.744670</td>\n",
       "      <td>0.743342</td>\n",
       "      <td>0.731599</td>\n",
       "      <td>0.743098</td>\n",
       "      <td>0.736512</td>\n",
       "      <td>0.702985</td>\n",
       "      <td>0.698789</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>0.709136</td>\n",
       "      <td>0.745753</td>\n",
       "      <td>0.732615</td>\n",
       "      <td>0.641977</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.741647</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>0.659293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225994</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>0.263515</td>\n",
       "      <td>0.255078</td>\n",
       "      <td>0.254107</td>\n",
       "      <td>0.239633</td>\n",
       "      <td>0.236084</td>\n",
       "      <td>0.238824</td>\n",
       "      <td>0.300979</td>\n",
       "      <td>0.257073</td>\n",
       "      <td>0.312073</td>\n",
       "      <td>0.240015</td>\n",
       "      <td>0.256124</td>\n",
       "      <td>0.236380</td>\n",
       "      <td>0.248044</td>\n",
       "      <td>0.229450</td>\n",
       "      <td>0.256039</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.317020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905121</td>\n",
       "      <td>0.908202</td>\n",
       "      <td>0.902443</td>\n",
       "      <td>0.909820</td>\n",
       "      <td>0.903481</td>\n",
       "      <td>0.903708</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>0.908522</td>\n",
       "      <td>0.910965</td>\n",
       "      <td>0.849669</td>\n",
       "      <td>0.873373</td>\n",
       "      <td>0.836253</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.903944</td>\n",
       "      <td>0.911547</td>\n",
       "      <td>0.855545</td>\n",
       "      <td>0.902819</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.858448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803894</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.810213</td>\n",
       "      <td>0.861400</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.863230</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.844481</td>\n",
       "      <td>0.832912</td>\n",
       "      <td>0.857812</td>\n",
       "      <td>0.836521</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>0.807577</td>\n",
       "      <td>0.858694</td>\n",
       "      <td>0.837866</td>\n",
       "      <td>0.869585</td>\n",
       "      <td>0.816616</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.836606</td>\n",
       "      <td>0.805957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282883</td>\n",
       "      <td>0.289195</td>\n",
       "      <td>0.278769</td>\n",
       "      <td>0.261821</td>\n",
       "      <td>0.262067</td>\n",
       "      <td>0.265357</td>\n",
       "      <td>0.266116</td>\n",
       "      <td>0.267789</td>\n",
       "      <td>0.264228</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>0.293265</td>\n",
       "      <td>0.309422</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.275409</td>\n",
       "      <td>0.266691</td>\n",
       "      <td>0.231212</td>\n",
       "      <td>0.277253</td>\n",
       "      <td>0.260022</td>\n",
       "      <td>0.265275</td>\n",
       "      <td>0.268644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0  0.704171  0.719313  0.716673  0.742503  0.744670  0.743342  0.731599   \n",
       "1  0.225994  0.234714  0.240386  0.263515  0.255078  0.254107  0.239633   \n",
       "2  0.905121  0.908202  0.902443  0.909820  0.903481  0.903708  0.909699   \n",
       "3  0.803894  0.808522  0.810213  0.861400  0.860360  0.863230  0.847200   \n",
       "4  0.282883  0.289195  0.278769  0.261821  0.262067  0.265357  0.266116   \n",
       "\n",
       "    cat1983    cat550  tabmlp42  tabmlp1983  tabmlp550   lgb1701   xgb1701  \\\n",
       "0  0.743098  0.736512  0.702985    0.698789   0.703244  0.709136  0.745753   \n",
       "1  0.236084  0.238824  0.300979    0.257073   0.312073  0.240015  0.256124   \n",
       "2  0.908522  0.910965  0.849669    0.873373   0.836253  0.907301  0.903944   \n",
       "3  0.844481  0.832912  0.857812    0.836521   0.854306  0.807577  0.858694   \n",
       "4  0.267789  0.264228  0.209983    0.293265   0.309422  0.281437  0.275409   \n",
       "\n",
       "    cat1701  tablmp1701   lgb2063   xgb2063   cat2063  tablmp2063  \n",
       "0  0.732615    0.641977  0.712405  0.741647  0.729088    0.659293  \n",
       "1  0.236380    0.248044  0.229450  0.256039  0.242159    0.317020  \n",
       "2  0.911547    0.855545  0.902819  0.905785  0.907301    0.858448  \n",
       "3  0.837866    0.869585  0.816616  0.866747  0.836606    0.805957  \n",
       "4  0.266691    0.231212  0.277253  0.260022  0.265275    0.268644  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lv1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a7a3d8c-4684-4f40-84f7-940a6a485d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "test_lv2_full = test_lv2.join(test_lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6116488d-bda5-43b0-bb4f-f6cfd2c96156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>...</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696256</td>\n",
       "      <td>0.690326</td>\n",
       "      <td>0.692617</td>\n",
       "      <td>0.704171</td>\n",
       "      <td>0.719313</td>\n",
       "      <td>0.716673</td>\n",
       "      <td>0.742503</td>\n",
       "      <td>0.744670</td>\n",
       "      <td>0.743342</td>\n",
       "      <td>0.731599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698789</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>0.709136</td>\n",
       "      <td>0.745753</td>\n",
       "      <td>0.732615</td>\n",
       "      <td>0.641977</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.741647</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>0.659293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.269859</td>\n",
       "      <td>0.275947</td>\n",
       "      <td>0.225994</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>0.263515</td>\n",
       "      <td>0.255078</td>\n",
       "      <td>0.254107</td>\n",
       "      <td>0.239633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257073</td>\n",
       "      <td>0.312073</td>\n",
       "      <td>0.240015</td>\n",
       "      <td>0.256124</td>\n",
       "      <td>0.236380</td>\n",
       "      <td>0.248044</td>\n",
       "      <td>0.229450</td>\n",
       "      <td>0.256039</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.317020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.915829</td>\n",
       "      <td>0.912697</td>\n",
       "      <td>0.903958</td>\n",
       "      <td>0.905121</td>\n",
       "      <td>0.908202</td>\n",
       "      <td>0.902443</td>\n",
       "      <td>0.909820</td>\n",
       "      <td>0.903481</td>\n",
       "      <td>0.903708</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873373</td>\n",
       "      <td>0.836253</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.903944</td>\n",
       "      <td>0.911547</td>\n",
       "      <td>0.855545</td>\n",
       "      <td>0.902819</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.858448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.807240</td>\n",
       "      <td>0.812514</td>\n",
       "      <td>0.791061</td>\n",
       "      <td>0.803894</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.810213</td>\n",
       "      <td>0.861400</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.863230</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836521</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>0.807577</td>\n",
       "      <td>0.858694</td>\n",
       "      <td>0.837866</td>\n",
       "      <td>0.869585</td>\n",
       "      <td>0.816616</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.836606</td>\n",
       "      <td>0.805957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.293652</td>\n",
       "      <td>0.302775</td>\n",
       "      <td>0.282883</td>\n",
       "      <td>0.289195</td>\n",
       "      <td>0.278769</td>\n",
       "      <td>0.261821</td>\n",
       "      <td>0.262067</td>\n",
       "      <td>0.265357</td>\n",
       "      <td>0.266116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293265</td>\n",
       "      <td>0.309422</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.275409</td>\n",
       "      <td>0.266691</td>\n",
       "      <td>0.231212</td>\n",
       "      <td>0.277253</td>\n",
       "      <td>0.260022</td>\n",
       "      <td>0.265275</td>\n",
       "      <td>0.268644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    xgboost  catboost  lightgbm     lgb42   lgb1983    lgb550     xgb42  \\\n",
       "0  0.696256  0.690326  0.692617  0.704171  0.719313  0.716673  0.742503   \n",
       "1  0.269481  0.269859  0.275947  0.225994  0.234714  0.240386  0.263515   \n",
       "2  0.915829  0.912697  0.903958  0.905121  0.908202  0.902443  0.909820   \n",
       "3  0.807240  0.812514  0.791061  0.803894  0.808522  0.810213  0.861400   \n",
       "4  0.296900  0.293652  0.302775  0.282883  0.289195  0.278769  0.261821   \n",
       "\n",
       "    xgb1983    xgb550     cat42  ...  tabmlp1983  tabmlp550   lgb1701  \\\n",
       "0  0.744670  0.743342  0.731599  ...    0.698789   0.703244  0.709136   \n",
       "1  0.255078  0.254107  0.239633  ...    0.257073   0.312073  0.240015   \n",
       "2  0.903481  0.903708  0.909699  ...    0.873373   0.836253  0.907301   \n",
       "3  0.860360  0.863230  0.847200  ...    0.836521   0.854306  0.807577   \n",
       "4  0.262067  0.265357  0.266116  ...    0.293265   0.309422  0.281437   \n",
       "\n",
       "    xgb1701   cat1701  tablmp1701   lgb2063   xgb2063   cat2063  tablmp2063  \n",
       "0  0.745753  0.732615    0.641977  0.712405  0.741647  0.729088    0.659293  \n",
       "1  0.256124  0.236380    0.248044  0.229450  0.256039  0.242159    0.317020  \n",
       "2  0.903944  0.911547    0.855545  0.902819  0.905785  0.907301    0.858448  \n",
       "3  0.858694  0.837866    0.869585  0.816616  0.866747  0.836606    0.805957  \n",
       "4  0.275409  0.266691    0.231212  0.277253  0.260022  0.265275    0.268644  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lv2_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90b20494-95d6-4240-8a0d-b54de622b347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>...</th>\n",
       "      <th>tabmlp1983</th>\n",
       "      <th>tabmlp550</th>\n",
       "      <th>lgb1701</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603463</td>\n",
       "      <td>0.603793</td>\n",
       "      <td>0.609108</td>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.455730</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.965270</td>\n",
       "      <td>0.979586</td>\n",
       "      <td>0.975426</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.678293</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600854</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.716650</td>\n",
       "      <td>0.679206</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.317473</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.273882</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028643</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    xgboost  catboost  lightgbm     lgb42   lgb1983    lgb550     xgb42  \\\n",
       "0  0.603463  0.603793  0.609108  0.643063  0.644761  0.651015  0.627152   \n",
       "1  0.999806  0.996125  0.988117  0.979158  0.980269  0.979628  0.975591   \n",
       "2  0.678293  0.667067  0.679545  0.694800  0.735218  0.685842  0.674095   \n",
       "3  0.312112  0.317473  0.317336  0.315001  0.310552  0.317150  0.294775   \n",
       "4  0.028643  0.029519  0.038828  0.086256  0.089822  0.081587  0.069561   \n",
       "\n",
       "    xgb1983    xgb550     cat42  ...  tabmlp1983  tabmlp550   lgb1701  \\\n",
       "0  0.666962  0.658337  0.633626  ...    0.551580   0.455730  0.647845   \n",
       "1  0.976313  0.975725  0.978221  ...    0.958873   0.965270  0.979586   \n",
       "2  0.670068  0.668585  0.758380  ...    0.600854   0.755067  0.716650   \n",
       "3  0.321891  0.326354  0.277934  ...    0.214472   0.273882  0.301760   \n",
       "4  0.071851  0.072671  0.060639  ...    0.034382   0.082108  0.094915   \n",
       "\n",
       "    xgb1701   cat1701  tablmp1701   lgb2063   xgb2063   cat2063  tablmp2063  \n",
       "0  0.636991  0.604513    0.550344  0.636336  0.652631  0.630627    0.550438  \n",
       "1  0.975426  0.977638    0.967344  0.979467  0.973305  0.977416    0.966318  \n",
       "2  0.679206  0.788293    0.634997  0.642301  0.663404  0.696574    0.747513  \n",
       "3  0.318009  0.272723    0.223079  0.311523  0.316786  0.280914    0.174859  \n",
       "4  0.065146  0.066420    0.050387  0.084422  0.068258  0.064579    0.073367  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv2_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83f55d89-4ae1-4397-83ad-388e3d8e697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "oof_lv2_np = oof_lv2_full.to_numpy()\n",
    "test_lv2_np = test_lv2_full.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f5029bd-96d5-4c86-a4f5-1da358456a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(oof_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "411948c7-bc26-4722-962d-23f56857a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_y_np = oof_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c6aac-1344-4ee0-b2a2-1580d6c5356d",
   "metadata": {},
   "source": [
    "## Level Three (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de1db0b1-26d9-440b-864b-63df8aa6fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18fa300d-2e9b-4fcd-8553-cf3885228bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = model_selection.StratifiedKFold(n_splits=5, shuffle=False) # no random_state if shuffle == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ad51e38-ca0f-4e6c-9879-7993a8bd40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds, oof_y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e820c69a-13f3-4ace-a26f-d6e1fb097ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.zeros((X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ec5b2ec-8f29-471a-ab7d-d6be861a803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = oof_lv2_np\n",
    "y = oof_y_np\n",
    "X_test = test_lv2_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1f6d220b-7f9f-49ea-b3bf-7d477751121c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60346347, 0.60379302, 0.60910751, 0.6430626 , 0.64476147,\n",
       "        0.65101507, 0.62715232, 0.66696191, 0.658337  , 0.63362641,\n",
       "        0.63786275, 0.61812448, 0.52831805, 0.55158025, 0.45572963,\n",
       "        0.64784501, 0.63699114, 0.60451306, 0.55034405, 0.63633613,\n",
       "        0.65263098, 0.6306274 , 0.55043793],\n",
       "       [0.99980623, 0.99612459, 0.98811665, 0.97915809, 0.98026903,\n",
       "        0.97962814, 0.9755913 , 0.97631311, 0.97572541, 0.97822092,\n",
       "        0.9788715 , 0.97970244, 0.96083504, 0.95887262, 0.96526986,\n",
       "        0.97958613, 0.97542602, 0.97763838, 0.96734434, 0.97946677,\n",
       "        0.97330451, 0.97741563, 0.96631795],\n",
       "       [0.67829287, 0.66706652, 0.67954529, 0.69480043, 0.73521753,\n",
       "        0.68584185, 0.6740948 , 0.67006797, 0.66858542, 0.75837971,\n",
       "        0.69574226, 0.68765168, 0.72254694, 0.60085428, 0.75506681,\n",
       "        0.71664953, 0.67920649, 0.78829268, 0.63499689, 0.64230075,\n",
       "        0.66340375, 0.69657356, 0.74751294],\n",
       "       [0.31211236, 0.31747341, 0.31733638, 0.31500063, 0.31055182,\n",
       "        0.31714954, 0.29477474, 0.32189095, 0.32635427, 0.27793354,\n",
       "        0.28150182, 0.28031286, 0.20083654, 0.2144721 , 0.27388185,\n",
       "        0.30176009, 0.31800881, 0.27272258, 0.22307865, 0.31152269,\n",
       "        0.31678569, 0.2809145 , 0.17485939],\n",
       "       [0.02864293, 0.02951923, 0.03882779, 0.08625625, 0.08982228,\n",
       "        0.08158734, 0.06956097, 0.0718514 , 0.07267059, 0.06063941,\n",
       "        0.06107668, 0.06846076, 0.06094783, 0.03438157, 0.08210815,\n",
       "        0.09491485, 0.06514609, 0.06642006, 0.0503871 , 0.08442171,\n",
       "        0.06825778, 0.06457851, 0.07336691],\n",
       "       [0.97552717, 0.97387108, 0.9631045 , 0.93210856, 0.93400965,\n",
       "        0.92588765, 0.93387043, 0.9304139 , 0.93048108, 0.93660385,\n",
       "        0.93508565, 0.93286023, 0.88599241, 0.94791257, 0.92295378,\n",
       "        0.9286984 , 0.9327181 , 0.93429483, 0.93956804, 0.92358981,\n",
       "        0.92740691, 0.93023135, 0.91445518],\n",
       "       [0.81855118, 0.82172487, 0.80415594, 0.86351713, 0.86205768,\n",
       "        0.85102635, 0.83574039, 0.84129363, 0.83579946, 0.8386674 ,\n",
       "        0.83106644, 0.82526736, 0.87777346, 0.89849645, 0.87467116,\n",
       "        0.85568362, 0.84108514, 0.83370015, 0.87162048, 0.86634758,\n",
       "        0.83278817, 0.83715148, 0.89536178],\n",
       "       [0.17351441, 0.17291553, 0.18663911, 0.17815366, 0.1807829 ,\n",
       "        0.17024479, 0.15861823, 0.16667581, 0.15993515, 0.15541963,\n",
       "        0.15259177, 0.16023316, 0.15157375, 0.07128403, 0.24460748,\n",
       "        0.17834856, 0.1519548 , 0.16258141, 0.10743981, 0.17536179,\n",
       "        0.17014986, 0.16319204, 0.18081154],\n",
       "       [0.67817461, 0.68659923, 0.66709755, 0.68987173, 0.70130146,\n",
       "        0.69658033, 0.75263572, 0.71489632, 0.74086046, 0.74460156,\n",
       "        0.73708065, 0.73433129, 0.6421473 , 0.67400986, 0.68819451,\n",
       "        0.70784405, 0.73064923, 0.72355275, 0.65445626, 0.71546782,\n",
       "        0.73780459, 0.73637295, 0.69324279],\n",
       "       [0.83202136, 0.83947093, 0.81571809, 0.81849037, 0.83361482,\n",
       "        0.84287795, 0.85481358, 0.8621344 , 0.84278822, 0.85334679,\n",
       "        0.83840721, 0.84889198, 0.91792196, 0.92825603, 0.94096118,\n",
       "        0.82762211, 0.85184669, 0.84188173, 0.84649158, 0.83896783,\n",
       "        0.85121655, 0.83885447, 0.89299303]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c581a349-a22b-4383-b109-ec87ec9eed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = 'sklearn (LogisticRegressor(max_iter=1000))'\n",
    "# exmodel_config['library'] = library\n",
    "# wandb.init(\n",
    "#     project=\"202110_Kaggle_tabular_playground\",\n",
    "#     save_code=True,\n",
    "#     tags=wandb_config['tags'],\n",
    "#     name=wandb_config['name'],\n",
    "#     notes=wandb_config['notes'],\n",
    "#     config=exmodel_config\n",
    "# )   \n",
    "\n",
    "# prepare for k-fold cross-validation\n",
    "# kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "\n",
    "# setup for serialization\n",
    "# model_path = Path(datapath/f\"models/{wandb_config['name']}_{library}_{exmodel_config['kfolds']}folds/\")\n",
    "# (model_path).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefeecc-3536-482b-9f9c-8a286e3c6c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d405ab94-9fe2-4d95-b966-ad02de6f6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------\n",
      "ROC AUC of fold 0 is 0.8569595004826156\n",
      "FOLD 1\n",
      "---------------------\n",
      "ROC AUC of fold 1 is 0.8558408474590921\n",
      "FOLD 2\n",
      "---------------------\n",
      "ROC AUC of fold 2 is 0.8568110547897336\n",
      "FOLD 3\n",
      "---------------------\n",
      "ROC AUC of fold 3 is 0.8553678789830179\n",
      "FOLD 4\n",
      "---------------------\n",
      "ROC AUC of fold 4 is 0.8565676032821483\n",
      "Overall ROC_AUC is 0.8562392566675165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/sf/code/kaggle/tabular_playgrounds/oct2021/preds/stacking_manual_20211031_160241nb-20211031165953run-X_orig_test_lv3_preds.joblib']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(X,y)):\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    oof_preds.extend(preds)\n",
    "    oof_y.extend(y_valid)\n",
    "    \n",
    "    test_preds += model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f\"ROC AUC of fold {fold} is {valid_auc}\")\n",
    "    \n",
    "#     dump(preds, /'lv_3)\n",
    "\n",
    "valid_auc_total = roc_auc_score(oof_y, oof_preds)\n",
    "print(f\"Overall ROC_AUC is {valid_auc_total}\")\n",
    "\n",
    "dump(oof_preds, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_oof_lv3_preds.joblib\")\n",
    "dump(oof_y, predpath/'oof_lv3_y.joblib')\n",
    "\n",
    "test_preds /= 5\n",
    "\n",
    "dump(test_preds, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_test_lv3_preds.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a99cf5b-3477-47f4-9391-73e2ff93c7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_imputed-Median-wIndicators_StandardScaled.feather')\n",
    "# X_test_imputed_scaled = pd.read_feather(path=datapath/'X_test_NaNcounts_SummaryStats_imputed-Median-wIndicators-StandardScaled.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f347f-872f-4011-9f13-78fad542f36a",
   "metadata": {},
   "source": [
    "## Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0773d286-257d-4776-add5-0f724944befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_path = Path(datapath/\"preds/\")\n",
    "\n",
    "# blender_preds = blender.predict_proba(X_test_imputed_scaled)[:,1]\n",
    "# dump(blender_preds, preds_path/f\"{config_run['name']}_stack.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f63005-4b50-40e9-9af4-d858b9b73576",
   "metadata": {},
   "source": [
    "# Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cae3116a-5ded-4080-b8f9-20e1ebdb2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widedeep_preds = load(predpath/'stacking_manual_20211012_194716_widedeep-TabMLP_5folds_rs1983_500epochs_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f9ece5b1-b6aa-4ee9-80bc-9be931d04697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widedeep_preds = pd.Series(widedeep_preds, name='widedeep_tabmlp1983')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832dc6e3-b10f-4870-92d8-06fd1b1536d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lv1_xgb42 = load(predpath/'stacking_manual_20211020_104938_xgboost_5folds_rs42_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe47b41-bd5c-4274-b150-1ec5981d9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lv1_lgb42 = load(predpath/'stacking_manual_20211020_104938_lightgbm_5folds_rs42_test_preds.joblib')\n",
    "# test_lv1_cat42 = load(predpath/'stacking_manual_20211020_104938_catboost_5folds_rs42_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5bb5a-febb-496b-af26-e48e89269d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_lv1_xgb42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65240f3-f49d-4f94-a412-bab90a26c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_three = 0.5*test_preds + 0.3*test_lv1_xgb42 + 0.05*test_lv1_lgb42 + 0.05*test_lv1_cat42 + 0.1*test_lv1_tabmlp42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2ea7c-8a25-4032-8e71-1662c141dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_three_pow4 = 0.5*test_preds**4 + 0.3*test_lv1_xgb42**4 + 0.05*test_lv1_lgb42**4 + 0.05*test_lv1_cat42**4 + 0.1*test_lv1_tabmlp42**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312f49-71dd-4c4d-94b4-fc75e884fee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154706a-0190-465b-860d-488750178dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = mod_mix_three_pow4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f0d7d-bf40-41c4-a3f0-150c0444331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281493cc-512f-4871-aa9f-593d9339f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc619b-f6e1-4efd-aa4b-4f53c28d4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level_3rs-X_orig-GBM-0.5stack_0.3xgb42_0.1tabmlp42_0.05lgb42_0.05cat42_pow4_ensemble_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e31ab-1680-42bf-8e90-baa33a18faa0",
   "metadata": {},
   "source": [
    "## Level 4 (Passthrough)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a94aa-3b42-4a05-8446-6e82c647e8fe",
   "metadata": {},
   "source": [
    "### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae1644-2867-4235-b493-4b2ffc92a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_lv1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a020682-9728-45f9-9af6-61a2d93915b1",
   "metadata": {},
   "source": [
    "Let's see what we can get if we effectively do a pass-through -- that is, we join the results from the first level with the results from the second, and even potentially the third, then feed the resulting table through a few different models. (Given that we'll have a greater number of features, we might want to try XGBoost rather than just a simple logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8dcca0bc-0905-4999-8651-24ffcfc8b485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>...</th>\n",
       "      <th>xgb1701</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>0.637863</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.528318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "      <td>0.603463</td>\n",
       "      <td>0.603793</td>\n",
       "      <td>0.609108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975426</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.988117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679206</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.678293</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>0.679545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.317473</td>\n",
       "      <td>0.317336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.068461</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.028643</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.038828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0  0.643063  0.644761  0.651015  0.627152  0.666962  0.658337  0.633626   \n",
       "1  0.979158  0.980269  0.979628  0.975591  0.976313  0.975725  0.978221   \n",
       "2  0.694800  0.735218  0.685842  0.674095  0.670068  0.668585  0.758380   \n",
       "3  0.315001  0.310552  0.317150  0.294775  0.321891  0.326354  0.277934   \n",
       "4  0.086256  0.089822  0.081587  0.069561  0.071851  0.072671  0.060639   \n",
       "\n",
       "    cat1983    cat550  tabmlp42  ...   xgb1701   cat1701  tablmp1701  \\\n",
       "0  0.637863  0.618124  0.528318  ...  0.636991  0.604513    0.550344   \n",
       "1  0.978872  0.979702  0.960835  ...  0.975426  0.977638    0.967344   \n",
       "2  0.695742  0.687652  0.722547  ...  0.679206  0.788293    0.634997   \n",
       "3  0.281502  0.280313  0.200837  ...  0.318009  0.272723    0.223079   \n",
       "4  0.061077  0.068461  0.060948  ...  0.065146  0.066420    0.050387   \n",
       "\n",
       "    lgb2063   xgb2063   cat2063  tablmp2063   xgboost  catboost  lightgbm  \n",
       "0  0.636336  0.652631  0.630627    0.550438  0.603463  0.603793  0.609108  \n",
       "1  0.979467  0.973305  0.977416    0.966318  0.999806  0.996125  0.988117  \n",
       "2  0.642301  0.663404  0.696574    0.747513  0.678293  0.667067  0.679545  \n",
       "3  0.311523  0.316786  0.280914    0.174859  0.312112  0.317473  0.317336  \n",
       "4  0.084422  0.068258  0.064579    0.073367  0.028643  0.029519  0.038828  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lv1_and_2 = oof_lv1.join(oof_lv2)\n",
    "oof_lv1_and_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d354c8e-982e-4e75-89fc-99c39f9934e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>...</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>lv3_logistic_reg_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643063</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.651015</td>\n",
       "      <td>0.627152</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>0.658337</td>\n",
       "      <td>0.633626</td>\n",
       "      <td>0.637863</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.528318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604513</td>\n",
       "      <td>0.550344</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.652631</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>0.550438</td>\n",
       "      <td>0.603463</td>\n",
       "      <td>0.603793</td>\n",
       "      <td>0.609108</td>\n",
       "      <td>0.620127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.979628</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.978221</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.973305</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.966318</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.967607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788293</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.642301</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.678293</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.695375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315001</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>0.326354</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.174859</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.317473</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086256</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.068461</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.084422</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.028643</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>0.033848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.877003</td>\n",
       "      <td>0.866812</td>\n",
       "      <td>0.859368</td>\n",
       "      <td>0.873962</td>\n",
       "      <td>0.876338</td>\n",
       "      <td>0.882213</td>\n",
       "      <td>0.876955</td>\n",
       "      <td>0.876530</td>\n",
       "      <td>0.873538</td>\n",
       "      <td>0.872165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875290</td>\n",
       "      <td>0.880338</td>\n",
       "      <td>0.863979</td>\n",
       "      <td>0.866435</td>\n",
       "      <td>0.880339</td>\n",
       "      <td>0.894021</td>\n",
       "      <td>0.858877</td>\n",
       "      <td>0.856541</td>\n",
       "      <td>0.838445</td>\n",
       "      <td>0.872278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.735823</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>0.702689</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.785770</td>\n",
       "      <td>0.789151</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.768164</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768249</td>\n",
       "      <td>0.743479</td>\n",
       "      <td>0.712077</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.726242</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.721611</td>\n",
       "      <td>0.721759</td>\n",
       "      <td>0.722971</td>\n",
       "      <td>0.756245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.151834</td>\n",
       "      <td>0.155176</td>\n",
       "      <td>0.146293</td>\n",
       "      <td>0.140220</td>\n",
       "      <td>0.146466</td>\n",
       "      <td>0.153901</td>\n",
       "      <td>0.164341</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>0.164354</td>\n",
       "      <td>0.103621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155469</td>\n",
       "      <td>0.077828</td>\n",
       "      <td>0.143994</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.161125</td>\n",
       "      <td>0.168268</td>\n",
       "      <td>0.169669</td>\n",
       "      <td>0.166342</td>\n",
       "      <td>0.183475</td>\n",
       "      <td>0.159699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.205738</td>\n",
       "      <td>0.182986</td>\n",
       "      <td>0.196857</td>\n",
       "      <td>0.216337</td>\n",
       "      <td>0.200384</td>\n",
       "      <td>0.197216</td>\n",
       "      <td>0.232795</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>0.229330</td>\n",
       "      <td>0.277918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229789</td>\n",
       "      <td>0.335021</td>\n",
       "      <td>0.186798</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.226820</td>\n",
       "      <td>0.178284</td>\n",
       "      <td>0.251595</td>\n",
       "      <td>0.252851</td>\n",
       "      <td>0.254263</td>\n",
       "      <td>0.248749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.124505</td>\n",
       "      <td>0.116093</td>\n",
       "      <td>0.125708</td>\n",
       "      <td>0.127176</td>\n",
       "      <td>0.123510</td>\n",
       "      <td>0.127476</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.114628</td>\n",
       "      <td>0.112860</td>\n",
       "      <td>0.073573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111866</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.115872</td>\n",
       "      <td>0.120967</td>\n",
       "      <td>0.118960</td>\n",
       "      <td>0.139605</td>\n",
       "      <td>0.108671</td>\n",
       "      <td>0.111529</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>0.084113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0       0.643063  0.644761  0.651015  0.627152  0.666962  0.658337  0.633626   \n",
       "1       0.979158  0.980269  0.979628  0.975591  0.976313  0.975725  0.978221   \n",
       "2       0.694800  0.735218  0.685842  0.674095  0.670068  0.668585  0.758380   \n",
       "3       0.315001  0.310552  0.317150  0.294775  0.321891  0.326354  0.277934   \n",
       "4       0.086256  0.089822  0.081587  0.069561  0.071851  0.072671  0.060639   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.877003  0.866812  0.859368  0.873962  0.876338  0.882213  0.876955   \n",
       "999996  0.735823  0.732218  0.702689  0.777820  0.785770  0.789151  0.766000   \n",
       "999997  0.151834  0.155176  0.146293  0.140220  0.146466  0.153901  0.164341   \n",
       "999998  0.205738  0.182986  0.196857  0.216337  0.200384  0.197216  0.232795   \n",
       "999999  0.124505  0.116093  0.125708  0.127176  0.123510  0.127476  0.111852   \n",
       "\n",
       "         cat1983    cat550  tabmlp42  ...   cat1701  tablmp1701   lgb2063  \\\n",
       "0       0.637863  0.618124  0.528318  ...  0.604513    0.550344  0.636336   \n",
       "1       0.978872  0.979702  0.960835  ...  0.977638    0.967344  0.979467   \n",
       "2       0.695742  0.687652  0.722547  ...  0.788293    0.634997  0.642301   \n",
       "3       0.281502  0.280313  0.200837  ...  0.272723    0.223079  0.311523   \n",
       "4       0.061077  0.068461  0.060948  ...  0.066420    0.050387  0.084422   \n",
       "...          ...       ...       ...  ...       ...         ...       ...   \n",
       "999995  0.876530  0.873538  0.872165  ...  0.875290    0.880338  0.863979   \n",
       "999996  0.766401  0.768164  0.751403  ...  0.768249    0.743479  0.712077   \n",
       "999997  0.165027  0.164354  0.103621  ...  0.155469    0.077828  0.143994   \n",
       "999998  0.227559  0.229330  0.277918  ...  0.229789    0.335021  0.186798   \n",
       "999999  0.114628  0.112860  0.073573  ...  0.111866    0.124561  0.115872   \n",
       "\n",
       "         xgb2063   cat2063  tablmp2063   xgboost  catboost  lightgbm  \\\n",
       "0       0.652631  0.630627    0.550438  0.603463  0.603793  0.609108   \n",
       "1       0.973305  0.977416    0.966318  0.999806  0.996125  0.988117   \n",
       "2       0.663404  0.696574    0.747513  0.678293  0.667067  0.679545   \n",
       "3       0.316786  0.280914    0.174859  0.312112  0.317473  0.317336   \n",
       "4       0.068258  0.064579    0.073367  0.028643  0.029519  0.038828   \n",
       "...          ...       ...         ...       ...       ...       ...   \n",
       "999995  0.866435  0.880339    0.894021  0.858877  0.856541  0.838445   \n",
       "999996  0.768061  0.726242    0.661662  0.721611  0.721759  0.722971   \n",
       "999997  0.135747  0.161125    0.168268  0.169669  0.166342  0.183475   \n",
       "999998  0.224917  0.226820    0.178284  0.251595  0.252851  0.254263   \n",
       "999999  0.120967  0.118960    0.139605  0.108671  0.111529  0.120485   \n",
       "\n",
       "        lv3_logistic_reg_preds  \n",
       "0                     0.620127  \n",
       "1                     0.967607  \n",
       "2                     0.695375  \n",
       "3                     0.320700  \n",
       "4                     0.033848  \n",
       "...                        ...  \n",
       "999995                0.872278  \n",
       "999996                0.756245  \n",
       "999997                0.159699  \n",
       "999998                0.248749  \n",
       "999999                0.084113  \n",
       "\n",
       "[1000000 rows x 24 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_all_lvs = oof_lv1_and_2.join(pd.Series(oof_preds, name='lv3_logistic_reg_preds'))\n",
    "oof_all_lvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abbd2769-5c53-4738-be3f-b4a28bf56062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "test_all_lvs = test_lv1.join(test_lv2).join(pd.Series(test_preds, name='lv3_logistic_test_preds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87f21050-ab5e-4394-8f88-c03810fba347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb42</th>\n",
       "      <th>lgb1983</th>\n",
       "      <th>lgb550</th>\n",
       "      <th>xgb42</th>\n",
       "      <th>xgb1983</th>\n",
       "      <th>xgb550</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat1983</th>\n",
       "      <th>cat550</th>\n",
       "      <th>tabmlp42</th>\n",
       "      <th>...</th>\n",
       "      <th>cat1701</th>\n",
       "      <th>tablmp1701</th>\n",
       "      <th>lgb2063</th>\n",
       "      <th>xgb2063</th>\n",
       "      <th>cat2063</th>\n",
       "      <th>tablmp2063</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>lv3_logistic_test_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.704171</td>\n",
       "      <td>0.719313</td>\n",
       "      <td>0.716673</td>\n",
       "      <td>0.742503</td>\n",
       "      <td>0.744670</td>\n",
       "      <td>0.743342</td>\n",
       "      <td>0.731599</td>\n",
       "      <td>0.743098</td>\n",
       "      <td>0.736512</td>\n",
       "      <td>0.702985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732615</td>\n",
       "      <td>0.641977</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.741647</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>0.659293</td>\n",
       "      <td>0.696256</td>\n",
       "      <td>0.690326</td>\n",
       "      <td>0.692617</td>\n",
       "      <td>0.701891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225994</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>0.263515</td>\n",
       "      <td>0.255078</td>\n",
       "      <td>0.254107</td>\n",
       "      <td>0.239633</td>\n",
       "      <td>0.236084</td>\n",
       "      <td>0.238824</td>\n",
       "      <td>0.300979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236380</td>\n",
       "      <td>0.248044</td>\n",
       "      <td>0.229450</td>\n",
       "      <td>0.256039</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.269859</td>\n",
       "      <td>0.275947</td>\n",
       "      <td>0.267346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905121</td>\n",
       "      <td>0.908202</td>\n",
       "      <td>0.902443</td>\n",
       "      <td>0.909820</td>\n",
       "      <td>0.903481</td>\n",
       "      <td>0.903708</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>0.908522</td>\n",
       "      <td>0.910965</td>\n",
       "      <td>0.849669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911547</td>\n",
       "      <td>0.855545</td>\n",
       "      <td>0.902819</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.858448</td>\n",
       "      <td>0.915829</td>\n",
       "      <td>0.912697</td>\n",
       "      <td>0.903958</td>\n",
       "      <td>0.938763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803894</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.810213</td>\n",
       "      <td>0.861400</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.863230</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.844481</td>\n",
       "      <td>0.832912</td>\n",
       "      <td>0.857812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837866</td>\n",
       "      <td>0.869585</td>\n",
       "      <td>0.816616</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.836606</td>\n",
       "      <td>0.805957</td>\n",
       "      <td>0.807240</td>\n",
       "      <td>0.812514</td>\n",
       "      <td>0.791061</td>\n",
       "      <td>0.815654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282883</td>\n",
       "      <td>0.289195</td>\n",
       "      <td>0.278769</td>\n",
       "      <td>0.261821</td>\n",
       "      <td>0.262067</td>\n",
       "      <td>0.265357</td>\n",
       "      <td>0.266116</td>\n",
       "      <td>0.267789</td>\n",
       "      <td>0.264228</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266691</td>\n",
       "      <td>0.231212</td>\n",
       "      <td>0.277253</td>\n",
       "      <td>0.260022</td>\n",
       "      <td>0.265275</td>\n",
       "      <td>0.268644</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.293652</td>\n",
       "      <td>0.302775</td>\n",
       "      <td>0.308340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lgb42   lgb1983    lgb550     xgb42   xgb1983    xgb550     cat42  \\\n",
       "0  0.704171  0.719313  0.716673  0.742503  0.744670  0.743342  0.731599   \n",
       "1  0.225994  0.234714  0.240386  0.263515  0.255078  0.254107  0.239633   \n",
       "2  0.905121  0.908202  0.902443  0.909820  0.903481  0.903708  0.909699   \n",
       "3  0.803894  0.808522  0.810213  0.861400  0.860360  0.863230  0.847200   \n",
       "4  0.282883  0.289195  0.278769  0.261821  0.262067  0.265357  0.266116   \n",
       "\n",
       "    cat1983    cat550  tabmlp42  ...   cat1701  tablmp1701   lgb2063  \\\n",
       "0  0.743098  0.736512  0.702985  ...  0.732615    0.641977  0.712405   \n",
       "1  0.236084  0.238824  0.300979  ...  0.236380    0.248044  0.229450   \n",
       "2  0.908522  0.910965  0.849669  ...  0.911547    0.855545  0.902819   \n",
       "3  0.844481  0.832912  0.857812  ...  0.837866    0.869585  0.816616   \n",
       "4  0.267789  0.264228  0.209983  ...  0.266691    0.231212  0.277253   \n",
       "\n",
       "    xgb2063   cat2063  tablmp2063   xgboost  catboost  lightgbm  \\\n",
       "0  0.741647  0.729088    0.659293  0.696256  0.690326  0.692617   \n",
       "1  0.256039  0.242159    0.317020  0.269481  0.269859  0.275947   \n",
       "2  0.905785  0.907301    0.858448  0.915829  0.912697  0.903958   \n",
       "3  0.866747  0.836606    0.805957  0.807240  0.812514  0.791061   \n",
       "4  0.260022  0.265275    0.268644  0.296900  0.293652  0.302775   \n",
       "\n",
       "   lv3_logistic_test_preds  \n",
       "0                 0.701891  \n",
       "1                 0.267346  \n",
       "2                 0.938763  \n",
       "3                 0.815654  \n",
       "4                 0.308340  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_lvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f31c72-fd0c-4d3c-90d9-8b50136b4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_all_lvs.to_feather(altdatapath/'oof_all_lvs_passthru_20211031-final.feather')\n",
    "test_all_lvs.to_feather(altdatapath/'test_all_lvs_passthru_20211031-final.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0fd13-29da-473d-a25e-721afe96c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lv4_params = {\n",
    "    'n_estimators': 3878,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.024785857161974977,\n",
    "    'reg_alpha': 26.867682044658245,\n",
    "    'reg_lambda': 10.839759074147148,\n",
    "    'subsample': 0.8208581489835881,\n",
    "    'min_child_weight': 8.829122644339664,\n",
    "    'colsample_bytree': 0.906420714280384,\n",
    "    'gamma': 1.472322916021486\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddd61190-1b7a-4676-b504-fcf07750e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lv4_model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    verbosity=1,\n",
    "    tree_method='gpu_hist',\n",
    "    booster='gbtree', # not bothering with dart for time reasons\n",
    "    random_state=SEED,\n",
    "    **xgb_lv4_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e33ab912-aa8d-495d-9f31-324cb0b25eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lv4_train, X_lv4_valid, y_lv4_train, y_lv4_valid = train_test_split(oof_all_lvs, oof_y, test_size=0.2, random_state=int(SEED), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6402e3b0-7596-446e-9ba7-ea49aa3f16c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lv4_model.fit(X_lv4_train, y_lv4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2096d778-f8a4-4275-843b-8a7982640399",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv4_train_preds = xgb_lv4_model.predict_proba(X_lv4_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2266b8d-1843-4771-b9ce-211694dc2005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8568572581392072"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=lv4_train_preds, y_true=y_lv4_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73637673-956f-4454-94c0-506a0d4c1496",
   "metadata": {},
   "source": [
    "Let's compare that number to what we'd gotten at lv 3, and then what we'd get at lv 4 with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb503f0b-7640-41cb-a7b1-d577a5e1e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "log_lv4_model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a6fa213-5d86-472c-bb5f-90ee10adc2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_lv4_model.fit(X_lv4_train, y_lv4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fc121ac-985c-4488-a17a-4c6f72110b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "lv4_log_train_preds = log_lv4_model.predict_proba(X_lv4_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66717f73-789d-4509-8eb2-71831072811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8568131691662475"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=lv4_log_train_preds, y_true=y_lv4_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01e9aa-2ae7-450e-b1ad-c1cac980ec0e",
   "metadata": {},
   "source": [
    "So XGBoost at this level does do a bit better than LogisticRegression would. But should it come to this point? Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a27f56-ea78-42e4-ac5c-91c9400545bd",
   "metadata": {},
   "source": [
    "### Adding more models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2935b-681a-480d-affc-091525e430b3",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e37cd-f288-4a21-83f8-d2f22301c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_all_lvs = pd.read_feather(altdatapath/'oof_all_lvs_passthru_202110300859.feather')\n",
    "test_all_lvs = pd.read_feather(altdatapath/'test_all_lvs_passthru_202110300859.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf754eef-e6bc-4233-b68c-130b91bd8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = oof_y_np\n",
    "test_preds = np.zeros((X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79711158-8efe-4b88-8397-0843c2490126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------\n",
      "[17:00:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC of fold 0 is 0.8576973814950857\n",
      "FOLD 1\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC of fold 1 is 0.8564821246032219\n",
      "FOLD 2\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC of fold 2 is 0.8574951345643358\n",
      "FOLD 3\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:01:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC of fold 3 is 0.8563175511608968\n",
      "FOLD 4\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:01:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC of fold 4 is 0.8570563164588454\n",
      "Overall ROC_AUC is 0.8569724079813386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/sf/code/kaggle/tabular_playgrounds/oct2021/preds/stacking_manual_20211031_160241nb-20211031170152run-X_orig_test_lv4xgb_passthru_preds.joblib']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = oof_y\n",
    "oof_preds = []\n",
    "oof_y = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(oof_all_lvs, y)):\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **xgb_lv4_params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    oof_preds.extend(preds)\n",
    "    oof_y.extend(y_valid)\n",
    "    \n",
    "    test_preds += model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f\"ROC AUC of fold {fold} is {valid_auc}\")\n",
    "    \n",
    "#     dump(preds, /'lv_3)\n",
    "\n",
    "valid_auc_total = roc_auc_score(y_true=oof_y, y_score=oof_preds)\n",
    "print(f\"Overall ROC_AUC is {valid_auc_total}\")\n",
    "\n",
    "dump(oof_preds, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_oof_lv4xgb_passthru_preds.joblib\")\n",
    "dump(oof_y, predpath/'oof_lv4_y.joblib')\n",
    "\n",
    "test_preds /= 5\n",
    "\n",
    "dump(test_preds, predpath/f\"{wandb_config['name']}nb-{datetime.now().strftime('%Y%m%d%H%M%S')}run-X_orig_test_lv4xgb_passthru_preds.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169a83c-3a09-4048-b248-a9a47111a3d5",
   "metadata": {},
   "source": [
    "Notionally better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3a806-c9cd-45c1-b5da-e35129184137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d64740-a89f-4036-9fa7-bc233f9a7ac4",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1193a028-ea7f-4635-8c36-5cd517894784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cecede81-21ca-414d-8e1a-57baa3e5be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f5c9fc8c-45ab-4ea6-b40b-15149ad43751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.708235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>0.262932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>0.916396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003</td>\n",
       "      <td>0.808739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>0.284263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    target\n",
       "0  1000000  0.708235\n",
       "1  1000001  0.262932\n",
       "2  1000002  0.916396\n",
       "3  1000003  0.808739\n",
       "4  1000004  0.284263"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "32d80568-780e-4798-a26b-e2907825f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3d5e653c-a3de-4e25-a22f-4d7d0e1d49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_4level-GBM+TabMLP-ensemble_X-orig_3rs_{exmodel_config['kfolds']}folds_finalrs{42}_preds-FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6d256-1e73-4331-9464-a911c05943c8",
   "metadata": {},
   "source": [
    "LB 0.85628 -- an improvement, at long last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c8dfd-4282-45fb-bd1b-cebccbaea68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log({'leaderboard_auc': ,\n",
    "# #            'catboost_params': str(best_catboost_params),\n",
    "#           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1cda7-ee10-4db7-9d99-2748be655a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188650a9-6b22-45c6-9ff7-996fe917b5b4",
   "metadata": {},
   "source": [
    "# Power Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261029fd-fd23-4785-9144-990ba07180a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_sub = sample_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d4313-541c-4abf-a06d-38363f8cb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_preds = stack_sub.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d39f1-1bc2-49b8-bb6f-53784be6a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat1983_preds = load(predpath/'stacking_manual_20211005_205933_catboost_5folds_rs1983_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b302164-b933-47fe-b245-d0e00d5693fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d27110-7a50-410d-9958-605702d297cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack_sub.iloc[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c0782-89d2-49d6-8aca-88b2e45305ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb1983_preds = load(predpath/'stacking_manual_20211005_205933_lightgbm_5folds_rs1983_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832d4b8-d36b-433f-ba35-4c4997e566a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb1983_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6e776-d3b7-4dc2-ab49-45ed4825e62f",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "Before I make these predictions, let's try some rigor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a3a43-2947-419d-8c9c-f729612ec63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627db17-d6f3-4ab3-9832-698e6b180f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cf707-6d53-453e-8169-9fbfd7897c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_lv1.iloc[:,:].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524630b-ce15-4074-bc77-bce503550fd1",
   "metadata": {},
   "source": [
    "- So what this is saying is,XGBoost (models 0 and 1) is a bit closer to LightGBM (models 2 and 3) than to CatBoost (models 4 and 5), and LightGBM is closer to Catboost than to XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e39c35-2237-442a-83c8-685fda60ecfe",
   "metadata": {},
   "source": [
    "What if we bring in the full stack's predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380dcb6e-d7fd-4ef5-955a-31983febcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_feature = pd.Series(test_preds, name='full_stack')\n",
    "corr_compare = test_lv1.join(stack_feature)\n",
    "corr_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc117d74-1b3b-4016-ab09-9cd3bcb56a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_compare.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8efa3-8d9a-409a-aac8-3b9dbe747a3b",
   "metadata": {},
   "source": [
    "- So this is indicating that the stack is further apart from each of the GBMs than they are from one another -- but, it's marginally closer to CatBoost than to LightGBM, and it's definitely closer to both of those than to XGBoost alone. **So, wrt power averaging, it actually may not make sense to power average with CatBoost and LightGBM alongside the stack.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e2e1a-91de-4968-a6d0-bf68bbcf43cf",
   "metadata": {},
   "source": [
    "What if we bring in some `widedeep` predictions too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff6a31-076d-4669-9dbb-7c715cabe6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep_preds = load(predpath/'stacking_manual_20211012_194716_widedeep-TabMLP_5folds_rs1983_500epochs_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e42ee-ac0b-456b-aaff-230557f16ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(widedeep_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ba23b-38e8-45cd-9644-af632edba07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep_preds = pd.Series(widedeep_preds, name='widedeep_tabmlp1983')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e052c-aba7-458a-af27-0fd9af85b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_compare_deep = corr_compare.join(widedeep_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7ca5b-fc17-47a5-be58-08ddec6653a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_compare_deep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71282a20-5ef9-40d7-897e-563ac8b5ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_compare_deep.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2aff57-0237-4e45-9e6e-6ccef16a22b0",
   "metadata": {},
   "source": [
    "## Modified Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dae3c-3c8c-44aa-9874-ead3ccf27d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix = 0.5*stack_preds + 0.4*test_lv1_xgb42 + 0.1*widedeep_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cceab2-2972-4405-b967-b3483b5b9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2804828-19c2-443b-ad08-9bab6e8bf2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12378ce3-b713-4952-9dbc-54ec1faa9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = mod_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b22e9-8ad0-48a6-9ab1-5661e3c581df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a0531-b5a3-4e21-a9e3-afb6b83aab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0ddb9-7606-4b76-a856-5f19255244d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-X_orig+KMeans8+synth-0.5stack_0.4xgb42_0.1tabmlp1983_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea56ae-cad7-42ac-ae07-a0ed0a7af92a",
   "metadata": {},
   "source": [
    "## Mod Mix Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49747714-8a6c-4d24-8d00-7f80bab4564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_two = 0.6*stack_preds + 0.2*test_lv1_xgb42 + 0.05*test_lv1_lgb42 + 0.05*test_lv1_cat42 + 0.1*widedeep_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c90d7-7bd3-4891-a078-1bc2852ab5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_two[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507c000-7e9e-4b8f-96b8-ad3ea39fba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30aaeb1-6d7e-4412-8044-7df0faa6df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = mod_mix_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfe90a-69d0-4a3e-b1b2-c30af8a372bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59421a-6bf9-4717-b5b2-b19680663818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42d162-588b-4fa0-b9e1-24beb2b27609",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-0.6stack_0.2xgb42_0.1tabmlp1983_0.05lgb42_0.05cat42_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f59805-ea37-479f-92e1-b7251fd3ff86",
   "metadata": {},
   "source": [
    "# Mod Mix Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2c595-2dca-405e-985d-fd7a4ea6c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_three = 0.5*stack_preds + 0.3*test_lv1_xgb42 + 0.05*test_lv1_lgb42 + 0.05*test_lv1_cat42 + 0.1*widedeep_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236110c6-8fda-4509-b6f2-33f18400763f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a0dbe-fb0f-4f08-b6d5-69671c1fd074",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = mod_mix_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93860a9f-3335-4602-a061-32cd7e5f3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ae46-8978-489f-8ffc-329ac842e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248cf0d-8f14-426a-a5b0-01f1e6434256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-0.5stack_0.3xgb42_0.1tabmlp1983_0.05lgb42_0.05cat42_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3476e9-6947-432d-858c-fd6afcac7433",
   "metadata": {},
   "source": [
    "## 4th power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1b2f7-a1d0-4adb-b19e-53222489bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_mix_three_pow4 = 0.5*stack_preds**4 + 0.3*test_lv1_xgb42**4 + 0.05*test_lv1_lgb42**4 + 0.05*test_lv1_cat42**4 + 0.1*widedeep_preds**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5e31f-1e63-4e52-8c44-b2cda14ba59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d571-33d8-4909-b77e-65639167e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = mod_mix_three_pow4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365e324-02c5-4fc9-bdd4-81bc4a2cdf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8a2d4-898f-4531-af52-28f40edbc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37721c0-ddf7-430b-b273-2a25b52298fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-0.5stack_0.3xgb42_0.1tabmlp1983_0.05lgb42_0.05cat42_pow4_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f1361-c7fc-49b2-86e5-844487bca686",
   "metadata": {},
   "outputs": [],
   "source": [
    "power4_avg_alt = 0.5*stack_preds**4 + 0.4*test_lv1_xgb42 + 0.1*widedeep_preds** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28966015-2491-428d-8a74-6f8e5e19330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power4_avg_alt[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f353c-ea30-4360-aebb-23d4d89d39d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a1c7f-3350-4610-9cb4-e8f1c4d8d89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a835c-7077-425d-acdf-8af36a864605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = power4_avg_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4b808-d9fe-490c-a078-71e695f94fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24018d55-37f4-4586-b853-9840b1e7564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27df16-b3e8-4fd8-b4ca-d8d3533de81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-0.5stack_0.4xgb42_0.1tabmlp1983_pow-avg4_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152f70e-867f-4042-98a2-c955ab265892",
   "metadata": {},
   "source": [
    "## 6th power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c026f46-3f2a-4570-a856-3615945af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "power6_avg = (stack_preds**6 + cat1983_preds**6 + lgb1983_preds**6) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2de33-5e52-45c4-98ea-f4da676dbe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "power6_avg[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88965733-2a5b-498e-bb57-fbba89929a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5d894-77a5-4412-9f69-395581b18048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d6475-8c93-48e7-998c-01aef9c38136",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = power6_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584579e-c04f-482e-8a1b-cfa53a6ce468",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91341fd2-7ddb-443f-b653-b203f5adead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970d847-5cf8-48fe-bcbd-57def1a70309",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-stack_cat1983_lgb1983_pow-avg6_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f544286-a2ae-46fb-b358-d1c0d8af81a8",
   "metadata": {},
   "source": [
    "## 5th power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f75b6-6c95-49b0-9df8-f2924176a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "power5_avg = (stack_preds**5 + cat1983_preds**5 + lgb1983_preds**5) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0a842-b42a-4b42-b2dc-24b5871aaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power5_avg[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd42c5-9de0-4c28-9b42-71b965a9f148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c7ee4-20e2-44b2-8b95-afe3e2386cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b19c3-7249-4c27-be92-3250990f7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = power5_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0f742-5076-4c5d-be11-9aaa0e4fc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec99b0-4581-4c1b-91af-f9fbc988406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478bab0-280f-493b-8ad6-4db7eb259ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-stack_cat1983_lgb1983_pow-avg5_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a7092-551c-453e-a529-f225caf84334",
   "metadata": {},
   "source": [
    "## 3rd power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6f07f-0d59-4972-ac21-d0d4aec233bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "power3_avg = (stack_preds**3 + cat1983_preds**3 + lgb1983_preds**3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcbcc7-d5d5-4233-b091-14c474e4dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power5_avg[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08039950-9ee8-4347-a3ce-603f3d2127e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676ca5a-9491-4797-9e41-cb31ef96967d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2872c8-9db5-4564-93c9-788e05e563b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = power3_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063b49a-13f5-49f1-ace5-35429ff51f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcfc39-c682-452a-95da-c35fe2a7b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c73b0e-0ceb-4c7b-96bc-857b6f499966",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-GBM-stack_cat1983_lgb1983_pow-avg3_ensemble_preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
