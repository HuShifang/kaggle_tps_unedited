{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e956e261-cd6a-4337-bb90-5082d7bdb582",
   "metadata": {},
   "source": [
    "# denoising_20211109\n",
    "Taking ideas from [this Bryan Arnold notebook](https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21), which does a few cool things but mainly attempts denoising the labels with `cleanlab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import datatable as dt\n",
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495d9a8-d339-4ead-9c92-fb382da7e59f",
   "metadata": {},
   "source": [
    "- `gc` is the garbage collection interface in Python; he uses it to optimize memory utilization, in tandem with `del` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d84988-5ddb-40d9-bc12-826012acb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from torchmetrics import AUROC\n",
    "# import torch\n",
    "# from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880b9f33-b517-40ef-a3e6-049dcc52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5b910-f9fe-4a8f-9981-bba2a2b9c99a",
   "metadata": {},
   "source": [
    "The following function is used to optimize dataset memory utilization in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd31b35-397d-46e7-9cb8-49bec94ef2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c2f4c-bec4-4df0-a418-7ec31595b9bb",
   "metadata": {},
   "source": [
    "- Basically, you start by creating a list of the numeric types you may be using, and initializing the memory utilization (so you can see at the end how much you've saved). \n",
    "- Then, you iterate over the columns (`for col in df.columns:`) and check if the column's [[data type]] is numeric; if it is, then you store the minimum and maximum values for the column (since one of them is guaranteed to be the biggest memory-hog of the bunch, though which depends on the feature's range). \n",
    "- Then, you start going through a series of case statements, deciding whether the datatype is an integer or not, and then proceeding through the different [[NumPy]] integer or float types in increasing size, [[typecasting]] when you come to the first size that will accommodate both the max and min value from the column. (*Note here that `np.iinfo(np.int64).min` et al will apparently return a value rather than an absolute size in bits, which is fine.*)\n",
    "- Then, you find out what the final memory size is, and print out how big of a savings you've obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca30399c-36e0-4ced-87f3-0edc363221b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': datapath/'X_orig.feather',\n",
    "    'target_source': datapath/'y_orig.joblib',\n",
    "    # 'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60cd4c5f-d848-4e4c-9fa6-097961ac8cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "# dataset_params = {\n",
    "#     'train_source': str(datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "#     'target_source': str(datapath/'y_orig.joblib'),\n",
    "#     'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "#     'scaler': str(RobustScaler()),\n",
    "#     'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "#     'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "# }   \n",
    "\n",
    "# # referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# # dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# # now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "# y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "\n",
    "# dataset_params['feature_count'] = X.shape[1]\n",
    "# dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a79ce6-a08e-4f31-94f9-edb77143e1d7",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d647e8af-e065-4ea8-aa6c-5d158791904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# exmodel_config = {\n",
    "# #     \"feature_selector\": SelectKBest,\n",
    "# #     \"k_best\": 80,\n",
    "# #     \"feature_selection_scoring\": f_regression,\n",
    "# #     'random_state': SEED,\n",
    "# #     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "# #     'subsample': 1,\n",
    "#     'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 5, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "#     **dataset_params\n",
    "# #     'features_created': False,\n",
    "# #     'feature_creator': None,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e413bb-53c4-4e45-8d52-2169fe3775d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.59437</td>\n",
       "      <td>132.8040</td>\n",
       "      <td>3.18428</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.73238</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.09959</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>1.09862</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.97877</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.67336</td>\n",
       "      <td>76.5336</td>\n",
       "      <td>3.37825</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.27562</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.54594</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>3.46017</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.57786</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.49747</td>\n",
       "      <td>233.5460</td>\n",
       "      <td>2.19435</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.05687</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.80187</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>4.88300</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001688</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.14112</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>779.9670</td>\n",
       "      <td>1.89064</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.69800</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.50332</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>3.47439</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.96860</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.71542</td>\n",
       "      <td>156.1280</td>\n",
       "      <td>2.14772</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.15492</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.37145</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>1.91059</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.07481</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2       f3        f4       f5       f6        f7  \\\n",
       "0  0.106643  3.59437  132.8040  3.18428  0.081971  1.18859  3.73238  2.266270   \n",
       "1  0.125021  1.67336   76.5336  3.37825  0.099400  5.09366  1.27562 -0.471318   \n",
       "2  0.036330  1.49747  233.5460  2.19435  0.026914  3.12694  5.05687  3.849460   \n",
       "3 -0.014077  0.24600  779.9670  1.89064  0.006948  1.53112  2.69800  4.517330   \n",
       "4 -0.003259  3.71542  156.1280  2.14772  0.018284  2.09859  4.15492 -0.038236   \n",
       "\n",
       "        f8        f9  ...       f90      f91       f92       f93       f94  \\\n",
       "0  2.09959  0.012330  ...  0.010739  1.09862  0.013331 -0.011715  0.052759   \n",
       "1  4.54594  0.037706  ...  0.135838  3.46017  0.017054  0.124863  0.154064   \n",
       "2  1.80187  0.056995  ...  0.117310  4.88300  0.085222  0.032396  0.116092   \n",
       "3  4.50332  0.123494  ... -0.015347  3.47439 -0.017103 -0.008100  0.062013   \n",
       "4  3.37145  0.034166  ...  0.013781  1.91059 -0.042943  0.105616  0.125072   \n",
       "\n",
       "        f95       f96      f97       f98       f99  \n",
       "0  0.065400  4.211250  1.97877  0.085974  0.240496  \n",
       "1  0.606848 -0.267928  2.57786 -0.020877  0.024719  \n",
       "2 -0.001688 -0.520069  2.14112  0.124464  0.148209  \n",
       "3  0.041193  0.511657  1.96860  0.040017  0.044873  \n",
       "4  0.037509  1.043790  1.07481 -0.012819  0.072798  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c93da36-c96b-4592-89bd-3f9ddcb8d5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.414343</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.223129</td>\n",
       "      <td>0.219181</td>\n",
       "      <td>-0.549174</td>\n",
       "      <td>0.356604</td>\n",
       "      <td>-0.117173</td>\n",
       "      <td>-0.149785</td>\n",
       "      <td>-0.569723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615937</td>\n",
       "      <td>-0.519509</td>\n",
       "      <td>-0.523000</td>\n",
       "      <td>-1.073580</td>\n",
       "      <td>-0.111175</td>\n",
       "      <td>0.042435</td>\n",
       "      <td>0.625515</td>\n",
       "      <td>-0.282294</td>\n",
       "      <td>0.287257</td>\n",
       "      <td>2.097848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073411</td>\n",
       "      <td>-0.324111</td>\n",
       "      <td>-0.220699</td>\n",
       "      <td>0.301799</td>\n",
       "      <td>0.406584</td>\n",
       "      <td>0.980651</td>\n",
       "      <td>-0.584290</td>\n",
       "      <td>-1.216782</td>\n",
       "      <td>0.824004</td>\n",
       "      <td>-0.258296</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.432846</td>\n",
       "      <td>-0.487967</td>\n",
       "      <td>1.071220</td>\n",
       "      <td>0.943432</td>\n",
       "      <td>7.115126</td>\n",
       "      <td>-1.115475</td>\n",
       "      <td>-0.041835</td>\n",
       "      <td>-0.812236</td>\n",
       "      <td>-0.388992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.165673</td>\n",
       "      <td>-0.391725</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>-0.178365</td>\n",
       "      <td>-0.372808</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>0.863859</td>\n",
       "      <td>0.518747</td>\n",
       "      <td>-0.268295</td>\n",
       "      <td>-0.021567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882475</td>\n",
       "      <td>1.006638</td>\n",
       "      <td>0.153544</td>\n",
       "      <td>-0.380862</td>\n",
       "      <td>0.548134</td>\n",
       "      <td>-0.833910</td>\n",
       "      <td>-1.213478</td>\n",
       "      <td>-0.217131</td>\n",
       "      <td>0.683318</td>\n",
       "      <td>1.034235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.301555</td>\n",
       "      <td>-0.872802</td>\n",
       "      <td>2.498527</td>\n",
       "      <td>-0.301544</td>\n",
       "      <td>-0.587486</td>\n",
       "      <td>-0.414987</td>\n",
       "      <td>-0.039545</td>\n",
       "      <td>0.787011</td>\n",
       "      <td>0.807038</td>\n",
       "      <td>0.794548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.982719</td>\n",
       "      <td>0.438580</td>\n",
       "      <td>-0.809415</td>\n",
       "      <td>-1.016802</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>-0.273769</td>\n",
       "      <td>-0.812462</td>\n",
       "      <td>-0.286376</td>\n",
       "      <td>-0.185636</td>\n",
       "      <td>-0.156724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.272393</td>\n",
       "      <td>0.460876</td>\n",
       "      <td>0.086985</td>\n",
       "      <td>-0.197278</td>\n",
       "      <td>-0.465605</td>\n",
       "      <td>-0.192678</td>\n",
       "      <td>0.518429</td>\n",
       "      <td>-1.042825</td>\n",
       "      <td>0.356489</td>\n",
       "      <td>-0.301740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573168</td>\n",
       "      <td>-0.192062</td>\n",
       "      <td>-1.052588</td>\n",
       "      <td>0.768968</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>-0.321887</td>\n",
       "      <td>-0.605630</td>\n",
       "      <td>-0.645120</td>\n",
       "      <td>-0.729316</td>\n",
       "      <td>0.165118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.023869  0.414343 -0.003178  0.223129  0.219181 -0.549174  0.356604   \n",
       "1  0.073411 -0.324111 -0.220699  0.301799  0.406584  0.980651 -0.584290   \n",
       "2 -0.165673 -0.391725  0.386256 -0.178365 -0.372808  0.210182  0.863859   \n",
       "3 -0.301555 -0.872802  2.498527 -0.301544 -0.587486 -0.414987 -0.039545   \n",
       "4 -0.272393  0.460876  0.086985 -0.197278 -0.465605 -0.192678  0.518429   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.117173 -0.149785 -0.569723  ... -0.615937 -0.519509 -0.523000 -1.073580   \n",
       "1 -1.216782  0.824004 -0.258296  ...  1.142983  0.432846 -0.487967  1.071220   \n",
       "2  0.518747 -0.268295 -0.021567  ...  0.882475  1.006638  0.153544 -0.380862   \n",
       "3  0.787011  0.807038  0.794548  ... -0.982719  0.438580 -0.809415 -1.016802   \n",
       "4 -1.042825  0.356489 -0.301740  ... -0.573168 -0.192062 -1.052588  0.768968   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.111175  0.042435  0.625515 -0.282294  0.287257  2.097848  \n",
       "1  0.943432  7.115126 -1.115475 -0.041835 -0.812236 -0.388992  \n",
       "2  0.548134 -0.833910 -1.213478 -0.217131  0.683318  1.034235  \n",
       "3 -0.014837 -0.273769 -0.812462 -0.286376 -0.185636 -0.156724  \n",
       "4  0.641618 -0.321887 -0.605630 -0.645120 -0.729316  0.165118  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_robust = RobustScaler().fit_transform(X)\n",
    "X_robust = pd.DataFrame(X_robust, columns=X.columns)\n",
    "X_robust.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c1db18-b757-42f0-ac14-24660401c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadc1986-6372-4e9b-a831-ec553e793323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382553</td>\n",
       "      <td>0.705772</td>\n",
       "      <td>-0.315075</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>-0.229657</td>\n",
       "      <td>-0.875660</td>\n",
       "      <td>0.660314</td>\n",
       "      <td>-0.197064</td>\n",
       "      <td>-0.286162</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>-0.872508</td>\n",
       "      <td>-0.258806</td>\n",
       "      <td>-0.595537</td>\n",
       "      <td>-0.199502</td>\n",
       "      <td>-0.196145</td>\n",
       "      <td>1.067358</td>\n",
       "      <td>-0.400887</td>\n",
       "      <td>-0.167145</td>\n",
       "      <td>0.443374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347377</td>\n",
       "      <td>-0.530387</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>-0.187909</td>\n",
       "      <td>1.623543</td>\n",
       "      <td>-0.910506</td>\n",
       "      <td>-1.963980</td>\n",
       "      <td>1.309644</td>\n",
       "      <td>-0.229122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573313</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>-0.252018</td>\n",
       "      <td>0.548089</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>2.392938</td>\n",
       "      <td>-1.806811</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>-0.412110</td>\n",
       "      <td>-0.371198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517136</td>\n",
       "      <td>-0.643571</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.361533</td>\n",
       "      <td>0.364863</td>\n",
       "      <td>1.507175</td>\n",
       "      <td>0.824771</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.183401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408845</td>\n",
       "      <td>1.580886</td>\n",
       "      <td>-0.127714</td>\n",
       "      <td>-0.226174</td>\n",
       "      <td>-0.062423</td>\n",
       "      <td>-0.516946</td>\n",
       "      <td>-1.968603</td>\n",
       "      <td>-0.294434</td>\n",
       "      <td>-0.078904</td>\n",
       "      <td>0.094984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613619</td>\n",
       "      <td>-1.448884</td>\n",
       "      <td>0.857867</td>\n",
       "      <td>-0.490286</td>\n",
       "      <td>-0.409357</td>\n",
       "      <td>-0.656445</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1.255833</td>\n",
       "      <td>1.281843</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.768719</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>-0.314304</td>\n",
       "      <td>-0.565262</td>\n",
       "      <td>-0.179472</td>\n",
       "      <td>-0.311897</td>\n",
       "      <td>-1.306572</td>\n",
       "      <td>-0.407556</td>\n",
       "      <td>-0.272505</td>\n",
       "      <td>-0.295118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592913</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.382205</td>\n",
       "      <td>-0.293270</td>\n",
       "      <td>0.930480</td>\n",
       "      <td>-1.684456</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510155</td>\n",
       "      <td>-0.346112</td>\n",
       "      <td>-0.361423</td>\n",
       "      <td>0.386926</td>\n",
       "      <td>-0.042986</td>\n",
       "      <td>-0.329511</td>\n",
       "      <td>-0.965117</td>\n",
       "      <td>-0.993613</td>\n",
       "      <td>-0.393636</td>\n",
       "      <td>-0.189697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.382553  0.705772 -0.315075  0.347277 -0.229657 -0.875660  0.660314   \n",
       "1 -0.347377 -0.530387 -0.417061  0.472862 -0.187909  1.623543 -0.910506   \n",
       "2 -0.517136 -0.643571 -0.132486 -0.293650 -0.361533  0.364863  1.507175   \n",
       "3 -0.613619 -1.448884  0.857867 -0.490286 -0.409357 -0.656445 -0.001055   \n",
       "4 -0.592913  0.783666 -0.272802 -0.323841 -0.382205 -0.293270  0.930480   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.197064 -0.286162 -0.289270  ... -0.537157 -0.872508 -0.258806 -0.595537   \n",
       "1 -1.963980  1.309644 -0.229122  ...  0.573313  0.658473 -0.252018  0.548089   \n",
       "2  0.824771 -0.480372 -0.183401  ...  0.408845  1.580886 -0.127714 -0.226174   \n",
       "3  1.255833  1.281843 -0.025780  ... -0.768719  0.667692 -0.314304 -0.565262   \n",
       "4 -1.684456  0.543499 -0.237512  ... -0.510155 -0.346112 -0.361423  0.386926   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.199502 -0.196145  1.067358 -0.400887 -0.167145  0.443374  \n",
       "1  0.019765  2.392938 -1.806811 -0.008064 -0.412110 -0.371198  \n",
       "2 -0.062423 -0.516946 -1.968603 -0.294434 -0.078904  0.094984  \n",
       "3 -0.179472 -0.311897 -1.306572 -0.407556 -0.272505 -0.295118  \n",
       "4 -0.042986 -0.329511 -0.965117 -0.993613 -0.393636 -0.189697  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standard = StandardScaler().fit_transform(X)\n",
    "X_standard = pd.DataFrame(X_standard, columns=X.columns)\n",
    "X_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5143d984-1480-4453-8790-0d8e41547cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c610d19c-ddd3-4d01-a754-dde244eddf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.330764</td>\n",
       "      <td>0.720239</td>\n",
       "      <td>-0.185486</td>\n",
       "      <td>0.362574</td>\n",
       "      <td>-0.156842</td>\n",
       "      <td>-0.853394</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>-0.160510</td>\n",
       "      <td>-0.234598</td>\n",
       "      <td>-0.357589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565506</td>\n",
       "      <td>-0.847819</td>\n",
       "      <td>-0.307379</td>\n",
       "      <td>-0.927254</td>\n",
       "      <td>-0.194510</td>\n",
       "      <td>-0.098997</td>\n",
       "      <td>1.055397</td>\n",
       "      <td>-0.388207</td>\n",
       "      <td>-0.105342</td>\n",
       "      <td>0.724264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.272488</td>\n",
       "      <td>-0.486992</td>\n",
       "      <td>-0.313108</td>\n",
       "      <td>0.485275</td>\n",
       "      <td>-0.087189</td>\n",
       "      <td>1.558091</td>\n",
       "      <td>-0.899712</td>\n",
       "      <td>-2.103362</td>\n",
       "      <td>1.270651</td>\n",
       "      <td>-0.229298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>0.676891</td>\n",
       "      <td>-0.297071</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>2.603714</td>\n",
       "      <td>-1.911892</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>-0.532986</td>\n",
       "      <td>-0.400761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567016</td>\n",
       "      <td>-0.604689</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>-0.272131</td>\n",
       "      <td>-0.388096</td>\n",
       "      <td>0.395922</td>\n",
       "      <td>1.479006</td>\n",
       "      <td>0.828781</td>\n",
       "      <td>-0.432729</td>\n",
       "      <td>-0.135055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468604</td>\n",
       "      <td>1.513583</td>\n",
       "      <td>-0.111917</td>\n",
       "      <td>-0.323559</td>\n",
       "      <td>0.091440</td>\n",
       "      <td>-0.786038</td>\n",
       "      <td>-2.114633</td>\n",
       "      <td>-0.281473</td>\n",
       "      <td>0.036836</td>\n",
       "      <td>0.283660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.750805</td>\n",
       "      <td>-1.499700</td>\n",
       "      <td>0.958682</td>\n",
       "      <td>-0.470166</td>\n",
       "      <td>-0.476486</td>\n",
       "      <td>-0.621742</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>1.230873</td>\n",
       "      <td>1.245859</td>\n",
       "      <td>0.170004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829848</td>\n",
       "      <td>0.685489</td>\n",
       "      <td>-0.392448</td>\n",
       "      <td>-0.876844</td>\n",
       "      <td>-0.151133</td>\n",
       "      <td>-0.331031</td>\n",
       "      <td>-1.324488</td>\n",
       "      <td>-0.394903</td>\n",
       "      <td>-0.282993</td>\n",
       "      <td>-0.280477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.710261</td>\n",
       "      <td>0.792576</td>\n",
       "      <td>-0.135717</td>\n",
       "      <td>-0.302424</td>\n",
       "      <td>-0.425993</td>\n",
       "      <td>-0.249634</td>\n",
       "      <td>0.928278</td>\n",
       "      <td>-1.759618</td>\n",
       "      <td>0.571015</td>\n",
       "      <td>-0.246894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534985</td>\n",
       "      <td>-0.297603</td>\n",
       "      <td>-0.465794</td>\n",
       "      <td>0.627528</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.367829</td>\n",
       "      <td>-0.951063</td>\n",
       "      <td>-0.988675</td>\n",
       "      <td>-0.498888</td>\n",
       "      <td>-0.119675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.330764  0.720239 -0.185486  0.362574 -0.156842 -0.853394  0.667399   \n",
       "1 -0.272488 -0.486992 -0.313108  0.485275 -0.087189  1.558091 -0.899712   \n",
       "2 -0.567016 -0.604689  0.020900 -0.272131 -0.388096  0.395922  1.479006   \n",
       "3 -0.750805 -1.499700  0.958682 -0.470166 -0.476486 -0.621742  0.019516   \n",
       "4 -0.710261  0.792576 -0.135717 -0.302424 -0.425993 -0.249634  0.928278   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.160510 -0.234598 -0.357589  ... -0.565506 -0.847819 -0.307379 -0.927254   \n",
       "1 -2.103362  1.270651 -0.229298  ...  0.641452  0.676891 -0.297071  0.867816   \n",
       "2  0.828781 -0.432729 -0.135055  ...  0.468604  1.513583 -0.111917 -0.323559   \n",
       "3  1.230873  1.245859  0.170004  ... -0.829848  0.685489 -0.392448 -0.876844   \n",
       "4 -1.759618  0.571015 -0.246894  ... -0.534985 -0.297603 -0.465794  0.627528   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.194510 -0.098997  1.055397 -0.388207 -0.105342  0.724264  \n",
       "1  0.251454  2.603714 -1.911892  0.004260 -0.532986 -0.400761  \n",
       "2  0.091440 -0.786038 -2.114633 -0.281473  0.036836  0.283660  \n",
       "3 -0.151133 -0.331031 -1.324488 -0.394903 -0.282993 -0.280477  \n",
       "4  0.130013 -0.367829 -0.951063 -0.988675 -0.498888 -0.119675  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_power = PowerTransformer().fit_transform(X)\n",
    "X_power = pd.DataFrame(X_power, columns=X.columns)\n",
    "X_power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e74a11-18ca-4f68-aab9-e08ca71717c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524853</td>\n",
       "      <td>0.708279</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.601757</td>\n",
       "      <td>0.615981</td>\n",
       "      <td>0.235575</td>\n",
       "      <td>0.689244</td>\n",
       "      <td>0.445161</td>\n",
       "      <td>0.430700</td>\n",
       "      <td>0.208504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188796</td>\n",
       "      <td>0.226388</td>\n",
       "      <td>0.225639</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>0.521712</td>\n",
       "      <td>0.829877</td>\n",
       "      <td>0.374985</td>\n",
       "      <td>0.646461</td>\n",
       "      <td>0.884742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.569210</td>\n",
       "      <td>0.349651</td>\n",
       "      <td>0.339730</td>\n",
       "      <td>0.640245</td>\n",
       "      <td>0.699997</td>\n",
       "      <td>0.954619</td>\n",
       "      <td>0.227940</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.888431</td>\n",
       "      <td>0.360631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901757</td>\n",
       "      <td>0.702314</td>\n",
       "      <td>0.242310</td>\n",
       "      <td>0.945676</td>\n",
       "      <td>0.873161</td>\n",
       "      <td>0.969689</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>0.481632</td>\n",
       "      <td>0.101632</td>\n",
       "      <td>0.288204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285286</td>\n",
       "      <td>0.313865</td>\n",
       "      <td>0.702259</td>\n",
       "      <td>0.413750</td>\n",
       "      <td>0.292967</td>\n",
       "      <td>0.601331</td>\n",
       "      <td>0.947447</td>\n",
       "      <td>0.755695</td>\n",
       "      <td>0.366651</td>\n",
       "      <td>0.488799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860375</td>\n",
       "      <td>0.943617</td>\n",
       "      <td>0.584301</td>\n",
       "      <td>0.308015</td>\n",
       "      <td>0.760965</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.405745</td>\n",
       "      <td>0.792971</td>\n",
       "      <td>0.855855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116842</td>\n",
       "      <td>0.071780</td>\n",
       "      <td>0.894046</td>\n",
       "      <td>0.348115</td>\n",
       "      <td>0.183657</td>\n",
       "      <td>0.304618</td>\n",
       "      <td>0.482549</td>\n",
       "      <td>0.880025</td>\n",
       "      <td>0.882009</td>\n",
       "      <td>0.840215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>0.075571</td>\n",
       "      <td>0.491928</td>\n",
       "      <td>0.353474</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0.373276</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>0.413024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148440</td>\n",
       "      <td>0.734622</td>\n",
       "      <td>0.556966</td>\n",
       "      <td>0.403929</td>\n",
       "      <td>0.243439</td>\n",
       "      <td>0.413076</td>\n",
       "      <td>0.785829</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.660243</td>\n",
       "      <td>0.337470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206515</td>\n",
       "      <td>0.402987</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.794711</td>\n",
       "      <td>0.328270</td>\n",
       "      <td>0.207874</td>\n",
       "      <td>0.196023</td>\n",
       "      <td>0.129622</td>\n",
       "      <td>0.587897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.524853  0.708279  0.498227  0.601757  0.615981  0.235575  0.689244   \n",
       "1  0.569210  0.349651  0.339730  0.640245  0.699997  0.954619  0.227940   \n",
       "2  0.285286  0.313865  0.702259  0.413750  0.292967  0.601331  0.947447   \n",
       "3  0.116842  0.071780  0.894046  0.348115  0.183657  0.304618  0.482549   \n",
       "4  0.148440  0.734622  0.556966  0.403929  0.243439  0.413076  0.785829   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0  0.445161  0.430700  0.208504  ...  0.188796  0.226388  0.225639  0.062870   \n",
       "1  0.010521  0.888431  0.360631  ...  0.901757  0.702314  0.242310  0.945676   \n",
       "2  0.755695  0.366651  0.488799  ...  0.860375  0.943617  0.584301  0.308015   \n",
       "3  0.880025  0.882009  0.840215  ...  0.064177  0.705091  0.112006  0.075571   \n",
       "4  0.038596  0.660243  0.337470  ...  0.206515  0.402987  0.047811  0.860640   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0  0.440959  0.521712  0.829877  0.374985  0.646461  0.884742  \n",
       "1  0.873161  0.969689  0.020048  0.481632  0.101632  0.288204  \n",
       "2  0.760965  0.105666  0.008053  0.405745  0.792971  0.855855  \n",
       "3  0.491928  0.353474  0.108497  0.373276  0.394803  0.413024  \n",
       "4  0.794711  0.328270  0.207874  0.196023  0.129622  0.587897  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "X_quantile = QuantileTransformer().fit_transform(X)\n",
    "X_quantile = pd.DataFrame(X_quantile, columns=X.columns)\n",
    "X_quantile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eadcedd9-2c96-4a0b-a41c-0be898c2736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058439</td>\n",
       "      <td>0.545402</td>\n",
       "      <td>-0.006520</td>\n",
       "      <td>0.251106</td>\n",
       "      <td>0.293641</td>\n",
       "      <td>-0.723694</td>\n",
       "      <td>0.493748</td>\n",
       "      <td>-0.131654</td>\n",
       "      <td>-0.178317</td>\n",
       "      <td>-0.806803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.888560</td>\n",
       "      <td>-0.756515</td>\n",
       "      <td>-0.755013</td>\n",
       "      <td>-1.538723</td>\n",
       "      <td>-0.150822</td>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.945523</td>\n",
       "      <td>-0.313074</td>\n",
       "      <td>0.379596</td>\n",
       "      <td>1.205548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173059</td>\n",
       "      <td>-0.383496</td>\n",
       "      <td>-0.415184</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.519891</td>\n",
       "      <td>1.703883</td>\n",
       "      <td>-0.747889</td>\n",
       "      <td>-2.296824</td>\n",
       "      <td>1.225082</td>\n",
       "      <td>-0.355518</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303408</td>\n",
       "      <td>0.529645</td>\n",
       "      <td>-0.702139</td>\n",
       "      <td>1.610642</td>\n",
       "      <td>1.152154</td>\n",
       "      <td>1.888093</td>\n",
       "      <td>-2.050964</td>\n",
       "      <td>-0.040877</td>\n",
       "      <td>-1.259755</td>\n",
       "      <td>-0.557536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.568764</td>\n",
       "      <td>-0.482315</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>-0.230806</td>\n",
       "      <td>-0.552589</td>\n",
       "      <td>0.260788</td>\n",
       "      <td>1.619715</td>\n",
       "      <td>0.695350</td>\n",
       "      <td>-0.343726</td>\n",
       "      <td>-0.030215</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082079</td>\n",
       "      <td>1.594912</td>\n",
       "      <td>0.208438</td>\n",
       "      <td>-0.505334</td>\n",
       "      <td>0.712735</td>\n",
       "      <td>-1.239604</td>\n",
       "      <td>-2.404666</td>\n",
       "      <td>-0.234336</td>\n",
       "      <td>0.808151</td>\n",
       "      <td>1.066985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.187532</td>\n",
       "      <td>-1.458381</td>\n",
       "      <td>1.245232</td>\n",
       "      <td>-0.400038</td>\n",
       "      <td>-0.904151</td>\n",
       "      <td>-0.511822</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>1.174559</td>\n",
       "      <td>1.191639</td>\n",
       "      <td>0.990184</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520453</td>\n",
       "      <td>0.537570</td>\n",
       "      <td>-1.220441</td>\n",
       "      <td>-1.444288</td>\n",
       "      <td>-0.019740</td>\n",
       "      <td>-0.382473</td>\n",
       "      <td>-1.234826</td>\n",
       "      <td>-0.318433</td>\n",
       "      <td>-0.259399</td>\n",
       "      <td>-0.215769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.042563</td>\n",
       "      <td>0.624011</td>\n",
       "      <td>0.140354</td>\n",
       "      <td>-0.256014</td>\n",
       "      <td>-0.700099</td>\n",
       "      <td>-0.216489</td>\n",
       "      <td>0.793705</td>\n",
       "      <td>-1.767176</td>\n",
       "      <td>0.413965</td>\n",
       "      <td>-0.417051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820200</td>\n",
       "      <td>-0.244171</td>\n",
       "      <td>-1.668502</td>\n",
       "      <td>1.084680</td>\n",
       "      <td>0.828077</td>\n",
       "      <td>-0.450044</td>\n",
       "      <td>-0.815142</td>\n",
       "      <td>-0.849233</td>\n",
       "      <td>-1.116413</td>\n",
       "      <td>0.223979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.058439  0.545402 -0.006520  0.251106  0.293641 -0.723694  0.493748   \n",
       "1  0.173059 -0.383496 -0.415184  0.352251  0.519891  1.703883 -0.747889   \n",
       "2 -0.568764 -0.482315  0.532258 -0.230806 -0.552589  0.260788  1.619715   \n",
       "3 -1.187532 -1.458381  1.245232 -0.400038 -0.904151 -0.511822 -0.041367   \n",
       "4 -1.042563  0.624011  0.140354 -0.256014 -0.700099 -0.216489  0.793705   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.131654 -0.178317 -0.806803  ... -0.888560 -0.756515 -0.755013 -1.538723   \n",
       "1 -2.296824  1.225082 -0.355518  ...  1.303408  0.529645 -0.702139  1.610642   \n",
       "2  0.695350 -0.343726 -0.030215  ...  1.082079  1.594912  0.208438 -0.505334   \n",
       "3  1.174559  1.191639  0.990184  ... -1.520453  0.537570 -1.220441 -1.444288   \n",
       "4 -1.767176  0.413965 -0.417051  ... -0.820200 -0.244171 -1.668502  1.084680   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.150822  0.052447  0.945523 -0.313074  0.379596  1.205548  \n",
       "1  1.152154  1.888093 -2.050964 -0.040877 -1.259755 -0.557536  \n",
       "2  0.712735 -1.239604 -2.404666 -0.234336  0.808151  1.066985  \n",
       "3 -0.019740 -0.382473 -1.234826 -0.318433 -0.259399 -0.215769  \n",
       "4  0.828077 -0.450044 -0.815142 -0.849233 -1.116413  0.223979  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "X_quantile_norm = QuantileTransformer(output_distribution='normal').fit_transform(X)\n",
    "X_quantile_norm = pd.DataFrame(X_quantile_norm, columns=X.columns)\n",
    "X_quantile_norm.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
