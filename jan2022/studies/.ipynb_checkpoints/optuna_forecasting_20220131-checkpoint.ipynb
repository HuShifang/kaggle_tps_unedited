{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba48c47a-dd6b-4902-b333-86a223e82418",
   "metadata": {},
   "source": [
    "# Hybrid\n",
    "Going to attempt a hybrid model after the example of [this Teck Meng Wong notebook](https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series/notebook).\n",
    "\n",
    "- 20220122: Going to try to form ensembles, with more code architecture. Forecasting models will include Prophet, NeuralProphet, Ridge, and Linear (with more to come -- e.g. perhaps transformers and other DNNs); residual models will include GBMs, perhaps some tabular DNNs too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dfc634-98f0-45b8-bf65-931d28ddb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "# if '/sf/' in pwd:\n",
    "#     COLAB, SAGE = False, False\n",
    "# elif 'google.colab' in str(get_ipython()):\n",
    "#     COLAB, SAGE = True, False # do colab-specific installs later\n",
    "# else:\n",
    "#     COLAB, SAGE = False, True\n",
    "    \n",
    "CONTEXT = 'local' # or 'colab', 'sage', 'kaggle'\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a1fae-dd27-45ff-a494-d3572d5893dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c99bcc4-0451-4896-ba41-78477c3a890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720163c-934a-472a-bdef-40de5b849b3e",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf5b0c8-8b46-41d2-8d6e-e017bfcc5540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# normalization\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee770b73-8343-4336-889e-f54d6b1e35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time series\n",
    "# import tsfresh\n",
    "\n",
    "# import darts\n",
    "# from darts import TimeSeries\n",
    "# from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel\n",
    "import holidays\n",
    "import dateutil.easter as easter\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188812f6-26a6-4b9c-b018-094861c5c077",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5b480-e54e-4e88-8826-8b453d3b9cd4",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714cb3da-ac98-479b-b823-57390f846f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONTEXT == 'colab':\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    root = Path('') # TODO\n",
    "\n",
    "elif CONTEXT == 'sage':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "elif CONTEXT == 'kaggle':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "else: # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath, modelpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1c918-7f76-4f7b-b194-7b9e19e4b87e",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9443f858-8b66-4a01-a9ab-aaaf32c54186",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb8923c-bf74-4de6-bffc-e041b8dab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d92853-fc1b-48bc-9236-2777b2209570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ac144e-1440-40cf-b172-bff04134d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-François Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb77153-1063-44a4-953f-043a35bd01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/282735\n",
    "def better_than_median(inputs, axis):\n",
    "    \"\"\"Compute the mean of the predictions if there are no outliers,\n",
    "    or the median if there are outliers.\n",
    "\n",
    "    Parameter: inputs = ndarray of shape (n_samples, n_folds)\"\"\"\n",
    "    spread = inputs.max(axis=axis) - inputs.min(axis=axis) \n",
    "    spread_lim = 0.45\n",
    "    print(f\"Inliers:  {(spread < spread_lim).sum():7} -> compute mean\")\n",
    "    print(f\"Outliers: {(spread >= spread_lim).sum():7} -> compute median\")\n",
    "    print(f\"Total:    {len(inputs):7}\")\n",
    "    return np.where(spread < spread_lim,\n",
    "                    np.mean(inputs, axis=axis),\n",
    "                    np.median(inputs, axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bac0f6-8bb1-453c-b567-398523792a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def plot_periodogram(ts, detrend='linear', ax=None):\n",
    "    from scipy.signal import periodogram\n",
    "    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n",
    "    freqencies, spectrum = periodogram(\n",
    "        ts,\n",
    "        fs=fs,\n",
    "        detrend=detrend,\n",
    "        window=\"boxcar\",\n",
    "        scaling='spectrum',\n",
    "    )\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.step(freqencies, spectrum, color=\"purple\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"Annual (1)\",\n",
    "            \"Semiannual (2)\",\n",
    "            \"Quarterly (4)\",\n",
    "            \"Bimonthly (6)\",\n",
    "            \"Monthly (12)\",\n",
    "            \"Biweekly (26)\",\n",
    "            \"Weekly (52)\",\n",
    "            \"Semiweekly (104)\",\n",
    "        ],\n",
    "        rotation=30,\n",
    "    )\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Periodogram\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a312e2-0175-41b3-a757-a81fb1186fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def fourier_features(index, freq, order):\n",
    "    time = np.arange(len(index), dtype=np.float32)\n",
    "    k = 2 * np.pi * (1 / freq) * time\n",
    "    features = {}\n",
    "    for i in range(1, order + 1):\n",
    "        features.update({\n",
    "            f\"sin_{freq}_{i}\": np.sin(i * k),\n",
    "            f\"cos_{freq}_{i}\": np.cos(i * k),\n",
    "        })\n",
    "    return pd.DataFrame(features, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e560bef-8d90-4f5d-b6b1-4eeb5c0f5b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f704be-62c1-4f86-aec6-3cf2975d64cd",
   "metadata": {},
   "source": [
    "### Original Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ed69e0-b9c6-4017-956f-b19e25238e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "    'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "test_df = pd.read_csv(datapath/'test.csv')\n",
    "orig_train_df = train_df.copy()\n",
    "orig_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9603-5103-4261-bbf4-47ad71eb1042",
   "metadata": {},
   "source": [
    "Since the dates are natively `Object` dtype (i.e. strings), we have to convert them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c268a78-b3db-4dbd-beee-790012b3cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model\n",
    "for df in [train_df, test_df]:\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "# for convenience later\n",
    "countries = ['Sweden', 'Finland', 'Norway']\n",
    "stores = ['KaggleMart', 'KaggleRama']\n",
    "products = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d9b59-f4f9-487b-806d-1f69b7e68450",
   "metadata": {},
   "source": [
    "Provisionally, I'm going to concatenate together the `train_df` and `test_df` for preprocessing, to avoid having to constantly apply transforms twice (since I don't anticipate doing any transforms that might allow data leakage to occur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e13b145-46f1-424b-86db-4a89fabcd0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "# all_df.columns\n",
    "print(len(all_df) == len(train_df) + len(test_df))\n",
    "del train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57249aa-2cec-49be-bbc6-c90773bf541c",
   "metadata": {},
   "source": [
    "### GDP Data\n",
    "Here's data from Carl McBride Ellis ([notebook](https://www.kaggle.com/carlmcbrideellis/gdp-of-finland-norway-and-sweden-2015-2019) and [dataset](https://www.kaggle.com/carlmcbrideellis/gdp-20152019-finland-norway-and-sweden) for doing GDP comparisons. They're frequently used in other entries. I've created a function to add them on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194cf800-7a26-4e72-a71e-ad0e44887565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gdp_data(df):\n",
    "    gdp_df = pd.read_csv(datapath/'GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df.set_index('year', inplace=True)\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country]\n",
    "\n",
    "    df['gdp'] = np.log1p(df.apply(get_gdp, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f745cd8-5e1b-4e98-90c1-d68a55b7b3a4",
   "metadata": {},
   "source": [
    "I'll also define here (but perhaps move later) the GDP exponent, which will be used to transform the targets before inference (dividing num_sold by the $GDP^{1.212}$ and then taking the logarithm (after @ambrosm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e373efbe-04ec-4b49-bb89-ab2903e7b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_exponent = 1.2121103201489674 # see https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model for an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66cbab38-f2c9-4e1a-9b32-5a72e4756885",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = add_gdp_data(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7531064c-b43c-4ab2-b990-b8866aa1c0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp  \n",
       "0     5.461456  \n",
       "1     5.461456  \n",
       "2     5.461456  \n",
       "3     5.461456  \n",
       "4     5.461456  \n",
       "...        ...  \n",
       "6565  6.282042  \n",
       "6566  6.282042  \n",
       "6567  6.282042  \n",
       "6568  6.282042  \n",
       "6569  6.282042  \n",
       "\n",
       "[32868 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012426d-60f2-484d-b970-4f6e9e7b4501",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3c71c-2040-41b7-afa9-cdecfe882fed",
   "metadata": {},
   "source": [
    "### Time Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebfbaa-3575-4030-bcf2-6ba358035c6e",
   "metadata": {},
   "source": [
    "The goal of this function is to create features that will capture seasonalities -- but **not** trends. The trends will (hopefully) be captured by the deployment of linear forecasting algorithms on raw time series data (consisting exclusively of dates and targets); we want to have seasonalities that the residual models can learn, however -- holidays, weekly patterns, climactic season patterns, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20669349-b517-4f24-9c78-3bc3e3f98427",
   "metadata": {},
   "source": [
    "The cell below will generate the `holidays` library's entries for the three countries. I may want to follow the template of @teckmengwong's code below, and add more holidays -- then, do some feature importance checking, and perhaps whittle down the features accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ab7c4c-d94a-48f8-b6a6-f5754bf42b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor, sqrt\n",
    "# from https://www.kaggle.com/fergusfindley/ensembling-and-rounding-techniques-comparison\n",
    "def geometric_round(arr):\n",
    "    result_array = arr\n",
    "    result_array = np.where(result_array < np.sqrt(np.floor(arr)*np.ceil(arr)), np.floor(arr), result_array)\n",
    "    result_array = np.where(result_array >= np.sqrt(np.floor(arr)*np.ceil(arr)), np.ceil(arr), result_array)\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6992f6a4-0d32-4d2d-a574-8956d486dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"date\"\n",
    "YEAR = \"year\"\n",
    "QUARTER = \"quarter\"\n",
    "MONTH = \"month\"\n",
    "WEEK = \"week\"\n",
    "DAY = \"day\"\n",
    "DAYOFYEAR = \"dayofyear\"\n",
    "WEEKOFYEAR = \"weekofyear\"\n",
    "DAYOFMONTH = \"dayofMonth\"\n",
    "DAYOFWEEK = \"dayofweek\"\n",
    "WEEKDAY = \"weekday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15be24b6-7c1d-4a41-b09c-913635f2b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "\n",
    "def periodic_spline_transformer(period, n_splines=None, degree=3):\n",
    "    if n_splines is None:\n",
    "        n_splines = period\n",
    "    n_knots = n_splines + 1  # periodic and include_bias is True\n",
    "    return SplineTransformer(\n",
    "        degree=degree,\n",
    "        n_knots=n_knots,\n",
    "        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n",
    "        extrapolation=\"periodic\",\n",
    "        include_bias=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a99958f-a8fa-4149-9bc5-b433014afd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "year_df = pd.DataFrame(\n",
    "    np.linspace(0, 365, 1000).reshape(-1, 1),\n",
    "    columns=[DAYOFYEAR],\n",
    ")\n",
    "splines = periodic_spline_transformer(365, n_splines=12, degree=2).fit_transform(year_df)\n",
    "splines_df = pd.DataFrame(\n",
    "    splines,\n",
    "    columns=[f\"spline_{i}\" for i in range(splines.shape[1])],\n",
    ")\n",
    "pd.concat([year_df, splines_df], axis=\"columns\").plot(x=DAYOFYEAR, cmap=plt.cm.tab20b)\n",
    "_ = plt.title(f\"Periodic spline-based encoding for the {DAYOFYEAR} feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab721635-570a-44e4-8192-4625138c2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/samuelcortinhas/tps-jan-22-quick-eda-hybrid-model/notebook\n",
    "def unofficial_holiday(df):\n",
    "    countries = {'Finland': 1, 'Norway': 2, 'Sweden': 3}\n",
    "    stores = {'KaggleMart': 1, 'KaggleRama': 2}\n",
    "    products = {'Kaggle Mug': 1,'Kaggle Hat': 2, 'Kaggle Sticker': 3}\n",
    "    \n",
    "    # load holiday info.\n",
    "#     hol_path = '../input/public-and-unofficial-holidays-nor-fin-swe-201519/holidays.csv'\n",
    "    hol_path = datapath/'holidays.csv'\n",
    "    holiday = pd.read_csv(hol_path)\n",
    "    \n",
    "    fin_holiday = holiday.loc[holiday.country == 'Finland']\n",
    "    swe_holiday = holiday.loc[holiday.country == 'Sweden']\n",
    "    nor_holiday = holiday.loc[holiday.country == 'Norway']\n",
    "    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n",
    "    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n",
    "    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n",
    "    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n",
    "    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n",
    "    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n",
    "    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n",
    "    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23464323-8d45-472b-906f-15008fc5b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUID calendar columns\n",
    "MONTH_COLUMNS = []\n",
    "WEEKOFYEAR_COLUMNS = []\n",
    "DAYOFYEAR_COLUMNS = []\n",
    "WEEKDAY_COLUMNS = []\n",
    "\n",
    "for x in [MONTH,WEEKOFYEAR,DAYOFYEAR,WEEKDAY]:\n",
    "    for y in [f'mug_{x}', f'hat_{x}', f'stick_{x}']:\n",
    "        if x == MONTH:\n",
    "            MONTH_COLUMNS.append(y)\n",
    "        if x == WEEKOFYEAR:\n",
    "            WEEKOFYEAR_COLUMNS.append(y)\n",
    "        if x == DAYOFYEAR:\n",
    "            DAYOFYEAR_COLUMNS.append(y)\n",
    "        if x == WEEKDAY:\n",
    "            WEEKDAY_COLUMNS.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9384818d-e0b6-4c6b-b7ed-56d73bb9bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(index, freq, order):\n",
    "    time = np.arange(len(index), dtype=np.float32)\n",
    "    k = 2 * np.pi * (1 / freq) * time\n",
    "    features = {}\n",
    "    for i in range(1, order + 1):\n",
    "        features.update({\n",
    "            f\"sin_{freq}_{i}\": np.sin(i * k),\n",
    "            f\"cos_{freq}_{i}\": np.cos(i * k),\n",
    "        })\n",
    "    return pd.DataFrame(features, index=index)\n",
    "\n",
    "def get_basic_ts_features(df):\n",
    "#     gdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df = pd.read_csv(datapath/'GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df.set_index('year', inplace=True)\n",
    "#     gdp_exponent = 1.2121103201489674 # see https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model for an explanation\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country] #**gdp_exponent\n",
    "\n",
    "    # Apply GDP log\n",
    "    df['gdp'] = np.log1p(df.apply(get_gdp, axis=1))\n",
    "    \n",
    "#     # Split GDP by country (for linear model)\n",
    "#     df['fin_gdp']=np.where(df['country'] == 'Finland', df['gdp'], 0)\n",
    "#     df['nor_gdp']=np.where(df['country'] == 'Norway', df['gdp'], 0)\n",
    "#     df['swe_gdp']=np.where(df['country'] == 'Sweden', df['gdp'], 0)\n",
    "    \n",
    "#     # Drop column\n",
    "#     df=df.drop(['gdp'],axis=1)\n",
    "    \n",
    "    # one-hot encoding should be used. linear model should not learn this as numeric value\n",
    "#     df[YEAR] = df[DATE].dt.year\n",
    "#     df[MONTH] = df[DATE].dt.month\n",
    "#     df[WEEKOFYEAR] = df[DATE].dt.isocalendar().week\n",
    "#     df[DAYOFYEAR] = df[DATE].dt.dayofyear\n",
    "#     df[WEEKDAY] = df[DATE].dt.weekday\n",
    "#     df[DAY] = df[DATE].dt.day # day in month\n",
    "#     df[DAYOFMONTH] = df[DATE].dt.days_in_month\n",
    "#     df[DAYOFWEEK] = df[DATE].dt.dayofweek\n",
    "#     df[MONTH] = df[DATE].dt.month # Min SMAPE: 4.005319478790032\n",
    "#     df[QUARTER] = df.date.dt.quarter\n",
    "\n",
    "    df['wd0'] = df[DATE].dt.weekday == 0 # + Monday\n",
    "    df['wd1'] = df[DATE].dt.weekday == 1 # Tuesday\n",
    "    df['wd2'] = df[DATE].dt.weekday == 2\n",
    "    df['wd3'] = df[DATE].dt.weekday == 3\n",
    "    df['wd4'] = df[DATE].dt.weekday == 4 # + Friday\n",
    "    df['wd56'] = df[DATE].dt.weekday >= 5 # + Weekend\n",
    "\n",
    "#     df[f'mug_wd4'] = np.where(df['product'] == 'Kaggle Mug', df[f'wd4'], False)\n",
    "#     df[f'mug_wd56'] = np.where(df['product'] == 'Kaggle Mug', df[f'wd56'], False)\n",
    "#     df[f'hat_wd4'] = np.where(df['product'] == 'Kaggle Hat', df[f'wd4'], False)\n",
    "#     df[f'hat_wd56'] = np.where(df['product'] == 'Kaggle Hat', df[f'wd56'], False)\n",
    "#     df[f'stick_wd4'] = np.where(df['product'] == 'Kaggle Sticker', df[f'wd4'], False)\n",
    "#     df[f'stick_wd56'] = np.where(df['product'] == 'Kaggle Sticker', df[f'wd56'], False)\n",
    "#     df = df.drop(columns=[f'wd4', f'wd56'])\n",
    "    # 4 seasons\n",
    "#     df['season'] = ((df[DATE].dt.month % 12 + 3) // 3).map({1:'DJF', 2: 'MAM', 3:'JJA', 4:'SON'})\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_splines(df):\n",
    "    # one-hot encoding should be used. linear model should not learn this as numeric value\n",
    "#     df[MONTH] = df[DATE].dt.month\n",
    "#     df[WEEKOFYEAR] = df[DATE].dt.isocalendar().week\n",
    "    df[WEEKDAY] = df[DATE].dt.weekday\n",
    "#     df[DAYOFYEAR] = df[DATE].dt.dayofyear\n",
    "    \n",
    "    dayofyear_splines = periodic_spline_transformer(365, n_splines=9, degree=2).fit_transform(df[DATE].dt.dayofyear.values.reshape(-1, 1))\n",
    "    splines_df = pd.DataFrame(\n",
    "        dayofyear_splines,\n",
    "        columns=[f\"spline_{i}\" for i in range(dayofyear_splines.shape[1])],\n",
    "    )\n",
    "    for i in range(dayofyear_splines.shape[1]):\n",
    "        df[f'mug_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Mug', splines_df[f\"spline_{i}\"], 0.)\n",
    "        df[f'hat_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Hat', splines_df[f\"spline_{i}\"], 0.)\n",
    "        df[f'stick_{DAYOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Sticker', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'fin_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Finland', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'nor_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Norway', splines_df[f\"spline_{i}\"], 0.)\n",
    "#         df[f'swe_{DAYOFYEAR}{i}'] = np.where(df['country'] == 'Sweden', splines_df[f\"spline_{i}\"], 0.)\n",
    "\n",
    "#     weekofyear_splines = periodic_spline_transformer(52, n_splines=2, degree=2).fit_transform(df[DATE].dt.isocalendar().week.values.astype(np.float64).reshape(-1,1))\n",
    "#     splines_df = pd.DataFrame(\n",
    "#         weekofyear_splines,\n",
    "#         columns=[f\"spline_{i}\" for i in range(weekofyear_splines.shape[1])],\n",
    "#     )\n",
    "#     for i in range(weekofyear_splines.shape[1]):\n",
    "#         df[f'weekofyear_{WEEKOFYEAR}{i}'] = splines_df[f\"spline_{i}\"]\n",
    "#         df[f'hat_{WEEKOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Hat', splines_df[f\"spline_{i}\"], 0)\n",
    "#         df[f'stick_{WEEKOFYEAR}{i}'] = np.where(df['product'] == 'Kaggle Sticker', splines_df[f\"spline_{i}\"], 0)\n",
    "#     df[f'mug_{MONTH}'] = np.where(df['product'] == 'Kaggle Mug', df[MONTH], 0)\n",
    "#     df[f'mug_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Mug', df[WEEKOFYEAR], 0)\n",
    "#     df[f'mug_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Mug', df[DAYOFYEAR], 0)\n",
    "#     df[f'mug_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Mug', df[WEEKDAY], 0)\n",
    "#     df[f'hat_{MONTH}'] = np.where(df['product'] == 'Kaggle Hat', df[MONTH], 0)\n",
    "#     df[f'hat_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Hat', df[WEEKOFYEAR], 0)\n",
    "#     df[f'hat_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Hat', df[DAYOFYEAR], 0)\n",
    "#     df[f'hat_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Hat', df[WEEKDAY], 0)\n",
    "#     df[f'stick_{MONTH}'] = np.where(df['product'] == 'Kaggle Sticker', df[MONTH], 0)\n",
    "#     df[f'stick_{WEEKOFYEAR}'] = np.where(df['product'] == 'Kaggle Sticker', df[WEEKOFYEAR], 0)\n",
    "#     df[f'stick_{DAYOFYEAR}'] = np.where(df['product'] == 'Kaggle Sticker', df[DAYOFYEAR], 0)\n",
    "#     df[f'stick_{WEEKDAY}'] = np.where(df['product'] == 'Kaggle Sticker', df[WEEKDAY], 0)\n",
    "\n",
    "#     df = df.drop(columns=[DAYOFYEAR]) #MONTH, WEEKOFYEAR, WEEKDAY\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_periodic(df):\n",
    "    # 21 days cyclic for lunar\n",
    "    # 21 4.244872419046287 31 4.23870 37 4.2359085545955875 47 4.24590382934362 39 4.236812122257115 \n",
    "    # 35 4.2358561209794665 33 4.237682217183017 36 4.230652791910613 3 4.241000488616227 4.23833321067532\n",
    "    #[7, 14, 21, 28, 30, 31, 91] range(1, 32, 4) range(1,3,1)[1,2,4]\n",
    "    # Long term periodic\n",
    "    dayofyear = df.date.dt.dayofyear\n",
    "    j=-36\n",
    "    for k in [2]:\n",
    "        df = pd.concat([df,\n",
    "                        pd.DataFrame({\n",
    "                            f\"sin{k}\": np.sin((dayofyear+j) / 365 * 1 * math.pi * k),\n",
    "                            f\"cos{k}\": np.cos((dayofyear+j) / 365 * 1 * math.pi * k),\n",
    "                                     })], axis=1)\n",
    "        # Products\n",
    "        df[f'mug_sin{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'sin{k}'], 0)\n",
    "        df[f'mug_cos{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'cos{k}'], 0)\n",
    "        df[f'hat_sin{k}'] = np.where(df['product'] == 'Kaggle Hat', df[f'sin{k}'], 0)\n",
    "        df[f'hat_cos{k}'] = np.where(df['product'] == 'Kaggle Hat', df[f'cos{k}'], 0)\n",
    "        df[f'stick_sin{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'sin{k}'], 0)\n",
    "        df[f'stick_cos{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'cos{k}'], 0)\n",
    "        df = df.drop(columns=[f'sin{k}', f'cos{k}'])\n",
    "\n",
    "    # Short term Periodic\n",
    "    weekday = df.date.dt.weekday\n",
    "    df[f'weekly_sin'] = np.sin((1 / 7) * 2 * math.pi*(weekday+1)) #+\n",
    "    df[f'weekly_cos'] = np.cos((1 / 7) * 2 * math.pi*(weekday+1)) #+\n",
    "    df[f'semiweekly_sin'] = np.sin((1 / 7) * 4 * math.pi*(dayofyear-1.5)) #+ ⁅sin(1/7 𝜋⋅4(𝑥−2))⁆\n",
    "    df[f'semiweekly_cos'] = np.cos((1 / 7) * 4 * math.pi*(dayofyear-1.5)) #+ ⁅cos(1/7 𝜋⋅4𝑥)⁆\n",
    "    \n",
    "    df[f'fin_weekly_sin'] = np.where(df['country'] == 'Finland', df[f'weekly_sin'], 0)\n",
    "    df[f'fin_weekly_cos'] = np.where(df['country'] == 'Finland', df[f'weekly_cos'], 0)\n",
    "    df[f'nor_weekly_sin'] = np.where(df['country'] == 'Norway', df[f'weekly_sin'], 0)\n",
    "    df[f'nor_weekly_cos'] = np.where(df['country'] == 'Norway', df[f'weekly_cos'], 0)\n",
    "    df[f'swe_weekly_sin'] = np.where(df['country'] == 'Sweden', df[f'weekly_sin'], 0)\n",
    "    df[f'swe_weekly_cos'] = np.where(df['country'] == 'Sweden', df[f'weekly_cos'], 0)\n",
    "    \n",
    "    df[f'mug_weekly_sin'] = np.where(df['product'] == 'Kaggle Mug', df[f'weekly_sin'], 0)\n",
    "    df[f'mug_weekly_cos'] = np.where(df['product'] == 'Kaggle Mug', df[f'weekly_cos'], 0)\n",
    "    df[f'hat_weekly_sin'] = np.where(df['product'] == 'Kaggle Hat', df[f'weekly_sin'], 0)\n",
    "    df[f'hat_weekly_cos'] = np.where(df['product'] == 'Kaggle Hat', df[f'weekly_cos'], 0)\n",
    "    df[f'stick_weekly_sin'] = np.where(df['product'] == 'Kaggle Sticker', df[f'weekly_sin'], 0)\n",
    "    df[f'stick_weekly_cos'] = np.where(df['product'] == 'Kaggle Sticker', df[f'weekly_cos'], 0)\n",
    "    \n",
    "    df[f'mug_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Mug', df[f'semiweekly_sin'], 0)\n",
    "    df[f'mug_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Mug', df[f'semiweekly_cos'], 0)\n",
    "    df[f'hat_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Hat', df[f'semiweekly_sin'], 0)\n",
    "    df[f'hat_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Hat', df[f'semiweekly_cos'], 0)\n",
    "    df[f'stick_semiweekly_sin'] = np.where(df['product'] == 'Kaggle Sticker', df[f'semiweekly_sin'], 0)\n",
    "    df[f'stick_semiweekly_cos'] = np.where(df['product'] == 'Kaggle Sticker', df[f'semiweekly_cos'], 0)\n",
    "    \n",
    "    df = df.drop(columns=['weekly_sin', 'weekly_cos', 'semiweekly_sin', 'semiweekly_cos'])\n",
    "    \n",
    "#     df[f'semiannual_sin'] = np.sin(dayofyear / 182.5 * 2 * math.pi)\n",
    "#     df[f'semiannual_cos'] = np.cos(dayofyear / 182.5 * 2 * math.pi)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def feature_holiday(df):\n",
    "# Dec Jan\n",
    "    # End of year\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"f-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"n-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"s-dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "                                      for d in range(24, 32)}),\n",
    "                        pd.DataFrame({f\"f-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in range(1, 14)}),\n",
    "                        pd.DataFrame({f\"n-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "                                      for d in range(1, 10)}),\n",
    "                        pd.DataFrame({f\"s-jan{d}\":\n",
    "                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "                                      for d in range(1, 15)})\n",
    "                       ], axis=1)\n",
    "        \n",
    "    # May\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"may{d}\":\n",
    "                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n",
    "                                      for d in list(range(1, 10))}),\n",
    "                        pd.DataFrame({f\"may{d}\":\n",
    "                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & \n",
    "                                      (df.country == 'Norway')\n",
    "                                      for d in list(range(18, 28))})\n",
    "                        ], axis=1)\n",
    "    \n",
    "    # June and July 8, 14\n",
    "    df = pd.concat([df,\n",
    "                        pd.DataFrame({f\"june{d}\":\n",
    "                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & \n",
    "                                      (df.country == 'Sweden')\n",
    "                                      for d in list(range(8, 14))}),\n",
    "                       ], axis=1)\n",
    "    # Last Wednesday of June\n",
    "    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "                                         2016: pd.Timestamp(('2016-06-29')),\n",
    "                                         2017: pd.Timestamp(('2017-06-28')),\n",
    "                                         2018: pd.Timestamp(('2018-06-27')),\n",
    "                                         2019: pd.Timestamp(('2019-06-26'))})\n",
    "    df = pd.concat([df, pd.DataFrame({f\"wed_june{d}\": \n",
    "                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & \n",
    "                                      (df.country != 'Norway')\n",
    "                                      for d in list(range(-4, 6))})], axis=1)\n",
    "\n",
    "    # First Sunday of November\n",
    "    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "                                         2016: pd.Timestamp(('2016-11-6')),\n",
    "                                         2017: pd.Timestamp(('2017-11-5')),\n",
    "                                         2018: pd.Timestamp(('2018-11-4')),\n",
    "                                         2019: pd.Timestamp(('2019-11-3'))})\n",
    "    df = pd.concat([df, pd.DataFrame({f\"sun_nov{d}\":\n",
    "                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n",
    "                                      for d in list(range(0, 9))})], axis=1)\n",
    "    # First half of December (Independence Day of Finland, 6th of December)\n",
    "    df = pd.concat([df, pd.DataFrame({f\"dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in list(range(6, 14))})], axis=1)\n",
    "    # Easter April\n",
    "    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "    df = pd.concat([df, pd.DataFrame({f\"easter{d}\":\n",
    "                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n",
    "                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa321237-325b-4817-81aa-9b446322df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_engineering(df):\n",
    "    df = get_basic_ts_features(df)\n",
    "    df = feature_splines(df)\n",
    "    df = feature_periodic(df)\n",
    "    df = feature_holiday(df)\n",
    "    df = unofficial_holiday(df)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7541874-d7b9-4477-9fb2-1af5506c1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_all_df = temporal_engineering(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "479e68aa-3417-4671-a9d7-ea2c5d248ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>wd0</th>\n",
       "      <th>wd1</th>\n",
       "      <th>wd2</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp    wd0    wd1    wd2  ...  easter50  easter51  easter52  \\\n",
       "0     5.461456  False  False  False  ...     False     False     False   \n",
       "1     5.461456  False  False  False  ...     False     False     False   \n",
       "2     5.461456  False  False  False  ...     False     False     False   \n",
       "3     5.461456  False  False  False  ...     False     False     False   \n",
       "4     5.461456  False  False  False  ...     False     False     False   \n",
       "...        ...    ...    ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042  False   True  False  ...     False     False     False   \n",
       "6566  6.282042  False   True  False  ...     False     False     False   \n",
       "6567  6.282042  False   True  False  ...     False     False     False   \n",
       "6568  6.282042  False   True  False  ...     False     False     False   \n",
       "6569  6.282042  False   True  False  ...     False     False     False   \n",
       "\n",
       "      easter53  easter54  easter55  easter56  easter57  easter58  holiday  \n",
       "0        False     False     False     False     False     False        1  \n",
       "1        False     False     False     False     False     False        1  \n",
       "2        False     False     False     False     False     False        1  \n",
       "3        False     False     False     False     False     False        1  \n",
       "4        False     False     False     False     False     False        1  \n",
       "...        ...       ...       ...       ...       ...       ...      ...  \n",
       "6565     False     False     False     False     False     False        0  \n",
       "6566     False     False     False     False     False     False        0  \n",
       "6567     False     False     False     False     False     False        0  \n",
       "6568     False     False     False     False     False     False        0  \n",
       "6569     False     False     False     False     False     False        0  \n",
       "\n",
       "[32868 rows x 208 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09014037-96b4-4037-835b-f9f23b87a7bb",
   "metadata": {},
   "source": [
    "At this point, the `temporal_all_df` DataFrame contains all the time features for both the training and testing sets.\n",
    "* **Todo**: consider not only adding in holidays from `holidays`, but also borrowing ideas from the AmbrosM Linear notebook too (which creates fewer features, populating them instead with temporal distances from the selected holidays)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86376eb-1c0b-4a8b-814d-b77eff89b925",
   "metadata": {},
   "source": [
    "### Target Transformation\n",
    "Now, I'll do the target transformation proposed by @AmbrosM. (I'll do it to the non-encoded DataFrame too, for testing with Prophet and NeuralProphet later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5542ef40-2c0e-4061-8e04-3a64e20cf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [temporal_all_df]:\n",
    "    df['target'] = np.log(df['num_sold'] / df['gdp']**gdp_exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eb5b7d9-8846-4014-995d-5a129daf267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detransform(preds, ref_df):\n",
    "    return np.exp(preds) * ref_df['gdp']**gdp_exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20683a88-cfe1-499f-9ad1-bf15b5fea392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df['target'] = np.log(encoded_all_df['num_sold'] / (encoded_all_df['gdp']**gdp_exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24c415b1-2f0e-4636-9928-ae713a0d74a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>wd0</th>\n",
       "      <th>wd1</th>\n",
       "      <th>wd2</th>\n",
       "      <th>...</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>holiday</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.925788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.291321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp    wd0    wd1    wd2  ...  easter51  easter52  easter53  \\\n",
       "0     5.461456  False  False  False  ...     False     False     False   \n",
       "1     5.461456  False  False  False  ...     False     False     False   \n",
       "2     5.461456  False  False  False  ...     False     False     False   \n",
       "3     5.461456  False  False  False  ...     False     False     False   \n",
       "4     5.461456  False  False  False  ...     False     False     False   \n",
       "...        ...    ...    ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042  False   True  False  ...     False     False     False   \n",
       "6566  6.282042  False   True  False  ...     False     False     False   \n",
       "6567  6.282042  False   True  False  ...     False     False     False   \n",
       "6568  6.282042  False   True  False  ...     False     False     False   \n",
       "6569  6.282042  False   True  False  ...     False     False     False   \n",
       "\n",
       "      easter54  easter55  easter56  easter57  easter58  holiday    target  \n",
       "0        False     False     False     False     False        1  3.738239  \n",
       "1        False     False     False     False     False        1  4.196010  \n",
       "2        False     False     False     False     False        1  2.925788  \n",
       "3        False     False     False     False     False        1  4.291321  \n",
       "4        False     False     False     False     False        1  4.756724  \n",
       "...        ...       ...       ...       ...       ...      ...       ...  \n",
       "6565     False     False     False     False     False        0       NaN  \n",
       "6566     False     False     False     False     False        0       NaN  \n",
       "6567     False     False     False     False     False        0       NaN  \n",
       "6568     False     False     False     False     False        0       NaN  \n",
       "6569     False     False     False     False     False        0       NaN  \n",
       "\n",
       "[32868 rows x 209 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d953a5-33b0-401d-aefa-cd78fb6a6840",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569cc7f-ad48-481e-bb7e-7ac16d4adfc3",
   "metadata": {},
   "source": [
    "I'm going to encapsulate this in a function so that it can be invoked just-in-time, in the hopes of avoiding confusions with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d55d72bb-efeb-4b21-afd4-2e848636fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    features = ['country', 'product', 'store']\n",
    "    le_dict = {feature: LabelEncoder().fit(orig_train_df[feature]) for feature in features}\n",
    "    enc_df = df.copy()\n",
    "    for feature in features:\n",
    "        enc_df[feature] = le_dict[feature].transform(df[feature])\n",
    "    return le_dict, enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a98c723-1369-4421-884c-c195b07bcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in le_dict.keys():\n",
    "#     print(f\"Values for key {key} are {le_dict[key].inverse_transform(range(len(le_dict[key].values())))}\")#\"\n",
    "# print(le_dict['country'].inverse_transform([0,1,2]))\n",
    "# print(le_dict['product'].inverse_transform([0,1,2]))\n",
    "# print(le_dict['store'].inverse_transform([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030cb25-4179-482f-81aa-d83779f0f278",
   "metadata": {},
   "source": [
    "```\n",
    "['Finland' 'Norway' 'Sweden']\n",
    "['Kaggle Hat' 'Kaggle Mug' 'Kaggle Sticker']\n",
    "['KaggleMart' 'KaggleRama']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39254279-4486-412e-8c57-ba2e01a5c702",
   "metadata": {},
   "source": [
    "Now, we'll do the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9186208-c4b9-4974-9daa-78dc05d4e599",
   "metadata": {},
   "source": [
    "At this point, the `encoded_all_df` can be used -- perhaps with a call to `LabelEncoder.inverse_transform` -- to recover the \"original\" data when necessary (e.g. for feeding it into Prophet and NeuralProphet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1da434d5-b499-4d24-ae0e-6f58fc8a9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df = label_encoder(temporal_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76eb5ed-d638-4879-941e-7b9754459340",
   "metadata": {},
   "source": [
    "### Pseudolabeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ef2c6-14c7-4eaf-af12-5cf752e76fef",
   "metadata": {},
   "source": [
    "I'm not going to try this right now, but I may return to it later -- I note that Teck Meng Wong had some good results with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946e675-76be-45ba-9137-a6642e0e2b55",
   "metadata": {},
   "source": [
    "### Data Splitting, Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3176f-0deb-4477-8f08-2517b9a5cef3",
   "metadata": {},
   "source": [
    "Now that the preprocessing is done, I'm going to split the data back into the train and test sets; then, I'll create a view on the dataframes that omits the year. The year-less dataframes will be suitable for residual learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ec51c66-81b6-4587-bed7-ede9ffef2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = encoded_all_df.drop(columns=['num_sold', 'row_id'])\n",
    "all_df = temporal_all_df.drop(columns=['row_id']) # writing over the previous version of `all_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8ac1517-0b40-4c76-b136-7255216d5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df = all_df[:len(orig_train_df)] # training and validation sets -- still not encoded\n",
    "test_df = all_df[len(orig_train_df):] # still not encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca9532ef-4a78-4a8d-a474-03b6f270946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = encoded_all_df.iloc[np.where(encoded_all_df['date'] < '2019-01-01'), :]\n",
    "# test_df = encoded_all_df[[np.where(encoded_all_df['date'] > '2018-12-31')]]\n",
    "\n",
    "# encoded_tv_df = encoded_all_df.drop(columns=['row_id'])[:len(orig_train_df)]\n",
    "# encoded_test_df = encoded_all_df.drop(columns=['row_id'])[len(orig_train_df):]\n",
    "\n",
    "# valid_df = tv_df[tv_df['date'] > '2017-12-31']\n",
    "# train_df = tv_df[tv_df['date'] <= '2017-12-31']\n",
    "\n",
    "# train_and_valid_residual_df = train_and_valid_df.drop(columns=['date'])\n",
    "# test_residual_df = test_df.drop(columns=['date'])\n",
    "\n",
    "# len(valid_df) + len(train_df) == len(tv_df)\n",
    "\n",
    "# encoded_tv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b92520-09d6-4a6e-a37e-8f8a81e0147f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beecb19-335d-4a0d-ba86-5957165ed5d4",
   "metadata": {},
   "source": [
    "### Forecasting Models Prep\n",
    "First, we'll set up functions to handle the training of forecasting models which will discern trends, and which may -- or may not -- yield insights concerning seasonality. While the Scikit-Learn models will be able to share a single trainer function, the Prophet and NeuralProphet models have subtly different expectations of their data, and as such will require separate handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f86c3a25-87e2-4287-b2ac-933ef1aaa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, HuberRegressor, LinearRegression, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "# earth? wouldn't install via pip on my machine at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23c0c2dd-9e9d-4bda-96b1-49c61d667e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from skorch import NeuralNetRegressor\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab7ae8-ee37-498c-85db-f02548c896d1",
   "metadata": {},
   "source": [
    "#### (Preprepared Preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837ecbe-5be3-4e0c-bff0-a3576e6aed25",
   "metadata": {},
   "source": [
    "The next cell contains code to import already-existing predictions -- but I think it's better to centralize the code that produces them here, and will comment out the import code for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2157a8d2-c17f-451f-9835-20b9ad537fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_trainset = load(predpath/'20220121_prophet_baseline_trainset.joblib')\n",
    "\n",
    "# neural_trainset = load(predpath/'20220121_neuralprophet_baseline_trainset.joblib')\n",
    "# neural_test_preds = load(predpath/'20220121_neuralprophet_baseline_testset.joblib')\n",
    "\n",
    "# ridge_tv_preds = load(predpath/'20210121_ridge_baseline_trainset_preds.joblib')\n",
    "# ridge_test_preds = load(predpath/'20220121_ridge_testset_preds.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9114c3-5287-4862-b94d-dca7e55f43c8",
   "metadata": {},
   "source": [
    "And this cell would handle the parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6871927d-969a-4507-91ca-6e56d0196637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_tv_preds = neural_trainset['prophet_forecast']\n",
    "# prophet_tv_preds = prophet_trainset['prophet_forecast']\n",
    "\n",
    "# neural_train_preds = neural_tv_preds[:train_length]\n",
    "# neural_valid_preds = neural_tv_preds[train_length:]\n",
    "\n",
    "# prophet_train_preds = prophet_tv_preds[:train_length]\n",
    "# prophet_valid_preds = prophet_tv_preds[train_length:]\n",
    "\n",
    "# train_length = len(neural_trainset[neural_trainset['date'] <= '2017-12-31'])\n",
    "\n",
    "# ridge_train_preds = ridge_tv_preds[:train_length]\n",
    "# ridge_valid_preds = ridge_tv_preds[train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb08ecf-a947-47cd-97ad-cf55179cf717",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Linear Models Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46336d-e7f0-4b8c-bdd6-a24156e02557",
   "metadata": {},
   "source": [
    "Linear models from Scikit-Learn seemingly require that datetime data be converted to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f248a-fd99-496f-93f7-953275129874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83b82602-e3ce-4476-bc3f-05bc6f2a8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_linear_df = train_df.copy()\n",
    "# valid_linear_df = valid_df.copy()\n",
    "# test_linear_df = test_df.copy()\n",
    "# tv_linear_df = tv_df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1a9a2-72e5-4edd-a532-42990e5d6a15",
   "metadata": {},
   "source": [
    "### Forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c1987-3246-45df-884c-864bde832811",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "I'll hard-code them for now, but in the future may Optuna them. May want to create a dict of all the kwargs to be used for all the models, with the model names as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42a07e24-4627-47b2-bcc9-906b45194d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "#     'holidays':holidays_train, # will add this in-function\n",
    "    'n_changepoints':10,\n",
    "    'changepoint_range':0.4,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_prior_scale':25,\n",
    "    'holidays_prior_scale':100,\n",
    "    'changepoint_prior_scale':0.01,\n",
    "    'interval_width':0.5,\n",
    "    'uncertainty_samples':False\n",
    "}\n",
    "\n",
    "neuralprophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "    'n_changepoints':10,\n",
    "    'changepoints_range':0.4,\n",
    "    'trend_reg':1,\n",
    "    'trend_reg_threshold':False,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_reg':1,\n",
    "    'n_forecasts':365,\n",
    "    'normalize':'off'\n",
    "}\n",
    "\n",
    "# for pytorch / skorch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tcn_kwargs = {\n",
    "#     'module': estimator, # will be handled at-call\n",
    "    'criterion': nn.MSELoss, # consider enhancement here\n",
    "    \"lr\": 0.01, # default is 0.01\n",
    "    'optimizer':Adam,\n",
    "    'max_epochs':10, # default is 10\n",
    "    'device':device,\n",
    "}\n",
    "\n",
    "# model_params['hyperparams'] = str(neuralprophet_kwargs)\n",
    "# model_params['holiday_source'] = 'Prophet builtin for each country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08d9fa-ca5a-435b-97d8-48b950d6ff6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7452345e-fb0c-45dd-8f73-052280897e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'eval_metric': ['mae', 'mape', 'rmse'],\n",
    "    'learning_rate': .09,\n",
    "    'max_depth': 0,\n",
    "    'subsample': .15,\n",
    "#     'sampling_method': 'gradient_based',\n",
    "#     'seed': 42,\n",
    "#     'grow_policy': 'lossguide',\n",
    "    'max_leaves': 255,\n",
    "    'lambda': 100,\n",
    "#     'n_estimators': 3000,\n",
    "#     'objective': 'reg:squarederror',\n",
    "    'n_estimators': 50,\n",
    "#     'verbose': True,\n",
    "}\n",
    "\n",
    "\n",
    "lightgbm_params = {\n",
    "    'objective': 'mse',\n",
    "    'random_state': 42,\n",
    "    'device_type': 'cpu',\n",
    "    'n_jobs': -1,\n",
    "#                 eval_metric='auc',\n",
    "#     'device_type': 'gpu',\n",
    "#     'max_bin': 63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     'gpu_use_dp': False,\n",
    "    'max_depth': 0,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': .15,\n",
    "    'n_estimators': 1500,\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'task_type':'GPU',\n",
    "    'silent':True,\n",
    "    'random_state':42,\n",
    "}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f38f08-c75d-470f-9504-049c4d6146d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd9c74e-1f65-4dd1-8cc1-845a1ff8d309",
   "metadata": {},
   "source": [
    "#### Temporal Convolutional Network\n",
    "\n",
    "Implementation from https://www.kaggle.com/ceshine/pytorch-temporal-convolutional-networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cad2d00-74f3-4d9d-8b3b-f60927ec405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TemporalBlock(nn.Module):\n",
    "#     def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "#         super(TemporalBlock, self).__init__()\n",
    "        \n",
    "#         # this is the first convolutional layer; note that it foregoes padding irrespective of argument\n",
    "#         self.conv1 = weight_norm(nn.Conv2d(n_inputs, n_outputs, (1, kernel_size),\n",
    "#                                            stride=stride, padding=0, dilation=dilation))\n",
    "#         # the padding is then added after the first conv layer\n",
    "#         self.pad = torch.nn.ZeroPad2d((padding, 0, 0, 0))\n",
    "#         # this is a very standard choice\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#         # the second convolutional layer in the block is identical to the first, but now padding has been added to the input\n",
    "#         self.conv2 = weight_norm(nn.Conv2d(n_outputs, n_outputs, (1, kernel_size),\n",
    "#                                            stride=stride, padding=0, dilation=dilation))\n",
    "        \n",
    "#         # this simply strings together the above architectural elements, for convenience I guess\n",
    "#         self.net = nn.Sequential(self.pad, self.conv1, self.relu, self.dropout,\n",
    "#                                  self.pad, self.conv2, self.relu, self.dropout)\n",
    "        \n",
    "#         # if the n_outputs is nonzero, this adds on a final convlutional layer to ensure that we get the desired number of outputs\n",
    "#         self.downsample = nn.Conv1d(\n",
    "#             n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "#         self.relu = nn.ReLU()\n",
    "        \n",
    "#         # this initializes the weights as specified in the separate weight initialization method, below\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         # this method initializes the weights for the Conv1D and Conv2D layers, plus the Downsample layer (if it's used)\n",
    "#         self.conv1.weight.data.normal_(0, 0.01)\n",
    "#         self.conv2.weight.data.normal_(0, 0.01)\n",
    "#         if self.downsample is not None:\n",
    "#             self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # note the nice one-liner here, to add in the requisite number of dimensions both inbound to the NN and outbound\n",
    "#         out = self.net(x.unsqueeze(2)).squeeze(2)\n",
    "#         # is this a residual, then?\n",
    "#         res = x if self.downsample is None else self.downsample(x)\n",
    "#         return self.relu(out + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb8cf494-61be-4ac6-bfd4-75e3a3786607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TemporalConvNet(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         super(TemporalConvNet, self).__init__()\n",
    "#         layers = []\n",
    "#         num_levels = len(num_channels)\n",
    "#         for i in range(num_levels):\n",
    "#             dilation_size = 2 ** i\n",
    "#             in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "#             out_channels = num_channels[i]\n",
    "#             layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "#                                      padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "#         self.network = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cbc7b59-1dee-4aa3-9a20-e6236992605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TCNModel(nn.Module):\n",
    "#     def __init__(self, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         super(TCNModel, self).__init__()\n",
    "#         self.tcn = TemporalConvNet(\n",
    "#             128, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.decoder = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.decoder(self.dropout(self.tcn(x)[:, :, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18a23398-2c1f-4b4b-85d2-2124dcdc872c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, output_sz,\n",
    "                 kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
    "                                     dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size,\n",
    "                                     dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_sz)\n",
    "        self.last_activation = nn.ReLU()\n",
    "        self.output_sz = output_sz\n",
    "        # self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_sz = x.shape[0]\n",
    "        out = self.network(x.unsqueeze(1))\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.linear(out).mean(dim=1)\n",
    "        out = out.to(dtype=torch.float32) # my addition\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be25f9b-9e9f-4736-a9ac-46029fbd7703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599e350f-b1b3-4383-8242-19506a389c10",
   "metadata": {},
   "source": [
    "#### Trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32330b-fdd4-41de-95e9-ce2ec0cabf8d",
   "metadata": {},
   "source": [
    "##### NeuralProphet\n",
    "I'm leaving the folds as they are. ~~Label encoding shouldn't matter -- the values are just being iterated over anyway.~~ It does matter because the Prophets use the strings to identify countries' holidays to add. Not sure about doing the target transform -- if you try it, just have the trainer call pass `target='target'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55823ee3-106b-4bb2-80ea-261525cafee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_folds = [\n",
    "    ('2015-01-01', '2018-01-01'),\n",
    "    ('2018-01-01', '2019-01-01'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c0dd9b5-3818-40c3-ac85-4fb833cfd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_tv_df = tv_df_encoded.copy() # encoded_tv_df.copy()\n",
    "# prophet_test_df = test_df_encoded.copy() # encoded_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "863448a8-8069-4d46-98a7-37c13e6f385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in ['country', 'product', 'store']:\n",
    "#     prophet_tv_df[feature] = orig_train_df[feature]\n",
    "#     prophet_test_df[feature] = orig_test_df[feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24e2403b-869b-4ca7-b3d2-119e1d1720ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_tv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f347d9a0-166c-4ebf-bd0a-3aea11e4d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_enc = le_dict['country'].transform(countries)\n",
    "# stores_enc = le_dict['store'].transform(stores)\n",
    "# products_enc = le_dict['product'].transform(products)\n",
    "\n",
    "# countries, countries_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33d3cbbc-2518-47e1-ac2d-75a3f6e824b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neuralprophet_trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=prophet_folds, \n",
    "                          tv_df=tv_df, test_df=test_df,\n",
    "#                           df_train=tv_df, df_test=test_df, \n",
    "                          target='num_sold', wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    # no label encoding here -- but test it with too\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', target: 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', target: 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'neuralprophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'neuralprophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test['y'] = np.nan\n",
    "                    test_predictions = model.predict(test)['yhat1']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "#     train_\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train['neuralprophet_forecast'], df_test['neuralprophet_forecast']#, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1f716-7669-495e-b8c3-44b053d95537",
   "metadata": {},
   "source": [
    "##### Prophet Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e743f32b-d1bf-4eeb-85b9-e43f33c25de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prophet_trainer(prophet_kwargs=prophet_kwargs, countries=countries, stores=stores, products=products, folds=prophet_folds, \n",
    "                    tv_df=tv_df, test_df=test_df,\n",
    "#                           df_train=tv_df, df_test=test_df, \n",
    "                    target='num_sold', wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "                    \n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', target]].reset_index(drop=True)\n",
    "#                     print(train.shape)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', target]].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', target: 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', target: 'y'})\n",
    "\n",
    "                    model = Prophet(**prophet_kwargs)\n",
    "\n",
    "                    model.add_country_holidays(country_name=country) # uses FacebookProphet API to add holidays\n",
    "                    model.fit(train)\n",
    "        \n",
    "                    train_predictions = model.predict(train[['ds']])['yhat']\n",
    "                    val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test_predictions = model.predict(test[['ds']])['yhat']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'prophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train['prophet_forecast'], df_test['prophet_forecast']#, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82559992-18c5-4b13-b1a4-e3060f6d15da",
   "metadata": {},
   "source": [
    "##### Scikit-Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a8981e5-ffb7-42ef-949b-2793b0294d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sklearn_trainer(estimator, model_kwargs={}, tv_df=tv_df, test_df=test_df, #X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                    folds=prophet_folds, countries=countries, stores=stores, products=products, target='target',\n",
    "#                     by_combo=True, \n",
    "                    model_type=None, # None -> fully scikit-learn compatible; alternatives are 'skorch' or 'gbm'\n",
    "                    wandb_tracked=False):\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, tv_df = label_encoder(df_train) # should leave broader scope's tv_df alone\n",
    "    _, test_df = label_encoder(df_test) # should leave broader scope's test_df alone\n",
    "    del df_train, df_test\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    # drop whichever version of the dependent variable is not being used\n",
    "#     for df in [tv_df, test_df]:\n",
    "    if target == 'num_sold': \n",
    "        tv_df = tv_df.drop(columns=['target'])\n",
    "        test_df = test_df.drop(columns=['target'])\n",
    "    else:\n",
    "        tv_df = tv_df.drop(columns=['num_sold'])\n",
    "        test_df = test_df.drop(columns=['num_sold'])\n",
    "            \n",
    "#     print(\"'num_sold' in test_df.columns == \", 'num_sold' in test_df.columns)\n",
    "    \n",
    "    # handling each combination of country, store, and product separately\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (tv_df['date'] >= start) &\\\n",
    "                                (tv_df['date'] < end) &\\\n",
    "                                (tv_df['country'] == country) &\\\n",
    "                                (tv_df['store'] == store) &\\\n",
    "                                (tv_df['product'] == product)\n",
    "\n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = tv_df.loc[train_idx, :].reset_index(drop=True)\n",
    "#                         print(train.shape)\n",
    "\n",
    "                    val_idx = (tv_df['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (tv_df['date'] < folds[fold + 1][1]) &\\\n",
    "                              (tv_df['country'] == country) &\\\n",
    "                              (tv_df['store'] == store) &\\\n",
    "                              (tv_df['product'] == product)\n",
    "\n",
    "                    val = tv_df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    test_idx = (test_df['country'] == country) &\\\n",
    "                               (test_df['store'] == store) &\\\n",
    "                               (test_df['product'] == product)\n",
    "                    test = test_df.loc[test_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    # with the training and validation sets sorted out, make them integers for model fitting\n",
    "                    for df in [train, val, test]:\n",
    "                        df['date'] = df['date'].map(dt.datetime.toordinal)\n",
    "                    if 'model_forecast' in train.columns:\n",
    "                        X = train.drop(columns=[target, 'model_forecast'])\n",
    "                        X_valid = val.drop(columns=[target, 'model_forecast'])\n",
    "                        X_test = test.drop(columns=[target, 'model_forecast'])\n",
    "                    else:\n",
    "                        X = train.drop(columns=[target])\n",
    "                        X_valid = val.drop(columns=[target])\n",
    "                        X_test = test.drop(columns=[target])\n",
    "\n",
    "                    y = train[target]\n",
    "                    y_valid = val[target]\n",
    "\n",
    "\n",
    "#                         print(type(X), type(y))\n",
    "#                         print(f\"X has {X.isna().any().sum()} NaNs\")\n",
    "#                         print(f\"y has {y.isna().sum()} NaNs\")\n",
    "#                     print(X_test.info())\n",
    "#                     print(y_valid.dtype)\n",
    "    \n",
    "                    if model_type == 'skorch':\n",
    "#                         for df in [X, X_valid, X_test]:\n",
    "# #                             df['date'] = df['date'].apply(dt.datetime.toordinal)\n",
    "#                             df = torch.tensor(df.to_numpy(dtype=np.float32))\n",
    "#                         for target in [y, y_valid]:\n",
    "#                             target = torch.tensor(np.array(target))\n",
    "# #                             target = target.reshape(-1,1)\n",
    "#                             target = target.unsqueeze(0)\n",
    "                        X = torch.tensor(X.to_numpy(dtype=np.float32))\n",
    "                        X_valid = torch.tensor(X_valid.to_numpy(dtype=np.float32))\n",
    "                        X_test = torch.tensor(X_test.to_numpy(dtype=np.float32))\n",
    "            \n",
    "                        y = torch.tensor(np.array(y)).reshape(-1,1)\n",
    "                        y_valid = torch.tensor(np.array(y)).reshape(-1,1)\n",
    "    \n",
    "                        tcn_kwargs = {\n",
    "                            'num_channels': X_valid.shape[0] * X_valid.shape[1]\n",
    "                        }\n",
    "                        print(type(y), type(y_valid))\n",
    "#                         y = y.reshape(-1,1)\n",
    "#                         y_valid = y_valid.reshape(-1,1)\n",
    "                        # create the Datasets\n",
    "                \n",
    "                        # create the DataLoaders\n",
    "\n",
    "                        # instantiate the wrapper\n",
    "                        model = NeuralNetRegressor(\n",
    "                            module=estimator(**tcn_kwargs),\n",
    "                            **model_kwargs\n",
    "                        )\n",
    "#                     elif model_type=='gbm':\n",
    "                        \n",
    "                    else:\n",
    "                        model = estimator(**model_kwargs)\n",
    "\n",
    "                    model.fit(X,y)\n",
    "\n",
    "                    model_train_preds = model.predict(X)\n",
    "                    model_valid_preds = model.predict(X_valid)\n",
    "                    model_test_preds = model.predict(X_test)\n",
    "\n",
    "                    tv_df.loc[train_idx, 'model_forecast'] = model_train_preds#.values\n",
    "                    tv_df.loc[val_idx, 'model_forecast'] =  model_valid_preds#.values\n",
    "                    test_df.loc[test_idx, 'model_forecast'] = model_test_preds#.values\n",
    "\n",
    "\n",
    "    # reverse the dependent variable transform if appropriate\n",
    "    if target == 'target':\n",
    "#             model_tv_preds = np.multiply(np.exp(model_tv_preds), tv_df['gdp']**gdp_exponent)\n",
    "        tv_df['model_forecast'] = np.exp(tv_df['model_forecast']) * tv_df['gdp']**gdp_exponent\n",
    "#             output_tv_df['model_forecast'] = np.exp(output_tv_df['model_forecast']) * output_tv_df['gdp']**gdp_exponent\n",
    "\n",
    "#             model_test_preds = np.multiply(np.exp(model_test_preds), test_df['gdp']**gdp_exponent)\n",
    "        test_df['model_forecast'] = np.exp(test_df['model_forecast']) * test_df['gdp']**gdp_exponent\n",
    "#             output_test_df['model_forecast'] = np.exp(output_test_df['model_forecast']) * output_test_df['gdp']**gdp_exponent\n",
    "#             model_test_preds = np.exp(model_test_preds) * test_df['gdp']**gdp_exponent\n",
    "        \n",
    "#         tv_df['model_forecast'] = model_tv_preds\n",
    "#         test_df['model_forecast'] = model_test_preds\n",
    "#     return output_tv_df, output_test_df\n",
    "    return tv_df['model_forecast'], test_df['model_forecast']\n",
    "#     return tv_df['model_forecast'], test_df['model_forecast']\n",
    "#     return model_tv_preds, model_test_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0506dd3-d1cc-456a-87eb-2e52e751d85c",
   "metadata": {},
   "source": [
    "##### GBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "691d09f7-18da-4121-8d0d-e3c6399c06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5625e7a5-724c-45ec-9173-e56c8812f745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gbm_trainer(arch:str, model_kwargs={}, exmodel_config={}, tv_df=tv_df, test_df=test_df, #X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                countries=countries, stores=stores, products=products, \n",
    "                target='target', wandb_tracked=True, random_state=42):\n",
    "    \n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    X = tv_df.copy()\n",
    "#     X_test = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, X = label_encoder(X) # should leave broader scope's tv_df alone\n",
    "#     _, X_test = label_encoder(X_test) # should leave broader scope's test_df alone\n",
    "#     del df_train, df_test\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "#     train_smape = 0\n",
    "#     val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "        )\n",
    "    \n",
    "    # drop whichever version of the dependent variable is not being used\n",
    "#     for df in [tv_df, test_df]:\n",
    "    y = X[target]\n",
    "#     for df in [X, X_test]:\n",
    "#         df = df.drop(columns=['num_sold', 'target'])\n",
    "    X = X.drop(columns=['num_sold', 'target'])\n",
    "#     X = X.drop(columns)\n",
    "#     if target == 'num_sold': \n",
    "#         y = X['num_sold']\n",
    "#         X = X.drop(columns=['target'])\n",
    "#         X_test = X_test.drop(columns=['target'])\n",
    "#     else:\n",
    "#         X = X.drop(columns=['num_sold'])\n",
    "#         X_test = X_test.drop(columns=['num_sold'])\n",
    "    \n",
    "    kfold = GroupKFold(n_splits=4)\n",
    "    oof_preds = pd.Series(0, index=tv_df.index)\n",
    "#     oof_preds, oof_y = [], []\n",
    "    \n",
    "#     test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X, groups=X.date.dt.year)):\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        # remove dates \n",
    "#         for df in [X, X_test]:\n",
    "#             df = df.drop(columns=['date'])\n",
    "        if 'date' in X.columns:\n",
    "            X = X.drop(columns=['date'])\n",
    "#             X_test = X_test.drop(columns=['date'])#, 'num_sold'])\n",
    "        \n",
    "        y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "        X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:]\n",
    "        \n",
    "        if arch == 'xgboost':\n",
    "            model = XGBRegressor(\n",
    "                tree_method='gpu_hist',\n",
    "                predictor= 'gpu_predictor',\n",
    "                eval_metric=['mae', 'mape'],\n",
    "                sampling_method='gradient_based',\n",
    "                seed=42,\n",
    "                grow_policy='lossguide',\n",
    "                objective='reg:squarederror',\n",
    "                **model_kwargs)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        elif arch == 'lightgbm':\n",
    "            model = LGBMRegressor(**model_kwargs)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostRegressor(\n",
    "                task_type='GPU',\n",
    "                verbose= False,\n",
    "                random_state=42,\n",
    "                **model_kwargs)\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_preds = model.predict(X_valid)\n",
    "        \n",
    "#         oof_preds.extend(y_valid_preds)\n",
    "#         oof_y.extend(y_valid)\n",
    "        oof_preds[valid_ids] = y_valid_preds\n",
    "                \n",
    "    if target == 'target':\n",
    "        oof_preds = np.exp(oof_preds) * tv_df['gdp']**gdp_exponent\n",
    "#         oof_y = np.exp(tv_df[target]) * tv_df['gdp']**gdp_exponent\n",
    "#         test_preds = np.exp(test_preds) * test_df['gdp']**gdp_exponent\n",
    "\n",
    "#     return oof_preds, test_preds\n",
    "    smape = SMAPE(y_pred=oof_preds, y_true=tv_df['num_sold'])\n",
    "#     print(\"Lengths of oof_preds and tv_df[target] are same? \", len(oof_preds) == len(tv_df[target]))\n",
    "#     print(oof_preds[:10])\n",
    "#     print(tv_df[target][:10])\n",
    "    if wandb_tracked:\n",
    "        wandb.log({\n",
    "            'arch': arch,\n",
    "            'SMAPE': smape,\n",
    "            'model_params': str(model_kwargs),\n",
    "            'model_seed': random_state\n",
    "        })\n",
    "        wandb.finish()\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59ee7523-007b-4faf-9932-f2a9e3f15784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4207,\n",
       " 'learning_rate': 0.05378597302351865,\n",
       " 'reg_alpha': 0.0067949392113948815,\n",
       " 'reg_lambda': 0.04865823628931899,\n",
       " 'subsample': 0.212875760245356,\n",
       " 'min_child_weight': 6.997692447967251,\n",
       " 'colsample_bytree': 0.9824893256584818,\n",
       " 'gamma': 0.10395228539921328,\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost_params = load(studypath/'optuna_xgboost_study-20220126213551.joblib').best_trial.params\n",
    "best_xgboost_params['max_depth'] = best_xgboost_params['depth']\n",
    "del best_xgboost_params['depth']\n",
    "best_xgboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75f9ad57-6f33-4f33-8ad4-6209cb08f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbm_trainer(arch='xgboost', model_kwargs=best_xgboost_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be7d0c-66bb-4a37-82f1-819c8f3ebbc5",
   "metadata": {},
   "source": [
    "### Skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8981ca20-2cd5-4599-830b-a6bd4dbb63d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6570"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_df[tv_df['date'] > '2017-12-31'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7e4e906-c221-4381-b1e2-aa01a320b8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_df[tv_df['date'] > '2017-12-31']) == len(tv_df[-6570:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6867a398-e07c-42b6-bf1b-21371de93414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def skorch_trainer(model=TemporalConvNet, model_kwargs={}, tv_df=tv_df, test_df=test_df, folds=prophet_folds,#X=X, y=y, X_valid=X_valid, y_valid=y_valid, X_test=X_test, \n",
    "                countries=countries, stores=stores, products=products, random_seed=SEED,\n",
    "                target='target', wandb_tracked=False, forecasting=True):\n",
    "    \n",
    "    # preprocessing\n",
    "    \n",
    "    if USE_GPU and torch.cuda.is_available():\n",
    "        device = 'cuda' \n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # start by creating working copies of dataframes to avoid mutation\n",
    "#     working_tv_df = tv_df.copy()\n",
    "#     working_test_df = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, tv_df = label_encoder(tv_df) # should leave broader scope's tv_df alone\n",
    "    _, test_df = label_encoder(test_df) # should leave broader scope's test_df alone\n",
    "#     del df_train, df_test\n",
    "    \n",
    "    valid_df = tv_df[tv_df['date'] > '2017-12-31']\n",
    "    \n",
    "    # encode the lists of countries, stores, and products\n",
    "    countries = le_dict['country'].transform(countries)\n",
    "    stores = le_dict['store'].transform(stores)\n",
    "    products = le_dict['product'].transform(products)\n",
    "    \n",
    "#     y_tv = tv_df['num_sold']\n",
    "    tv_preds = pd.Series(0, index=tv_df.index)\n",
    "    test_preds = pd.Series(0, index=test_df.index)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    # handling each combination of country, store, and product separately\n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                print(f\"Training {le_dict['country'].inverse_transform([country])}, {le_dict['store'].inverse_transform([store])}, {le_dict['product'].inverse_transform([product])}\")\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (tv_df['date'] >= start) &\\\n",
    "                                (tv_df['date'] < end) &\\\n",
    "                                (tv_df['country'] == country) &\\\n",
    "                                (tv_df['store'] == store) &\\\n",
    "                                (tv_df['product'] == product)\n",
    "\n",
    "#                     print(train_idx)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = tv_df.loc[train_idx, :].reset_index(drop=True)\n",
    "#                         print(train.shape)\n",
    "\n",
    "                    val_idx = (tv_df['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (tv_df['date'] < folds[fold + 1][1]) &\\\n",
    "                              (tv_df['country'] == country) &\\\n",
    "                              (tv_df['store'] == store) &\\\n",
    "                              (tv_df['product'] == product)\n",
    "\n",
    "                    val = tv_df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "                    test_idx = (test_df['country'] == country) &\\\n",
    "                               (test_df['store'] == store) &\\\n",
    "                               (test_df['product'] == product)\n",
    "                    test = test_df.loc[test_idx, :].reset_index(drop=True)\n",
    "                    \n",
    "                    y = train[target]\n",
    "                    y_valid = val[target]\n",
    "                    \n",
    "                    # with the training and validation sets sorted out, make them integers for model fitting\n",
    "                    for df in [train, val, test]:\n",
    "                        df['date'] = df['date'].map(dt.datetime.toordinal)\n",
    "                        df = df.drop(columns=['num_sold', 'target'], inplace=True)\n",
    "#                         df = df.astype(np.float32)\n",
    "                    \n",
    "#                     print(train.columns)\n",
    "#                     print(train.dtypes)\n",
    "#                     train_df = train_df.astype(np.float32)\n",
    "                    X, X_valid, X_test = train.astype(np.float32), val.astype(np.float32), test.astype(np.float32)\n",
    "#                         for feature in ['num_sold', 'target', 'model_forecast']:\n",
    "#                             if feature in df.columns:\n",
    "#                                 df = df.drop(columns=feature)\n",
    "#                     if 'model_forecast' in train.columns:\n",
    "#                         X = train.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                         X_valid = val.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                         X_test = test.drop(columns=['num_sold', 'target', 'model_forecast'])\n",
    "#                     else:\n",
    "#                         X = train.drop(columns=['num_sold', 'target'])\n",
    "#                         X_valid = val.drop(columns=['num_sold', 'target'])\n",
    "#                         X_test = test.drop(columns=['num_sold', 'target'])\n",
    "\n",
    "                    \n",
    "                    \n",
    "#                     X = train_df.drop(columns=['num_sold', 'target'])\n",
    "#                     y = train_df[target]\n",
    "\n",
    "#                     X_valid = valid_df.drop(columns=['num_sold', 'target'])\n",
    "#                     y_valid = valid_df[target]\n",
    "\n",
    "#                     X_test = working_test_df.drop(columns=['num_sold', 'target'])\n",
    "\n",
    "                    # tensorify\n",
    "#                     print(X.dtypes)\n",
    "#                     print(type(X.values))\n",
    "                    X = torch.tensor(X.values, dtype=torch.float32)\n",
    "                    X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "                    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "                    y = torch.tensor(np.array(y).reshape(-1,1), dtype=torch.float32)\n",
    "                    y_valid = torch.tensor(np.array(y_valid).reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "#                     print(X.shape, y.shape)\n",
    "#                     print(X.dtype, y.dtype)\n",
    "\n",
    "                    net = NeuralNetRegressor(\n",
    "                        module=model,\n",
    "#                         module__output_sz=1,\n",
    "                        **model_kwargs\n",
    "#                         module__num_inputs=1,\n",
    "#                         module__num_channels=[10] * 11,\n",
    "#                         module__output_sz=1, #2 * samples_per_hour,\n",
    "#                         module__kernel_size=5,\n",
    "#                         module__dropout=0.0,\n",
    "#                         max_epochs=1, # 60,\n",
    "#                         batch_size=256,\n",
    "#                         lr=2e-3,\n",
    "#                         optimizer=torch.optim.Adam,\n",
    "#                         device=device,\n",
    "                    #     iterator_train__shuffle=True,\n",
    "#                         callbacks=[Checkpoint(dirname=modelpath/'20220128-TCN-country{country}-store{store}-product{product}/')],\n",
    "                    #     callbacks=[GradientNormClipping(gradient_clip_value=1,\n",
    "                    #                                     gradient_clip_norm_type=2)],\n",
    "#                         train_split=None,\n",
    "                    )\n",
    "\n",
    "                    net.fit(X,y)\n",
    "                    \n",
    "#                     net.save_params(f_params=modelpath/f'20220128-TCN-country{country}-store{store}-product{product}-model_params.pkl')\n",
    "            \n",
    "                    y_train_preds = np.squeeze(net.predict(X))\n",
    "                    y_valid_preds = np.squeeze(net.predict(X_valid))\n",
    "                    fold_test_preds = np.squeeze(net.predict(X_test))\n",
    "#                     print(f\"Shape of fold test preds is {fold_test_preds.shape}\")\n",
    "\n",
    "                    tv_preds[train_idx] = y_train_preds\n",
    "                    tv_preds[val_idx] = y_valid_preds\n",
    "                    test_preds[test_idx] = fold_test_preds\n",
    "                    \n",
    "                    \n",
    "#                     combo_smape = SMAPE(y_true=tv_df.loc[val_idx, 'num_sold'], y_pred=detransform(y_valid_preds, valid_df))\n",
    "#                     print(combo_smape)\n",
    "#                     print(f\"Valid SMAPE for {le_dict['country'].inverse_transform([country])}, {le_dict['store'].inverse_transform([store])}, {le_dict['product'].inverse_transform([product])} is {SMAPE(y_true=tv_df.loc[val_idx, 'num_sold'], y_pred=y_valid_preds)}\")\n",
    "                    \n",
    "    # reverse the dependent variable transform if appropriate\n",
    "    if target == 'target':\n",
    "#             model_tv_preds = np.multiply(np.exp(model_tv_preds), tv_df['gdp']**gdp_exponent)\n",
    "#         tv_df['model_forecast'] = np.exp(tv_df['model_forecast']) * tv_df['gdp']**gdp_exponent\n",
    "        tv_preds = np.exp(tv_preds) * tv_df['gdp']**gdp_exponent\n",
    "        test_preds = np.exp(test_preds) * test_df['gdp']**gdp_exponent\n",
    "    \n",
    "    smape = SMAPE(y_true=tv_df.iloc[-6570:,]['num_sold'], y_pred=tv_preds[-6570:])\n",
    "#     return tv_preds, test_preds\n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9bf2cf3-972e-4c18-be7f-cd807884071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape_experiment = skorch_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "128baefa-1b68-4f29-9b12-c31d69854d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv_df.iloc[-6570:,]['num_sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7019003-65b5-43d4-9bbe-06f18a1bcb26",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87bdcb0f-fb34-4174-af7f-e179fbaf7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"optuna_forecasting_{datetime.now().strftime('%Y%m%d')}.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d783ff37-e792-45dc-a4c2-5aedd8dc726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmodel_config = {\n",
    "    'cross-validation': 'GroupKFold(n_split=4)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bb79231-1142-4006-8b3a-1259fe809d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['study', 'TCN'],\n",
    "    'notes': \"Optuna study of forecasting methods -- XGBoost\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b74e299a-d2ab-4ed3-8ee6-5fd2a961aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0a9dc78-98f2-4128-a85d-afaad65a8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial, arch=arch):#, tune_fold=tune_fold):\n",
    "    \"\"\"\n",
    "    Wrapper around cross_validation_trainer to test different model hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    if arch == 'catboost':\n",
    "        model_params = {\n",
    "            'iterations' : trial.suggest_int('iterations', 2000, 30000),                         \n",
    "            'depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.5),               \n",
    "            'random_strength': trial.suggest_int('random_strength', 0, 100), \n",
    "    #         'objective': trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "    #         'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['MVC', 'Bernoulli']),#, 'Poisson']),\n",
    "            'od_wait': trial.suggest_int('od_wait', 20, 2000),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 2, 70), # aka l2_leaf_reg\n",
    "            'border_count': trial.suggest_int('border_count', 50, 275),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20), # aka min_data_in_leaf\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 5),\n",
    "#             'task_type':'GPU',\n",
    "#             'verbose': False,\n",
    "# #             'silent':True,\n",
    "#             'random_state':42,\n",
    "            # 'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "    #         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "    #         'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "            # 'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    #         'max_leaves': trial.suggest_int('max_leaves', 32, 128)\n",
    "        }\n",
    "        \n",
    "    elif arch == 'lightgbm':\n",
    "        pass # todo -- fill in tomorrow\n",
    "        \n",
    "    elif arch == 'xgboost':\n",
    "        model_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 500, 10000), # was 900-4500 for CPU\n",
    "            'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.3),               \n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 50),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "    #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "            'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 12),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "            'gamma': trial.suggest_uniform('gamma', 0.1, 10),\n",
    "#             'tree_method': 'gpu_hist',\n",
    "#             'predictor': 'gpu_predictor',\n",
    "#             'eval_metric': ['mae', 'mape'],\n",
    "#             'sampling_method': 'gradient_based',\n",
    "#             'seed': 42,\n",
    "#             'grow_policy': 'lossguide',\n",
    "#             'max_leaves': 255,\n",
    "#             'lambda': 100,\n",
    "#     'n_estimators': 3000,\n",
    "#             'objective': 'reg:squarederror',\n",
    "#             'n_estimators': 500,\n",
    "#     'verbose': True,\n",
    "            \n",
    "        } \n",
    "        \n",
    "    elif arch == 'TCN':\n",
    "        levels = trial.suggest_int('levels', 5, 15)\n",
    "        hidden_units = trial.suggest_int('hidden_units', 5,30)\n",
    "#             optimizer = trial.suggest_categorical('optimizer', ['Adam', 'AdamW', 'SGD'])\n",
    "\n",
    "        model_params = {\n",
    "            'module__num_inputs': 1,\n",
    "            'module__output_sz': 1,\n",
    "            'module__num_channels': [hidden_units] * (levels-1),\n",
    "            'module__kernel_size': trial.suggest_int('kernel_size', 2, 10),\n",
    "            'module__dropout': trial.suggest_uniform('dropout', 0, 0.2),\n",
    "            'batch_size': 256,\n",
    "#                 'batch_size': trial.suggest_categorical('batch_size', [64,128,256]),\n",
    "            'lr': trial.suggest_loguniform('learning_rate', 0.001, 0.3),\n",
    "            'max_epochs': 25,\n",
    "            'optimizer': torch.optim.Adam,\n",
    "            'device': 'cuda',\n",
    "            'train_split': None\n",
    "        }\n",
    "    \n",
    "    return gbm_trainer(arch=arch, model_kwargs=model_params, wandb_tracked=False)#, telegram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "086838b7-c9da-4cfc-a608-c9a3c0f8a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/uncategorized/runs/2be66kx7\" target=\"_blank\">optuna_forecasting_20220131_084157</a></strong> to <a href=\"https://wandb.ai/hushifang/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f839bd-f07d-44e4-b259-e8456000608d",
   "metadata": {},
   "source": [
    "#### TCN Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e1368ad-e60e-4f31-8649-010add3c0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "827abeba-2e90-42ea-8bf4-f0ea5aa6d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "826004df-b66d-4868-b53f-c15001bae969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:42:03,266]\u001b[0m A new study created in memory with name: xgboost_study-20220131084203\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# start_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# study = optuna.create_study(direction = \"minimize\", \n",
    "#                             sampler = TPESampler(seed=int(SEED)), \n",
    "#                             study_name=f\"{arch}_study-{start_time}\")\n",
    "\n",
    "study = load(studypath/'optuna_xgboost_study-20220131084203.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b96d3a54-2ec7-4d7f-a6ed-5f2c2d9d317f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:42:22,830]\u001b[0m Trial 0 finished with value: 8.873718361975232 and parameters: {'n_estimators': 4058, 'depth': 10, 'learning_rate': 0.06504856968981275, 'reg_alpha': 0.6502468545951017, 'reg_lambda': 0.004994757081068292, 'subsample': 0.2403950683025824, 'min_child_weight': 0.6979452624062253, 'colsample_bytree': 0.9330880728874675, 'gamma': 6.051038616257767}. Best is trial 0 with value: 8.873718361975232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:42:53,114]\u001b[0m Trial 1 finished with value: 8.997552734388876 and parameters: {'n_estimators': 7227, 'depth': 3, 'learning_rate': 0.2526878207508456, 'reg_alpha': 8.158738235092015, 'reg_lambda': 0.00892622738184373, 'subsample': 0.26364247048639056, 'min_child_weight': 2.2016707137313523, 'colsample_bytree': 0.6521211214797689, 'gamma': 5.295088673159155}. Best is trial 0 with value: 8.873718361975232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:43:14,685]\u001b[0m Trial 2 finished with value: 7.928182532905388 and parameters: {'n_estimators': 4603, 'depth': 5, 'learning_rate': 0.032781876533976156, 'reg_alpha': 0.004523529917658778, 'reg_lambda': 0.02032202659636255, 'subsample': 0.4297256589643226, 'min_child_weight': 5.473383740620215, 'colsample_bytree': 0.8925879806965068, 'gamma': 2.0767704433677614}. Best is trial 2 with value: 7.928182532905388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:44:11,410]\u001b[0m Trial 3 finished with value: 9.383605161065528 and parameters: {'n_estimators': 5385, 'depth': 7, 'learning_rate': 0.0013033567475147442, 'reg_alpha': 0.7158714383119805, 'reg_lambda': 0.005800389779115683, 'subsample': 0.1585464336867516, 'min_child_weight': 11.386677561502745, 'colsample_bytree': 0.9828160165372797, 'gamma': 8.103133746352965}. Best is trial 2 with value: 7.928182532905388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:44:27,149]\u001b[0m Trial 4 finished with value: 8.262668175866997 and parameters: {'n_estimators': 3394, 'depth': 3, 'learning_rate': 0.04953682563497157, 'reg_alpha': 0.11702088154220885, 'reg_lambda': 0.0035186816415472676, 'subsample': 0.5456592191001431, 'min_child_weight': 0.41362786486150555, 'colsample_bytree': 0.954660201039391, 'gamma': 2.6619218178401676}. Best is trial 2 with value: 7.928182532905388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:44:58,088]\u001b[0m Trial 5 finished with value: 9.976375816230451 and parameters: {'n_estimators': 6794, 'depth': 5, 'learning_rate': 0.01942099825171803, 'reg_alpha': 0.37065955814875856, 'reg_lambda': 0.0067238158696505896, 'subsample': 0.9726261649881027, 'min_child_weight': 9.301818747510014, 'colsample_bytree': 0.9697494707820946, 'gamma': 8.958790769233723}. Best is trial 2 with value: 7.928182532905388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:45:45,017]\u001b[0m Trial 6 finished with value: 9.738619414002937 and parameters: {'n_estimators': 6180, 'depth': 10, 'learning_rate': 0.0016565580440884786, 'reg_alpha': 0.008335230071817131, 'reg_lambda': 0.001593999043568401, 'subsample': 0.39279729768693794, 'min_child_weight': 4.664738798984096, 'colsample_bytree': 0.6356745158869479, 'gamma': 8.3045013406041}. Best is trial 2 with value: 7.928182532905388.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:46:04,541]\u001b[0m Trial 7 finished with value: 7.600812163665391 and parameters: {'n_estimators': 3889, 'depth': 5, 'learning_rate': 0.022096526145513846, 'reg_alpha': 0.0045940816125026864, 'reg_lambda': 3.9042098517777197, 'subsample': 0.16709557931179375, 'min_child_weight': 11.842656352269607, 'colsample_bytree': 0.8861223846483287, 'gamma': 2.0672852471883068}. Best is trial 7 with value: 7.600812163665391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:46:08,320]\u001b[0m Trial 8 finished with value: 9.73226937280013 and parameters: {'n_estimators': 552, 'depth': 9, 'learning_rate': 0.0563600475052774, 'reg_alpha': 2.6642981030636883, 'reg_lambda': 2.838382119353614, 'subsample': 0.16664018656068133, 'min_child_weight': 4.302230276802727, 'colsample_bytree': 0.5579345297625649, 'gamma': 8.644723916168376}. Best is trial 7 with value: 7.600812163665391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:47:01,504]\u001b[0m Trial 9 finished with value: 8.943932415816418 and parameters: {'n_estimators': 6421, 'depth': 5, 'learning_rate': 0.0014369502768990666, 'reg_alpha': 0.028926547478415564, 'reg_lambda': 0.028568350317608886, 'subsample': 0.7566455605042577, 'min_child_weight': 7.651052098791203, 'colsample_bytree': 0.9436063712881633, 'gamma': 4.7749277591032975}. Best is trial 7 with value: 7.600812163665391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:47:56,365]\u001b[0m Trial 10 finished with value: 7.229660265568204 and parameters: {'n_estimators': 9479, 'depth': 7, 'learning_rate': 0.006074458973040422, 'reg_alpha': 0.0012145134109041748, 'reg_lambda': 24.68158512080416, 'subsample': 0.7212223662122307, 'min_child_weight': 11.676480091474728, 'colsample_bytree': 0.8120417635861829, 'gamma': 0.49401610016244657}. Best is trial 10 with value: 7.229660265568204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:49:06,887]\u001b[0m Trial 11 finished with value: 6.690846052430442 and parameters: {'n_estimators': 9961, 'depth': 7, 'learning_rate': 0.0052150224962752385, 'reg_alpha': 0.0013009317376811282, 'reg_lambda': 27.26637288668004, 'subsample': 0.7324293094821988, 'min_child_weight': 11.606357124072144, 'colsample_bytree': 0.8081058697314522, 'gamma': 0.14626834995746157}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:50:15,827]\u001b[0m Trial 12 finished with value: 6.712118125718353 and parameters: {'n_estimators': 9687, 'depth': 7, 'learning_rate': 0.005282340120819482, 'reg_alpha': 0.00114725468237819, 'reg_lambda': 29.131357499989157, 'subsample': 0.7459713835929908, 'min_child_weight': 9.734075569913824, 'colsample_bytree': 0.7722118796780563, 'gamma': 0.13076127519625277}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:51:18,520]\u001b[0m Trial 13 finished with value: 7.03573708363488 and parameters: {'n_estimators': 9963, 'depth': 8, 'learning_rate': 0.005628423420920334, 'reg_alpha': 0.0010205425759564327, 'reg_lambda': 25.95069315093941, 'subsample': 0.7924447844043707, 'min_child_weight': 9.504282724735212, 'colsample_bytree': 0.7636750657666191, 'gamma': 0.28109112399129427}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:51:57,570]\u001b[0m Trial 14 finished with value: 10.054943818005972 and parameters: {'n_estimators': 8292, 'depth': 8, 'learning_rate': 0.007482695086358302, 'reg_alpha': 47.891005655423214, 'reg_lambda': 0.6690231225707517, 'subsample': 0.9103501396805831, 'min_child_weight': 9.504934613169098, 'colsample_bytree': 0.8062116736930935, 'gamma': 3.4813975398282837}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:52:52,150]\u001b[0m Trial 15 finished with value: 7.733423513994869 and parameters: {'n_estimators': 8555, 'depth': 6, 'learning_rate': 0.003218069333252296, 'reg_alpha': 0.057188673293697194, 'reg_lambda': 4.4362782609146825, 'subsample': 0.6429012359255132, 'min_child_weight': 7.604634461727919, 'colsample_bytree': 0.6736107945356555, 'gamma': 1.1338884239599287}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:53:32,364]\u001b[0m Trial 16 finished with value: 8.751140530293604 and parameters: {'n_estimators': 8360, 'depth': 8, 'learning_rate': 0.010517859724223763, 'reg_alpha': 0.02038964092028516, 'reg_lambda': 0.1433619740060279, 'subsample': 0.8510778247058909, 'min_child_weight': 7.767695037799701, 'colsample_bytree': 0.7217310108812355, 'gamma': 3.6480638194263646}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:54:03,858]\u001b[0m Trial 17 finished with value: 7.820722164437568 and parameters: {'n_estimators': 2526, 'depth': 6, 'learning_rate': 0.003109773942712369, 'reg_alpha': 0.003246656527409357, 'reg_lambda': 11.116631370520947, 'subsample': 0.6215330411510379, 'min_child_weight': 10.28483915722487, 'colsample_bytree': 0.8474187468856239, 'gamma': 1.3121823617491915}. Best is trial 11 with value: 6.690846052430442.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:55:42,245]\u001b[0m Trial 18 finished with value: 6.6781533842896605 and parameters: {'n_estimators': 9224, 'depth': 9, 'learning_rate': 0.0032078716062004797, 'reg_alpha': 0.0010042312446081319, 'reg_lambda': 0.5686975854659696, 'subsample': 0.5141410801208897, 'min_child_weight': 10.553746868913452, 'colsample_bytree': 0.7340124648757067, 'gamma': 0.23132812252075657}. Best is trial 18 with value: 6.6781533842896605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:56:29,609]\u001b[0m Trial 19 finished with value: 9.370120039621655 and parameters: {'n_estimators': 7556, 'depth': 9, 'learning_rate': 0.002609298479430933, 'reg_alpha': 0.01426311291151818, 'reg_lambda': 0.4708654822585449, 'subsample': 0.5016898076050326, 'min_child_weight': 6.5997252344814745, 'colsample_bytree': 0.7090770411410371, 'gamma': 6.266506199121654}. Best is trial 18 with value: 6.6781533842896605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:57:09,025]\u001b[0m Trial 20 finished with value: 10.01998570420843 and parameters: {'n_estimators': 8966, 'depth': 9, 'learning_rate': 0.009932969756438028, 'reg_alpha': 0.06051154172987657, 'reg_lambda': 0.20713341522638484, 'subsample': 0.38686833639654095, 'min_child_weight': 10.6446420239791, 'colsample_bytree': 0.5058104808137766, 'gamma': 9.939043571992118}. Best is trial 18 with value: 6.6781533842896605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:58:28,359]\u001b[0m Trial 21 finished with value: 6.6461083364737865 and parameters: {'n_estimators': 9888, 'depth': 7, 'learning_rate': 0.004128379187728361, 'reg_alpha': 0.0019186918767558545, 'reg_lambda': 1.3654428971904735, 'subsample': 0.618919077826999, 'min_child_weight': 8.755631431527496, 'colsample_bytree': 0.7623963323122871, 'gamma': 0.18704339864562242}. Best is trial 21 with value: 6.6461083364737865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 08:59:35,213]\u001b[0m Trial 22 finished with value: 7.739018889509461 and parameters: {'n_estimators': 7975, 'depth': 8, 'learning_rate': 0.0025203647625826444, 'reg_alpha': 0.0026484117407428957, 'reg_lambda': 1.4036274317842408, 'subsample': 0.6557983238521454, 'min_child_weight': 8.407768713592324, 'colsample_bytree': 0.8106452018417597, 'gamma': 1.3275291698470226}. Best is trial 21 with value: 6.6461083364737865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:00:26,920]\u001b[0m Trial 23 finished with value: 8.205155864490195 and parameters: {'n_estimators': 9069, 'depth': 6, 'learning_rate': 0.004024054516106538, 'reg_alpha': 0.009060885673633936, 'reg_lambda': 0.09409505467613731, 'subsample': 0.49399224390882907, 'min_child_weight': 10.831480560133144, 'colsample_bytree': 0.7305883778847562, 'gamma': 2.623547902404547}. Best is trial 21 with value: 6.6461083364737865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:01:17,451]\u001b[0m Trial 24 finished with value: 7.673087154578495 and parameters: {'n_estimators': 9804, 'depth': 4, 'learning_rate': 0.00965449370755515, 'reg_alpha': 0.00197618642169521, 'reg_lambda': 1.1851601779679846, 'subsample': 0.6158780897378449, 'min_child_weight': 8.76628575819377, 'colsample_bytree': 0.5993495214981637, 'gamma': 1.015626374820976}. Best is trial 21 with value: 6.6461083364737865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:03:25,899]\u001b[0m Trial 25 finished with value: 6.543240191674137 and parameters: {'n_estimators': 8916, 'depth': 7, 'learning_rate': 0.0020217553307759224, 'reg_alpha': 0.005058337204297794, 'reg_lambda': 7.895423895405226, 'subsample': 0.6955706602526546, 'min_child_weight': 10.205512233451342, 'colsample_bytree': 0.8661200505468215, 'gamma': 0.12162701340694149}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:04:59,115]\u001b[0m Trial 26 finished with value: 8.13571226705477 and parameters: {'n_estimators': 8966, 'depth': 9, 'learning_rate': 0.0011337241837740674, 'reg_alpha': 0.00814748788691534, 'reg_lambda': 8.268960999560916, 'subsample': 0.56310391206881, 'min_child_weight': 6.50600227593757, 'colsample_bytree': 0.8638738370682826, 'gamma': 2.168839288986346}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:05:58,110]\u001b[0m Trial 27 finished with value: 8.70734317023213 and parameters: {'n_estimators': 5808, 'depth': 8, 'learning_rate': 0.002098210891016959, 'reg_alpha': 0.004269840619766357, 'reg_lambda': 1.8174310213019886, 'subsample': 0.8358576158052936, 'min_child_weight': 10.353208262193167, 'colsample_bytree': 0.6887414896123305, 'gamma': 3.2693931584402542}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:08:30,899]\u001b[0m Trial 28 finished with value: 7.408008862477253 and parameters: {'n_estimators': 7625, 'depth': 10, 'learning_rate': 0.0010095819865913963, 'reg_alpha': 0.02920944246763691, 'reg_lambda': 0.3823787424486451, 'subsample': 0.30822364910178657, 'min_child_weight': 8.478310043068007, 'colsample_bytree': 0.7644888254662644, 'gamma': 0.981321087021487}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:09:03,641]\u001b[0m Trial 29 finished with value: 9.448016403366825 and parameters: {'n_estimators': 7191, 'depth': 10, 'learning_rate': 0.10368801288938737, 'reg_alpha': 0.13045104912555144, 'reg_lambda': 8.016479683110122, 'subsample': 0.6832234432169217, 'min_child_weight': 3.127736484890427, 'colsample_bytree': 0.918393596467251, 'gamma': 6.73039289755044}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:10:14,389]\u001b[0m Trial 30 finished with value: 8.690174866333772 and parameters: {'n_estimators': 8927, 'depth': 6, 'learning_rate': 0.002058526446415388, 'reg_alpha': 0.0027840557115642833, 'reg_lambda': 0.062494598124044905, 'subsample': 0.5678029931400088, 'min_child_weight': 7.060477773423624, 'colsample_bytree': 0.8515825474842189, 'gamma': 4.049438453854517}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:11:54,819]\u001b[0m Trial 31 finished with value: 6.553593828700427 and parameters: {'n_estimators': 9418, 'depth': 7, 'learning_rate': 0.003942107727353582, 'reg_alpha': 0.0017718208866115133, 'reg_lambda': 10.072876459815184, 'subsample': 0.7010194801542587, 'min_child_weight': 11.10926653124382, 'colsample_bytree': 0.8096693323417856, 'gamma': 0.11176772193475355}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:12:56,011]\u001b[0m Trial 32 finished with value: 7.844494977991737 and parameters: {'n_estimators': 9412, 'depth': 7, 'learning_rate': 0.0040212971719916805, 'reg_alpha': 0.001995947257939645, 'reg_lambda': 11.303551573579016, 'subsample': 0.48201566238623605, 'min_child_weight': 10.918267187638339, 'colsample_bytree': 0.7849935199607477, 'gamma': 1.546034555815891}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:13:41,519]\u001b[0m Trial 33 finished with value: 7.348953472164631 and parameters: {'n_estimators': 8090, 'depth': 7, 'learning_rate': 0.013472084478849195, 'reg_alpha': 0.006988724164960547, 'reg_lambda': 0.8127634658988183, 'subsample': 0.7044905896362773, 'min_child_weight': 10.005639753851488, 'colsample_bytree': 0.7408927596578003, 'gamma': 0.6942128844921893}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:14:40,048]\u001b[0m Trial 34 finished with value: 7.951884448531581 and parameters: {'n_estimators': 8812, 'depth': 6, 'learning_rate': 0.00388390232353048, 'reg_alpha': 0.0141870583738768, 'reg_lambda': 2.332104927226432, 'subsample': 0.5990412860041013, 'min_child_weight': 8.769764672520623, 'colsample_bytree': 0.8327715745969848, 'gamma': 1.840019888618064}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:15:43,065]\u001b[0m Trial 35 finished with value: 8.364815566553911 and parameters: {'n_estimators': 9356, 'depth': 4, 'learning_rate': 0.0015694183868536318, 'reg_alpha': 1.2947304024819317, 'reg_lambda': 4.539646141488393, 'subsample': 0.43636992291692994, 'min_child_weight': 11.11606793350447, 'colsample_bytree': 0.8877059697751343, 'gamma': 2.7492646954450146}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:16:05,823]\u001b[0m Trial 36 finished with value: 6.9771651345424095 and parameters: {'n_estimators': 4866, 'depth': 8, 'learning_rate': 0.2674210244066616, 'reg_alpha': 0.004910253190038022, 'reg_lambda': 0.25290168853574163, 'subsample': 0.5374979686275003, 'min_child_weight': 10.212247094571477, 'colsample_bytree': 0.9143965635679931, 'gamma': 0.6733884482741548}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:16:38,936]\u001b[0m Trial 37 finished with value: 7.823966804527941 and parameters: {'n_estimators': 7145, 'depth': 7, 'learning_rate': 0.15484137154223204, 'reg_alpha': 0.0023365963308087916, 'reg_lambda': 1.0210172812692038, 'subsample': 0.34798519324010224, 'min_child_weight': 1.363123325186442, 'colsample_bytree': 0.6579459169521727, 'gamma': 1.649845395012465}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:17:24,244]\u001b[0m Trial 38 finished with value: 6.805090943774882 and parameters: {'n_estimators': 7747, 'depth': 8, 'learning_rate': 0.0325381150968407, 'reg_alpha': 0.0019689709955520453, 'reg_lambda': 13.101748769552357, 'subsample': 0.8077063143881177, 'min_child_weight': 11.930962007301167, 'colsample_bytree': 0.6225499899172158, 'gamma': 0.10250325019056884}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:17:47,744]\u001b[0m Trial 39 finished with value: 12.819922501906218 and parameters: {'n_estimators': 1721, 'depth': 9, 'learning_rate': 0.002045245406533474, 'reg_alpha': 0.0042823528012985, 'reg_lambda': 5.634908991216327, 'subsample': 0.9228388908400815, 'min_child_weight': 9.047145506245581, 'colsample_bytree': 0.7826717597174861, 'gamma': 7.027182815967784}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:18:18,028]\u001b[0m Trial 40 finished with value: 9.656955224660823 and parameters: {'n_estimators': 6786, 'depth': 4, 'learning_rate': 0.015866987582203024, 'reg_alpha': 30.292770972587245, 'reg_lambda': 1.8077465994741027, 'subsample': 0.24014981017285547, 'min_child_weight': 8.050322806375661, 'colsample_bytree': 0.7036742755207821, 'gamma': 4.649924458409602}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:19:13,663]\u001b[0m Trial 41 finished with value: 7.289370681945544 and parameters: {'n_estimators': 9888, 'depth': 7, 'learning_rate': 0.007000954959349917, 'reg_alpha': 0.0014113785144768093, 'reg_lambda': 3.3426028381915773, 'subsample': 0.6761032833267904, 'min_child_weight': 11.320610800311712, 'colsample_bytree': 0.8060190276561986, 'gamma': 0.671913703298763}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:20:22,824]\u001b[0m Trial 42 finished with value: 6.682968379423912 and parameters: {'n_estimators': 9289, 'depth': 7, 'learning_rate': 0.004814429596140817, 'reg_alpha': 0.0016248938490707012, 'reg_lambda': 17.76354344070126, 'subsample': 0.760463039803282, 'min_child_weight': 11.378012241774728, 'colsample_bytree': 0.870899098202748, 'gamma': 0.1748912403686512}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:21:22,323]\u001b[0m Trial 43 finished with value: 7.40088353199465 and parameters: {'n_estimators': 8626, 'depth': 6, 'learning_rate': 0.0033842294558276884, 'reg_alpha': 0.0057800054109047585, 'reg_lambda': 6.730663313681601, 'subsample': 0.789551132737736, 'min_child_weight': 5.579871580838803, 'colsample_bytree': 0.8639142475577476, 'gamma': 0.7575236345102465}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:22:10,892]\u001b[0m Trial 44 finished with value: 8.229844478583574 and parameters: {'n_estimators': 9297, 'depth': 5, 'learning_rate': 0.004473330023584718, 'reg_alpha': 0.001058902495298244, 'reg_lambda': 15.16331187581661, 'subsample': 0.5903775284906787, 'min_child_weight': 11.026463729574404, 'colsample_bytree': 0.8323027653830168, 'gamma': 2.264918772940371}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:23:27,398]\u001b[0m Trial 45 finished with value: 7.265408281954906 and parameters: {'n_estimators': 9443, 'depth': 7, 'learning_rate': 0.0025418257337102464, 'reg_alpha': 0.012033231214828473, 'reg_lambda': 15.3204227630692, 'subsample': 0.8773761556320427, 'min_child_weight': 9.730893386538384, 'colsample_bytree': 0.9745596489073532, 'gamma': 0.5956782561543924}. Best is trial 25 with value: 6.543240191674137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:24:29,754]\u001b[0m Trial 46 finished with value: 6.454164614598097 and parameters: {'n_estimators': 8504, 'depth': 7, 'learning_rate': 0.007562228643368722, 'reg_alpha': 0.0016617709545688629, 'reg_lambda': 2.7616010063763072, 'subsample': 0.7540146474400606, 'min_child_weight': 11.45298130730635, 'colsample_bytree': 0.9154158976040565, 'gamma': 0.1096414541461264}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:25:17,824]\u001b[0m Trial 47 finished with value: 7.613371200553254 and parameters: {'n_estimators': 8438, 'depth': 8, 'learning_rate': 0.00757833745224633, 'reg_alpha': 0.4427260599024236, 'reg_lambda': 0.5895844239405963, 'subsample': 0.4444084393466952, 'min_child_weight': 9.297749118988571, 'colsample_bytree': 0.917951518973829, 'gamma': 1.431751964074567}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:26:02,365]\u001b[0m Trial 48 finished with value: 9.140442004914885 and parameters: {'n_estimators': 4289, 'depth': 6, 'learning_rate': 0.0017096662869672573, 'reg_alpha': 0.0031572232882799236, 'reg_lambda': 2.495220036907954, 'subsample': 0.7090919802207432, 'min_child_weight': 10.510601887026137, 'colsample_bytree': 0.990902063718839, 'gamma': 5.525284583720263}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:26:44,069]\u001b[0m Trial 49 finished with value: 8.159241097543394 and parameters: {'n_estimators': 8030, 'depth': 5, 'learning_rate': 0.00650157512138886, 'reg_alpha': 9.484845312461019, 'reg_lambda': 0.35246500886134086, 'subsample': 0.9801768791870431, 'min_child_weight': 11.930613711461316, 'colsample_bytree': 0.9418748561635888, 'gamma': 1.0975335516219595}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:28:03,122]\u001b[0m Trial 50 finished with value: 7.9773505292388505 and parameters: {'n_estimators': 5499, 'depth': 7, 'learning_rate': 0.0012660591867625377, 'reg_alpha': 0.0010378334415478408, 'reg_lambda': 0.0022885084083971493, 'subsample': 0.5213217873564788, 'min_child_weight': 9.966715694908874, 'colsample_bytree': 0.7530522638064235, 'gamma': 1.8612352725599992}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:29:08,583]\u001b[0m Trial 51 finished with value: 6.9452424741979994 and parameters: {'n_estimators': 9578, 'depth': 7, 'learning_rate': 0.004963572434006688, 'reg_alpha': 0.0018642054953074683, 'reg_lambda': 3.319244071006554, 'subsample': 0.7619045182828033, 'min_child_weight': 11.436636100893987, 'colsample_bytree': 0.8974484384420764, 'gamma': 0.39654471416654824}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:30:31,488]\u001b[0m Trial 52 finished with value: 6.753725222490769 and parameters: {'n_estimators': 9143, 'depth': 7, 'learning_rate': 0.003075802247358831, 'reg_alpha': 0.0015052808093240205, 'reg_lambda': 6.351035399207817, 'subsample': 0.6506116694603149, 'min_child_weight': 11.500123216902587, 'colsample_bytree': 0.8809949115967088, 'gamma': 0.2741945299145571}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:31:30,183]\u001b[0m Trial 53 finished with value: 6.638918679744977 and parameters: {'n_estimators': 8631, 'depth': 8, 'learning_rate': 0.008674184279524067, 'reg_alpha': 0.003987784104516919, 'reg_lambda': 19.183660884779815, 'subsample': 0.7521405947327131, 'min_child_weight': 10.656121184172882, 'colsample_bytree': 0.8303673337020786, 'gamma': 0.12479068335660468}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:32:20,576]\u001b[0m Trial 54 finished with value: 7.626686864791092 and parameters: {'n_estimators': 9989, 'depth': 8, 'learning_rate': 0.008875397999980125, 'reg_alpha': 0.003697431968822604, 'reg_lambda': 22.205078206112432, 'subsample': 0.7210329929763346, 'min_child_weight': 10.674504641549781, 'colsample_bytree': 0.7949900598127352, 'gamma': 0.9318310701982573}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:33:08,997]\u001b[0m Trial 55 finished with value: 7.033285656688677 and parameters: {'n_estimators': 8722, 'depth': 9, 'learning_rate': 0.01297872453963423, 'reg_alpha': 0.006961293923538981, 'reg_lambda': 1.5183304849879726, 'subsample': 0.6834257495428948, 'min_child_weight': 9.370681847344743, 'colsample_bytree': 0.8298584161514788, 'gamma': 0.4841647183080162}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:33:48,141]\u001b[0m Trial 56 finished with value: 7.612082074779867 and parameters: {'n_estimators': 8363, 'depth': 9, 'learning_rate': 0.021603954669940577, 'reg_alpha': 0.0026668609881902177, 'reg_lambda': 8.89526780332887, 'subsample': 0.6374998456278362, 'min_child_weight': 4.521177309371419, 'colsample_bytree': 0.9584476268507487, 'gamma': 1.2797599131624229}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:34:33,629]\u001b[0m Trial 57 finished with value: 7.6765629190100055 and parameters: {'n_estimators': 9611, 'depth': 8, 'learning_rate': 0.012036507383068893, 'reg_alpha': 0.03213928783787625, 'reg_lambda': 4.422371182126275, 'subsample': 0.11270576228084556, 'min_child_weight': 9.913139590521604, 'colsample_bytree': 0.7488797053195819, 'gamma': 2.4744096550540835}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:35:36,678]\u001b[0m Trial 58 finished with value: 6.66273549352684 and parameters: {'n_estimators': 7423, 'depth': 8, 'learning_rate': 0.00588659426585652, 'reg_alpha': 0.017291133084895, 'reg_lambda': 2.4851867896987803, 'subsample': 0.7971870323504513, 'min_child_weight': 10.572837481783147, 'colsample_bytree': 0.8227931578760197, 'gamma': 0.1551750277670552}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:36:24,349]\u001b[0m Trial 59 finished with value: 7.386677861160918 and parameters: {'n_estimators': 6548, 'depth': 8, 'learning_rate': 0.006105923738806427, 'reg_alpha': 0.021585985143750475, 'reg_lambda': 0.014309227694213602, 'subsample': 0.8206349387778137, 'min_child_weight': 10.960523733322894, 'colsample_bytree': 0.8461461567535842, 'gamma': 0.8813360561505468}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:37:04,168]\u001b[0m Trial 60 finished with value: 8.128360306687508 and parameters: {'n_estimators': 7781, 'depth': 8, 'learning_rate': 0.008317286085103962, 'reg_alpha': 0.01001125749837905, 'reg_lambda': 29.951665089769904, 'subsample': 0.7840927064996097, 'min_child_weight': 10.281480054758049, 'colsample_bytree': 0.82251336375325, 'gamma': 1.701232584598887}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:38:13,012]\u001b[0m Trial 61 finished with value: 7.074916303308444 and parameters: {'n_estimators': 8710, 'depth': 7, 'learning_rate': 0.0035355773860020726, 'reg_alpha': 0.005422822400858426, 'reg_lambda': 1.0351990643580613, 'subsample': 0.8538877785949319, 'min_child_weight': 10.59028587510002, 'colsample_bytree': 0.7757012123769484, 'gamma': 0.41278944531613776}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:39:50,002]\u001b[0m Trial 62 finished with value: 6.7501313159168195 and parameters: {'n_estimators': 8200, 'depth': 9, 'learning_rate': 0.0027707605715526777, 'reg_alpha': 0.0034084904521937093, 'reg_lambda': 2.2481478021397487, 'subsample': 0.7418562339068946, 'min_child_weight': 9.560053156729554, 'colsample_bytree': 0.7944857208762349, 'gamma': 0.21065666604955813}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:40:36,913]\u001b[0m Trial 63 finished with value: 7.750463784758597 and parameters: {'n_estimators': 7322, 'depth': 10, 'learning_rate': 0.005371010634517668, 'reg_alpha': 0.001399040467649833, 'reg_lambda': 0.7580375544771447, 'subsample': 0.8862759449992583, 'min_child_weight': 9.039904456246383, 'colsample_bytree': 0.7224557380771675, 'gamma': 1.1490974184159009}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:42:02,968]\u001b[0m Trial 64 finished with value: 7.131519827552754 and parameters: {'n_estimators': 8925, 'depth': 8, 'learning_rate': 0.0022845132440074915, 'reg_alpha': 0.1562538631914649, 'reg_lambda': 5.068181743829626, 'subsample': 0.6766537696031633, 'min_child_weight': 11.683535105243221, 'colsample_bytree': 0.8544378695581268, 'gamma': 0.5117630937013143}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:43:21,395]\u001b[0m Trial 65 finished with value: 7.410637251162908 and parameters: {'n_estimators': 8444, 'depth': 6, 'learning_rate': 0.001838612659751915, 'reg_alpha': 0.002604696779785025, 'reg_lambda': 10.037392399463142, 'subsample': 0.5897319951367982, 'min_child_weight': 11.110710335650552, 'colsample_bytree': 0.906988977554258, 'gamma': 0.8832165296066085}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:44:38,354]\u001b[0m Trial 66 finished with value: 6.677333336914997 and parameters: {'n_estimators': 9684, 'depth': 7, 'learning_rate': 0.004276084565946289, 'reg_alpha': 0.06037060929224214, 'reg_lambda': 3.071517214424668, 'subsample': 0.7343069926081752, 'min_child_weight': 10.272507292943722, 'colsample_bytree': 0.7613840580546388, 'gamma': 0.1481889093416411}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:45:09,475]\u001b[0m Trial 67 finished with value: 6.658489166915119 and parameters: {'n_estimators': 3220, 'depth': 7, 'learning_rate': 0.010372575004568101, 'reg_alpha': 0.05800706141948306, 'reg_lambda': 3.1383140806498444, 'subsample': 0.7688743350191216, 'min_child_weight': 3.740247260614792, 'colsample_bytree': 0.7607787888888105, 'gamma': 0.1252569211824447}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:45:26,867]\u001b[0m Trial 68 finished with value: 9.935355449412437 and parameters: {'n_estimators': 3294, 'depth': 7, 'learning_rate': 0.011172949357794329, 'reg_alpha': 0.02171149160838135, 'reg_lambda': 19.993134144231618, 'subsample': 0.9371795582213756, 'min_child_weight': 3.7914665247133206, 'colsample_bytree': 0.8189419222383115, 'gamma': 7.5640310868189555}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:45:38,232]\u001b[0m Trial 69 finished with value: 7.763210114582796 and parameters: {'n_estimators': 1382, 'depth': 6, 'learning_rate': 0.014570982900007785, 'reg_alpha': 0.04174329383277832, 'reg_lambda': 6.4047931832885885, 'subsample': 0.7710181830999232, 'min_child_weight': 2.983165627180989, 'colsample_bytree': 0.8414196487860316, 'gamma': 1.2321963391659185}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:45:59,103]\u001b[0m Trial 70 finished with value: 7.1325552651498665 and parameters: {'n_estimators': 3790, 'depth': 7, 'learning_rate': 0.02743098416095711, 'reg_alpha': 0.07792611992095595, 'reg_lambda': 11.987478383110261, 'subsample': 0.8123962609509247, 'min_child_weight': 1.0890029258910645, 'colsample_bytree': 0.9334713044780631, 'gamma': 0.5192802870920489}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:46:58,399]\u001b[0m Trial 71 finished with value: 6.672607310596271 and parameters: {'n_estimators': 9695, 'depth': 7, 'learning_rate': 0.008405627492583414, 'reg_alpha': 0.0799850750520688, 'reg_lambda': 3.6244947142045425, 'subsample': 0.7308917202192167, 'min_child_weight': 0.14820549506918956, 'colsample_bytree': 0.761284856262863, 'gamma': 0.15051505625662093}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:47:23,630]\u001b[0m Trial 72 finished with value: 7.424514161469059 and parameters: {'n_estimators': 3134, 'depth': 7, 'learning_rate': 0.008136893714400384, 'reg_alpha': 0.09565286954031484, 'reg_lambda': 2.108248356055302, 'subsample': 0.6958172128766479, 'min_child_weight': 1.9528835797327881, 'colsample_bytree': 0.8049183202211485, 'gamma': 0.7919831821810999}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:47:42,297]\u001b[0m Trial 73 finished with value: 7.126774536598918 and parameters: {'n_estimators': 2821, 'depth': 8, 'learning_rate': 0.018826643015663766, 'reg_alpha': 0.012398916652348973, 'reg_lambda': 4.353616194199383, 'subsample': 0.8432683705903476, 'min_child_weight': 1.7210289058439419, 'colsample_bytree': 0.793593116682123, 'gamma': 0.4375586351286418}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:48:26,088]\u001b[0m Trial 74 finished with value: 6.530803540817963 and parameters: {'n_estimators': 6199, 'depth': 7, 'learning_rate': 0.010324821046941095, 'reg_alpha': 0.20682523842761402, 'reg_lambda': 1.37791251257756, 'subsample': 0.6210592484703457, 'min_child_weight': 0.20462734855435016, 'colsample_bytree': 0.8735805715131391, 'gamma': 0.1543146416184735}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:48:57,904]\u001b[0m Trial 75 finished with value: 7.743032626849002 and parameters: {'n_estimators': 5791, 'depth': 6, 'learning_rate': 0.009992418822550184, 'reg_alpha': 0.2754556096538069, 'reg_lambda': 1.5661655848979872, 'subsample': 0.6209318455170159, 'min_child_weight': 5.1299141163811335, 'colsample_bytree': 0.8983305751692845, 'gamma': 1.4497439610924445}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:49:43,004]\u001b[0m Trial 76 finished with value: 7.4831057411133495 and parameters: {'n_estimators': 6840, 'depth': 8, 'learning_rate': 0.006247261334468014, 'reg_alpha': 0.20655489506372224, 'reg_lambda': 1.2664035456855713, 'subsample': 0.6586171974969989, 'min_child_weight': 2.576969008243388, 'colsample_bytree': 0.8772705475614998, 'gamma': 0.9692979403923564}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:50:10,626]\u001b[0m Trial 77 finished with value: 7.327747011185982 and parameters: {'n_estimators': 4955, 'depth': 7, 'learning_rate': 0.015663869710691364, 'reg_alpha': 0.7864790067346923, 'reg_lambda': 7.233941894047512, 'subsample': 0.7062482469242368, 'min_child_weight': 7.270789777268959, 'colsample_bytree': 0.8566945450472111, 'gamma': 0.6078581405486312}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:51:28,397]\u001b[0m Trial 78 finished with value: 6.5075334962070075 and parameters: {'n_estimators': 7426, 'depth': 8, 'learning_rate': 0.005680293849017179, 'reg_alpha': 0.04069322245466272, 'reg_lambda': 0.03854117862243754, 'subsample': 0.7936609355776133, 'min_child_weight': 6.326496716367925, 'colsample_bytree': 0.8416133123478248, 'gamma': 0.11424070425494176}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:52:03,925]\u001b[0m Trial 79 finished with value: 7.553856966468927 and parameters: {'n_estimators': 6452, 'depth': 7, 'learning_rate': 0.010418326446859588, 'reg_alpha': 1.3586317899671467, 'reg_lambda': 0.034949739609224255, 'subsample': 0.7589797204021012, 'min_child_weight': 6.064360922529813, 'colsample_bytree': 0.8407021919502687, 'gamma': 0.7885373469316845}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:52:37,875]\u001b[0m Trial 80 finished with value: 7.969902721308679 and parameters: {'n_estimators': 5971, 'depth': 6, 'learning_rate': 0.007254822096060237, 'reg_alpha': 0.5331982682395167, 'reg_lambda': 0.13149088131688416, 'subsample': 0.5674890178312907, 'min_child_weight': 3.913622986706866, 'colsample_bytree': 0.8693725362740853, 'gamma': 2.0350668780688776}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:53:41,400]\u001b[0m Trial 81 finished with value: 6.865379507241604 and parameters: {'n_estimators': 7512, 'depth': 8, 'learning_rate': 0.00581808100451032, 'reg_alpha': 0.04027960209908029, 'reg_lambda': 0.00841234023050466, 'subsample': 0.7905836436746797, 'min_child_weight': 0.5707397226394142, 'colsample_bytree': 0.823889086995173, 'gamma': 0.3171269311042587}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:54:56,569]\u001b[0m Trial 82 finished with value: 6.602643097994855 and parameters: {'n_estimators': 7038, 'depth': 8, 'learning_rate': 0.005171634447253101, 'reg_alpha': 0.02000444709193474, 'reg_lambda': 0.05245949237414937, 'subsample': 0.8247432628027229, 'min_child_weight': 6.726723903737046, 'colsample_bytree': 0.7733790113054255, 'gamma': 0.1244870889801467}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:55:54,883]\u001b[0m Trial 83 finished with value: 7.271494849073943 and parameters: {'n_estimators': 7051, 'depth': 7, 'learning_rate': 0.003658981628520109, 'reg_alpha': 0.04979255651559057, 'reg_lambda': 0.0585231827376164, 'subsample': 0.8704668769907044, 'min_child_weight': 6.632956390424901, 'colsample_bytree': 0.7818138679074013, 'gamma': 0.6345397913949933}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:56:35,400]\u001b[0m Trial 84 finished with value: 10.053610859234729 and parameters: {'n_estimators': 7762, 'depth': 8, 'learning_rate': 0.004449816686656141, 'reg_alpha': 0.02671160937921801, 'reg_lambda': 0.026330693637258398, 'subsample': 0.8279037180009108, 'min_child_weight': 5.322429587027387, 'colsample_bytree': 0.7099622675576316, 'gamma': 9.140350003857435}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:57:28,178]\u001b[0m Trial 85 finished with value: 7.472876403282129 and parameters: {'n_estimators': 9099, 'depth': 7, 'learning_rate': 0.0067699682610108365, 'reg_alpha': 0.1792455212739013, 'reg_lambda': 0.04616249510011881, 'subsample': 0.6667169390205043, 'min_child_weight': 6.995330743529732, 'colsample_bytree': 0.8888793213023124, 'gamma': 1.070983923707658}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:58:09,185]\u001b[0m Trial 86 finished with value: 6.963906559662051 and parameters: {'n_estimators': 6053, 'depth': 8, 'learning_rate': 0.00903542036306144, 'reg_alpha': 0.32089019150260456, 'reg_lambda': 0.07226520694030109, 'subsample': 0.629002606639172, 'min_child_weight': 4.916770196391809, 'colsample_bytree': 0.7933367297298423, 'gamma': 0.3998752465858445}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:59:14,205]\u001b[0m Trial 87 finished with value: 6.537555280064937 and parameters: {'n_estimators': 6309, 'depth': 7, 'learning_rate': 0.00500807522667771, 'reg_alpha': 0.006596649794738806, 'reg_lambda': 0.13172428505150813, 'subsample': 0.6007217419283788, 'min_child_weight': 6.073654397592775, 'colsample_bytree': 0.7438240294369054, 'gamma': 0.1295295442495671}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 09:59:57,647]\u001b[0m Trial 88 finished with value: 7.2656308664794595 and parameters: {'n_estimators': 6224, 'depth': 6, 'learning_rate': 0.005037426893165624, 'reg_alpha': 0.006721471121266015, 'reg_lambda': 0.09439793502024875, 'subsample': 0.6013736341425334, 'min_child_weight': 5.95674746668263, 'colsample_bytree': 0.7433635425930295, 'gamma': 0.6876638107335717}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:00:40,475]\u001b[0m Trial 89 finished with value: 8.401824331874801 and parameters: {'n_estimators': 6932, 'depth': 7, 'learning_rate': 0.004036770160799094, 'reg_alpha': 0.00488844380483034, 'reg_lambda': 0.26212806117087334, 'subsample': 0.5399415565714698, 'min_child_weight': 8.079763837154243, 'colsample_bytree': 0.7272921354181507, 'gamma': 3.0502852533034774}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:01:35,895]\u001b[0m Trial 90 finished with value: 7.795332141488065 and parameters: {'n_estimators': 6650, 'depth': 8, 'learning_rate': 0.002962599701047281, 'reg_alpha': 0.004073850371164009, 'reg_lambda': 0.014150265358776101, 'subsample': 0.6443240642546998, 'min_child_weight': 6.109955764390142, 'colsample_bytree': 0.679816174361577, 'gamma': 1.479373534653199}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:02:19,525]\u001b[0m Trial 91 finished with value: 6.5846941552396565 and parameters: {'n_estimators': 6261, 'depth': 7, 'learning_rate': 0.011419909723411822, 'reg_alpha': 0.008951006315696676, 'reg_lambda': 0.14931637359979485, 'subsample': 0.7214844503344768, 'min_child_weight': 5.752371293129889, 'colsample_bytree': 0.7753066359197609, 'gamma': 0.14495464029649877}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:02:56,509]\u001b[0m Trial 92 finished with value: 7.005550570660273 and parameters: {'n_estimators': 6272, 'depth': 7, 'learning_rate': 0.012801954171271801, 'reg_alpha': 0.0081313869653023, 'reg_lambda': 0.12767765983393065, 'subsample': 0.7119608933042182, 'min_child_weight': 5.540602835295273, 'colsample_bytree': 0.8109424802987, 'gamma': 0.4584145937562206}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:03:46,396]\u001b[0m Trial 93 finished with value: 6.8811594818945165 and parameters: {'n_estimators': 5437, 'depth': 7, 'learning_rate': 0.0049985904978913035, 'reg_alpha': 0.010456555671995464, 'reg_lambda': 0.16727416827869723, 'subsample': 0.6922502280049228, 'min_child_weight': 7.516454764069183, 'colsample_bytree': 0.773147151699414, 'gamma': 0.3534163141374524}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:04:22,904]\u001b[0m Trial 94 finished with value: 7.3584149718516745 and parameters: {'n_estimators': 5183, 'depth': 7, 'learning_rate': 0.007247711973480826, 'reg_alpha': 0.01587379011413588, 'reg_lambda': 0.09568166034518129, 'subsample': 0.7418543102935092, 'min_child_weight': 6.750493173376734, 'colsample_bytree': 0.8395822125280433, 'gamma': 0.8565422889930393}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:05:30,454]\u001b[0m Trial 95 finished with value: 7.480005569216226 and parameters: {'n_estimators': 5744, 'depth': 8, 'learning_rate': 0.0023349322021390118, 'reg_alpha': 0.006143045780287685, 'reg_lambda': 0.042854251430233845, 'subsample': 0.5733242820048849, 'min_child_weight': 8.42716988480145, 'colsample_bytree': 0.7382858344222223, 'gamma': 1.0703367004518518}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:06:21,465]\u001b[0m Trial 96 finished with value: 6.729089513158523 and parameters: {'n_estimators': 7928, 'depth': 9, 'learning_rate': 0.011733441580699784, 'reg_alpha': 0.0034003911806528052, 'reg_lambda': 0.4195487937153827, 'subsample': 0.7235944247306442, 'min_child_weight': 5.818611608103431, 'colsample_bytree': 0.860827690595312, 'gamma': 0.28839103199332417}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:06:56,416]\u001b[0m Trial 97 finished with value: 7.2204788325167835 and parameters: {'n_estimators': 6372, 'depth': 3, 'learning_rate': 0.005553555470940355, 'reg_alpha': 0.002046128306007497, 'reg_lambda': 0.22437299457234972, 'subsample': 0.6099831479354937, 'min_child_weight': 6.427246527647021, 'colsample_bytree': 0.9087599282079782, 'gamma': 0.6343930315948133}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:08:17,033]\u001b[0m Trial 98 finished with value: 6.8640350716932685 and parameters: {'n_estimators': 7173, 'depth': 8, 'learning_rate': 0.0034871723530080522, 'reg_alpha': 0.002294038566213667, 'reg_lambda': 0.3070728944505734, 'subsample': 0.6770523231708193, 'min_child_weight': 6.311817689275965, 'colsample_bytree': 0.5048493347752954, 'gamma': 0.12670618699304137}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:09:06,034]\u001b[0m Trial 99 finished with value: 7.752832256875713 and parameters: {'n_estimators': 8224, 'depth': 6, 'learning_rate': 0.004560834236284807, 'reg_alpha': 0.008087129236428948, 'reg_lambda': 15.581174805247848, 'subsample': 0.6486272665662548, 'min_child_weight': 6.8951083455397795, 'colsample_bytree': 0.9301676261951007, 'gamma': 1.298540582413913}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:09:56,348]\u001b[0m Trial 100 finished with value: 6.753616676081323 and parameters: {'n_estimators': 6677, 'depth': 7, 'learning_rate': 0.007922913896975319, 'reg_alpha': 0.001730368993458141, 'reg_lambda': 0.02111784553179958, 'subsample': 0.46753790911804594, 'min_child_weight': 8.009722335276503, 'colsample_bytree': 0.8781615291803863, 'gamma': 0.4066147542663705}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:10:57,834]\u001b[0m Trial 101 finished with value: 6.583162929726315 and parameters: {'n_estimators': 8601, 'depth': 7, 'learning_rate': 0.009869032644984052, 'reg_alpha': 0.11522414639633326, 'reg_lambda': 0.07983806700179426, 'subsample': 0.7789553615294585, 'min_child_weight': 4.295758937128856, 'colsample_bytree': 0.7508006583560254, 'gamma': 0.10063359083223826}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:11:52,166]\u001b[0m Trial 102 finished with value: 7.307658492493366 and parameters: {'n_estimators': 8788, 'depth': 7, 'learning_rate': 0.009225670431031171, 'reg_alpha': 0.1175525127474384, 'reg_lambda': 0.18129336593704096, 'subsample': 0.7809669485313431, 'min_child_weight': 7.263726899793601, 'colsample_bytree': 0.7156913045002424, 'gamma': 0.6040365219245017}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:12:56,396]\u001b[0m Trial 103 finished with value: 6.916794329076512 and parameters: {'n_estimators': 8614, 'depth': 7, 'learning_rate': 0.007011147459980373, 'reg_alpha': 0.001197917000261583, 'reg_lambda': 0.06722503680174874, 'subsample': 0.8041061347054501, 'min_child_weight': 4.333058096055829, 'colsample_bytree': 0.7688440974584133, 'gamma': 0.33138812531509065}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:13:39,799]\u001b[0m Trial 104 finished with value: 8.844446627411164 and parameters: {'n_estimators': 9230, 'depth': 7, 'learning_rate': 0.017707882029614316, 'reg_alpha': 0.018286209252267704, 'reg_lambda': 0.09835355307966485, 'subsample': 0.7529836616614209, 'min_child_weight': 5.780268814410242, 'colsample_bytree': 0.751020055739805, 'gamma': 4.166664670082916}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:14:32,759]\u001b[0m Trial 105 finished with value: 7.3418238177522515 and parameters: {'n_estimators': 8433, 'depth': 7, 'learning_rate': 0.006460392146908844, 'reg_alpha': 0.0029431931931550733, 'reg_lambda': 0.11403474570123352, 'subsample': 0.6940001825875886, 'min_child_weight': 11.221452291524418, 'colsample_bytree': 0.784371559811146, 'gamma': 0.8290738400745756}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:15:40,692]\u001b[0m Trial 106 finished with value: 6.5968647715995825 and parameters: {'n_estimators': 9009, 'depth': 8, 'learning_rate': 0.014611794405971665, 'reg_alpha': 0.0044094814389070034, 'reg_lambda': 0.04742877730727614, 'subsample': 0.7447527335472727, 'min_child_weight': 10.84069422415997, 'colsample_bytree': 0.800947722701379, 'gamma': 0.1348388516936033}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:16:37,293]\u001b[0m Trial 107 finished with value: 6.626115231278922 and parameters: {'n_estimators': 8878, 'depth': 8, 'learning_rate': 0.02192813847460374, 'reg_alpha': 0.004678216697122884, 'reg_lambda': 0.05053576307131369, 'subsample': 0.8272094303165929, 'min_child_weight': 11.65690455152424, 'colsample_bytree': 0.807002804409828, 'gamma': 0.1453203560608784}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:17:27,486]\u001b[0m Trial 108 finished with value: 7.159616657271248 and parameters: {'n_estimators': 9004, 'depth': 8, 'learning_rate': 0.02134912385458681, 'reg_alpha': 0.013123920637248937, 'reg_lambda': 0.05231428944112277, 'subsample': 0.8616339575884812, 'min_child_weight': 11.987695679390317, 'colsample_bytree': 0.8051926137497132, 'gamma': 0.5839364508116419}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:18:06,719]\u001b[0m Trial 109 finished with value: 9.139788922885057 and parameters: {'n_estimators': 7962, 'depth': 9, 'learning_rate': 0.05531032658524802, 'reg_alpha': 0.010224741858397082, 'reg_lambda': 0.03261454034714515, 'subsample': 0.8235348580891297, 'min_child_weight': 11.56927137337061, 'colsample_bytree': 0.7984523635661028, 'gamma': 5.372638186972002}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:19:01,543]\u001b[0m Trial 110 finished with value: 6.53039081609645 and parameters: {'n_estimators': 7305, 'depth': 8, 'learning_rate': 0.014669088296171381, 'reg_alpha': 0.005055558574304621, 'reg_lambda': 0.02364617324007064, 'subsample': 0.7767399019475771, 'min_child_weight': 11.733407341151988, 'colsample_bytree': 0.815963148045383, 'gamma': 0.10362745689734412}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:19:41,235]\u001b[0m Trial 111 finished with value: 6.845165531158918 and parameters: {'n_estimators': 6995, 'depth': 8, 'learning_rate': 0.024790470814433006, 'reg_alpha': 0.005067742115849227, 'reg_lambda': 0.01936503636308391, 'subsample': 0.8359327583182762, 'min_child_weight': 11.703772951482282, 'colsample_bytree': 0.8150998789574352, 'gamma': 0.3229996464307221}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:20:35,180]\u001b[0m Trial 112 finished with value: 6.575485987835268 and parameters: {'n_estimators': 7349, 'depth': 8, 'learning_rate': 0.015048632049117739, 'reg_alpha': 0.02539101716530532, 'reg_lambda': 0.0770138766130954, 'subsample': 0.7871245012664705, 'min_child_weight': 11.218704491221798, 'colsample_bytree': 0.7878222156737059, 'gamma': 0.12518884958454082}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:21:28,113]\u001b[0m Trial 113 finished with value: 7.017868743057217 and parameters: {'n_estimators': 7526, 'depth': 8, 'learning_rate': 0.014406248510391744, 'reg_alpha': 0.03664027360293604, 'reg_lambda': 0.08061295030426628, 'subsample': 0.7729710281909464, 'min_child_weight': 10.97457690613005, 'colsample_bytree': 0.7862335579937021, 'gamma': 0.4427371120094008}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:22:07,997]\u001b[0m Trial 114 finished with value: 7.347294916207288 and parameters: {'n_estimators': 7383, 'depth': 8, 'learning_rate': 0.01631423628289692, 'reg_alpha': 0.14549835251894264, 'reg_lambda': 0.03979357872940921, 'subsample': 0.8078658971304304, 'min_child_weight': 10.815146897164817, 'colsample_bytree': 0.7720826067689532, 'gamma': 0.721524361132707}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:22:47,853]\u001b[0m Trial 115 finished with value: 7.600152867482618 and parameters: {'n_estimators': 7261, 'depth': 9, 'learning_rate': 0.013692275541055654, 'reg_alpha': 0.025607319939186673, 'reg_lambda': 0.022617769936148995, 'subsample': 0.9062863660929167, 'min_child_weight': 11.33859268020967, 'colsample_bytree': 0.7002500900122671, 'gamma': 0.9870573695608468}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:23:45,417]\u001b[0m Trial 116 finished with value: 6.461355556173233 and parameters: {'n_estimators': 6806, 'depth': 8, 'learning_rate': 0.010645606716314497, 'reg_alpha': 0.07581959165625318, 'reg_lambda': 0.014548228741069858, 'subsample': 0.7250926515069709, 'min_child_weight': 4.976665827332974, 'colsample_bytree': 0.8492824083970493, 'gamma': 0.10758645227199055}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:24:21,954]\u001b[0m Trial 117 finished with value: 7.043604185349181 and parameters: {'n_estimators': 5984, 'depth': 7, 'learning_rate': 0.011955535505493931, 'reg_alpha': 0.07656812880094079, 'reg_lambda': 0.015068235894330928, 'subsample': 0.7167889947951945, 'min_child_weight': 3.431458378807459, 'colsample_bytree': 0.85160144157572, 'gamma': 0.5162315968176252}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:24:53,217]\u001b[0m Trial 118 finished with value: 7.232088118650518 and parameters: {'n_estimators': 5603, 'depth': 8, 'learning_rate': 0.019375614696460694, 'reg_alpha': 0.11010808666478854, 'reg_lambda': 0.011756060377870033, 'subsample': 0.7384123896038837, 'min_child_weight': 4.90425859336612, 'colsample_bytree': 0.8346865205640102, 'gamma': 0.7763738136065472}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:25:34,012]\u001b[0m Trial 119 finished with value: 7.092513568162149 and parameters: {'n_estimators': 6501, 'depth': 7, 'learning_rate': 0.010601526973627906, 'reg_alpha': 0.20716457862845764, 'reg_lambda': 0.0053743831895584826, 'subsample': 0.7263475834435501, 'min_child_weight': 5.316645046479007, 'colsample_bytree': 0.5732331225225322, 'gamma': 0.31824808570323715}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:26:08,292]\u001b[0m Trial 120 finished with value: 7.651239023198782 and parameters: {'n_estimators': 6780, 'depth': 7, 'learning_rate': 0.032707543788904454, 'reg_alpha': 0.08729013144758693, 'reg_lambda': 0.02999804445101968, 'subsample': 0.7886724769149052, 'min_child_weight': 10.05135902877726, 'colsample_bytree': 0.7322245150849346, 'gamma': 1.148950631475126}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:27:00,189]\u001b[0m Trial 121 finished with value: 6.563286584795403 and parameters: {'n_estimators': 7611, 'depth': 8, 'learning_rate': 0.015191953761964416, 'reg_alpha': 0.02465412115631331, 'reg_lambda': 0.03913359431804099, 'subsample': 0.7531944631397912, 'min_child_weight': 4.721461597932685, 'colsample_bytree': 0.7524383270374401, 'gamma': 0.11170867845422625}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:27:51,870]\u001b[0m Trial 122 finished with value: 6.455931399973175 and parameters: {'n_estimators': 7674, 'depth': 8, 'learning_rate': 0.015030054255087535, 'reg_alpha': 0.03143400882857498, 'reg_lambda': 0.03680766375506735, 'subsample': 0.7591075098064097, 'min_child_weight': 4.751174361218043, 'colsample_bytree': 0.8652971829750471, 'gamma': 0.11320486709953195}. Best is trial 46 with value: 6.454164614598097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:28:45,639]\u001b[0m Trial 123 finished with value: 6.422233347155155 and parameters: {'n_estimators': 7675, 'depth': 8, 'learning_rate': 0.017711440414536976, 'reg_alpha': 0.047850328173391375, 'reg_lambda': 0.026097279022092676, 'subsample': 0.7655039557616568, 'min_child_weight': 4.794304858012415, 'colsample_bytree': 0.8709820576573599, 'gamma': 0.10342065293254903}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:29:24,501]\u001b[0m Trial 124 finished with value: 9.291308121957247 and parameters: {'n_estimators': 7738, 'depth': 8, 'learning_rate': 0.02703298479162841, 'reg_alpha': 0.04687548294734149, 'reg_lambda': 0.010286621705236034, 'subsample': 0.7664804312580435, 'min_child_weight': 4.703750986067962, 'colsample_bytree': 0.8677830449267815, 'gamma': 5.991287703511073}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:30:12,272]\u001b[0m Trial 125 finished with value: 7.002359178339611 and parameters: {'n_estimators': 8133, 'depth': 8, 'learning_rate': 0.017024524748710225, 'reg_alpha': 0.06722771619774415, 'reg_lambda': 0.02865696541196505, 'subsample': 0.7937830306770851, 'min_child_weight': 4.325595274008528, 'colsample_bytree': 0.8906662688782873, 'gamma': 0.5193066733627684}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:30:58,678]\u001b[0m Trial 126 finished with value: 6.786026368321145 and parameters: {'n_estimators': 7625, 'depth': 9, 'learning_rate': 0.018064091125419218, 'reg_alpha': 0.0467474634687452, 'reg_lambda': 0.016201890592820414, 'subsample': 0.754026900954403, 'min_child_weight': 4.555484679824745, 'colsample_bytree': 0.8491638744738433, 'gamma': 0.33551072691881034}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:31:53,998]\u001b[0m Trial 127 finished with value: 6.451379172150816 and parameters: {'n_estimators': 7268, 'depth': 8, 'learning_rate': 0.013312649981617165, 'reg_alpha': 0.03247094327873458, 'reg_lambda': 0.024315309474571535, 'subsample': 0.7804074069897265, 'min_child_weight': 4.046815779326688, 'colsample_bytree': 0.9015704591440803, 'gamma': 0.10601058888374575}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:32:36,636]\u001b[0m Trial 128 finished with value: 7.2841330421437736 and parameters: {'n_estimators': 7363, 'depth': 8, 'learning_rate': 0.015518719136739995, 'reg_alpha': 0.03181442636975969, 'reg_lambda': 0.007272889072906565, 'subsample': 0.6875325021064073, 'min_child_weight': 4.051162223614142, 'colsample_bytree': 0.9280871683855136, 'gamma': 0.9026145460421343}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:33:18,919]\u001b[0m Trial 129 finished with value: 7.031632228535832 and parameters: {'n_estimators': 7809, 'depth': 8, 'learning_rate': 0.03797721570417186, 'reg_alpha': 0.024667087056054623, 'reg_lambda': 0.025127435885768667, 'subsample': 0.7084006248195919, 'min_child_weight': 5.003526954690015, 'colsample_bytree': 0.8766142109294616, 'gamma': 0.5711219742825333}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:34:05,915]\u001b[0m Trial 130 finished with value: 6.881860179274788 and parameters: {'n_estimators': 7155, 'depth': 9, 'learning_rate': 0.013009585789561944, 'reg_alpha': 0.029746512054192775, 'reg_lambda': 0.037313268701758724, 'subsample': 0.8493843540260613, 'min_child_weight': 5.335298443290281, 'colsample_bytree': 0.9009222511772389, 'gamma': 0.39957544593821187}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:35:06,919]\u001b[0m Trial 131 finished with value: 6.490802931991383 and parameters: {'n_estimators': 7463, 'depth': 8, 'learning_rate': 0.010034523373110471, 'reg_alpha': 0.03626698572410272, 'reg_lambda': 0.07180933171775775, 'subsample': 0.7777968489505015, 'min_child_weight': 3.487910299342041, 'colsample_bytree': 0.8809203102643204, 'gamma': 0.12472861805226171}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:35:58,161]\u001b[0m Trial 132 finished with value: 6.772696724661123 and parameters: {'n_estimators': 7651, 'depth': 8, 'learning_rate': 0.013518050806544233, 'reg_alpha': 0.03717333805755206, 'reg_lambda': 0.0034337877853931153, 'subsample': 0.8096482932035658, 'min_child_weight': 3.5785035091674073, 'colsample_bytree': 0.8854257301454097, 'gamma': 0.2972590738368304}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:36:37,094]\u001b[0m Trial 133 finished with value: 7.099217273871812 and parameters: {'n_estimators': 6826, 'depth': 8, 'learning_rate': 0.01999954324674854, 'reg_alpha': 0.059147316441797104, 'reg_lambda': 0.020136698717943092, 'subsample': 0.766346840265175, 'min_child_weight': 3.0485768693457023, 'colsample_bytree': 0.8628270034254336, 'gamma': 0.6227066587300154}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-31 10:40:36,729]\u001b[0m Trial 134 finished with value: 6.469669164135957 and parameters: {'n_estimators': 7485, 'depth': 8, 'learning_rate': 0.0014703541495205248, 'reg_alpha': 0.02198128049093327, 'reg_lambda': 0.011587552410242733, 'subsample': 0.7355007115269864, 'min_child_weight': 4.6850288988732, 'colsample_bytree': 0.9061919747299838, 'gamma': 0.10396994470988148}. Best is trial 123 with value: 6.422233347155155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-317569f7f3c2>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, arch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         }\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgbm_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_tracked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, telegram=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-b8b0c5809de8>\u001b[0m in \u001b[0;36mgbm_trainer\u001b[0;34m(arch, model_kwargs, exmodel_config, tv_df, test_df, countries, stores, products, target, wandb_tracked, random_state)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0march\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lightgbm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for x in range(1, 500):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=False)#, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=studypath/f\"optuna_{arch}_study-{start_time}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6ff21d6-c1ab-4ad3-86cb-f0e9fab889dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d6080df18083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m wandb.log({'best_params': str(study.best_trial.params),\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#            'trials_in_run': len(study.trials),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0;34m'trials_in_study'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           })\n\u001b[1;32m      5\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/time/lib/python3.8/site-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPreInitCallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: N802\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must call wandb.init() before {}()\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "wandb.log({'best_params': str(study.best_trial.params),\n",
    "#            'trials_in_run': len(study.trials),\n",
    "           'trials_in_study': len(study.trials)\n",
    "          })\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70917a2f-adbc-4f81-9b62-7bac65219ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 7675,\n",
       "  'depth': 8,\n",
       "  'learning_rate': 0.017711440414536976,\n",
       "  'reg_alpha': 0.047850328173391375,\n",
       "  'reg_lambda': 0.026097279022092676,\n",
       "  'subsample': 0.7655039557616568,\n",
       "  'min_child_weight': 4.794304858012415,\n",
       "  'colsample_bytree': 0.8709820576573599,\n",
       "  'gamma': 0.10342065293254903},\n",
       " 6.422233347155155)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params, study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80653134-2ee0-493f-9feb-7304c7686546",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e96174-8238-4938-ab8e-71ecea5ee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CatBoost Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082ff8-efd9-4455-95d9-63753d4190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'xgbboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba9a6c-580b-4b36-bebf-9edbda790d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f39f9-d5fc-4150-ab80-0dcfab032c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial, arch=arch):#, tune_fold=tune_fold):\n",
    "    \"\"\"\n",
    "    Wrapper around cross_validation_trainer to test different model hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    if arch == 'catboost':\n",
    "        model_params = {\n",
    "            'iterations' : trial.suggest_int('iterations', 2000, 30000),                         \n",
    "            'depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.5),               \n",
    "            'random_strength': trial.suggest_int('random_strength', 0, 100), \n",
    "    #         'objective': trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "    #         'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['MVC', 'Bernoulli']),#, 'Poisson']),\n",
    "            'od_wait': trial.suggest_int('od_wait', 20, 2000),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 2, 70), # aka l2_leaf_reg\n",
    "            'border_count': trial.suggest_int('border_count', 50, 275),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20), # aka min_data_in_leaf\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 5),\n",
    "            'task_type':'GPU',\n",
    "            'verbose': False,\n",
    "#             'silent':True,\n",
    "            'random_state':42,\n",
    "            # 'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "    #         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "    #         'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "            # 'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    #         'max_leaves': trial.suggest_int('max_leaves', 32, 128)\n",
    "        }\n",
    "        \n",
    "    elif arch == 'lightgbm':\n",
    "        pass # todo -- fill in tomorrow\n",
    "        \n",
    "    elif arch == 'xgboost':\n",
    "        model_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 500, 10000), # was 900-4500 for CPU\n",
    "            'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.3),               \n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 50),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "    #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "            'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 12),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "            'gamma': trial.suggest_uniform('gamma', 0.1, 10),\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'predictor': 'gpu_predictor',\n",
    "            'eval_metric': ['mae', 'mape'],\n",
    "            'sampling_method': 'gradient_based',\n",
    "            'seed': 42,\n",
    "            'grow_policy': 'lossguide',\n",
    "#             'max_leaves': 255,\n",
    "#             'lambda': 100,\n",
    "#     'n_estimators': 3000,\n",
    "            'objective': 'reg:squarederror',\n",
    "#             'n_estimators': 500,\n",
    "#     'verbose': True,\n",
    "            \n",
    "        } \n",
    "    \n",
    "    return gbm_trainer(arch=arch, model_kwargs=model_params, wandb_tracked=False)#, telegram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c38c97-ce17-4d82-a6a7-801f9f07f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "study = optuna.create_study(direction = \"minimize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"{arch}_study-{start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14a95a-e4fa-454a-9614-848dfae27209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "for x in range(1, 500):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=False)#, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=studypath/f\"optuna_{arch}_study-{start_time}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516fc3c-047d-4806-9e46-7547f8b64134",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610ac75-eb8e-4473-a93b-996ecfa25770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.log({'best_params': str(study.best_trial.params),\n",
    "#            'trials_in_run': len(study.trials),\n",
    "           'trials_in_study': len(study.trials)\n",
    "          })\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec884f-0800-4f8c-a537-bade46f8ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55cb29-118e-4fd4-9bd3-3a4050e0e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390d93d-f686-4e9b-830c-f0dc1078f272",
   "metadata": {},
   "source": [
    "#### Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edb698ce-e8b3-49b5-8839-cd02b147b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n",
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 0 OOF SMAPE: 0.8476365395298698\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 1 OOF SMAPE: 0.9349776188629331\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 2 OOF SMAPE: 0.8853828441336109\n",
      "FOLD 3\n",
      "------------------------------\n",
      "FOLD 3 OOF SMAPE: 0.8532543631116587\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "xgb_forecast_oof_preds, xgb_forecast_test_preds = gbm_trainer(arch='xgboost', model_kwargs=xgboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1073243-467b-4737-9367-c0133fefb957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.193614221145653"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=xgb_forecast_oof_preds, y_true=orig_train_df['num_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e742b58-9e0a-4fed-b79f-c29105bba7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n",
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 0 OOF SMAPE: 0.21107808385399895\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 1 OOF SMAPE: 0.21276162296052187\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 2 OOF SMAPE: 0.2137797867063078\n",
      "FOLD 3\n",
      "------------------------------\n",
      "FOLD 3 OOF SMAPE: 0.2224652160189054\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "xgb_forecast_oof_preds, xgb_forecast_test_preds = gbm_trainer(arch='xgboost', model_kwargs=xgboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c6fa8b5-733c-4fe6-aab1-d11151d37dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.594899764124257"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=xgb_forecast_oof_preds, y_true=orig_train_df['num_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17e710da-da33-4b43-a96b-8bd40444c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.594899764124257"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=xgb_forecast_oof_preds, y_true=orig_train_df['num_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbc9ad0d-6a4f-4dcf-bfb0-048b1a89906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_xgb_params = {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.0013033567475147442, 'reg_alpha': 0.7158714383119805, 'reg_lambda': 0.005800389779115683, 'subsample': 0.1585464336867516, 'min_child_weight': 11.386677561502745, 'colsample_bytree': 0.9828160165372797, 'gamma': 8.103133746352965}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f09a4f89-b444-4a6f-9bdc-ac2c7ff5895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "------------------------------\n",
      "FOLD 1\n",
      "------------------------------\n",
      "FOLD 2\n",
      "------------------------------\n",
      "FOLD 3\n",
      "------------------------------\n",
      "CPU times: user 48.5 s, sys: 964 ms, total: 49.5 s\n",
      "Wall time: 15.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194.7930179896259"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# xgb_forecast_oof_preds, xgb_forecast_test_preds = gbm_trainer(arch='xgboost', model_kwargs=example_xgb_params, wandb_tracked=False)\n",
    "example_smape = gbm_trainer(arch='xgboost', model_kwargs=xgboost_params, wandb_tracked=False)\n",
    "example_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f34a132c-0215-4261-b93d-4a6dca720c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.07542834209443"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0af38064-2ebe-41f0-b5a2-4e976297ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-851c018962a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtcn_tv_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcn_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTCNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_skorch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-9593bc7ea5c4>\u001b[0m in \u001b[0;36msklearn_trainer\u001b[0;34m(estimator, model_kwargs, tv_df, test_df, folds, countries, stores, products, target, use_skorch, wandb_tracked)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;31m# instantiate the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         model = NeuralNetRegressor(\n\u001b[0;32m--> 131\u001b[0;31m                             \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtcn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                         )\n",
      "\u001b[0;32m<ipython-input-41-b996328a3e80>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_channels, kernel_size, dropout)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTCNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         self.tcn = TemporalConvNet(\n\u001b[0m\u001b[1;32m      5\u001b[0m             128, num_channels, kernel_size=kernel_size, dropout=dropout)\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-36d610169439>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_inputs, num_channels, kernel_size, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTemporalConvNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnum_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mdilation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "%time \n",
    "tcn_tv_preds, tcn_test_preds = sklearn_trainer(estimator=TCNModel, use_skorch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04c45b67-c595-4155-92c6-80828d312510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleMart - Kaggle Mug - Train SMAPE: 6.815541\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleMart - Kaggle Mug - Validation SMAPE: 8.011073\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleMart - Kaggle Hat - Train SMAPE: 7.210369\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleMart - Kaggle Hat - Validation SMAPE: 7.470548\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleMart - Kaggle Sticker - Train SMAPE: 7.056273\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleMart - Kaggle Sticker - Validation SMAPE: 7.264969\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleRama - Kaggle Mug - Train SMAPE: 6.716048\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleRama - Kaggle Mug - Validation SMAPE: 7.406634\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleRama - Kaggle Hat - Train SMAPE: 7.000068\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleRama - Kaggle Hat - Validation SMAPE: 7.162872\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Sweden - KaggleRama - Kaggle Sticker - Train SMAPE: 6.674554\n",
      "Validation Range [2018-01-01, 2019-01-01) - Sweden - KaggleRama - Kaggle Sticker - Validation SMAPE: 7.606732\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleMart - Kaggle Mug - Train SMAPE: 7.224865\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleMart - Kaggle Mug - Validation SMAPE: 7.034564\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleMart - Kaggle Hat - Train SMAPE: 7.135125\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleMart - Kaggle Hat - Validation SMAPE: 6.984664\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleMart - Kaggle Sticker - Train SMAPE: 6.903014\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleMart - Kaggle Sticker - Validation SMAPE: 6.821940\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleRama - Kaggle Mug - Train SMAPE: 7.026900\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleRama - Kaggle Mug - Validation SMAPE: 6.906350\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleRama - Kaggle Hat - Train SMAPE: 7.069145\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleRama - Kaggle Hat - Validation SMAPE: 7.116741\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Finland - KaggleRama - Kaggle Sticker - Train SMAPE: 7.058737\n",
      "Validation Range [2018-01-01, 2019-01-01) - Finland - KaggleRama - Kaggle Sticker - Validation SMAPE: 7.042075\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleMart - Kaggle Mug - Train SMAPE: 7.287884\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleMart - Kaggle Mug - Validation SMAPE: 6.890005\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleMart - Kaggle Hat - Train SMAPE: 7.413405\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleMart - Kaggle Hat - Validation SMAPE: 7.504373\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleMart - Kaggle Sticker - Train SMAPE: 7.033793\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleMart - Kaggle Sticker - Validation SMAPE: 7.441114\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleRama - Kaggle Mug - Train SMAPE: 7.094054\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleRama - Kaggle Mug - Validation SMAPE: 7.095961\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleRama - Kaggle Hat - Train SMAPE: 7.359608\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleRama - Kaggle Hat - Validation SMAPE: 7.178791\n",
      "\n",
      "\n",
      "Training Range [2015-01-01, 2018-01-01) - Norway - KaggleRama - Kaggle Sticker - Train SMAPE: 6.934721\n",
      "Validation Range [2018-01-01, 2019-01-01) - Norway - KaggleRama - Kaggle Sticker - Validation SMAPE: 7.135771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "prophet_tv_preds, prophet_test_preds = prophet_trainer(target='num_sold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "671874c4-3fec-4bb1-acfd-ed377a7e58ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.58 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# neural_tv_preds, neural_test_preds = neuralprophet_trainer(target='num_sold')\n",
    "# dump(neural_tv_preds, predpath/'20220124_neuralprophet_tv_preds.joblib')\n",
    "# dump(neural_test_preds, predpath/'20220124_neuralprophet_test_preds.joblib')\n",
    "neural_tv_preds = load(predpath/'20220124_neuralprophet_tv_preds.joblib')\n",
    "neural_test_preds = load(predpath/'20220124_neuralprophet_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba8ec95a-702d-4977-a5a1-c0be6fd3f869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %time\n",
    "# ridge_tv_preds, ridge_test_preds = sklearn_trainer(estimator=Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26593c2b-48a8-4941-acba-b19b9e775c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ridge_combo_tv_preds, ridge_combo_test_preds = sklearn_trainer(estimator=Ridge)#, by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68dc0965-4453-4bb8-98ca-28f020cfc4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# linear_tv_preds, linear_test_preds = sklearn_trainer(estimator=LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f3df316-714d-4f71-91d3-e3aef8285b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_combo_tv_preds, linear_combo_test_preds = sklearn_trainer(estimator=LinearRegression)#, by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58dbf5f8-68df-4893-b07f-9798fb046a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_combo_tv_preds, huber_combo_test_preds = sklearn_trainer(estimator=HuberRegressor)#, by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9684657-1299-48c4-85c3-65f8943ba97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_combo_tv_preds, mlp_combo_test_preds = sklearn_trainer(estimator=MLPRegressor)#, by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fdadc1d-946c-42bd-ac0c-67805d248bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_combo_tv_preds, lasso_combo_test_preds = sklearn_trainer(estimator=Lasso)#), by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49aaf836-ee48-4abf-a9b5-b86a5017f061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "from pyearth import Earth\n",
    "%time\n",
    "earth_combo_tv_preds, earth_combo_test_preds = sklearn_trainer(estimator=Earth), #by_combo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f929d8e1-13c9-4a1c-a0d1-d29f5e7d218c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         360.672190\n",
       "1         584.851806\n",
       "2         138.401176\n",
       "3         562.479785\n",
       "4         944.584508\n",
       "            ...     \n",
       "26293     836.947940\n",
       "26294     254.287204\n",
       "26295    1058.174059\n",
       "26296    2036.549357\n",
       "26297     472.307718\n",
       "Name: model_forecast, Length: 26298, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earth_combo_tv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "093e0c26-07f7-40f7-9709-654ae0710cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tv = orig_train_df['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03467410-5520-4a5b-9bb8-8ed743410ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.098824805150043\n",
      "4.781041939812455\n",
      "4.175573461450916\n",
      "14.396222549610735\n",
      "99.04042806269284\n",
      "7.926662675729486\n",
      "15.11713989060885\n",
      "5.338351055481194\n"
     ]
    }
   ],
   "source": [
    "for preds in [prophet_tv_preds, ridge_combo_tv_preds, linear_combo_tv_preds, huber_combo_tv_preds, mlp_combo_tv_preds, neural_tv_preds, lasso_combo_tv_preds, earth_combo_tv_preds]:\n",
    "    print(SMAPE(y_pred=preds, y_true=y_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d933b-7036-4667-9023-4d2aa6135433",
   "metadata": {},
   "source": [
    "Clearly, doing it by combination is the way to go. I think Ridge and LinearRegressor are definitely good to use; Prophet and NeuralProphet are worth including as well. Huber, probably not; MLPRegressor, definitely not barring the discovery of better hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115ef92-8be4-45d5-a153-4f1e4aedfc04",
   "metadata": {},
   "source": [
    "### Forecast Bundling\n",
    "Now, create an iterable collection consisting of all the forecaster predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "257a398a-c8c5-45ee-a426-c44b3779af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_tv_preds = {\n",
    "    'prophet': prophet_tv_preds,\n",
    "    'neuralprophet': neural_tv_preds,\n",
    "    'ridge': ridge_combo_tv_preds,\n",
    "    'linear': linear_combo_tv_preds,\n",
    "    'huber': huber_combo_tv_preds,\n",
    "    'lasso': lasso_combo_tv_preds,\n",
    "    'earth': earth_combo_tv_preds,\n",
    "}\n",
    "\n",
    "forecast_test_preds = {\n",
    "    'prophet': prophet_test_preds,\n",
    "    'neuralprophet': neural_test_preds,\n",
    "    'ridge': ridge_combo_test_preds,\n",
    "    'linear': linear_combo_test_preds,\n",
    "    'huber': huber_combo_test_preds,\n",
    "    'lasso': lasso_combo_test_preds,\n",
    "    'earth': earth_combo_test_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1304683-0d0b-4386-ad43-cac2a1a9eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_preds = pd.DataFrame({\n",
    "    'date': orig_train_df['date'],\n",
    "    'num_sold': orig_train_df['num_sold'],\n",
    "    **forecast_tv_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3134137-eb04-4b15-b1f9-01051867ee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>329</td>\n",
       "      <td>346.560416</td>\n",
       "      <td>329.134521</td>\n",
       "      <td>283.272258</td>\n",
       "      <td>324.188332</td>\n",
       "      <td>239.868861</td>\n",
       "      <td>176.381725</td>\n",
       "      <td>360.672190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>520</td>\n",
       "      <td>536.203586</td>\n",
       "      <td>458.008301</td>\n",
       "      <td>439.771734</td>\n",
       "      <td>503.081569</td>\n",
       "      <td>334.618687</td>\n",
       "      <td>334.453055</td>\n",
       "      <td>584.851806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>146</td>\n",
       "      <td>143.412803</td>\n",
       "      <td>145.325577</td>\n",
       "      <td>120.885683</td>\n",
       "      <td>136.667932</td>\n",
       "      <td>96.086063</td>\n",
       "      <td>89.802390</td>\n",
       "      <td>138.401176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>572</td>\n",
       "      <td>590.117165</td>\n",
       "      <td>552.571167</td>\n",
       "      <td>488.810710</td>\n",
       "      <td>555.531957</td>\n",
       "      <td>330.014790</td>\n",
       "      <td>307.788806</td>\n",
       "      <td>562.479785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>911</td>\n",
       "      <td>939.673009</td>\n",
       "      <td>781.967285</td>\n",
       "      <td>771.701702</td>\n",
       "      <td>890.469201</td>\n",
       "      <td>875.922092</td>\n",
       "      <td>583.510103</td>\n",
       "      <td>944.584508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>823</td>\n",
       "      <td>898.322121</td>\n",
       "      <td>669.418457</td>\n",
       "      <td>723.714830</td>\n",
       "      <td>846.597603</td>\n",
       "      <td>407.206130</td>\n",
       "      <td>397.285794</td>\n",
       "      <td>836.947940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>250</td>\n",
       "      <td>253.512355</td>\n",
       "      <td>227.158142</td>\n",
       "      <td>205.880079</td>\n",
       "      <td>241.048951</td>\n",
       "      <td>132.620712</td>\n",
       "      <td>126.765608</td>\n",
       "      <td>254.287204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1004</td>\n",
       "      <td>1039.635205</td>\n",
       "      <td>715.639648</td>\n",
       "      <td>832.192362</td>\n",
       "      <td>975.785339</td>\n",
       "      <td>401.224848</td>\n",
       "      <td>430.368706</td>\n",
       "      <td>1058.174059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1441</td>\n",
       "      <td>1526.908216</td>\n",
       "      <td>980.234009</td>\n",
       "      <td>1255.885410</td>\n",
       "      <td>1468.776593</td>\n",
       "      <td>863.230649</td>\n",
       "      <td>689.775798</td>\n",
       "      <td>2036.549357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>388</td>\n",
       "      <td>463.705207</td>\n",
       "      <td>423.052612</td>\n",
       "      <td>373.542094</td>\n",
       "      <td>441.128842</td>\n",
       "      <td>272.140350</td>\n",
       "      <td>220.531682</td>\n",
       "      <td>472.307718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold      prophet  neuralprophet        ridge  \\\n",
       "0      2015-01-01       329   346.560416     329.134521   283.272258   \n",
       "1      2015-01-01       520   536.203586     458.008301   439.771734   \n",
       "2      2015-01-01       146   143.412803     145.325577   120.885683   \n",
       "3      2015-01-01       572   590.117165     552.571167   488.810710   \n",
       "4      2015-01-01       911   939.673009     781.967285   771.701702   \n",
       "...           ...       ...          ...            ...          ...   \n",
       "26293  2018-12-31       823   898.322121     669.418457   723.714830   \n",
       "26294  2018-12-31       250   253.512355     227.158142   205.880079   \n",
       "26295  2018-12-31      1004  1039.635205     715.639648   832.192362   \n",
       "26296  2018-12-31      1441  1526.908216     980.234009  1255.885410   \n",
       "26297  2018-12-31       388   463.705207     423.052612   373.542094   \n",
       "\n",
       "            linear       huber       lasso        earth  \n",
       "0       324.188332  239.868861  176.381725   360.672190  \n",
       "1       503.081569  334.618687  334.453055   584.851806  \n",
       "2       136.667932   96.086063   89.802390   138.401176  \n",
       "3       555.531957  330.014790  307.788806   562.479785  \n",
       "4       890.469201  875.922092  583.510103   944.584508  \n",
       "...            ...         ...         ...          ...  \n",
       "26293   846.597603  407.206130  397.285794   836.947940  \n",
       "26294   241.048951  132.620712  126.765608   254.287204  \n",
       "26295   975.785339  401.224848  430.368706  1058.174059  \n",
       "26296  1468.776593  863.230649  689.775798  2036.549357  \n",
       "26297   441.128842  272.140350  220.531682   472.307718  \n",
       "\n",
       "[26298 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17daeb57-cc7a-4449-9257-437edec6f194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>405</td>\n",
       "      <td>383.365770</td>\n",
       "      <td>374.809906</td>\n",
       "      <td>345.296498</td>\n",
       "      <td>417.388135</td>\n",
       "      <td>249.679981</td>\n",
       "      <td>211.676443</td>\n",
       "      <td>382.162985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19729</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>621</td>\n",
       "      <td>602.594228</td>\n",
       "      <td>539.082520</td>\n",
       "      <td>536.708119</td>\n",
       "      <td>637.949409</td>\n",
       "      <td>348.560475</td>\n",
       "      <td>348.732376</td>\n",
       "      <td>609.231013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>176</td>\n",
       "      <td>161.735807</td>\n",
       "      <td>167.919098</td>\n",
       "      <td>147.203184</td>\n",
       "      <td>174.086997</td>\n",
       "      <td>99.898973</td>\n",
       "      <td>107.780206</td>\n",
       "      <td>167.839584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19731</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>714</td>\n",
       "      <td>656.201669</td>\n",
       "      <td>635.251648</td>\n",
       "      <td>596.599377</td>\n",
       "      <td>713.788713</td>\n",
       "      <td>343.757663</td>\n",
       "      <td>368.614186</td>\n",
       "      <td>597.369896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1043</td>\n",
       "      <td>1044.903702</td>\n",
       "      <td>940.582886</td>\n",
       "      <td>930.576635</td>\n",
       "      <td>1110.805235</td>\n",
       "      <td>913.849095</td>\n",
       "      <td>604.430617</td>\n",
       "      <td>1059.300177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>823</td>\n",
       "      <td>898.322121</td>\n",
       "      <td>669.418457</td>\n",
       "      <td>723.714830</td>\n",
       "      <td>846.597603</td>\n",
       "      <td>407.206130</td>\n",
       "      <td>397.285794</td>\n",
       "      <td>836.947940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>250</td>\n",
       "      <td>253.512355</td>\n",
       "      <td>227.158142</td>\n",
       "      <td>205.880079</td>\n",
       "      <td>241.048951</td>\n",
       "      <td>132.620712</td>\n",
       "      <td>126.765608</td>\n",
       "      <td>254.287204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1004</td>\n",
       "      <td>1039.635205</td>\n",
       "      <td>715.639648</td>\n",
       "      <td>832.192362</td>\n",
       "      <td>975.785339</td>\n",
       "      <td>401.224848</td>\n",
       "      <td>430.368706</td>\n",
       "      <td>1058.174059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1441</td>\n",
       "      <td>1526.908216</td>\n",
       "      <td>980.234009</td>\n",
       "      <td>1255.885410</td>\n",
       "      <td>1468.776593</td>\n",
       "      <td>863.230649</td>\n",
       "      <td>689.775798</td>\n",
       "      <td>2036.549357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>388</td>\n",
       "      <td>463.705207</td>\n",
       "      <td>423.052612</td>\n",
       "      <td>373.542094</td>\n",
       "      <td>441.128842</td>\n",
       "      <td>272.140350</td>\n",
       "      <td>220.531682</td>\n",
       "      <td>472.307718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold      prophet  neuralprophet        ridge  \\\n",
       "19728  2018-01-01       405   383.365770     374.809906   345.296498   \n",
       "19729  2018-01-01       621   602.594228     539.082520   536.708119   \n",
       "19730  2018-01-01       176   161.735807     167.919098   147.203184   \n",
       "19731  2018-01-01       714   656.201669     635.251648   596.599377   \n",
       "19732  2018-01-01      1043  1044.903702     940.582886   930.576635   \n",
       "...           ...       ...          ...            ...          ...   \n",
       "26293  2018-12-31       823   898.322121     669.418457   723.714830   \n",
       "26294  2018-12-31       250   253.512355     227.158142   205.880079   \n",
       "26295  2018-12-31      1004  1039.635205     715.639648   832.192362   \n",
       "26296  2018-12-31      1441  1526.908216     980.234009  1255.885410   \n",
       "26297  2018-12-31       388   463.705207     423.052612   373.542094   \n",
       "\n",
       "            linear       huber       lasso        earth  \n",
       "19728   417.388135  249.679981  211.676443   382.162985  \n",
       "19729   637.949409  348.560475  348.732376   609.231013  \n",
       "19730   174.086997   99.898973  107.780206   167.839584  \n",
       "19731   713.788713  343.757663  368.614186   597.369896  \n",
       "19732  1110.805235  913.849095  604.430617  1059.300177  \n",
       "...            ...         ...         ...          ...  \n",
       "26293   846.597603  407.206130  397.285794   836.947940  \n",
       "26294   241.048951  132.620712  126.765608   254.287204  \n",
       "26295   975.785339  401.224848  430.368706  1058.174059  \n",
       "26296  1468.776593  863.230649  689.775798  2036.549357  \n",
       "26297   441.128842  272.140350  220.531682   472.307718  \n",
       "\n",
       "[6570 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_forecast_preds = tv_preds[tv_preds['date'] > '2017-12-31']\n",
    "valid_forecast_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71b4df91-1d40-496a-8ab0-90bfe3cd8970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_sold</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972938</td>\n",
       "      <td>0.961440</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.995334</td>\n",
       "      <td>0.910517</td>\n",
       "      <td>0.899862</td>\n",
       "      <td>0.984322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prophet</th>\n",
       "      <td>0.972938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990336</td>\n",
       "      <td>0.985617</td>\n",
       "      <td>0.975158</td>\n",
       "      <td>0.937816</td>\n",
       "      <td>0.939803</td>\n",
       "      <td>0.972174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralprophet</th>\n",
       "      <td>0.961440</td>\n",
       "      <td>0.990336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978596</td>\n",
       "      <td>0.962073</td>\n",
       "      <td>0.947772</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>0.961384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.985617</td>\n",
       "      <td>0.978596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996412</td>\n",
       "      <td>0.926965</td>\n",
       "      <td>0.919398</td>\n",
       "      <td>0.989698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.995334</td>\n",
       "      <td>0.975158</td>\n",
       "      <td>0.962073</td>\n",
       "      <td>0.996412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910123</td>\n",
       "      <td>0.901341</td>\n",
       "      <td>0.987908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>0.910517</td>\n",
       "      <td>0.937816</td>\n",
       "      <td>0.947772</td>\n",
       "      <td>0.926965</td>\n",
       "      <td>0.910123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922899</td>\n",
       "      <td>0.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.899862</td>\n",
       "      <td>0.939803</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>0.919398</td>\n",
       "      <td>0.901341</td>\n",
       "      <td>0.922899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earth</th>\n",
       "      <td>0.984322</td>\n",
       "      <td>0.972174</td>\n",
       "      <td>0.961384</td>\n",
       "      <td>0.989698</td>\n",
       "      <td>0.987908</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.906948</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               num_sold   prophet  neuralprophet     ridge    linear  \\\n",
       "num_sold       1.000000  0.972938       0.961440  0.992806  0.995334   \n",
       "prophet        0.972938  1.000000       0.990336  0.985617  0.975158   \n",
       "neuralprophet  0.961440  0.990336       1.000000  0.978596  0.962073   \n",
       "ridge          0.992806  0.985617       0.978596  1.000000  0.996412   \n",
       "linear         0.995334  0.975158       0.962073  0.996412  1.000000   \n",
       "huber          0.910517  0.937816       0.947772  0.926965  0.910123   \n",
       "lasso          0.899862  0.939803       0.950331  0.919398  0.901341   \n",
       "earth          0.984322  0.972174       0.961384  0.989698  0.987908   \n",
       "\n",
       "                  huber     lasso     earth  \n",
       "num_sold       0.910517  0.899862  0.984322  \n",
       "prophet        0.937816  0.939803  0.972174  \n",
       "neuralprophet  0.947772  0.950331  0.961384  \n",
       "ridge          0.926965  0.919398  0.989698  \n",
       "linear         0.910123  0.901341  0.987908  \n",
       "huber          1.000000  0.922899  0.910400  \n",
       "lasso          0.922899  1.000000  0.906948  \n",
       "earth          0.910400  0.906948  1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_forecast_preds.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d18d79d8-9700-465c-8c09-e9e7eaa7eec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_sold</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975093</td>\n",
       "      <td>0.960082</td>\n",
       "      <td>0.993110</td>\n",
       "      <td>0.995846</td>\n",
       "      <td>0.907911</td>\n",
       "      <td>0.899352</td>\n",
       "      <td>0.990016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prophet</th>\n",
       "      <td>0.975093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985693</td>\n",
       "      <td>0.986481</td>\n",
       "      <td>0.977785</td>\n",
       "      <td>0.933401</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.974833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralprophet</th>\n",
       "      <td>0.960082</td>\n",
       "      <td>0.985693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978010</td>\n",
       "      <td>0.962507</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.939915</td>\n",
       "      <td>0.960241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.993110</td>\n",
       "      <td>0.986481</td>\n",
       "      <td>0.978010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996573</td>\n",
       "      <td>0.926616</td>\n",
       "      <td>0.919336</td>\n",
       "      <td>0.992161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.995846</td>\n",
       "      <td>0.977785</td>\n",
       "      <td>0.962507</td>\n",
       "      <td>0.996573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909135</td>\n",
       "      <td>0.900973</td>\n",
       "      <td>0.994045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>0.907911</td>\n",
       "      <td>0.933401</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.926616</td>\n",
       "      <td>0.909135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923215</td>\n",
       "      <td>0.907105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.899352</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.939915</td>\n",
       "      <td>0.919336</td>\n",
       "      <td>0.900973</td>\n",
       "      <td>0.923215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earth</th>\n",
       "      <td>0.990016</td>\n",
       "      <td>0.974833</td>\n",
       "      <td>0.960241</td>\n",
       "      <td>0.992161</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.907105</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               num_sold   prophet  neuralprophet     ridge    linear  \\\n",
       "num_sold       1.000000  0.975093       0.960082  0.993110  0.995846   \n",
       "prophet        0.975093  1.000000       0.985693  0.986481  0.977785   \n",
       "neuralprophet  0.960082  0.985693       1.000000  0.978010  0.962507   \n",
       "ridge          0.993110  0.986481       0.978010  1.000000  0.996573   \n",
       "linear         0.995846  0.977785       0.962507  0.996573  1.000000   \n",
       "huber          0.907911  0.933401       0.938389  0.926616  0.909135   \n",
       "lasso          0.899352  0.927660       0.939915  0.919336  0.900973   \n",
       "earth          0.990016  0.974833       0.960241  0.992161  0.994045   \n",
       "\n",
       "                  huber     lasso     earth  \n",
       "num_sold       0.907911  0.899352  0.990016  \n",
       "prophet        0.933401  0.927660  0.974833  \n",
       "neuralprophet  0.938389  0.939915  0.960241  \n",
       "ridge          0.926616  0.919336  0.992161  \n",
       "linear         0.909135  0.900973  0.994045  \n",
       "huber          1.000000  0.923215  0.907105  \n",
       "lasso          0.923215  1.000000  0.900047  \n",
       "earth          0.907105  0.900047  1.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_preds.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129e48f-dd45-4627-af08-1544cd69aa1b",
   "metadata": {},
   "source": [
    "So Ridge and Linear perform best, and are quite similar; Prophet and NeuralProphet are next best, and similar to one another; Huber is an outlier (and not so good). Lasso performs worst of all, but is closer to Prophet and NeuralProphet in performance than the others. It's closest of all to NeuralProphet, interestingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a0d99ea-df90-4533-b1bf-6ed324c74235",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forecast_preds = pd.DataFrame({\n",
    "    'date': orig_test_df['date'],\n",
    "#     'num_sold': orig_train_df['num_sold'],\n",
    "    **forecast_test_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bad0b95-51ee-46d0-9c2a-a2d724840cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>402.296576</td>\n",
       "      <td>383.543457</td>\n",
       "      <td>359.817081</td>\n",
       "      <td>392.328390</td>\n",
       "      <td>248.728792</td>\n",
       "      <td>221.118411</td>\n",
       "      <td>417.102143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>631.642099</td>\n",
       "      <td>551.044983</td>\n",
       "      <td>560.783324</td>\n",
       "      <td>620.092467</td>\n",
       "      <td>347.337935</td>\n",
       "      <td>347.623611</td>\n",
       "      <td>693.844970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>169.992094</td>\n",
       "      <td>173.065674</td>\n",
       "      <td>153.552940</td>\n",
       "      <td>166.788184</td>\n",
       "      <td>99.483226</td>\n",
       "      <td>112.590591</td>\n",
       "      <td>181.642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>684.559821</td>\n",
       "      <td>648.783691</td>\n",
       "      <td>622.237644</td>\n",
       "      <td>675.674104</td>\n",
       "      <td>342.549613</td>\n",
       "      <td>384.790895</td>\n",
       "      <td>594.166542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1092.875362</td>\n",
       "      <td>965.683716</td>\n",
       "      <td>969.065554</td>\n",
       "      <td>1084.980801</td>\n",
       "      <td>911.102831</td>\n",
       "      <td>601.189400</td>\n",
       "      <td>1142.564632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>917.085861</td>\n",
       "      <td>674.891174</td>\n",
       "      <td>742.331990</td>\n",
       "      <td>797.964290</td>\n",
       "      <td>404.876685</td>\n",
       "      <td>391.134492</td>\n",
       "      <td>830.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>261.569590</td>\n",
       "      <td>232.082169</td>\n",
       "      <td>210.920805</td>\n",
       "      <td>225.576610</td>\n",
       "      <td>131.774790</td>\n",
       "      <td>129.930008</td>\n",
       "      <td>269.498973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1065.400121</td>\n",
       "      <td>730.457275</td>\n",
       "      <td>852.091174</td>\n",
       "      <td>925.788409</td>\n",
       "      <td>398.926697</td>\n",
       "      <td>440.077496</td>\n",
       "      <td>1133.560974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1568.407214</td>\n",
       "      <td>1005.392944</td>\n",
       "      <td>1286.814471</td>\n",
       "      <td>1397.071983</td>\n",
       "      <td>858.595973</td>\n",
       "      <td>677.887045</td>\n",
       "      <td>2627.470943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>476.122783</td>\n",
       "      <td>428.916565</td>\n",
       "      <td>382.800781</td>\n",
       "      <td>417.035222</td>\n",
       "      <td>270.478738</td>\n",
       "      <td>225.775009</td>\n",
       "      <td>507.799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      prophet  neuralprophet        ridge       linear  \\\n",
       "0     2019-01-01   402.296576     383.543457   359.817081   392.328390   \n",
       "1     2019-01-01   631.642099     551.044983   560.783324   620.092467   \n",
       "2     2019-01-01   169.992094     173.065674   153.552940   166.788184   \n",
       "3     2019-01-01   684.559821     648.783691   622.237644   675.674104   \n",
       "4     2019-01-01  1092.875362     965.683716   969.065554  1084.980801   \n",
       "...          ...          ...            ...          ...          ...   \n",
       "6565  2019-12-31   917.085861     674.891174   742.331990   797.964290   \n",
       "6566  2019-12-31   261.569590     232.082169   210.920805   225.576610   \n",
       "6567  2019-12-31  1065.400121     730.457275   852.091174   925.788409   \n",
       "6568  2019-12-31  1568.407214    1005.392944  1286.814471  1397.071983   \n",
       "6569  2019-12-31   476.122783     428.916565   382.800781   417.035222   \n",
       "\n",
       "           huber       lasso        earth  \n",
       "0     248.728792  221.118411   417.102143  \n",
       "1     347.337935  347.623611   693.844970  \n",
       "2      99.483226  112.590591   181.642807  \n",
       "3     342.549613  384.790895   594.166542  \n",
       "4     911.102831  601.189400  1142.564632  \n",
       "...          ...         ...          ...  \n",
       "6565  404.876685  391.134492   830.606248  \n",
       "6566  131.774790  129.930008   269.498973  \n",
       "6567  398.926697  440.077496  1133.560974  \n",
       "6568  858.595973  677.887045  2627.470943  \n",
       "6569  270.478738  225.775009   507.799360  \n",
       "\n",
       "[6570 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forecast_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1c5c1-21a7-4baf-936a-acb46efa451e",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc5287-ab0f-4fa2-9461-06e1a2958cb8",
   "metadata": {},
   "source": [
    "At this point, I have two DataFrames containing predictions from the forecasting models (which try to learn trends): \n",
    "1. `valid_forecast_preds`\n",
    "2. `test_forecast_preds`\n",
    "\n",
    "Both still contain the features `'date'` (having a datetime type) and the validation preds contain `num_sold`.\n",
    "\n",
    "The goal now will be to iteratively generate a final prediction DataFrame containing all possible combinations of the forecasting model predictions and residual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c4b00bf-0ab4-4f7c-a3ab-9ca923e5d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_models = ['prophet', 'neuralprophet', 'ridge', 'linear', 'huber', 'lasso', 'earth'] # models to use to provide basis for residual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58e4125f-99c4-49d1-a6ed-f0bf26c76393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47e6ec23-4a69-4862-ab61-25949945cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(encoded_all_df, datapath/'encoded_train+testset_with_gdp+teckmengwong-time-features+transformed-target-for-train.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eebd4acf-8940-493b-90f8-26d04cb2d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid_train_df = encoded_all_df[:len(train_df)]\n",
    "# hybrid_valid_df = encoded_all_df[len(train_df): len(train_df)+len(valid_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9040538b-351a-4d0f-8a6c-03394d8aa2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid_test_df = encoded_all_df[len(train_df)+len(valid_df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2879f3ec-7e9e-4b39-9060-8b4546e71686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04403cf9-708c-4d7c-8470-899780c58fd6",
   "metadata": {},
   "source": [
    "Note that the `tv_df` still contains both transformed targets and `num_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abe1053a-ecc9-49db-92bc-145b642557f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.925788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.291321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>823.0</td>\n",
       "      <td>6.321586</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.477861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6.321586</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.286366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>6.321586</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.676652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>6.321586</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.037997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6.321586</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.725910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  country       store         product  num_sold       gdp  \\\n",
       "0     2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0  5.461456   \n",
       "1     2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0  5.461456   \n",
       "2     2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0  5.461456   \n",
       "3     2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0  5.461456   \n",
       "4     2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0  5.461456   \n",
       "...          ...      ...         ...             ...       ...       ...   \n",
       "26293 2018-12-31   Sweden  KaggleMart      Kaggle Hat     823.0  6.321586   \n",
       "26294 2018-12-31   Sweden  KaggleMart  Kaggle Sticker     250.0  6.321586   \n",
       "26295 2018-12-31   Sweden  KaggleRama      Kaggle Mug    1004.0  6.321586   \n",
       "26296 2018-12-31   Sweden  KaggleRama      Kaggle Hat    1441.0  6.321586   \n",
       "26297 2018-12-31   Sweden  KaggleRama  Kaggle Sticker     388.0  6.321586   \n",
       "\n",
       "       month  season    wd4   wd56  ...  easter50  easter51  easter52  \\\n",
       "0          1       1  False  False  ...     False     False     False   \n",
       "1          1       1  False  False  ...     False     False     False   \n",
       "2          1       1  False  False  ...     False     False     False   \n",
       "3          1       1  False  False  ...     False     False     False   \n",
       "4          1       1  False  False  ...     False     False     False   \n",
       "...      ...     ...    ...    ...  ...       ...       ...       ...   \n",
       "26293     12       1  False  False  ...     False     False     False   \n",
       "26294     12       1  False  False  ...     False     False     False   \n",
       "26295     12       1  False  False  ...     False     False     False   \n",
       "26296     12       1  False  False  ...     False     False     False   \n",
       "26297     12       1  False  False  ...     False     False     False   \n",
       "\n",
       "       easter53  easter54  easter55  easter56  easter57  easter58    target  \n",
       "0         False     False     False     False     False     False  3.738239  \n",
       "1         False     False     False     False     False     False  4.196010  \n",
       "2         False     False     False     False     False     False  2.925788  \n",
       "3         False     False     False     False     False     False  4.291321  \n",
       "4         False     False     False     False     False     False  4.756724  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "26293     False     False     False     False     False     False  4.477861  \n",
       "26294     False     False     False     False     False     False  3.286366  \n",
       "26295     False     False     False     False     False     False  4.676652  \n",
       "26296     False     False     False     False     False     False  5.037997  \n",
       "26297     False     False     False     False     False     False  3.725910  \n",
       "\n",
       "[26298 rows x 246 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ead87f7c-1cf5-4292-96a0-9909c630c8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.597614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.597614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.597614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.597614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.597614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  country       store         product  num_sold       gdp  \\\n",
       "0    2019-01-01  Finland  KaggleMart      Kaggle Mug       NaN  5.597614   \n",
       "1    2019-01-01  Finland  KaggleMart      Kaggle Hat       NaN  5.597614   \n",
       "2    2019-01-01  Finland  KaggleMart  Kaggle Sticker       NaN  5.597614   \n",
       "3    2019-01-01  Finland  KaggleRama      Kaggle Mug       NaN  5.597614   \n",
       "4    2019-01-01  Finland  KaggleRama      Kaggle Hat       NaN  5.597614   \n",
       "...         ...      ...         ...             ...       ...       ...   \n",
       "6565 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN  6.282042   \n",
       "6566 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN  6.282042   \n",
       "6567 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN  6.282042   \n",
       "6568 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN  6.282042   \n",
       "6569 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN  6.282042   \n",
       "\n",
       "      month  season    wd4   wd56  ...  easter50  easter51  easter52  \\\n",
       "0         1       1  False  False  ...     False     False     False   \n",
       "1         1       1  False  False  ...     False     False     False   \n",
       "2         1       1  False  False  ...     False     False     False   \n",
       "3         1       1  False  False  ...     False     False     False   \n",
       "4         1       1  False  False  ...     False     False     False   \n",
       "...     ...     ...    ...    ...  ...       ...       ...       ...   \n",
       "6565     12       1  False  False  ...     False     False     False   \n",
       "6566     12       1  False  False  ...     False     False     False   \n",
       "6567     12       1  False  False  ...     False     False     False   \n",
       "6568     12       1  False  False  ...     False     False     False   \n",
       "6569     12       1  False  False  ...     False     False     False   \n",
       "\n",
       "      easter53  easter54  easter55  easter56  easter57  easter58  target  \n",
       "0        False     False     False     False     False     False     NaN  \n",
       "1        False     False     False     False     False     False     NaN  \n",
       "2        False     False     False     False     False     False     NaN  \n",
       "3        False     False     False     False     False     False     NaN  \n",
       "4        False     False     False     False     False     False     NaN  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "6565     False     False     False     False     False     False     NaN  \n",
       "6566     False     False     False     False     False     False     NaN  \n",
       "6567     False     False     False     False     False     False     NaN  \n",
       "6568     False     False     False     False     False     False     NaN  \n",
       "6569     False     False     False     False     False     False     NaN  \n",
       "\n",
       "[6570 rows x 246 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8825c-4f51-4d27-89af-6b5416a0f98c",
   "metadata": {},
   "source": [
    "One question: should the full `tv_df` be passed as data, or only the validation set? I think it's better to supply as much data as possible, so I'll use the whole thing for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03445ac7-a189-40f8-a42b-2e57001df451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b36b5a4-4c73-45ed-acb6-6b283a43d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26298"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00188415-c7de-448d-afad-69c6bc853480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26298"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c91fb31b-b595-4905-966f-9bb5229e738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b888c8e0-081b-497c-b771-0a7ef0eccd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527db03d-15fe-41bc-96ee-e7a99868c0c7",
   "metadata": {},
   "source": [
    "#### Residual Trainer \n",
    "(assumes Scikit-Learn API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b19a872c-4e83-4f2e-a979-1a004f0eeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_trainer(estimator, model_kwargs={}, forecast_models=forecast_models,\n",
    "                     tv_df=tv_df, test_df=test_df,\n",
    "                     tv_forecast_preds=tv_preds, test_forecast_preds=test_forecast_preds):\n",
    "#     df_2018 = tv_df[tv_df['date'] > '2017-12-31']\n",
    "    # create local versions of the dataframes, to avoid mutation\n",
    "    df_train = tv_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    \n",
    "    # apply label encoding (which Scikit-Learn models require, but *Prophets don't)\n",
    "    le_dict, tv_df = label_encoder(df_train) # should leave broader scope's tv_df alone\n",
    "    _, test_df = label_encoder(df_test) # should leave broader scope's test_df alone\n",
    "    del df_train, df_test\n",
    "    \n",
    "    residual_tv_df = pd.DataFrame({\n",
    "        'date': orig_train_df['date'],\n",
    "        'num_sold': orig_train_df['num_sold']\n",
    "    })\n",
    "    print(len(residual_tv_df))\n",
    "    \n",
    "    residual_test_df = pd.DataFrame({\n",
    "        'date': orig_test_df['date'],\n",
    "    })\n",
    "    \n",
    "    # getting rid of unneeded 'target' feature, also num_sold since we're only interested in predicting the residual\n",
    "    # following @ambrosm lightgbm nb and leaving date in for GroupKFold, but unsure of this (or if I should drop it later)\n",
    "    tv_df = tv_df.drop(columns=['target', 'num_sold'])#, 'date'])\n",
    "    test_df = test_df.drop(columns=['target', 'num_sold'])#, 'date'])\n",
    "    \n",
    "    kfolds= GroupKFold(n_splits=4)\n",
    "    \n",
    "    test_fold_preds = {}\n",
    "    \n",
    "    for forecast_model in forecast_models:\n",
    "        print(f\"Working with forecasts from {forecast_model}...\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        forecast = tv_forecast_preds[forecast_model] # pull out the predictions on the t-v sets for a given estimator\n",
    "        residuals = residual_tv_df['num_sold'] - forecast # get the residuals for the given model's forecast\n",
    "#         residual_df[f'actual_{forecast_model}_residual'] = residuals # may not need to put this in there\n",
    "#         tv_df['residual'] = residuals # residuals will rotate in and out of this feature\n",
    "        \n",
    "        \n",
    "        X_test = test_df.drop(columns=['date'])\n",
    "#         print(\"y.shape is \", y.shape)\n",
    "        \n",
    "        # prepare for Group K-Fold cross-val; below from @ambrosm LightGBM notebook\n",
    "        oof_preds = pd.Series(0, index=tv_df.index)\n",
    "#         test_preds_df = pd.DataFrame({\n",
    "#             'date': test_df['date']\n",
    "#         })\n",
    "        score_list = []\n",
    "#         params['seed'] = 1\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfolds.split(tv_df, groups=tv_df.date.dt.year)):\n",
    "            print(\"-----------------------------------------------------\")\n",
    "            print(f\"FOLD {fold}\")\n",
    "            X = tv_df.iloc[train_idx].drop(columns=['date'])\n",
    "            y = residuals.iloc[train_idx]#['date']\n",
    "            X_valid = tv_df.iloc[val_idx].drop(columns=['date'])\n",
    "            y_valid = residuals.iloc[val_idx]#['date']\n",
    "            \n",
    "            model = estimator(**model_kwargs)\n",
    "            model.fit(X, y)\n",
    "            \n",
    "            residual_valid_preds = model.predict(X_valid)\n",
    "            residual_test_preds = model.predict(X_test)\n",
    "            \n",
    "            oof_preds[val_idx] = residual_valid_preds\n",
    "#             test_preds_df[f'{forecast_model}_fold_{fold}_preds'] = residual_test_preds\n",
    "#             residual_test_df = residual_test_df.join(test_preds_df)\n",
    "#             smape = SMAPE(y_pred=residual_valid_preds, y_true=y_valid.values)\n",
    "#             print(f\"SMAPE: {smape}\")\n",
    "            rmse = math.sqrt(mean_squared_error(y_pred=residual_valid_preds, y_true=y_valid.values))\n",
    "            print(f\"RMSE: {rmse}\")\n",
    "            test_fold_preds[f'{forecast_model}_{fold}_residual_preds'] = residual_test_preds\n",
    "        residual_tv_df[f'{forecast_model}_oof_residual_preds'] = oof_preds\n",
    "#         residual_test_df = residual_test_df.join(test_preds_df)\n",
    "    return residual_tv_df, test_fold_preds #residual_test_df\n",
    "        \n",
    "            \n",
    "            \n",
    "#             model, smape = fit_model(X_tr, X_va, run=0, fold=fold)\n",
    "\n",
    "# print(f\"Average SMAPE: {sum(score_list) / len(score_list):.5f}\")\n",
    "# with open('oof.pickle', 'wb') as handle: pickle.dump(oof, handle)\n",
    "#         X = tv_df.drop(columns=['residual'])\n",
    "#         y = tv_df['residual']\n",
    "        \n",
    "#         tv_\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "#     y_valid = valid_df['num_sold']\n",
    "#     valid_df = valid_df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd79291a-e0db-47ac-937e-c8973318f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282e7b8-a7f7-4b7c-b3dd-18c0bc4a1f3f",
   "metadata": {},
   "source": [
    "#### Residual model hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f894553e-497a-4335-b955-3ca63074ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'eval_metric': ['mae', 'mape', 'rmse'],\n",
    "    'learning_rate': .09,\n",
    "    'max_depth': 0,\n",
    "    'subsample': .15,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'seed': 42,\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 255,\n",
    "    'lambda': 100,\n",
    "#     'n_estimators': 3000,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 500\n",
    "#     'verbose': True,\n",
    "}\n",
    "\n",
    "\n",
    "lightgbm_params = {\n",
    "    'objective': 'mse',\n",
    "    'random_state': 42,\n",
    "    'device_type': 'cpu',\n",
    "    'n_jobs': -1,\n",
    "#                 eval_metric='auc',\n",
    "#     'device_type': 'gpu',\n",
    "#     'max_bin': 63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     'gpu_use_dp': False,\n",
    "    'max_depth': 0,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': .15,\n",
    "    'n_estimators': 1500,\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'task_type':'GPU',\n",
    "    'silent':True,\n",
    "    'random_state':42,\n",
    "}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f28c06-be28-45ff-989b-da6278d676ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be4ad4ba-04df-47d6-bc2a-8e57c1d81856",
   "metadata": {
    "tags": []
   },
   "source": [
    "XGBoost SMAPEs with `n_estimators=500`:\n",
    "\n",
    "```\n",
    "26298\n",
    "Working with forecasts from prophet...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 44.22169948290956\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 42.2884194618039\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 38.87851134388903\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 39.14401892347087\n",
    "Working with forecasts from neuralprophet...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 71.59711327241503\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 50.410812085025206\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 56.30623610755547\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 71.87002649034811\n",
    "Working with forecasts from ridge...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 29.951196797722172\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 33.87710734178301\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 30.3425528497887\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 30.908377053367243\n",
    "Working with forecasts from linear...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 25.909733767351145\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 32.55539418287357\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 28.02573800531867\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 27.512157750399876\n",
    "Working with forecasts from huber...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 43.8980188030959\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 55.40375581530791\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 46.37734856211295\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 41.743947334147386\n",
    "Working with forecasts from lasso...\n",
    "-----------------------------------------------------\n",
    "-----------------------------------------------------\n",
    "FOLD 0\n",
    "RMSE: 42.212939444847706\n",
    "-----------------------------------------------------\n",
    "FOLD 1\n",
    "RMSE: 58.6828784233263\n",
    "-----------------------------------------------------\n",
    "FOLD 2\n",
    "RMSE: 47.91103516420516\n",
    "-----------------------------------------------------\n",
    "FOLD 3\n",
    "RMSE: 41.89282012115221\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71150a-f321-4384-a2ed-8ee6c2e49490",
   "metadata": {},
   "source": [
    "#### Residual model training / loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9f495a4-121d-4a0d-b8e0-74486c89224e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3 µs, total: 3 µs\n",
      "Wall time: 6.68 µs\n",
      "26298\n",
      "Working with forecasts from prophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 44.22169948290956\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 42.2884194618039\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 38.87851134388903\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 39.14401892347087\n",
      "Working with forecasts from neuralprophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 72.2965394109592\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 50.48678606565055\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 56.39589310004499\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 71.94274727206121\n",
      "Working with forecasts from ridge...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 29.951196797722172\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 33.87710734178301\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 30.3425528497887\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 30.908377053367243\n",
      "Working with forecasts from linear...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 25.909733767351145\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 32.55539418287357\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 28.02573800531867\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 27.512157750399876\n",
      "Working with forecasts from huber...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 43.8980188030959\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 55.40375581530791\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 46.37734856211295\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 41.743947334147386\n",
      "Working with forecasts from lasso...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 42.212939444847706\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 58.6828784233263\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 47.91103516420516\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 41.89282012115221\n",
      "Working with forecasts from earth...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 34.05471068306962\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 61.12729726220758\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 29.471981225905832\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 29.940868554298905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/preds/20220125_+earth_residual_test_residual_xgboost_preds.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "xgb_tv_df, xgb_test_fold_preds = residual_trainer(estimator=XGBRegressor, model_kwargs=xgboost_params,)\n",
    "dump(xgb_tv_df, predpath/'20220125_+earth_residual_oof_residual_xgboost_preds.joblib')\n",
    "dump(xgb_test_fold_preds, predpath/'20220125_+earth_residual_test_residual_xgboost_preds.joblib')\n",
    "\n",
    "# loading the 500-estimator version, which is universally better\n",
    "# xgb_tv_df = load(predpath/'20220124_residual_oof_xgboost_preds.joblib')\n",
    "# xgb_test_fold_preds = load(predpath/'20220124_residual_test_xgboost_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ef97520-5580-40a3-9a3f-50870f058dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd76fcae-43a6-4c0e-a480-e3dfe69d17c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 34 µs, total: 34 µs\n",
      "Wall time: 4.77 µs\n",
      "26298\n",
      "Working with forecasts from prophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 40.2958973133468\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 40.72754418203894\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 34.289662190196665\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 35.118251779330976\n",
      "Working with forecasts from neuralprophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 71.44951581377815\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 47.489823189781696\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 53.766625686957966\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 58.62494371250313\n",
      "Working with forecasts from ridge...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 29.1758980759644\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 33.17791852141062\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 29.035903366744673\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 28.530932307922356\n",
      "Working with forecasts from linear...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 25.632615621428638\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 32.88386805881275\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 27.907903444127207\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 27.140741714529003\n",
      "Working with forecasts from huber...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 39.46063927967101\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 51.72152452875036\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 39.27808711548493\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 37.62176191674883\n",
      "Working with forecasts from lasso...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 38.72077573106818\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 54.17187391555231\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 43.34653801480466\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 41.403254671293766\n",
      "Working with forecasts from earth...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 32.91704769304584\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 61.15997939366359\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 54.999180102287674\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 27.98231558301558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/preds/20220125_+earth_residual_test_residual_lightgbm_preds.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "lgb_tv_df, lgb_test_fold_preds = residual_trainer(estimator=LGBMRegressor, model_kwargs=lightgbm_params,)\n",
    "dump(lgb_tv_df, predpath/'20220125_+earth_residual_oof_residual_lightgbm_preds.joblib')\n",
    "dump(lgb_test_fold_preds, predpath/'20220125_+earth_residual_test_residual_lightgbm_preds.joblib')\n",
    "# lgb_tv_df = load(predpath/'20220124_residual_oof_residual_lightgbm_preds.joblib')\n",
    "# lgb_test_fold_preds = load(predpath/'20220124_residual_test_residual_lightgbm_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9880e97d-f8b2-4f37-b86b-34398de4c68a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 1e+03 ns, total: 35 µs\n",
      "Wall time: 4.77 µs\n",
      "26298\n",
      "Working with forecasts from prophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 34.85084358418546\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 39.134690709805604\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 32.316241553438786\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 32.297408734705535\n",
      "Working with forecasts from neuralprophet...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 64.4820465743269\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 45.80180130203257\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 47.036335391797884\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 54.06048073783771\n",
      "Working with forecasts from ridge...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 26.251081904204213\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 30.45670675869378\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 26.271441489436786\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 25.00787346748404\n",
      "Working with forecasts from linear...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 22.234160986704488\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 29.878801441293223\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 24.755833666838416\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 24.009469711556655\n",
      "Working with forecasts from huber...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 41.24345131543122\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 56.97872174248675\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 42.85941675464167\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 38.77474216823641\n",
      "Working with forecasts from lasso...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 37.64543227176428\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 57.090421289133424\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 42.018547320567315\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 40.365839954271145\n",
      "Working with forecasts from earth...\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "FOLD 0\n",
      "RMSE: 30.477470319935083\n",
      "-----------------------------------------------------\n",
      "FOLD 1\n",
      "RMSE: 60.10663311666607\n",
      "-----------------------------------------------------\n",
      "FOLD 2\n",
      "RMSE: 52.11538787220516\n",
      "-----------------------------------------------------\n",
      "FOLD 3\n",
      "RMSE: 25.49402551949479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/preds/20220125_+earth_residual_test_residual_catboost_preds.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "cat_tv_df, cat_test_fold_preds = residual_trainer(estimator=CatBoostRegressor, model_kwargs=catboost_params,)\n",
    "dump(cat_tv_df, predpath/'20220125_+earth_residual_oof_residual_catboost_preds.joblib')\n",
    "dump(cat_test_fold_preds, predpath/'20220125_+earth_residual_test_residual_catboost_preds.joblib')\n",
    "# cat_tv_df = load(predpath/'20220124_residual_oof_residual_catboost_preds.joblib')\n",
    "# cat_test_fold_preds = load(predpath/'20220124_residual_test_residual_catboost_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd50763d-658c-46d3-bcdb-018e61f6f089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# ridge_tv_df, ridge_test_fold_preds = residual_trainer(estimator=Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0085b3ef-6efd-4bfe-a70f-89d97a5a5363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# lasso_tv_df, lasso_test_fold_preds = residual_trainer(estimator=Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6dceb449-46ee-4ce6-9736-7549f7b5192d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# linear_tv_df, linear_test_fold_preds = residual_trainer(estimator=LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "082ba17d-b909-4d13-91d1-166fa0b0f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(valid_forecast_preds, predpath/'20220124_forecast_valid2018_preds.joblib')\n",
    "# dump(test_forecast_preds, predpath/'20220124_forecast_test_preds.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea69bb6-001b-478c-9497-b21c91d521f5",
   "metadata": {},
   "source": [
    "#### Assembling together residual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12ac91d1-2234-4b47-bedf-4a266b82cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dfs = {\n",
    "    'xgb': xgb_tv_df, \n",
    "    'lgb': lgb_tv_df, \n",
    "    'cat': cat_tv_df,\n",
    "#     'ridge': ridge_tv_df,\n",
    "#     'lasso': lasso_tv_df,\n",
    "#     'linear': linear_tv_df,\n",
    "}\n",
    "\n",
    "for arch in tv_dfs.keys():\n",
    "    for forecast_model in forecast_models:\n",
    "        tv_dfs[arch][f'{forecast_model}_pred'] = tv_preds[forecast_model]\n",
    "        tv_dfs[arch][f'{forecast_model}_residual'] = tv_dfs[arch]['num_sold'] - tv_preds[forecast_model] #- xgb_tv_df['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "437c3330-0afa-4635-b986-671a741af3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_tv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06263943-6c13-48f4-a475-273c610cafb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet_oof_residual_preds</th>\n",
       "      <th>neuralprophet_oof_residual_preds</th>\n",
       "      <th>ridge_oof_residual_preds</th>\n",
       "      <th>linear_oof_residual_preds</th>\n",
       "      <th>huber_oof_residual_preds</th>\n",
       "      <th>lasso_oof_residual_preds</th>\n",
       "      <th>earth_oof_residual_preds</th>\n",
       "      <th>prophet_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>ridge_pred</th>\n",
       "      <th>ridge_residual</th>\n",
       "      <th>linear_pred</th>\n",
       "      <th>linear_residual</th>\n",
       "      <th>huber_pred</th>\n",
       "      <th>huber_residual</th>\n",
       "      <th>lasso_pred</th>\n",
       "      <th>lasso_residual</th>\n",
       "      <th>earth_pred</th>\n",
       "      <th>earth_residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>329</td>\n",
       "      <td>1.278618</td>\n",
       "      <td>19.981554</td>\n",
       "      <td>34.222641</td>\n",
       "      <td>3.645102</td>\n",
       "      <td>139.376175</td>\n",
       "      <td>166.224564</td>\n",
       "      <td>14.680798</td>\n",
       "      <td>346.560416</td>\n",
       "      <td>...</td>\n",
       "      <td>283.272258</td>\n",
       "      <td>45.727742</td>\n",
       "      <td>324.188332</td>\n",
       "      <td>4.811668</td>\n",
       "      <td>239.868861</td>\n",
       "      <td>89.131139</td>\n",
       "      <td>176.381725</td>\n",
       "      <td>152.618275</td>\n",
       "      <td>360.672190</td>\n",
       "      <td>-31.672190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>520</td>\n",
       "      <td>-10.982243</td>\n",
       "      <td>35.412369</td>\n",
       "      <td>57.832901</td>\n",
       "      <td>-9.185784</td>\n",
       "      <td>192.085785</td>\n",
       "      <td>217.624084</td>\n",
       "      <td>12.078963</td>\n",
       "      <td>536.203586</td>\n",
       "      <td>...</td>\n",
       "      <td>439.771734</td>\n",
       "      <td>80.228266</td>\n",
       "      <td>503.081569</td>\n",
       "      <td>16.918431</td>\n",
       "      <td>334.618687</td>\n",
       "      <td>185.381313</td>\n",
       "      <td>334.453055</td>\n",
       "      <td>185.546945</td>\n",
       "      <td>584.851806</td>\n",
       "      <td>-64.851806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>146</td>\n",
       "      <td>-5.641450</td>\n",
       "      <td>3.151324</td>\n",
       "      <td>11.319877</td>\n",
       "      <td>-6.932339</td>\n",
       "      <td>66.705956</td>\n",
       "      <td>53.481075</td>\n",
       "      <td>-3.095822</td>\n",
       "      <td>143.412803</td>\n",
       "      <td>...</td>\n",
       "      <td>120.885683</td>\n",
       "      <td>25.114317</td>\n",
       "      <td>136.667932</td>\n",
       "      <td>9.332068</td>\n",
       "      <td>96.086063</td>\n",
       "      <td>49.913937</td>\n",
       "      <td>89.802390</td>\n",
       "      <td>56.197610</td>\n",
       "      <td>138.401176</td>\n",
       "      <td>7.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>572</td>\n",
       "      <td>7.359212</td>\n",
       "      <td>25.241949</td>\n",
       "      <td>65.995567</td>\n",
       "      <td>11.750156</td>\n",
       "      <td>285.283234</td>\n",
       "      <td>283.822510</td>\n",
       "      <td>56.345188</td>\n",
       "      <td>590.117165</td>\n",
       "      <td>...</td>\n",
       "      <td>488.810710</td>\n",
       "      <td>83.189290</td>\n",
       "      <td>555.531957</td>\n",
       "      <td>16.468043</td>\n",
       "      <td>330.014790</td>\n",
       "      <td>241.985210</td>\n",
       "      <td>307.788806</td>\n",
       "      <td>264.211194</td>\n",
       "      <td>562.479785</td>\n",
       "      <td>9.520215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>911</td>\n",
       "      <td>0.859362</td>\n",
       "      <td>103.271629</td>\n",
       "      <td>132.802261</td>\n",
       "      <td>-6.488067</td>\n",
       "      <td>122.903603</td>\n",
       "      <td>407.049622</td>\n",
       "      <td>8.930732</td>\n",
       "      <td>939.673009</td>\n",
       "      <td>...</td>\n",
       "      <td>771.701702</td>\n",
       "      <td>139.298298</td>\n",
       "      <td>890.469201</td>\n",
       "      <td>20.530799</td>\n",
       "      <td>875.922092</td>\n",
       "      <td>35.077908</td>\n",
       "      <td>583.510103</td>\n",
       "      <td>327.489897</td>\n",
       "      <td>944.584508</td>\n",
       "      <td>-33.584508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>823</td>\n",
       "      <td>-3.253311</td>\n",
       "      <td>283.321930</td>\n",
       "      <td>132.241791</td>\n",
       "      <td>-10.704310</td>\n",
       "      <td>465.822357</td>\n",
       "      <td>427.108459</td>\n",
       "      <td>-25.774075</td>\n",
       "      <td>898.322121</td>\n",
       "      <td>...</td>\n",
       "      <td>723.714830</td>\n",
       "      <td>99.285170</td>\n",
       "      <td>846.597603</td>\n",
       "      <td>-23.597603</td>\n",
       "      <td>407.206130</td>\n",
       "      <td>415.793870</td>\n",
       "      <td>397.285794</td>\n",
       "      <td>425.714206</td>\n",
       "      <td>836.947940</td>\n",
       "      <td>-13.947940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>250</td>\n",
       "      <td>-14.439471</td>\n",
       "      <td>6.964965</td>\n",
       "      <td>46.179234</td>\n",
       "      <td>5.300345</td>\n",
       "      <td>118.407372</td>\n",
       "      <td>119.623322</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>253.512355</td>\n",
       "      <td>...</td>\n",
       "      <td>205.880079</td>\n",
       "      <td>44.119921</td>\n",
       "      <td>241.048951</td>\n",
       "      <td>8.951049</td>\n",
       "      <td>132.620712</td>\n",
       "      <td>117.379288</td>\n",
       "      <td>126.765608</td>\n",
       "      <td>123.234392</td>\n",
       "      <td>254.287204</td>\n",
       "      <td>-4.287204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1004</td>\n",
       "      <td>-31.400349</td>\n",
       "      <td>364.578430</td>\n",
       "      <td>146.736877</td>\n",
       "      <td>-6.179089</td>\n",
       "      <td>552.454895</td>\n",
       "      <td>531.086609</td>\n",
       "      <td>-23.914564</td>\n",
       "      <td>1039.635205</td>\n",
       "      <td>...</td>\n",
       "      <td>832.192362</td>\n",
       "      <td>171.807638</td>\n",
       "      <td>975.785339</td>\n",
       "      <td>28.214661</td>\n",
       "      <td>401.224848</td>\n",
       "      <td>602.775152</td>\n",
       "      <td>430.368706</td>\n",
       "      <td>573.631294</td>\n",
       "      <td>1058.174059</td>\n",
       "      <td>-54.174059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1441</td>\n",
       "      <td>34.119045</td>\n",
       "      <td>638.341980</td>\n",
       "      <td>227.119736</td>\n",
       "      <td>-13.130022</td>\n",
       "      <td>642.822388</td>\n",
       "      <td>774.511536</td>\n",
       "      <td>-40.309673</td>\n",
       "      <td>1526.908216</td>\n",
       "      <td>...</td>\n",
       "      <td>1255.885410</td>\n",
       "      <td>185.114590</td>\n",
       "      <td>1468.776593</td>\n",
       "      <td>-27.776593</td>\n",
       "      <td>863.230649</td>\n",
       "      <td>577.769351</td>\n",
       "      <td>689.775798</td>\n",
       "      <td>751.224202</td>\n",
       "      <td>2036.549357</td>\n",
       "      <td>-595.549357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>388</td>\n",
       "      <td>-28.147552</td>\n",
       "      <td>98.937172</td>\n",
       "      <td>74.027718</td>\n",
       "      <td>3.612769</td>\n",
       "      <td>147.187302</td>\n",
       "      <td>216.445160</td>\n",
       "      <td>0.980584</td>\n",
       "      <td>463.705207</td>\n",
       "      <td>...</td>\n",
       "      <td>373.542094</td>\n",
       "      <td>14.457906</td>\n",
       "      <td>441.128842</td>\n",
       "      <td>-53.128842</td>\n",
       "      <td>272.140350</td>\n",
       "      <td>115.859650</td>\n",
       "      <td>220.531682</td>\n",
       "      <td>167.468318</td>\n",
       "      <td>472.307718</td>\n",
       "      <td>-84.307718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold  prophet_oof_residual_preds  \\\n",
       "0      2015-01-01       329                    1.278618   \n",
       "1      2015-01-01       520                  -10.982243   \n",
       "2      2015-01-01       146                   -5.641450   \n",
       "3      2015-01-01       572                    7.359212   \n",
       "4      2015-01-01       911                    0.859362   \n",
       "...           ...       ...                         ...   \n",
       "26293  2018-12-31       823                   -3.253311   \n",
       "26294  2018-12-31       250                  -14.439471   \n",
       "26295  2018-12-31      1004                  -31.400349   \n",
       "26296  2018-12-31      1441                   34.119045   \n",
       "26297  2018-12-31       388                  -28.147552   \n",
       "\n",
       "       neuralprophet_oof_residual_preds  ridge_oof_residual_preds  \\\n",
       "0                             19.981554                 34.222641   \n",
       "1                             35.412369                 57.832901   \n",
       "2                              3.151324                 11.319877   \n",
       "3                             25.241949                 65.995567   \n",
       "4                            103.271629                132.802261   \n",
       "...                                 ...                       ...   \n",
       "26293                        283.321930                132.241791   \n",
       "26294                          6.964965                 46.179234   \n",
       "26295                        364.578430                146.736877   \n",
       "26296                        638.341980                227.119736   \n",
       "26297                         98.937172                 74.027718   \n",
       "\n",
       "       linear_oof_residual_preds  huber_oof_residual_preds  \\\n",
       "0                       3.645102                139.376175   \n",
       "1                      -9.185784                192.085785   \n",
       "2                      -6.932339                 66.705956   \n",
       "3                      11.750156                285.283234   \n",
       "4                      -6.488067                122.903603   \n",
       "...                          ...                       ...   \n",
       "26293                 -10.704310                465.822357   \n",
       "26294                   5.300345                118.407372   \n",
       "26295                  -6.179089                552.454895   \n",
       "26296                 -13.130022                642.822388   \n",
       "26297                   3.612769                147.187302   \n",
       "\n",
       "       lasso_oof_residual_preds  earth_oof_residual_preds  prophet_pred  ...  \\\n",
       "0                    166.224564                 14.680798    346.560416  ...   \n",
       "1                    217.624084                 12.078963    536.203586  ...   \n",
       "2                     53.481075                 -3.095822    143.412803  ...   \n",
       "3                    283.822510                 56.345188    590.117165  ...   \n",
       "4                    407.049622                  8.930732    939.673009  ...   \n",
       "...                         ...                       ...           ...  ...   \n",
       "26293                427.108459                -25.774075    898.322121  ...   \n",
       "26294                119.623322                 -0.278643    253.512355  ...   \n",
       "26295                531.086609                -23.914564   1039.635205  ...   \n",
       "26296                774.511536                -40.309673   1526.908216  ...   \n",
       "26297                216.445160                  0.980584    463.705207  ...   \n",
       "\n",
       "        ridge_pred  ridge_residual  linear_pred  linear_residual  huber_pred  \\\n",
       "0       283.272258       45.727742   324.188332         4.811668  239.868861   \n",
       "1       439.771734       80.228266   503.081569        16.918431  334.618687   \n",
       "2       120.885683       25.114317   136.667932         9.332068   96.086063   \n",
       "3       488.810710       83.189290   555.531957        16.468043  330.014790   \n",
       "4       771.701702      139.298298   890.469201        20.530799  875.922092   \n",
       "...            ...             ...          ...              ...         ...   \n",
       "26293   723.714830       99.285170   846.597603       -23.597603  407.206130   \n",
       "26294   205.880079       44.119921   241.048951         8.951049  132.620712   \n",
       "26295   832.192362      171.807638   975.785339        28.214661  401.224848   \n",
       "26296  1255.885410      185.114590  1468.776593       -27.776593  863.230649   \n",
       "26297   373.542094       14.457906   441.128842       -53.128842  272.140350   \n",
       "\n",
       "       huber_residual  lasso_pred  lasso_residual   earth_pred  earth_residual  \n",
       "0           89.131139  176.381725      152.618275   360.672190      -31.672190  \n",
       "1          185.381313  334.453055      185.546945   584.851806      -64.851806  \n",
       "2           49.913937   89.802390       56.197610   138.401176        7.598824  \n",
       "3          241.985210  307.788806      264.211194   562.479785        9.520215  \n",
       "4           35.077908  583.510103      327.489897   944.584508      -33.584508  \n",
       "...               ...         ...             ...          ...             ...  \n",
       "26293      415.793870  397.285794      425.714206   836.947940      -13.947940  \n",
       "26294      117.379288  126.765608      123.234392   254.287204       -4.287204  \n",
       "26295      602.775152  430.368706      573.631294  1058.174059      -54.174059  \n",
       "26296      577.769351  689.775798      751.224202  2036.549357     -595.549357  \n",
       "26297      115.859650  220.531682      167.468318   472.307718      -84.307718  \n",
       "\n",
       "[26298 rows x 23 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dfs['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8afcd17-bd33-4e8a-a663-901f20a3cc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For xgb...\n",
      "\n",
      "Before residual adjustment, SMAPE for prophet was 7.098824805150043. Final SMAPE for prophet is 6.459337760847558.\n",
      "Before residual adjustment, SMAPE for neuralprophet was 7.926662675729486. Final SMAPE for neuralprophet is 9.055081593920645.\n",
      "Before residual adjustment, SMAPE for ridge was 4.781041939812455. Final SMAPE for ridge is 5.4770486671076055.\n",
      "Before residual adjustment, SMAPE for linear was 4.175573461450916. Final SMAPE for linear is 5.141834427310028.\n",
      "Before residual adjustment, SMAPE for huber was 14.396222549610735. Final SMAPE for huber is 7.442538563573811.\n",
      "Before residual adjustment, SMAPE for lasso was 15.11713989060885. Final SMAPE for lasso is 7.000306029463663.\n",
      "Before residual adjustment, SMAPE for earth was 5.338351055481194. Final SMAPE for earth is 6.105282898894313.\n",
      "\n",
      "For lgb...\n",
      "\n",
      "Before residual adjustment, SMAPE for prophet was 7.098824805150043. Final SMAPE for prophet is 5.977672631338595.\n",
      "Before residual adjustment, SMAPE for neuralprophet was 7.926662675729486. Final SMAPE for neuralprophet is 8.104872610910304.\n",
      "Before residual adjustment, SMAPE for ridge was 4.781041939812455. Final SMAPE for ridge is 5.15287494607212.\n",
      "Before residual adjustment, SMAPE for linear was 4.175573461450916. Final SMAPE for linear is 4.933124980579043.\n",
      "Before residual adjustment, SMAPE for huber was 14.396222549610735. Final SMAPE for huber is 6.706282750127812.\n",
      "Before residual adjustment, SMAPE for lasso was 15.11713989060885. Final SMAPE for lasso is 6.369568027882475.\n",
      "Before residual adjustment, SMAPE for earth was 5.338351055481194. Final SMAPE for earth is 6.3868978947188495.\n",
      "\n",
      "For cat...\n",
      "\n",
      "Before residual adjustment, SMAPE for prophet was 7.098824805150043. Final SMAPE for prophet is 5.454673291818714.\n",
      "Before residual adjustment, SMAPE for neuralprophet was 7.926662675729486. Final SMAPE for neuralprophet is 7.617847189750102.\n",
      "Before residual adjustment, SMAPE for ridge was 4.781041939812455. Final SMAPE for ridge is 4.570248790100535.\n",
      "Before residual adjustment, SMAPE for linear was 4.175573461450916. Final SMAPE for linear is 4.344799773011887.\n",
      "Before residual adjustment, SMAPE for huber was 14.396222549610735. Final SMAPE for huber is 7.335023879027378.\n",
      "Before residual adjustment, SMAPE for lasso was 15.11713989060885. Final SMAPE for lasso is 6.22673260505288.\n",
      "Before residual adjustment, SMAPE for earth was 5.338351055481194. Final SMAPE for earth is 5.926546778998049.\n"
     ]
    }
   ],
   "source": [
    "for arch in tv_dfs.keys(): # xgb, then lgb, then cat\n",
    "    print(f\"\\nFor {arch}...\\n\")\n",
    "    for forecast_model in forecast_models:\n",
    "        \n",
    "#         if arch == 'xgb':\n",
    "#             adjusted_smape = SMAPE(y_pred=tv_dfs[arch][f'{forecast_model}_pred']+tv_dfs[arch][f'{forecast_model}_oof_preds'], y_true=tv_dfs[arch]['num_sold'])\n",
    "#         else:\n",
    "        adjusted_smape = SMAPE(y_pred=tv_dfs[arch][f'{forecast_model}_pred']+tv_dfs[arch][f'{forecast_model}_oof_residual_preds'], y_true=tv_dfs[arch]['num_sold'])\n",
    "        original_smape = SMAPE(y_pred=tv_dfs[arch][f'{forecast_model}_pred'], y_true=tv_dfs[arch]['num_sold'])\n",
    "        print(f'Before residual adjustment, SMAPE for {forecast_model} was {original_smape}. Final SMAPE for {forecast_model} is {adjusted_smape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505001bf-53ae-45c5-adcb-84350f5fb58c",
   "metadata": {},
   "source": [
    "With + as operator:\n",
    "```\n",
    "Before residual adjustment, SMAPE for prophet was 7.098824805150043. Final SMAPE for prophet is 14.394425598661853.\n",
    "Before residual adjustment, SMAPE for neuralprophet was 7.930322204823288. Final SMAPE for neuralprophet is 17.10022501507438.\n",
    "Before residual adjustment, SMAPE for ridge was 4.781041939812455. Final SMAPE for ridge is 9.6272249020869.\n",
    "Before residual adjustment, SMAPE for linear was 4.175573461450916. Final SMAPE for linear is 8.315020784789288.\n",
    "Before residual adjustment, SMAPE for huber was 14.396222549610735. Final SMAPE for huber is 30.438323388261274.\n",
    "Before residual adjustment, SMAPE for lasso was 15.11713989060885. Final SMAPE for lasso is 31.73839575442759.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0ac496e4-7154-443b-a20d-58945057154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_preds_df = pd.DataFrame(xgb_test_fold_preds)\n",
    "lgb_test_preds_df = pd.DataFrame(lgb_test_fold_preds)\n",
    "cat_test_preds_df = pd.DataFrame(cat_test_fold_preds)\n",
    "\n",
    "test_dfs_dict = {\n",
    "    'xgb': xgb_test_preds_df,\n",
    "    'lgb': lgb_test_preds_df,\n",
    "    'cat': cat_test_preds_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "381e6b1a-c13d-430f-bee1-e5da18473e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prophet_0_residual_preds</th>\n",
       "      <th>prophet_1_residual_preds</th>\n",
       "      <th>prophet_2_residual_preds</th>\n",
       "      <th>prophet_3_residual_preds</th>\n",
       "      <th>neuralprophet_0_residual_preds</th>\n",
       "      <th>neuralprophet_1_residual_preds</th>\n",
       "      <th>neuralprophet_2_residual_preds</th>\n",
       "      <th>neuralprophet_3_residual_preds</th>\n",
       "      <th>ridge_0_residual_preds</th>\n",
       "      <th>ridge_1_residual_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>huber_2_residual_preds</th>\n",
       "      <th>huber_3_residual_preds</th>\n",
       "      <th>lasso_0_residual_preds</th>\n",
       "      <th>lasso_1_residual_preds</th>\n",
       "      <th>lasso_2_residual_preds</th>\n",
       "      <th>lasso_3_residual_preds</th>\n",
       "      <th>earth_0_residual_preds</th>\n",
       "      <th>earth_1_residual_preds</th>\n",
       "      <th>earth_2_residual_preds</th>\n",
       "      <th>earth_3_residual_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.628039</td>\n",
       "      <td>-22.776003</td>\n",
       "      <td>-4.337413</td>\n",
       "      <td>9.217171</td>\n",
       "      <td>-1.113973</td>\n",
       "      <td>-14.270683</td>\n",
       "      <td>9.624284</td>\n",
       "      <td>20.024666</td>\n",
       "      <td>40.829250</td>\n",
       "      <td>32.131512</td>\n",
       "      <td>...</td>\n",
       "      <td>117.732880</td>\n",
       "      <td>152.466690</td>\n",
       "      <td>171.862076</td>\n",
       "      <td>167.369675</td>\n",
       "      <td>165.736267</td>\n",
       "      <td>189.338898</td>\n",
       "      <td>3.466743</td>\n",
       "      <td>-5.279877</td>\n",
       "      <td>4.872921</td>\n",
       "      <td>15.645398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.307783</td>\n",
       "      <td>-29.234877</td>\n",
       "      <td>-19.299370</td>\n",
       "      <td>-4.380471</td>\n",
       "      <td>38.565910</td>\n",
       "      <td>21.016108</td>\n",
       "      <td>30.840876</td>\n",
       "      <td>49.329002</td>\n",
       "      <td>76.017052</td>\n",
       "      <td>67.138077</td>\n",
       "      <td>...</td>\n",
       "      <td>180.163071</td>\n",
       "      <td>218.693390</td>\n",
       "      <td>227.298630</td>\n",
       "      <td>220.408157</td>\n",
       "      <td>213.388229</td>\n",
       "      <td>245.253067</td>\n",
       "      <td>4.695372</td>\n",
       "      <td>-7.733302</td>\n",
       "      <td>-15.240776</td>\n",
       "      <td>17.300634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548766</td>\n",
       "      <td>-9.147127</td>\n",
       "      <td>-2.938624</td>\n",
       "      <td>-1.790694</td>\n",
       "      <td>-1.135752</td>\n",
       "      <td>-8.805696</td>\n",
       "      <td>3.665533</td>\n",
       "      <td>5.309555</td>\n",
       "      <td>17.624104</td>\n",
       "      <td>17.756908</td>\n",
       "      <td>...</td>\n",
       "      <td>67.835770</td>\n",
       "      <td>82.093063</td>\n",
       "      <td>67.499695</td>\n",
       "      <td>60.452721</td>\n",
       "      <td>63.432430</td>\n",
       "      <td>64.438507</td>\n",
       "      <td>4.077691</td>\n",
       "      <td>-8.597854</td>\n",
       "      <td>-6.490247</td>\n",
       "      <td>1.034713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.687498</td>\n",
       "      <td>-30.114052</td>\n",
       "      <td>6.320381</td>\n",
       "      <td>14.146542</td>\n",
       "      <td>14.123075</td>\n",
       "      <td>-9.601943</td>\n",
       "      <td>12.965332</td>\n",
       "      <td>26.437778</td>\n",
       "      <td>81.154427</td>\n",
       "      <td>64.653954</td>\n",
       "      <td>...</td>\n",
       "      <td>288.372559</td>\n",
       "      <td>320.592285</td>\n",
       "      <td>301.413605</td>\n",
       "      <td>306.337585</td>\n",
       "      <td>279.525238</td>\n",
       "      <td>316.741058</td>\n",
       "      <td>62.406052</td>\n",
       "      <td>40.480110</td>\n",
       "      <td>59.990955</td>\n",
       "      <td>72.885109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.396700</td>\n",
       "      <td>-8.923676</td>\n",
       "      <td>6.745495</td>\n",
       "      <td>-4.918637</td>\n",
       "      <td>81.434113</td>\n",
       "      <td>111.132454</td>\n",
       "      <td>113.018555</td>\n",
       "      <td>98.424866</td>\n",
       "      <td>114.582291</td>\n",
       "      <td>143.575012</td>\n",
       "      <td>...</td>\n",
       "      <td>91.613174</td>\n",
       "      <td>134.632111</td>\n",
       "      <td>415.758423</td>\n",
       "      <td>449.545532</td>\n",
       "      <td>398.279816</td>\n",
       "      <td>440.636688</td>\n",
       "      <td>0.899182</td>\n",
       "      <td>17.500675</td>\n",
       "      <td>12.615296</td>\n",
       "      <td>14.708526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>-100.418335</td>\n",
       "      <td>-32.443649</td>\n",
       "      <td>-59.012535</td>\n",
       "      <td>-8.907444</td>\n",
       "      <td>139.995728</td>\n",
       "      <td>198.155090</td>\n",
       "      <td>168.623062</td>\n",
       "      <td>276.320374</td>\n",
       "      <td>105.135254</td>\n",
       "      <td>117.854515</td>\n",
       "      <td>...</td>\n",
       "      <td>370.991180</td>\n",
       "      <td>414.747345</td>\n",
       "      <td>354.354706</td>\n",
       "      <td>386.669739</td>\n",
       "      <td>401.603943</td>\n",
       "      <td>436.174225</td>\n",
       "      <td>0.590873</td>\n",
       "      <td>-23.707037</td>\n",
       "      <td>-44.231205</td>\n",
       "      <td>-75.286507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>-29.682568</td>\n",
       "      <td>-29.894447</td>\n",
       "      <td>-19.465675</td>\n",
       "      <td>-14.519586</td>\n",
       "      <td>-19.383842</td>\n",
       "      <td>-28.602324</td>\n",
       "      <td>-16.461973</td>\n",
       "      <td>19.153826</td>\n",
       "      <td>36.606209</td>\n",
       "      <td>35.228756</td>\n",
       "      <td>...</td>\n",
       "      <td>110.502045</td>\n",
       "      <td>99.124031</td>\n",
       "      <td>110.722855</td>\n",
       "      <td>102.684364</td>\n",
       "      <td>112.017014</td>\n",
       "      <td>107.182640</td>\n",
       "      <td>7.660434</td>\n",
       "      <td>2.207999</td>\n",
       "      <td>14.715510</td>\n",
       "      <td>-1.407388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>-87.339149</td>\n",
       "      <td>-49.978775</td>\n",
       "      <td>-58.895260</td>\n",
       "      <td>14.599092</td>\n",
       "      <td>230.109726</td>\n",
       "      <td>267.625427</td>\n",
       "      <td>238.597366</td>\n",
       "      <td>347.494507</td>\n",
       "      <td>147.598892</td>\n",
       "      <td>139.108032</td>\n",
       "      <td>...</td>\n",
       "      <td>523.964050</td>\n",
       "      <td>589.809082</td>\n",
       "      <td>484.957825</td>\n",
       "      <td>499.436707</td>\n",
       "      <td>526.032043</td>\n",
       "      <td>545.696228</td>\n",
       "      <td>-9.219683</td>\n",
       "      <td>-6.820998</td>\n",
       "      <td>-10.478740</td>\n",
       "      <td>-35.574120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>-71.144836</td>\n",
       "      <td>6.305995</td>\n",
       "      <td>-51.087128</td>\n",
       "      <td>34.664040</td>\n",
       "      <td>456.211670</td>\n",
       "      <td>523.982727</td>\n",
       "      <td>444.451630</td>\n",
       "      <td>567.523499</td>\n",
       "      <td>212.100479</td>\n",
       "      <td>217.488190</td>\n",
       "      <td>...</td>\n",
       "      <td>519.880859</td>\n",
       "      <td>593.520569</td>\n",
       "      <td>658.354858</td>\n",
       "      <td>731.390320</td>\n",
       "      <td>701.821655</td>\n",
       "      <td>754.522644</td>\n",
       "      <td>-51.764935</td>\n",
       "      <td>-23.280802</td>\n",
       "      <td>-131.861771</td>\n",
       "      <td>-192.554993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>-70.108177</td>\n",
       "      <td>-38.455235</td>\n",
       "      <td>-66.111984</td>\n",
       "      <td>-59.722992</td>\n",
       "      <td>-12.677993</td>\n",
       "      <td>36.336235</td>\n",
       "      <td>1.808316</td>\n",
       "      <td>44.851543</td>\n",
       "      <td>40.913830</td>\n",
       "      <td>64.288582</td>\n",
       "      <td>...</td>\n",
       "      <td>105.610016</td>\n",
       "      <td>110.981804</td>\n",
       "      <td>166.225479</td>\n",
       "      <td>195.639450</td>\n",
       "      <td>178.190170</td>\n",
       "      <td>157.762695</td>\n",
       "      <td>7.226946</td>\n",
       "      <td>15.078609</td>\n",
       "      <td>2.785188</td>\n",
       "      <td>-17.074615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prophet_0_residual_preds  prophet_1_residual_preds  \\\n",
       "0                     1.628039                -22.776003   \n",
       "1                    -1.307783                -29.234877   \n",
       "2                     0.548766                 -9.147127   \n",
       "3                    11.687498                -30.114052   \n",
       "4                   -18.396700                 -8.923676   \n",
       "...                        ...                       ...   \n",
       "6565               -100.418335                -32.443649   \n",
       "6566                -29.682568                -29.894447   \n",
       "6567                -87.339149                -49.978775   \n",
       "6568                -71.144836                  6.305995   \n",
       "6569                -70.108177                -38.455235   \n",
       "\n",
       "      prophet_2_residual_preds  prophet_3_residual_preds  \\\n",
       "0                    -4.337413                  9.217171   \n",
       "1                   -19.299370                 -4.380471   \n",
       "2                    -2.938624                 -1.790694   \n",
       "3                     6.320381                 14.146542   \n",
       "4                     6.745495                 -4.918637   \n",
       "...                        ...                       ...   \n",
       "6565                -59.012535                 -8.907444   \n",
       "6566                -19.465675                -14.519586   \n",
       "6567                -58.895260                 14.599092   \n",
       "6568                -51.087128                 34.664040   \n",
       "6569                -66.111984                -59.722992   \n",
       "\n",
       "      neuralprophet_0_residual_preds  neuralprophet_1_residual_preds  \\\n",
       "0                          -1.113973                      -14.270683   \n",
       "1                          38.565910                       21.016108   \n",
       "2                          -1.135752                       -8.805696   \n",
       "3                          14.123075                       -9.601943   \n",
       "4                          81.434113                      111.132454   \n",
       "...                              ...                             ...   \n",
       "6565                      139.995728                      198.155090   \n",
       "6566                      -19.383842                      -28.602324   \n",
       "6567                      230.109726                      267.625427   \n",
       "6568                      456.211670                      523.982727   \n",
       "6569                      -12.677993                       36.336235   \n",
       "\n",
       "      neuralprophet_2_residual_preds  neuralprophet_3_residual_preds  \\\n",
       "0                           9.624284                       20.024666   \n",
       "1                          30.840876                       49.329002   \n",
       "2                           3.665533                        5.309555   \n",
       "3                          12.965332                       26.437778   \n",
       "4                         113.018555                       98.424866   \n",
       "...                              ...                             ...   \n",
       "6565                      168.623062                      276.320374   \n",
       "6566                      -16.461973                       19.153826   \n",
       "6567                      238.597366                      347.494507   \n",
       "6568                      444.451630                      567.523499   \n",
       "6569                        1.808316                       44.851543   \n",
       "\n",
       "      ridge_0_residual_preds  ridge_1_residual_preds  ...  \\\n",
       "0                  40.829250               32.131512  ...   \n",
       "1                  76.017052               67.138077  ...   \n",
       "2                  17.624104               17.756908  ...   \n",
       "3                  81.154427               64.653954  ...   \n",
       "4                 114.582291              143.575012  ...   \n",
       "...                      ...                     ...  ...   \n",
       "6565              105.135254              117.854515  ...   \n",
       "6566               36.606209               35.228756  ...   \n",
       "6567              147.598892              139.108032  ...   \n",
       "6568              212.100479              217.488190  ...   \n",
       "6569               40.913830               64.288582  ...   \n",
       "\n",
       "      huber_2_residual_preds  huber_3_residual_preds  lasso_0_residual_preds  \\\n",
       "0                 117.732880              152.466690              171.862076   \n",
       "1                 180.163071              218.693390              227.298630   \n",
       "2                  67.835770               82.093063               67.499695   \n",
       "3                 288.372559              320.592285              301.413605   \n",
       "4                  91.613174              134.632111              415.758423   \n",
       "...                      ...                     ...                     ...   \n",
       "6565              370.991180              414.747345              354.354706   \n",
       "6566              110.502045               99.124031              110.722855   \n",
       "6567              523.964050              589.809082              484.957825   \n",
       "6568              519.880859              593.520569              658.354858   \n",
       "6569              105.610016              110.981804              166.225479   \n",
       "\n",
       "      lasso_1_residual_preds  lasso_2_residual_preds  lasso_3_residual_preds  \\\n",
       "0                 167.369675              165.736267              189.338898   \n",
       "1                 220.408157              213.388229              245.253067   \n",
       "2                  60.452721               63.432430               64.438507   \n",
       "3                 306.337585              279.525238              316.741058   \n",
       "4                 449.545532              398.279816              440.636688   \n",
       "...                      ...                     ...                     ...   \n",
       "6565              386.669739              401.603943              436.174225   \n",
       "6566              102.684364              112.017014              107.182640   \n",
       "6567              499.436707              526.032043              545.696228   \n",
       "6568              731.390320              701.821655              754.522644   \n",
       "6569              195.639450              178.190170              157.762695   \n",
       "\n",
       "      earth_0_residual_preds  earth_1_residual_preds  earth_2_residual_preds  \\\n",
       "0                   3.466743               -5.279877                4.872921   \n",
       "1                   4.695372               -7.733302              -15.240776   \n",
       "2                   4.077691               -8.597854               -6.490247   \n",
       "3                  62.406052               40.480110               59.990955   \n",
       "4                   0.899182               17.500675               12.615296   \n",
       "...                      ...                     ...                     ...   \n",
       "6565                0.590873              -23.707037              -44.231205   \n",
       "6566                7.660434                2.207999               14.715510   \n",
       "6567               -9.219683               -6.820998              -10.478740   \n",
       "6568              -51.764935              -23.280802             -131.861771   \n",
       "6569                7.226946               15.078609                2.785188   \n",
       "\n",
       "      earth_3_residual_preds  \n",
       "0                  15.645398  \n",
       "1                  17.300634  \n",
       "2                   1.034713  \n",
       "3                  72.885109  \n",
       "4                  14.708526  \n",
       "...                      ...  \n",
       "6565              -75.286507  \n",
       "6566               -1.407388  \n",
       "6567              -35.574120  \n",
       "6568             -192.554993  \n",
       "6569              -17.074615  \n",
       "\n",
       "[6570 rows x 28 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "99fa483c-4905-4c59-8293-d484f64e0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prophet_0_residual_preds</th>\n",
       "      <th>prophet_1_residual_preds</th>\n",
       "      <th>prophet_2_residual_preds</th>\n",
       "      <th>prophet_3_residual_preds</th>\n",
       "      <th>neuralprophet_0_residual_preds</th>\n",
       "      <th>neuralprophet_1_residual_preds</th>\n",
       "      <th>neuralprophet_2_residual_preds</th>\n",
       "      <th>neuralprophet_3_residual_preds</th>\n",
       "      <th>ridge_0_residual_preds</th>\n",
       "      <th>ridge_1_residual_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>huber_2_residual_preds</th>\n",
       "      <th>huber_3_residual_preds</th>\n",
       "      <th>lasso_0_residual_preds</th>\n",
       "      <th>lasso_1_residual_preds</th>\n",
       "      <th>lasso_2_residual_preds</th>\n",
       "      <th>lasso_3_residual_preds</th>\n",
       "      <th>earth_0_residual_preds</th>\n",
       "      <th>earth_1_residual_preds</th>\n",
       "      <th>earth_2_residual_preds</th>\n",
       "      <th>earth_3_residual_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.659798</td>\n",
       "      <td>-5.406039</td>\n",
       "      <td>25.685431</td>\n",
       "      <td>25.702927</td>\n",
       "      <td>38.625799</td>\n",
       "      <td>-26.543532</td>\n",
       "      <td>42.386490</td>\n",
       "      <td>41.566642</td>\n",
       "      <td>62.010359</td>\n",
       "      <td>38.643447</td>\n",
       "      <td>...</td>\n",
       "      <td>156.201496</td>\n",
       "      <td>165.882975</td>\n",
       "      <td>203.273303</td>\n",
       "      <td>166.865059</td>\n",
       "      <td>204.484263</td>\n",
       "      <td>206.633983</td>\n",
       "      <td>14.030557</td>\n",
       "      <td>7.889509</td>\n",
       "      <td>23.599155</td>\n",
       "      <td>37.764264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.326129</td>\n",
       "      <td>-14.781889</td>\n",
       "      <td>7.569961</td>\n",
       "      <td>14.815576</td>\n",
       "      <td>74.046034</td>\n",
       "      <td>-2.021053</td>\n",
       "      <td>72.035079</td>\n",
       "      <td>59.873683</td>\n",
       "      <td>86.575967</td>\n",
       "      <td>59.412709</td>\n",
       "      <td>...</td>\n",
       "      <td>245.791512</td>\n",
       "      <td>271.419730</td>\n",
       "      <td>274.603292</td>\n",
       "      <td>189.301795</td>\n",
       "      <td>253.664893</td>\n",
       "      <td>277.652861</td>\n",
       "      <td>0.009271</td>\n",
       "      <td>24.333671</td>\n",
       "      <td>-6.616261</td>\n",
       "      <td>-0.398344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.903635</td>\n",
       "      <td>9.096575</td>\n",
       "      <td>19.581296</td>\n",
       "      <td>16.245287</td>\n",
       "      <td>17.059769</td>\n",
       "      <td>-4.708975</td>\n",
       "      <td>18.002370</td>\n",
       "      <td>15.954930</td>\n",
       "      <td>28.641066</td>\n",
       "      <td>15.127044</td>\n",
       "      <td>...</td>\n",
       "      <td>82.106209</td>\n",
       "      <td>87.898212</td>\n",
       "      <td>75.172092</td>\n",
       "      <td>61.772996</td>\n",
       "      <td>77.285651</td>\n",
       "      <td>71.062885</td>\n",
       "      <td>8.560491</td>\n",
       "      <td>1.254045</td>\n",
       "      <td>12.916000</td>\n",
       "      <td>17.966165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.888279</td>\n",
       "      <td>-13.094183</td>\n",
       "      <td>39.609446</td>\n",
       "      <td>44.406229</td>\n",
       "      <td>39.773920</td>\n",
       "      <td>-34.176598</td>\n",
       "      <td>61.832559</td>\n",
       "      <td>54.490520</td>\n",
       "      <td>99.549027</td>\n",
       "      <td>55.405590</td>\n",
       "      <td>...</td>\n",
       "      <td>340.399942</td>\n",
       "      <td>346.054952</td>\n",
       "      <td>321.728073</td>\n",
       "      <td>255.686679</td>\n",
       "      <td>326.044949</td>\n",
       "      <td>327.006351</td>\n",
       "      <td>68.726943</td>\n",
       "      <td>36.798843</td>\n",
       "      <td>82.212348</td>\n",
       "      <td>88.371916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.216878</td>\n",
       "      <td>-10.839813</td>\n",
       "      <td>27.319067</td>\n",
       "      <td>10.627042</td>\n",
       "      <td>125.004497</td>\n",
       "      <td>63.631370</td>\n",
       "      <td>149.099507</td>\n",
       "      <td>117.800786</td>\n",
       "      <td>124.353946</td>\n",
       "      <td>114.335094</td>\n",
       "      <td>...</td>\n",
       "      <td>148.752113</td>\n",
       "      <td>144.124544</td>\n",
       "      <td>445.731385</td>\n",
       "      <td>345.544891</td>\n",
       "      <td>455.457338</td>\n",
       "      <td>435.547905</td>\n",
       "      <td>-8.894213</td>\n",
       "      <td>24.726179</td>\n",
       "      <td>3.853427</td>\n",
       "      <td>-16.385015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>-68.673045</td>\n",
       "      <td>-56.764350</td>\n",
       "      <td>-62.810567</td>\n",
       "      <td>1.022159</td>\n",
       "      <td>180.027155</td>\n",
       "      <td>255.176557</td>\n",
       "      <td>147.445339</td>\n",
       "      <td>248.247112</td>\n",
       "      <td>120.124596</td>\n",
       "      <td>137.676273</td>\n",
       "      <td>...</td>\n",
       "      <td>379.192802</td>\n",
       "      <td>431.717952</td>\n",
       "      <td>376.910966</td>\n",
       "      <td>384.656657</td>\n",
       "      <td>387.463713</td>\n",
       "      <td>413.815027</td>\n",
       "      <td>-2.797492</td>\n",
       "      <td>-17.258207</td>\n",
       "      <td>-38.465439</td>\n",
       "      <td>-50.397515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>-5.854447</td>\n",
       "      <td>-6.348483</td>\n",
       "      <td>-13.550638</td>\n",
       "      <td>7.160769</td>\n",
       "      <td>11.840255</td>\n",
       "      <td>27.455167</td>\n",
       "      <td>18.720853</td>\n",
       "      <td>14.228303</td>\n",
       "      <td>46.428923</td>\n",
       "      <td>49.226229</td>\n",
       "      <td>...</td>\n",
       "      <td>112.660298</td>\n",
       "      <td>127.334350</td>\n",
       "      <td>129.797733</td>\n",
       "      <td>129.195569</td>\n",
       "      <td>124.898281</td>\n",
       "      <td>131.851480</td>\n",
       "      <td>9.458203</td>\n",
       "      <td>6.667925</td>\n",
       "      <td>16.496136</td>\n",
       "      <td>3.295281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>-42.575155</td>\n",
       "      <td>-77.468770</td>\n",
       "      <td>-69.646457</td>\n",
       "      <td>14.660957</td>\n",
       "      <td>298.763778</td>\n",
       "      <td>315.009559</td>\n",
       "      <td>218.779005</td>\n",
       "      <td>354.199629</td>\n",
       "      <td>169.165384</td>\n",
       "      <td>156.205672</td>\n",
       "      <td>...</td>\n",
       "      <td>526.079526</td>\n",
       "      <td>604.837679</td>\n",
       "      <td>508.729383</td>\n",
       "      <td>505.244678</td>\n",
       "      <td>511.136612</td>\n",
       "      <td>537.605524</td>\n",
       "      <td>-4.910637</td>\n",
       "      <td>-16.472856</td>\n",
       "      <td>26.800664</td>\n",
       "      <td>-0.590565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>-74.562045</td>\n",
       "      <td>-34.338660</td>\n",
       "      <td>-65.610515</td>\n",
       "      <td>36.533271</td>\n",
       "      <td>508.040128</td>\n",
       "      <td>569.731072</td>\n",
       "      <td>394.333840</td>\n",
       "      <td>553.090571</td>\n",
       "      <td>220.473254</td>\n",
       "      <td>231.219097</td>\n",
       "      <td>...</td>\n",
       "      <td>502.212720</td>\n",
       "      <td>565.484246</td>\n",
       "      <td>672.356991</td>\n",
       "      <td>709.551573</td>\n",
       "      <td>644.943501</td>\n",
       "      <td>708.009935</td>\n",
       "      <td>-67.639513</td>\n",
       "      <td>-28.942641</td>\n",
       "      <td>-64.581800</td>\n",
       "      <td>-136.314135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>-50.928891</td>\n",
       "      <td>-46.878015</td>\n",
       "      <td>-65.553308</td>\n",
       "      <td>-33.094068</td>\n",
       "      <td>42.311948</td>\n",
       "      <td>80.739986</td>\n",
       "      <td>-3.772213</td>\n",
       "      <td>41.666081</td>\n",
       "      <td>55.440748</td>\n",
       "      <td>79.670416</td>\n",
       "      <td>...</td>\n",
       "      <td>120.058046</td>\n",
       "      <td>132.947793</td>\n",
       "      <td>180.860479</td>\n",
       "      <td>219.843026</td>\n",
       "      <td>180.469186</td>\n",
       "      <td>177.393260</td>\n",
       "      <td>-12.558775</td>\n",
       "      <td>4.447575</td>\n",
       "      <td>18.771515</td>\n",
       "      <td>-7.338495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prophet_0_residual_preds  prophet_1_residual_preds  \\\n",
       "0                    30.659798                 -5.406039   \n",
       "1                    23.326129                -14.781889   \n",
       "2                    14.903635                  9.096575   \n",
       "3                    32.888279                -13.094183   \n",
       "4                    -3.216878                -10.839813   \n",
       "...                        ...                       ...   \n",
       "6565                -68.673045                -56.764350   \n",
       "6566                 -5.854447                 -6.348483   \n",
       "6567                -42.575155                -77.468770   \n",
       "6568                -74.562045                -34.338660   \n",
       "6569                -50.928891                -46.878015   \n",
       "\n",
       "      prophet_2_residual_preds  prophet_3_residual_preds  \\\n",
       "0                    25.685431                 25.702927   \n",
       "1                     7.569961                 14.815576   \n",
       "2                    19.581296                 16.245287   \n",
       "3                    39.609446                 44.406229   \n",
       "4                    27.319067                 10.627042   \n",
       "...                        ...                       ...   \n",
       "6565                -62.810567                  1.022159   \n",
       "6566                -13.550638                  7.160769   \n",
       "6567                -69.646457                 14.660957   \n",
       "6568                -65.610515                 36.533271   \n",
       "6569                -65.553308                -33.094068   \n",
       "\n",
       "      neuralprophet_0_residual_preds  neuralprophet_1_residual_preds  \\\n",
       "0                          38.625799                      -26.543532   \n",
       "1                          74.046034                       -2.021053   \n",
       "2                          17.059769                       -4.708975   \n",
       "3                          39.773920                      -34.176598   \n",
       "4                         125.004497                       63.631370   \n",
       "...                              ...                             ...   \n",
       "6565                      180.027155                      255.176557   \n",
       "6566                       11.840255                       27.455167   \n",
       "6567                      298.763778                      315.009559   \n",
       "6568                      508.040128                      569.731072   \n",
       "6569                       42.311948                       80.739986   \n",
       "\n",
       "      neuralprophet_2_residual_preds  neuralprophet_3_residual_preds  \\\n",
       "0                          42.386490                       41.566642   \n",
       "1                          72.035079                       59.873683   \n",
       "2                          18.002370                       15.954930   \n",
       "3                          61.832559                       54.490520   \n",
       "4                         149.099507                      117.800786   \n",
       "...                              ...                             ...   \n",
       "6565                      147.445339                      248.247112   \n",
       "6566                       18.720853                       14.228303   \n",
       "6567                      218.779005                      354.199629   \n",
       "6568                      394.333840                      553.090571   \n",
       "6569                       -3.772213                       41.666081   \n",
       "\n",
       "      ridge_0_residual_preds  ridge_1_residual_preds  ...  \\\n",
       "0                  62.010359               38.643447  ...   \n",
       "1                  86.575967               59.412709  ...   \n",
       "2                  28.641066               15.127044  ...   \n",
       "3                  99.549027               55.405590  ...   \n",
       "4                 124.353946              114.335094  ...   \n",
       "...                      ...                     ...  ...   \n",
       "6565              120.124596              137.676273  ...   \n",
       "6566               46.428923               49.226229  ...   \n",
       "6567              169.165384              156.205672  ...   \n",
       "6568              220.473254              231.219097  ...   \n",
       "6569               55.440748               79.670416  ...   \n",
       "\n",
       "      huber_2_residual_preds  huber_3_residual_preds  lasso_0_residual_preds  \\\n",
       "0                 156.201496              165.882975              203.273303   \n",
       "1                 245.791512              271.419730              274.603292   \n",
       "2                  82.106209               87.898212               75.172092   \n",
       "3                 340.399942              346.054952              321.728073   \n",
       "4                 148.752113              144.124544              445.731385   \n",
       "...                      ...                     ...                     ...   \n",
       "6565              379.192802              431.717952              376.910966   \n",
       "6566              112.660298              127.334350              129.797733   \n",
       "6567              526.079526              604.837679              508.729383   \n",
       "6568              502.212720              565.484246              672.356991   \n",
       "6569              120.058046              132.947793              180.860479   \n",
       "\n",
       "      lasso_1_residual_preds  lasso_2_residual_preds  lasso_3_residual_preds  \\\n",
       "0                 166.865059              204.484263              206.633983   \n",
       "1                 189.301795              253.664893              277.652861   \n",
       "2                  61.772996               77.285651               71.062885   \n",
       "3                 255.686679              326.044949              327.006351   \n",
       "4                 345.544891              455.457338              435.547905   \n",
       "...                      ...                     ...                     ...   \n",
       "6565              384.656657              387.463713              413.815027   \n",
       "6566              129.195569              124.898281              131.851480   \n",
       "6567              505.244678              511.136612              537.605524   \n",
       "6568              709.551573              644.943501              708.009935   \n",
       "6569              219.843026              180.469186              177.393260   \n",
       "\n",
       "      earth_0_residual_preds  earth_1_residual_preds  earth_2_residual_preds  \\\n",
       "0                  14.030557                7.889509               23.599155   \n",
       "1                   0.009271               24.333671               -6.616261   \n",
       "2                   8.560491                1.254045               12.916000   \n",
       "3                  68.726943               36.798843               82.212348   \n",
       "4                  -8.894213               24.726179                3.853427   \n",
       "...                      ...                     ...                     ...   \n",
       "6565               -2.797492              -17.258207              -38.465439   \n",
       "6566                9.458203                6.667925               16.496136   \n",
       "6567               -4.910637              -16.472856               26.800664   \n",
       "6568              -67.639513              -28.942641              -64.581800   \n",
       "6569              -12.558775                4.447575               18.771515   \n",
       "\n",
       "      earth_3_residual_preds  \n",
       "0                  37.764264  \n",
       "1                  -0.398344  \n",
       "2                  17.966165  \n",
       "3                  88.371916  \n",
       "4                 -16.385015  \n",
       "...                      ...  \n",
       "6565              -50.397515  \n",
       "6566                3.295281  \n",
       "6567               -0.590565  \n",
       "6568             -136.314135  \n",
       "6569               -7.338495  \n",
       "\n",
       "[6570 rows x 28 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_test_preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730423a-1dcc-452e-ad56-026186469007",
   "metadata": {},
   "source": [
    "## Submission of Naive Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0faf3-0003-42be-b4ac-cc5620ac058c",
   "metadata": {},
   "source": [
    "Something's up with the residuals; for now, let's just run a simple model on the original forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59ecd25a-9beb-4eaa-8cb5-71ffdc5f3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso()\n",
    "# model = Ridge() # not good\n",
    "# model = LinearRegression() # not good\n",
    "# model = CatBoostRegressor(**catboost_params) # very bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de4a9597-6f1a-49c0-b6fe-fe8d08359bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>329</td>\n",
       "      <td>346.560416</td>\n",
       "      <td>329.134521</td>\n",
       "      <td>283.272258</td>\n",
       "      <td>324.188332</td>\n",
       "      <td>239.868861</td>\n",
       "      <td>176.381725</td>\n",
       "      <td>360.672190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>520</td>\n",
       "      <td>536.203586</td>\n",
       "      <td>458.008301</td>\n",
       "      <td>439.771734</td>\n",
       "      <td>503.081569</td>\n",
       "      <td>334.618687</td>\n",
       "      <td>334.453055</td>\n",
       "      <td>584.851806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>146</td>\n",
       "      <td>143.412803</td>\n",
       "      <td>145.325577</td>\n",
       "      <td>120.885683</td>\n",
       "      <td>136.667932</td>\n",
       "      <td>96.086063</td>\n",
       "      <td>89.802390</td>\n",
       "      <td>138.401176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>572</td>\n",
       "      <td>590.117165</td>\n",
       "      <td>552.571167</td>\n",
       "      <td>488.810710</td>\n",
       "      <td>555.531957</td>\n",
       "      <td>330.014790</td>\n",
       "      <td>307.788806</td>\n",
       "      <td>562.479785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>911</td>\n",
       "      <td>939.673009</td>\n",
       "      <td>781.967285</td>\n",
       "      <td>771.701702</td>\n",
       "      <td>890.469201</td>\n",
       "      <td>875.922092</td>\n",
       "      <td>583.510103</td>\n",
       "      <td>944.584508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>823</td>\n",
       "      <td>898.322121</td>\n",
       "      <td>669.418457</td>\n",
       "      <td>723.714830</td>\n",
       "      <td>846.597603</td>\n",
       "      <td>407.206130</td>\n",
       "      <td>397.285794</td>\n",
       "      <td>836.947940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>250</td>\n",
       "      <td>253.512355</td>\n",
       "      <td>227.158142</td>\n",
       "      <td>205.880079</td>\n",
       "      <td>241.048951</td>\n",
       "      <td>132.620712</td>\n",
       "      <td>126.765608</td>\n",
       "      <td>254.287204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1004</td>\n",
       "      <td>1039.635205</td>\n",
       "      <td>715.639648</td>\n",
       "      <td>832.192362</td>\n",
       "      <td>975.785339</td>\n",
       "      <td>401.224848</td>\n",
       "      <td>430.368706</td>\n",
       "      <td>1058.174059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1441</td>\n",
       "      <td>1526.908216</td>\n",
       "      <td>980.234009</td>\n",
       "      <td>1255.885410</td>\n",
       "      <td>1468.776593</td>\n",
       "      <td>863.230649</td>\n",
       "      <td>689.775798</td>\n",
       "      <td>2036.549357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>388</td>\n",
       "      <td>463.705207</td>\n",
       "      <td>423.052612</td>\n",
       "      <td>373.542094</td>\n",
       "      <td>441.128842</td>\n",
       "      <td>272.140350</td>\n",
       "      <td>220.531682</td>\n",
       "      <td>472.307718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold      prophet  neuralprophet        ridge  \\\n",
       "0      2015-01-01       329   346.560416     329.134521   283.272258   \n",
       "1      2015-01-01       520   536.203586     458.008301   439.771734   \n",
       "2      2015-01-01       146   143.412803     145.325577   120.885683   \n",
       "3      2015-01-01       572   590.117165     552.571167   488.810710   \n",
       "4      2015-01-01       911   939.673009     781.967285   771.701702   \n",
       "...           ...       ...          ...            ...          ...   \n",
       "26293  2018-12-31       823   898.322121     669.418457   723.714830   \n",
       "26294  2018-12-31       250   253.512355     227.158142   205.880079   \n",
       "26295  2018-12-31      1004  1039.635205     715.639648   832.192362   \n",
       "26296  2018-12-31      1441  1526.908216     980.234009  1255.885410   \n",
       "26297  2018-12-31       388   463.705207     423.052612   373.542094   \n",
       "\n",
       "            linear       huber       lasso        earth  \n",
       "0       324.188332  239.868861  176.381725   360.672190  \n",
       "1       503.081569  334.618687  334.453055   584.851806  \n",
       "2       136.667932   96.086063   89.802390   138.401176  \n",
       "3       555.531957  330.014790  307.788806   562.479785  \n",
       "4       890.469201  875.922092  583.510103   944.584508  \n",
       "...            ...         ...         ...          ...  \n",
       "26293   846.597603  407.206130  397.285794   836.947940  \n",
       "26294   241.048951  132.620712  126.765608   254.287204  \n",
       "26295   975.785339  401.224848  430.368706  1058.174059  \n",
       "26296  1468.776593  863.230649  689.775798  2036.549357  \n",
       "26297   441.128842  272.140350  220.531682   472.307718  \n",
       "\n",
       "[26298 rows x 9 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1e7375c-d62b-4040-81c7-cfd21663d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tv_preds.drop(columns=['num_sold'])\n",
    "y = tv_preds['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16bae9f0-a1b8-4721-a1eb-45b454e10dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>402.296576</td>\n",
       "      <td>383.543457</td>\n",
       "      <td>359.817081</td>\n",
       "      <td>392.328390</td>\n",
       "      <td>248.728792</td>\n",
       "      <td>221.118411</td>\n",
       "      <td>417.102143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>631.642099</td>\n",
       "      <td>551.044983</td>\n",
       "      <td>560.783324</td>\n",
       "      <td>620.092467</td>\n",
       "      <td>347.337935</td>\n",
       "      <td>347.623611</td>\n",
       "      <td>693.844970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>169.992094</td>\n",
       "      <td>173.065674</td>\n",
       "      <td>153.552940</td>\n",
       "      <td>166.788184</td>\n",
       "      <td>99.483226</td>\n",
       "      <td>112.590591</td>\n",
       "      <td>181.642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>684.559821</td>\n",
       "      <td>648.783691</td>\n",
       "      <td>622.237644</td>\n",
       "      <td>675.674104</td>\n",
       "      <td>342.549613</td>\n",
       "      <td>384.790895</td>\n",
       "      <td>594.166542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1092.875362</td>\n",
       "      <td>965.683716</td>\n",
       "      <td>969.065554</td>\n",
       "      <td>1084.980801</td>\n",
       "      <td>911.102831</td>\n",
       "      <td>601.189400</td>\n",
       "      <td>1142.564632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>917.085861</td>\n",
       "      <td>674.891174</td>\n",
       "      <td>742.331990</td>\n",
       "      <td>797.964290</td>\n",
       "      <td>404.876685</td>\n",
       "      <td>391.134492</td>\n",
       "      <td>830.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>261.569590</td>\n",
       "      <td>232.082169</td>\n",
       "      <td>210.920805</td>\n",
       "      <td>225.576610</td>\n",
       "      <td>131.774790</td>\n",
       "      <td>129.930008</td>\n",
       "      <td>269.498973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1065.400121</td>\n",
       "      <td>730.457275</td>\n",
       "      <td>852.091174</td>\n",
       "      <td>925.788409</td>\n",
       "      <td>398.926697</td>\n",
       "      <td>440.077496</td>\n",
       "      <td>1133.560974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1568.407214</td>\n",
       "      <td>1005.392944</td>\n",
       "      <td>1286.814471</td>\n",
       "      <td>1397.071983</td>\n",
       "      <td>858.595973</td>\n",
       "      <td>677.887045</td>\n",
       "      <td>2627.470943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>476.122783</td>\n",
       "      <td>428.916565</td>\n",
       "      <td>382.800781</td>\n",
       "      <td>417.035222</td>\n",
       "      <td>270.478738</td>\n",
       "      <td>225.775009</td>\n",
       "      <td>507.799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      prophet  neuralprophet        ridge       linear  \\\n",
       "0     2019-01-01   402.296576     383.543457   359.817081   392.328390   \n",
       "1     2019-01-01   631.642099     551.044983   560.783324   620.092467   \n",
       "2     2019-01-01   169.992094     173.065674   153.552940   166.788184   \n",
       "3     2019-01-01   684.559821     648.783691   622.237644   675.674104   \n",
       "4     2019-01-01  1092.875362     965.683716   969.065554  1084.980801   \n",
       "...          ...          ...            ...          ...          ...   \n",
       "6565  2019-12-31   917.085861     674.891174   742.331990   797.964290   \n",
       "6566  2019-12-31   261.569590     232.082169   210.920805   225.576610   \n",
       "6567  2019-12-31  1065.400121     730.457275   852.091174   925.788409   \n",
       "6568  2019-12-31  1568.407214    1005.392944  1286.814471  1397.071983   \n",
       "6569  2019-12-31   476.122783     428.916565   382.800781   417.035222   \n",
       "\n",
       "           huber       lasso        earth  \n",
       "0     248.728792  221.118411   417.102143  \n",
       "1     347.337935  347.623611   693.844970  \n",
       "2      99.483226  112.590591   181.642807  \n",
       "3     342.549613  384.790895   594.166542  \n",
       "4     911.102831  601.189400  1142.564632  \n",
       "...          ...         ...          ...  \n",
       "6565  404.876685  391.134492   830.606248  \n",
       "6566  131.774790  129.930008   269.498973  \n",
       "6567  398.926697  440.077496  1133.560974  \n",
       "6568  858.595973  677.887045  2627.470943  \n",
       "6569  270.478738  225.775009   507.799360  \n",
       "\n",
       "[6570 rows x 8 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forecast_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "758f4b84-02bd-4a57-bb43-7b96c92e1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_forecast_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c1a215d-9b48-4989-bd11-d4f3254fc631",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date'] = pd.to_datetime(X.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3038304-5900-44da-97ed-da32d598e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date'] = X['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad1c67-42a7-453c-a600-c329282d0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(columns=['huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b883037a-511c-48c3-9b71-47b49231e68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17715f3f-ba7d-4b22-a555-3154a9364197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae2b4c00-0b4c-461d-add2-7359f908ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>402.296576</td>\n",
       "      <td>383.543457</td>\n",
       "      <td>359.817081</td>\n",
       "      <td>392.328390</td>\n",
       "      <td>248.728792</td>\n",
       "      <td>221.118411</td>\n",
       "      <td>417.102143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>631.642099</td>\n",
       "      <td>551.044983</td>\n",
       "      <td>560.783324</td>\n",
       "      <td>620.092467</td>\n",
       "      <td>347.337935</td>\n",
       "      <td>347.623611</td>\n",
       "      <td>693.844970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>169.992094</td>\n",
       "      <td>173.065674</td>\n",
       "      <td>153.552940</td>\n",
       "      <td>166.788184</td>\n",
       "      <td>99.483226</td>\n",
       "      <td>112.590591</td>\n",
       "      <td>181.642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>684.559821</td>\n",
       "      <td>648.783691</td>\n",
       "      <td>622.237644</td>\n",
       "      <td>675.674104</td>\n",
       "      <td>342.549613</td>\n",
       "      <td>384.790895</td>\n",
       "      <td>594.166542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1092.875362</td>\n",
       "      <td>965.683716</td>\n",
       "      <td>969.065554</td>\n",
       "      <td>1084.980801</td>\n",
       "      <td>911.102831</td>\n",
       "      <td>601.189400</td>\n",
       "      <td>1142.564632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>917.085861</td>\n",
       "      <td>674.891174</td>\n",
       "      <td>742.331990</td>\n",
       "      <td>797.964290</td>\n",
       "      <td>404.876685</td>\n",
       "      <td>391.134492</td>\n",
       "      <td>830.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>261.569590</td>\n",
       "      <td>232.082169</td>\n",
       "      <td>210.920805</td>\n",
       "      <td>225.576610</td>\n",
       "      <td>131.774790</td>\n",
       "      <td>129.930008</td>\n",
       "      <td>269.498973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1065.400121</td>\n",
       "      <td>730.457275</td>\n",
       "      <td>852.091174</td>\n",
       "      <td>925.788409</td>\n",
       "      <td>398.926697</td>\n",
       "      <td>440.077496</td>\n",
       "      <td>1133.560974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1568.407214</td>\n",
       "      <td>1005.392944</td>\n",
       "      <td>1286.814471</td>\n",
       "      <td>1397.071983</td>\n",
       "      <td>858.595973</td>\n",
       "      <td>677.887045</td>\n",
       "      <td>2627.470943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>476.122783</td>\n",
       "      <td>428.916565</td>\n",
       "      <td>382.800781</td>\n",
       "      <td>417.035222</td>\n",
       "      <td>270.478738</td>\n",
       "      <td>225.775009</td>\n",
       "      <td>507.799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      prophet  neuralprophet        ridge       linear  \\\n",
       "0     2019-01-01   402.296576     383.543457   359.817081   392.328390   \n",
       "1     2019-01-01   631.642099     551.044983   560.783324   620.092467   \n",
       "2     2019-01-01   169.992094     173.065674   153.552940   166.788184   \n",
       "3     2019-01-01   684.559821     648.783691   622.237644   675.674104   \n",
       "4     2019-01-01  1092.875362     965.683716   969.065554  1084.980801   \n",
       "...          ...          ...            ...          ...          ...   \n",
       "6565  2019-12-31   917.085861     674.891174   742.331990   797.964290   \n",
       "6566  2019-12-31   261.569590     232.082169   210.920805   225.576610   \n",
       "6567  2019-12-31  1065.400121     730.457275   852.091174   925.788409   \n",
       "6568  2019-12-31  1568.407214    1005.392944  1286.814471  1397.071983   \n",
       "6569  2019-12-31   476.122783     428.916565   382.800781   417.035222   \n",
       "\n",
       "           huber       lasso        earth  \n",
       "0     248.728792  221.118411   417.102143  \n",
       "1     347.337935  347.623611   693.844970  \n",
       "2      99.483226  112.590591   181.642807  \n",
       "3     342.549613  384.790895   594.166542  \n",
       "4     911.102831  601.189400  1142.564632  \n",
       "...          ...         ...          ...  \n",
       "6565  404.876685  391.134492   830.606248  \n",
       "6566  131.774790  129.930008   269.498973  \n",
       "6567  398.926697  440.077496  1133.560974  \n",
       "6568  858.595973  677.887045  2627.470943  \n",
       "6569  270.478738  225.775009   507.799360  \n",
       "\n",
       "[6570 rows x 8 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "91504ee2-bdf9-496a-aa77-4629a8e28199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['date'] = X['date'].map(dt.datetime.toordinal)\n",
    "X_test['date'] = pd.to_datetime(X_test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "37ea14b6-83c8-4e0f-9d6e-a7df05c78376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>402.296576</td>\n",
       "      <td>383.543457</td>\n",
       "      <td>359.817081</td>\n",
       "      <td>392.328390</td>\n",
       "      <td>248.728792</td>\n",
       "      <td>221.118411</td>\n",
       "      <td>417.102143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>631.642099</td>\n",
       "      <td>551.044983</td>\n",
       "      <td>560.783324</td>\n",
       "      <td>620.092467</td>\n",
       "      <td>347.337935</td>\n",
       "      <td>347.623611</td>\n",
       "      <td>693.844970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>169.992094</td>\n",
       "      <td>173.065674</td>\n",
       "      <td>153.552940</td>\n",
       "      <td>166.788184</td>\n",
       "      <td>99.483226</td>\n",
       "      <td>112.590591</td>\n",
       "      <td>181.642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>684.559821</td>\n",
       "      <td>648.783691</td>\n",
       "      <td>622.237644</td>\n",
       "      <td>675.674104</td>\n",
       "      <td>342.549613</td>\n",
       "      <td>384.790895</td>\n",
       "      <td>594.166542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1092.875362</td>\n",
       "      <td>965.683716</td>\n",
       "      <td>969.065554</td>\n",
       "      <td>1084.980801</td>\n",
       "      <td>911.102831</td>\n",
       "      <td>601.189400</td>\n",
       "      <td>1142.564632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>917.085861</td>\n",
       "      <td>674.891174</td>\n",
       "      <td>742.331990</td>\n",
       "      <td>797.964290</td>\n",
       "      <td>404.876685</td>\n",
       "      <td>391.134492</td>\n",
       "      <td>830.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>261.569590</td>\n",
       "      <td>232.082169</td>\n",
       "      <td>210.920805</td>\n",
       "      <td>225.576610</td>\n",
       "      <td>131.774790</td>\n",
       "      <td>129.930008</td>\n",
       "      <td>269.498973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1065.400121</td>\n",
       "      <td>730.457275</td>\n",
       "      <td>852.091174</td>\n",
       "      <td>925.788409</td>\n",
       "      <td>398.926697</td>\n",
       "      <td>440.077496</td>\n",
       "      <td>1133.560974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1568.407214</td>\n",
       "      <td>1005.392944</td>\n",
       "      <td>1286.814471</td>\n",
       "      <td>1397.071983</td>\n",
       "      <td>858.595973</td>\n",
       "      <td>677.887045</td>\n",
       "      <td>2627.470943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>476.122783</td>\n",
       "      <td>428.916565</td>\n",
       "      <td>382.800781</td>\n",
       "      <td>417.035222</td>\n",
       "      <td>270.478738</td>\n",
       "      <td>225.775009</td>\n",
       "      <td>507.799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      prophet  neuralprophet        ridge       linear  \\\n",
       "0    2019-01-01   402.296576     383.543457   359.817081   392.328390   \n",
       "1    2019-01-01   631.642099     551.044983   560.783324   620.092467   \n",
       "2    2019-01-01   169.992094     173.065674   153.552940   166.788184   \n",
       "3    2019-01-01   684.559821     648.783691   622.237644   675.674104   \n",
       "4    2019-01-01  1092.875362     965.683716   969.065554  1084.980801   \n",
       "...         ...          ...            ...          ...          ...   \n",
       "6565 2019-12-31   917.085861     674.891174   742.331990   797.964290   \n",
       "6566 2019-12-31   261.569590     232.082169   210.920805   225.576610   \n",
       "6567 2019-12-31  1065.400121     730.457275   852.091174   925.788409   \n",
       "6568 2019-12-31  1568.407214    1005.392944  1286.814471  1397.071983   \n",
       "6569 2019-12-31   476.122783     428.916565   382.800781   417.035222   \n",
       "\n",
       "           huber       lasso        earth  \n",
       "0     248.728792  221.118411   417.102143  \n",
       "1     347.337935  347.623611   693.844970  \n",
       "2      99.483226  112.590591   181.642807  \n",
       "3     342.549613  384.790895   594.166542  \n",
       "4     911.102831  601.189400  1142.564632  \n",
       "...          ...         ...          ...  \n",
       "6565  404.876685  391.134492   830.606248  \n",
       "6566  131.774790  129.930008   269.498973  \n",
       "6567  398.926697  440.077496  1133.560974  \n",
       "6568  858.595973  677.887045  2627.470943  \n",
       "6569  270.478738  225.775009   507.799360  \n",
       "\n",
       "[6570 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf019be3-b35b-4bec-bb77-b67659ea738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['date'] = X_test['date'].map(dt.datetime.toordinal)\n",
    "# X_test = X_test.drop(columns=['huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f690126-2ad9-493b-979a-9b359690d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ae84bb62-9562-492d-ae46-4a21146a21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tv_preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e4c62-c123-4fd2-a143-f337fda403c9",
   "metadata": {},
   "source": [
    "So, with all of the model preds used, Lasso SMAPE is 4.15283882859097\n",
    "- Dropping Huber only, it's 4.152469194333937\n",
    "- Dropping Huber+Lasso it's 4.1525522971210345\n",
    "- Dropping Lasso only, it's 4.15285802958327\n",
    "\n",
    "So of these, definitely the best is dropping Huber only.\n",
    "\n",
    "With all the model preds used, Ridge SMAPE is 4.158465882203197 -- that's much worse.\n",
    "\n",
    "With all the model preds used, LinearRegression SMAPE is 4.158465902939169 -- also much worse.\n",
    "\n",
    "Using the default hyperparams for CatBoost is even worse: 4.31463984301381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f61c148c-1723-45d9-b2d0-3128f5ddf54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1531645410329565"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=final_tv_preds, y_true=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bbe02-20dc-4d1b-8c3d-95404a607ba7",
   "metadata": {},
   "source": [
    "SMAPE on all of them, with Lasso as final, Earth included, is 4.1531645410329565."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6a8804a-6399-4757-aaec-8e9852ce3ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2003f8da-2ff6-4e1d-bc34-71b3bdd21a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'num_sold'] = final_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e58f8aa2-61ed-4ea1-bcc4-194bc289f2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26298</td>\n",
       "      <td>382.387610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26299</td>\n",
       "      <td>607.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26300</td>\n",
       "      <td>159.829226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26301</td>\n",
       "      <td>661.969460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26302</td>\n",
       "      <td>1063.321727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>787.496001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>217.033343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>915.852977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>1391.866271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>405.232506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id     num_sold\n",
       "0      26298   382.387610\n",
       "1      26299   607.651600\n",
       "2      26300   159.829226\n",
       "3      26301   661.969460\n",
       "4      26302  1063.321727\n",
       "...      ...          ...\n",
       "6565   32863   787.496001\n",
       "6566   32864   217.033343\n",
       "6567   32865   915.852977\n",
       "6568   32866  1391.866271\n",
       "6569   32867   405.232506\n",
       "\n",
       "[6570 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8a5769d-9966-49d3-90ea-e2ab2c7cb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['num_sold'] = sample_df['num_sold'].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f4f748ff-86d6-46ce-8cc1-830492186e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26298</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26299</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26300</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26301</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26302</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  num_sold\n",
       "0   26298       382\n",
       "1   26299       608\n",
       "2   26300       160\n",
       "3   26301       662\n",
       "4   26302      1063"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0bc832e4-76cf-4588-a3a3-219e43bb2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"20220125_forecasts+earth_lasso_preds_rounded.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11373ca-ce60-4aac-8363-a6d4de3a0e4b",
   "metadata": {},
   "source": [
    "## Submission of Adjusted XGB Naivish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b693a516-a1c6-47ed-ab44-001dd950d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "\n",
      "lgb\n",
      "\n",
      "cat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# oof_features = ['']\n",
    "adjusted_oof_preds = pd.DataFrame({\n",
    "    'date': orig_train_df['date'],\n",
    "})\n",
    "\n",
    "tv_dfs_dict = {\n",
    "    'xgb': xgb_tv_df,\n",
    "    'lgb': lgb_tv_df,\n",
    "    'cat': cat_tv_df,\n",
    "}\n",
    "\n",
    "for arch in tv_dfs_dict.keys():\n",
    "    print(f\"{arch}\\n\")\n",
    "    for forecast_model in forecast_models:\n",
    "#         if arch == 'xgb':\n",
    "#                         adjusted_oof_preds[f\"{arch}+{forecast_model}\"] = tv_dfs_dict[arch][f'{forecast_model}_pred']+tv_dfs_dict[arch][f'{forecast_model}_oof_preds']\n",
    "#         else:\n",
    "        adjusted_oof_preds[f\"{arch}+{forecast_model}\"] = tv_dfs_dict[arch][f'{forecast_model}_pred']+tv_dfs_dict[arch][f'{forecast_model}_oof_residual_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7ef2d931-acaf-47a7-b045-ed38fdb7e1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>xgb+prophet</th>\n",
       "      <th>xgb+neuralprophet</th>\n",
       "      <th>xgb+ridge</th>\n",
       "      <th>xgb+linear</th>\n",
       "      <th>xgb+huber</th>\n",
       "      <th>xgb+lasso</th>\n",
       "      <th>xgb+earth</th>\n",
       "      <th>lgb+prophet</th>\n",
       "      <th>lgb+neuralprophet</th>\n",
       "      <th>...</th>\n",
       "      <th>lgb+huber</th>\n",
       "      <th>lgb+lasso</th>\n",
       "      <th>lgb+earth</th>\n",
       "      <th>cat+prophet</th>\n",
       "      <th>cat+neuralprophet</th>\n",
       "      <th>cat+ridge</th>\n",
       "      <th>cat+linear</th>\n",
       "      <th>cat+huber</th>\n",
       "      <th>cat+lasso</th>\n",
       "      <th>cat+earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>347.839034</td>\n",
       "      <td>349.116076</td>\n",
       "      <td>317.494899</td>\n",
       "      <td>327.833433</td>\n",
       "      <td>379.245036</td>\n",
       "      <td>342.606288</td>\n",
       "      <td>375.352988</td>\n",
       "      <td>335.467823</td>\n",
       "      <td>332.675307</td>\n",
       "      <td>...</td>\n",
       "      <td>354.488671</td>\n",
       "      <td>333.410991</td>\n",
       "      <td>385.836067</td>\n",
       "      <td>333.915969</td>\n",
       "      <td>328.715831</td>\n",
       "      <td>314.826055</td>\n",
       "      <td>317.206583</td>\n",
       "      <td>346.279165</td>\n",
       "      <td>336.233347</td>\n",
       "      <td>381.225120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>525.221343</td>\n",
       "      <td>493.420670</td>\n",
       "      <td>497.604635</td>\n",
       "      <td>493.895785</td>\n",
       "      <td>526.704472</td>\n",
       "      <td>552.077139</td>\n",
       "      <td>596.930769</td>\n",
       "      <td>519.648545</td>\n",
       "      <td>473.685888</td>\n",
       "      <td>...</td>\n",
       "      <td>492.573564</td>\n",
       "      <td>541.304068</td>\n",
       "      <td>590.518820</td>\n",
       "      <td>509.140981</td>\n",
       "      <td>494.509681</td>\n",
       "      <td>506.135450</td>\n",
       "      <td>495.753502</td>\n",
       "      <td>495.232955</td>\n",
       "      <td>522.987775</td>\n",
       "      <td>589.324197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>137.771353</td>\n",
       "      <td>148.476901</td>\n",
       "      <td>132.205560</td>\n",
       "      <td>129.735593</td>\n",
       "      <td>162.792018</td>\n",
       "      <td>143.283465</td>\n",
       "      <td>135.305354</td>\n",
       "      <td>148.667331</td>\n",
       "      <td>138.844205</td>\n",
       "      <td>...</td>\n",
       "      <td>154.851398</td>\n",
       "      <td>136.278547</td>\n",
       "      <td>145.985095</td>\n",
       "      <td>142.338521</td>\n",
       "      <td>127.459581</td>\n",
       "      <td>128.473396</td>\n",
       "      <td>133.452584</td>\n",
       "      <td>145.584398</td>\n",
       "      <td>133.919333</td>\n",
       "      <td>141.192906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>597.476377</td>\n",
       "      <td>577.813116</td>\n",
       "      <td>554.806277</td>\n",
       "      <td>567.282113</td>\n",
       "      <td>615.298024</td>\n",
       "      <td>591.611316</td>\n",
       "      <td>618.824973</td>\n",
       "      <td>590.189094</td>\n",
       "      <td>556.542029</td>\n",
       "      <td>...</td>\n",
       "      <td>593.972827</td>\n",
       "      <td>571.047420</td>\n",
       "      <td>615.613465</td>\n",
       "      <td>583.211954</td>\n",
       "      <td>628.725821</td>\n",
       "      <td>569.523275</td>\n",
       "      <td>547.732239</td>\n",
       "      <td>615.549186</td>\n",
       "      <td>636.556795</td>\n",
       "      <td>613.489740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>940.532371</td>\n",
       "      <td>885.238914</td>\n",
       "      <td>904.503964</td>\n",
       "      <td>883.981135</td>\n",
       "      <td>998.825694</td>\n",
       "      <td>990.559725</td>\n",
       "      <td>953.515239</td>\n",
       "      <td>921.358231</td>\n",
       "      <td>850.556192</td>\n",
       "      <td>...</td>\n",
       "      <td>920.105059</td>\n",
       "      <td>926.419508</td>\n",
       "      <td>932.330567</td>\n",
       "      <td>935.543658</td>\n",
       "      <td>947.868121</td>\n",
       "      <td>898.809221</td>\n",
       "      <td>881.201439</td>\n",
       "      <td>964.717169</td>\n",
       "      <td>1008.016399</td>\n",
       "      <td>958.648482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>895.068810</td>\n",
       "      <td>952.740387</td>\n",
       "      <td>855.956621</td>\n",
       "      <td>835.893293</td>\n",
       "      <td>873.028487</td>\n",
       "      <td>824.394254</td>\n",
       "      <td>811.173865</td>\n",
       "      <td>841.557771</td>\n",
       "      <td>924.595014</td>\n",
       "      <td>...</td>\n",
       "      <td>791.482009</td>\n",
       "      <td>781.942451</td>\n",
       "      <td>819.689733</td>\n",
       "      <td>927.389893</td>\n",
       "      <td>968.623145</td>\n",
       "      <td>854.088327</td>\n",
       "      <td>848.968382</td>\n",
       "      <td>811.147037</td>\n",
       "      <td>832.155634</td>\n",
       "      <td>834.802035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>239.072883</td>\n",
       "      <td>234.123107</td>\n",
       "      <td>252.059312</td>\n",
       "      <td>246.349297</td>\n",
       "      <td>251.028084</td>\n",
       "      <td>246.388929</td>\n",
       "      <td>254.008561</td>\n",
       "      <td>247.163872</td>\n",
       "      <td>254.613309</td>\n",
       "      <td>...</td>\n",
       "      <td>250.723332</td>\n",
       "      <td>255.961176</td>\n",
       "      <td>260.955129</td>\n",
       "      <td>216.592747</td>\n",
       "      <td>265.774641</td>\n",
       "      <td>250.231972</td>\n",
       "      <td>244.564056</td>\n",
       "      <td>223.426179</td>\n",
       "      <td>236.455523</td>\n",
       "      <td>255.052840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1008.234856</td>\n",
       "      <td>1080.218079</td>\n",
       "      <td>978.929240</td>\n",
       "      <td>969.606250</td>\n",
       "      <td>953.679743</td>\n",
       "      <td>961.455315</td>\n",
       "      <td>1034.259495</td>\n",
       "      <td>962.166435</td>\n",
       "      <td>1030.649207</td>\n",
       "      <td>...</td>\n",
       "      <td>959.214436</td>\n",
       "      <td>935.613384</td>\n",
       "      <td>1041.701203</td>\n",
       "      <td>1075.349456</td>\n",
       "      <td>1073.352314</td>\n",
       "      <td>971.048282</td>\n",
       "      <td>969.551301</td>\n",
       "      <td>900.275331</td>\n",
       "      <td>944.275194</td>\n",
       "      <td>1027.932925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1561.027261</td>\n",
       "      <td>1618.575989</td>\n",
       "      <td>1483.005146</td>\n",
       "      <td>1455.646571</td>\n",
       "      <td>1506.053037</td>\n",
       "      <td>1464.287333</td>\n",
       "      <td>1996.239684</td>\n",
       "      <td>1492.569556</td>\n",
       "      <td>1549.965081</td>\n",
       "      <td>...</td>\n",
       "      <td>1387.095641</td>\n",
       "      <td>1399.327370</td>\n",
       "      <td>2007.606717</td>\n",
       "      <td>1663.235599</td>\n",
       "      <td>1589.577839</td>\n",
       "      <td>1468.298331</td>\n",
       "      <td>1468.509798</td>\n",
       "      <td>1504.615944</td>\n",
       "      <td>1418.220415</td>\n",
       "      <td>2036.327679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>435.557655</td>\n",
       "      <td>521.989784</td>\n",
       "      <td>447.569811</td>\n",
       "      <td>444.741611</td>\n",
       "      <td>419.327652</td>\n",
       "      <td>436.976842</td>\n",
       "      <td>473.288302</td>\n",
       "      <td>416.827192</td>\n",
       "      <td>503.792598</td>\n",
       "      <td>...</td>\n",
       "      <td>418.105068</td>\n",
       "      <td>440.374708</td>\n",
       "      <td>476.755292</td>\n",
       "      <td>466.528819</td>\n",
       "      <td>567.152143</td>\n",
       "      <td>446.202481</td>\n",
       "      <td>441.665551</td>\n",
       "      <td>461.853045</td>\n",
       "      <td>431.817724</td>\n",
       "      <td>465.013716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  xgb+prophet  xgb+neuralprophet    xgb+ridge   xgb+linear  \\\n",
       "0      2015-01-01   347.839034         349.116076   317.494899   327.833433   \n",
       "1      2015-01-01   525.221343         493.420670   497.604635   493.895785   \n",
       "2      2015-01-01   137.771353         148.476901   132.205560   129.735593   \n",
       "3      2015-01-01   597.476377         577.813116   554.806277   567.282113   \n",
       "4      2015-01-01   940.532371         885.238914   904.503964   883.981135   \n",
       "...           ...          ...                ...          ...          ...   \n",
       "26293  2018-12-31   895.068810         952.740387   855.956621   835.893293   \n",
       "26294  2018-12-31   239.072883         234.123107   252.059312   246.349297   \n",
       "26295  2018-12-31  1008.234856        1080.218079   978.929240   969.606250   \n",
       "26296  2018-12-31  1561.027261        1618.575989  1483.005146  1455.646571   \n",
       "26297  2018-12-31   435.557655         521.989784   447.569811   444.741611   \n",
       "\n",
       "         xgb+huber    xgb+lasso    xgb+earth  lgb+prophet  lgb+neuralprophet  \\\n",
       "0       379.245036   342.606288   375.352988   335.467823         332.675307   \n",
       "1       526.704472   552.077139   596.930769   519.648545         473.685888   \n",
       "2       162.792018   143.283465   135.305354   148.667331         138.844205   \n",
       "3       615.298024   591.611316   618.824973   590.189094         556.542029   \n",
       "4       998.825694   990.559725   953.515239   921.358231         850.556192   \n",
       "...            ...          ...          ...          ...                ...   \n",
       "26293   873.028487   824.394254   811.173865   841.557771         924.595014   \n",
       "26294   251.028084   246.388929   254.008561   247.163872         254.613309   \n",
       "26295   953.679743   961.455315  1034.259495   962.166435        1030.649207   \n",
       "26296  1506.053037  1464.287333  1996.239684  1492.569556        1549.965081   \n",
       "26297   419.327652   436.976842   473.288302   416.827192         503.792598   \n",
       "\n",
       "       ...    lgb+huber    lgb+lasso    lgb+earth  cat+prophet  \\\n",
       "0      ...   354.488671   333.410991   385.836067   333.915969   \n",
       "1      ...   492.573564   541.304068   590.518820   509.140981   \n",
       "2      ...   154.851398   136.278547   145.985095   142.338521   \n",
       "3      ...   593.972827   571.047420   615.613465   583.211954   \n",
       "4      ...   920.105059   926.419508   932.330567   935.543658   \n",
       "...    ...          ...          ...          ...          ...   \n",
       "26293  ...   791.482009   781.942451   819.689733   927.389893   \n",
       "26294  ...   250.723332   255.961176   260.955129   216.592747   \n",
       "26295  ...   959.214436   935.613384  1041.701203  1075.349456   \n",
       "26296  ...  1387.095641  1399.327370  2007.606717  1663.235599   \n",
       "26297  ...   418.105068   440.374708   476.755292   466.528819   \n",
       "\n",
       "       cat+neuralprophet    cat+ridge   cat+linear    cat+huber    cat+lasso  \\\n",
       "0             328.715831   314.826055   317.206583   346.279165   336.233347   \n",
       "1             494.509681   506.135450   495.753502   495.232955   522.987775   \n",
       "2             127.459581   128.473396   133.452584   145.584398   133.919333   \n",
       "3             628.725821   569.523275   547.732239   615.549186   636.556795   \n",
       "4             947.868121   898.809221   881.201439   964.717169  1008.016399   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "26293         968.623145   854.088327   848.968382   811.147037   832.155634   \n",
       "26294         265.774641   250.231972   244.564056   223.426179   236.455523   \n",
       "26295        1073.352314   971.048282   969.551301   900.275331   944.275194   \n",
       "26296        1589.577839  1468.298331  1468.509798  1504.615944  1418.220415   \n",
       "26297         567.152143   446.202481   441.665551   461.853045   431.817724   \n",
       "\n",
       "         cat+earth  \n",
       "0       381.225120  \n",
       "1       589.324197  \n",
       "2       141.192906  \n",
       "3       613.489740  \n",
       "4       958.648482  \n",
       "...            ...  \n",
       "26293   834.802035  \n",
       "26294   255.052840  \n",
       "26295  1027.932925  \n",
       "26296  2036.327679  \n",
       "26297   465.013716  \n",
       "\n",
       "[26298 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "85152ca2-aefb-442f-b671-e90c68b8815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_oof_preds['num_sold'] = orig_train_df['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0366c787-dfdf-470d-8831-b7815e858c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fa9120b-48b6-48cc-9c19-a4102027fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adjusted_oof_preds.drop(columns=['num_sold'])\n",
    "y = adjusted_oof_preds['num_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff5c4158-3be1-44db-a1d0-123745a46403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>xgb+prophet</th>\n",
       "      <th>xgb+neuralprophet</th>\n",
       "      <th>xgb+ridge</th>\n",
       "      <th>xgb+linear</th>\n",
       "      <th>xgb+huber</th>\n",
       "      <th>xgb+lasso</th>\n",
       "      <th>xgb+earth</th>\n",
       "      <th>lgb+prophet</th>\n",
       "      <th>lgb+neuralprophet</th>\n",
       "      <th>...</th>\n",
       "      <th>lgb+huber</th>\n",
       "      <th>lgb+lasso</th>\n",
       "      <th>lgb+earth</th>\n",
       "      <th>cat+prophet</th>\n",
       "      <th>cat+neuralprophet</th>\n",
       "      <th>cat+ridge</th>\n",
       "      <th>cat+linear</th>\n",
       "      <th>cat+huber</th>\n",
       "      <th>cat+lasso</th>\n",
       "      <th>cat+earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-4.067052</td>\n",
       "      <td>3.566073</td>\n",
       "      <td>41.074242</td>\n",
       "      <td>-2.927207</td>\n",
       "      <td>128.356812</td>\n",
       "      <td>173.576721</td>\n",
       "      <td>4.676296</td>\n",
       "      <td>19.160529</td>\n",
       "      <td>24.008850</td>\n",
       "      <td>...</td>\n",
       "      <td>153.611849</td>\n",
       "      <td>195.314152</td>\n",
       "      <td>20.820871</td>\n",
       "      <td>-14.551260</td>\n",
       "      <td>-1.800107</td>\n",
       "      <td>39.869848</td>\n",
       "      <td>-14.322520</td>\n",
       "      <td>132.503743</td>\n",
       "      <td>170.387482</td>\n",
       "      <td>12.443302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-13.555625</td>\n",
       "      <td>34.937973</td>\n",
       "      <td>68.296036</td>\n",
       "      <td>-5.406509</td>\n",
       "      <td>199.275787</td>\n",
       "      <td>226.587021</td>\n",
       "      <td>-0.244518</td>\n",
       "      <td>7.732444</td>\n",
       "      <td>50.983436</td>\n",
       "      <td>...</td>\n",
       "      <td>233.720382</td>\n",
       "      <td>248.805710</td>\n",
       "      <td>4.332084</td>\n",
       "      <td>-25.338150</td>\n",
       "      <td>41.845209</td>\n",
       "      <td>75.834353</td>\n",
       "      <td>-11.974044</td>\n",
       "      <td>202.962403</td>\n",
       "      <td>226.909551</td>\n",
       "      <td>-2.204298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-3.331920</td>\n",
       "      <td>-0.241590</td>\n",
       "      <td>18.091089</td>\n",
       "      <td>-0.690675</td>\n",
       "      <td>70.900955</td>\n",
       "      <td>63.955837</td>\n",
       "      <td>-2.493924</td>\n",
       "      <td>14.956698</td>\n",
       "      <td>11.577024</td>\n",
       "      <td>...</td>\n",
       "      <td>82.048371</td>\n",
       "      <td>71.323406</td>\n",
       "      <td>10.174175</td>\n",
       "      <td>-1.492796</td>\n",
       "      <td>-9.116931</td>\n",
       "      <td>16.343637</td>\n",
       "      <td>-6.888167</td>\n",
       "      <td>68.528241</td>\n",
       "      <td>53.385513</td>\n",
       "      <td>5.400922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.510092</td>\n",
       "      <td>10.981060</td>\n",
       "      <td>77.541725</td>\n",
       "      <td>-3.008889</td>\n",
       "      <td>286.174194</td>\n",
       "      <td>301.004395</td>\n",
       "      <td>58.940559</td>\n",
       "      <td>25.952443</td>\n",
       "      <td>30.480100</td>\n",
       "      <td>...</td>\n",
       "      <td>323.630889</td>\n",
       "      <td>307.616513</td>\n",
       "      <td>69.027512</td>\n",
       "      <td>-9.812288</td>\n",
       "      <td>63.185425</td>\n",
       "      <td>81.140506</td>\n",
       "      <td>-19.407028</td>\n",
       "      <td>301.357366</td>\n",
       "      <td>333.277065</td>\n",
       "      <td>34.791091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-6.373379</td>\n",
       "      <td>101.002495</td>\n",
       "      <td>131.558319</td>\n",
       "      <td>-14.222021</td>\n",
       "      <td>109.163857</td>\n",
       "      <td>426.055115</td>\n",
       "      <td>11.430920</td>\n",
       "      <td>5.972354</td>\n",
       "      <td>113.884040</td>\n",
       "      <td>...</td>\n",
       "      <td>126.000091</td>\n",
       "      <td>420.570380</td>\n",
       "      <td>0.825095</td>\n",
       "      <td>-9.019371</td>\n",
       "      <td>172.704790</td>\n",
       "      <td>133.047662</td>\n",
       "      <td>-19.296734</td>\n",
       "      <td>108.357982</td>\n",
       "      <td>440.198751</td>\n",
       "      <td>6.929261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-50.195488</td>\n",
       "      <td>195.773560</td>\n",
       "      <td>113.345879</td>\n",
       "      <td>-10.379541</td>\n",
       "      <td>375.811951</td>\n",
       "      <td>394.700653</td>\n",
       "      <td>-35.658470</td>\n",
       "      <td>-46.806451</td>\n",
       "      <td>207.724041</td>\n",
       "      <td>...</td>\n",
       "      <td>390.029170</td>\n",
       "      <td>390.711591</td>\n",
       "      <td>-27.229663</td>\n",
       "      <td>-14.822396</td>\n",
       "      <td>259.902562</td>\n",
       "      <td>119.144230</td>\n",
       "      <td>-2.358119</td>\n",
       "      <td>393.269959</td>\n",
       "      <td>416.836879</td>\n",
       "      <td>-25.232470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-23.390570</td>\n",
       "      <td>-11.323580</td>\n",
       "      <td>38.962296</td>\n",
       "      <td>5.678431</td>\n",
       "      <td>95.540482</td>\n",
       "      <td>108.151726</td>\n",
       "      <td>5.794139</td>\n",
       "      <td>-4.648200</td>\n",
       "      <td>18.061144</td>\n",
       "      <td>...</td>\n",
       "      <td>119.588726</td>\n",
       "      <td>128.935765</td>\n",
       "      <td>8.979386</td>\n",
       "      <td>-39.835409</td>\n",
       "      <td>7.455011</td>\n",
       "      <td>38.123140</td>\n",
       "      <td>4.600495</td>\n",
       "      <td>88.419512</td>\n",
       "      <td>106.974697</td>\n",
       "      <td>-0.656414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-45.403526</td>\n",
       "      <td>270.956757</td>\n",
       "      <td>150.691833</td>\n",
       "      <td>5.033105</td>\n",
       "      <td>530.443542</td>\n",
       "      <td>514.030701</td>\n",
       "      <td>-15.523385</td>\n",
       "      <td>-43.757356</td>\n",
       "      <td>296.687993</td>\n",
       "      <td>...</td>\n",
       "      <td>556.224723</td>\n",
       "      <td>515.679049</td>\n",
       "      <td>1.206652</td>\n",
       "      <td>18.973191</td>\n",
       "      <td>331.374321</td>\n",
       "      <td>138.763121</td>\n",
       "      <td>3.077579</td>\n",
       "      <td>493.934774</td>\n",
       "      <td>510.334507</td>\n",
       "      <td>-30.920033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-20.315483</td>\n",
       "      <td>498.042358</td>\n",
       "      <td>209.089203</td>\n",
       "      <td>-17.959795</td>\n",
       "      <td>551.822754</td>\n",
       "      <td>711.522400</td>\n",
       "      <td>-99.865623</td>\n",
       "      <td>-34.494487</td>\n",
       "      <td>506.298903</td>\n",
       "      <td>...</td>\n",
       "      <td>529.687931</td>\n",
       "      <td>683.715500</td>\n",
       "      <td>-74.369522</td>\n",
       "      <td>88.026475</td>\n",
       "      <td>578.599638</td>\n",
       "      <td>199.991247</td>\n",
       "      <td>-8.266427</td>\n",
       "      <td>631.048378</td>\n",
       "      <td>713.978299</td>\n",
       "      <td>-48.918927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-58.599598</td>\n",
       "      <td>17.579525</td>\n",
       "      <td>45.812351</td>\n",
       "      <td>-15.263520</td>\n",
       "      <td>108.524506</td>\n",
       "      <td>174.454453</td>\n",
       "      <td>2.004032</td>\n",
       "      <td>-49.113571</td>\n",
       "      <td>40.236451</td>\n",
       "      <td>...</td>\n",
       "      <td>130.496104</td>\n",
       "      <td>189.641488</td>\n",
       "      <td>0.830455</td>\n",
       "      <td>-20.146687</td>\n",
       "      <td>99.768567</td>\n",
       "      <td>59.887214</td>\n",
       "      <td>-4.701483</td>\n",
       "      <td>171.197127</td>\n",
       "      <td>198.514762</td>\n",
       "      <td>-8.180595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  xgb+prophet  xgb+neuralprophet   xgb+ridge  xgb+linear  \\\n",
       "0     2019-01-01    -4.067052           3.566073   41.074242   -2.927207   \n",
       "1     2019-01-01   -13.555625          34.937973   68.296036   -5.406509   \n",
       "2     2019-01-01    -3.331920          -0.241590   18.091089   -0.690675   \n",
       "3     2019-01-01     0.510092          10.981060   77.541725   -3.008889   \n",
       "4     2019-01-01    -6.373379         101.002495  131.558319  -14.222021   \n",
       "...          ...          ...                ...         ...         ...   \n",
       "6565  2019-12-31   -50.195488         195.773560  113.345879  -10.379541   \n",
       "6566  2019-12-31   -23.390570         -11.323580   38.962296    5.678431   \n",
       "6567  2019-12-31   -45.403526         270.956757  150.691833    5.033105   \n",
       "6568  2019-12-31   -20.315483         498.042358  209.089203  -17.959795   \n",
       "6569  2019-12-31   -58.599598          17.579525   45.812351  -15.263520   \n",
       "\n",
       "       xgb+huber   xgb+lasso  xgb+earth  lgb+prophet  lgb+neuralprophet  ...  \\\n",
       "0     128.356812  173.576721   4.676296    19.160529          24.008850  ...   \n",
       "1     199.275787  226.587021  -0.244518     7.732444          50.983436  ...   \n",
       "2      70.900955   63.955837  -2.493924    14.956698          11.577024  ...   \n",
       "3     286.174194  301.004395  58.940559    25.952443          30.480100  ...   \n",
       "4     109.163857  426.055115  11.430920     5.972354         113.884040  ...   \n",
       "...          ...         ...        ...          ...                ...  ...   \n",
       "6565  375.811951  394.700653 -35.658470   -46.806451         207.724041  ...   \n",
       "6566   95.540482  108.151726   5.794139    -4.648200          18.061144  ...   \n",
       "6567  530.443542  514.030701 -15.523385   -43.757356         296.687993  ...   \n",
       "6568  551.822754  711.522400 -99.865623   -34.494487         506.298903  ...   \n",
       "6569  108.524506  174.454453   2.004032   -49.113571          40.236451  ...   \n",
       "\n",
       "       lgb+huber   lgb+lasso  lgb+earth  cat+prophet  cat+neuralprophet  \\\n",
       "0     153.611849  195.314152  20.820871   -14.551260          -1.800107   \n",
       "1     233.720382  248.805710   4.332084   -25.338150          41.845209   \n",
       "2      82.048371   71.323406  10.174175    -1.492796          -9.116931   \n",
       "3     323.630889  307.616513  69.027512    -9.812288          63.185425   \n",
       "4     126.000091  420.570380   0.825095    -9.019371         172.704790   \n",
       "...          ...         ...        ...          ...                ...   \n",
       "6565  390.029170  390.711591 -27.229663   -14.822396         259.902562   \n",
       "6566  119.588726  128.935765   8.979386   -39.835409           7.455011   \n",
       "6567  556.224723  515.679049   1.206652    18.973191         331.374321   \n",
       "6568  529.687931  683.715500 -74.369522    88.026475         578.599638   \n",
       "6569  130.496104  189.641488   0.830455   -20.146687          99.768567   \n",
       "\n",
       "       cat+ridge  cat+linear   cat+huber   cat+lasso  cat+earth  \n",
       "0      39.869848  -14.322520  132.503743  170.387482  12.443302  \n",
       "1      75.834353  -11.974044  202.962403  226.909551  -2.204298  \n",
       "2      16.343637   -6.888167   68.528241   53.385513   5.400922  \n",
       "3      81.140506  -19.407028  301.357366  333.277065  34.791091  \n",
       "4     133.047662  -19.296734  108.357982  440.198751   6.929261  \n",
       "...          ...         ...         ...         ...        ...  \n",
       "6565  119.144230   -2.358119  393.269959  416.836879 -25.232470  \n",
       "6566   38.123140    4.600495   88.419512  106.974697  -0.656414  \n",
       "6567  138.763121    3.077579  493.934774  510.334507 -30.920033  \n",
       "6568  199.991247   -8.266427  631.048378  713.978299 -48.918927  \n",
       "6569   59.887214   -4.701483  171.197127  198.514762  -8.180595  \n",
       "\n",
       "[6570 rows x 22 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_test_preds = pd.DataFrame({\n",
    "    'date': orig_test_df['date']\n",
    "})\n",
    "\n",
    "# tv_dfs_dict = {\n",
    "#     'xgb': xgb_tv_df,\n",
    "#     'lgb': lgb_tv_df,\n",
    "#     'cat': cat_tv_df,\n",
    "# }\n",
    "\n",
    "for arch in test_dfs_dict.keys():#['xgb', 'lgb', 'cat']: #prophet_0_residual_preds\n",
    "    for forecast_model in forecast_models:\n",
    "        adjusted_test_preds[f'{arch}+{forecast_model}'] = sum([test_dfs_dict[arch][f'{forecast_model}_{i}_residual_preds'] for i in range(4)]) / 4\n",
    "adjusted_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4fc0f6ea-a9a6-4237-80aa-ec8d08e5e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prophet</th>\n",
       "      <th>neuralprophet</th>\n",
       "      <th>ridge</th>\n",
       "      <th>linear</th>\n",
       "      <th>huber</th>\n",
       "      <th>lasso</th>\n",
       "      <th>earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>737060</td>\n",
       "      <td>402.296576</td>\n",
       "      <td>383.543457</td>\n",
       "      <td>359.817081</td>\n",
       "      <td>392.328390</td>\n",
       "      <td>248.728792</td>\n",
       "      <td>221.118411</td>\n",
       "      <td>417.102143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737060</td>\n",
       "      <td>631.642099</td>\n",
       "      <td>551.044983</td>\n",
       "      <td>560.783324</td>\n",
       "      <td>620.092467</td>\n",
       "      <td>347.337935</td>\n",
       "      <td>347.623611</td>\n",
       "      <td>693.844970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737060</td>\n",
       "      <td>169.992094</td>\n",
       "      <td>173.065674</td>\n",
       "      <td>153.552940</td>\n",
       "      <td>166.788184</td>\n",
       "      <td>99.483226</td>\n",
       "      <td>112.590591</td>\n",
       "      <td>181.642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>737060</td>\n",
       "      <td>684.559821</td>\n",
       "      <td>648.783691</td>\n",
       "      <td>622.237644</td>\n",
       "      <td>675.674104</td>\n",
       "      <td>342.549613</td>\n",
       "      <td>384.790895</td>\n",
       "      <td>594.166542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>737060</td>\n",
       "      <td>1092.875362</td>\n",
       "      <td>965.683716</td>\n",
       "      <td>969.065554</td>\n",
       "      <td>1084.980801</td>\n",
       "      <td>911.102831</td>\n",
       "      <td>601.189400</td>\n",
       "      <td>1142.564632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>737424</td>\n",
       "      <td>917.085861</td>\n",
       "      <td>674.891174</td>\n",
       "      <td>742.331990</td>\n",
       "      <td>797.964290</td>\n",
       "      <td>404.876685</td>\n",
       "      <td>391.134492</td>\n",
       "      <td>830.606248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>737424</td>\n",
       "      <td>261.569590</td>\n",
       "      <td>232.082169</td>\n",
       "      <td>210.920805</td>\n",
       "      <td>225.576610</td>\n",
       "      <td>131.774790</td>\n",
       "      <td>129.930008</td>\n",
       "      <td>269.498973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>737424</td>\n",
       "      <td>1065.400121</td>\n",
       "      <td>730.457275</td>\n",
       "      <td>852.091174</td>\n",
       "      <td>925.788409</td>\n",
       "      <td>398.926697</td>\n",
       "      <td>440.077496</td>\n",
       "      <td>1133.560974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>737424</td>\n",
       "      <td>1568.407214</td>\n",
       "      <td>1005.392944</td>\n",
       "      <td>1286.814471</td>\n",
       "      <td>1397.071983</td>\n",
       "      <td>858.595973</td>\n",
       "      <td>677.887045</td>\n",
       "      <td>2627.470943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>737424</td>\n",
       "      <td>476.122783</td>\n",
       "      <td>428.916565</td>\n",
       "      <td>382.800781</td>\n",
       "      <td>417.035222</td>\n",
       "      <td>270.478738</td>\n",
       "      <td>225.775009</td>\n",
       "      <td>507.799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      prophet  neuralprophet        ridge       linear  \\\n",
       "0     737060   402.296576     383.543457   359.817081   392.328390   \n",
       "1     737060   631.642099     551.044983   560.783324   620.092467   \n",
       "2     737060   169.992094     173.065674   153.552940   166.788184   \n",
       "3     737060   684.559821     648.783691   622.237644   675.674104   \n",
       "4     737060  1092.875362     965.683716   969.065554  1084.980801   \n",
       "...      ...          ...            ...          ...          ...   \n",
       "6565  737424   917.085861     674.891174   742.331990   797.964290   \n",
       "6566  737424   261.569590     232.082169   210.920805   225.576610   \n",
       "6567  737424  1065.400121     730.457275   852.091174   925.788409   \n",
       "6568  737424  1568.407214    1005.392944  1286.814471  1397.071983   \n",
       "6569  737424   476.122783     428.916565   382.800781   417.035222   \n",
       "\n",
       "           huber       lasso        earth  \n",
       "0     248.728792  221.118411   417.102143  \n",
       "1     347.337935  347.623611   693.844970  \n",
       "2      99.483226  112.590591   181.642807  \n",
       "3     342.549613  384.790895   594.166542  \n",
       "4     911.102831  601.189400  1142.564632  \n",
       "...          ...         ...          ...  \n",
       "6565  404.876685  391.134492   830.606248  \n",
       "6566  131.774790  129.930008   269.498973  \n",
       "6567  398.926697  440.077496  1133.560974  \n",
       "6568  858.595973  677.887045  2627.470943  \n",
       "6569  270.478738  225.775009   507.799360  \n",
       "\n",
       "[6570 rows x 8 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forecast_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d0262d1-55c2-485f-892f-6cb8fd5e0035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/preds/20220125_residual_test_predictions+earth_averaged_by_fold_using_GBMs.joblib']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(adjusted_test_preds, predpath/'20220125_residual_test_predictions+earth_averaged_by_fold_using_GBMs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f507c36a-41d8-4afb-926a-b2774574b377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/preds/20220125_final_oof_predictions_forecast+Earth+GBMs-residuals.joblib']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(adjusted_oof_preds, predpath/'20220125_final_oof_predictions_forecast+Earth+GBMs-residuals.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6682497d-1ced-4c03-b1e2-9c2aa68ee694",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_test_residual_preds = adjusted_test_preds.copy() # fixing the confusing name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ec1a3a0-b34e-46d7-85ef-7af8d259a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_test_preds = pd.DataFrame({\n",
    "    'date': orig_test_df['date']\n",
    "})\n",
    "\n",
    "for arch in ['xgb', 'lgb', 'cat']: # ['xgb', 'lgb', 'cat']:\n",
    "    for forecast_model in forecast_models:\n",
    "        adjusted_test_preds[f'{arch}+{forecast_model}'] = test_forecast_preds[f'{forecast_model}'] + adjusted_test_residual_preds[f'{arch}+{forecast_model}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b7ca7176-8960-4ded-932c-84d64f28bf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>xgb+prophet</th>\n",
       "      <th>xgb+neuralprophet</th>\n",
       "      <th>xgb+ridge</th>\n",
       "      <th>xgb+linear</th>\n",
       "      <th>xgb+huber</th>\n",
       "      <th>xgb+lasso</th>\n",
       "      <th>xgb+earth</th>\n",
       "      <th>lgb+prophet</th>\n",
       "      <th>lgb+neuralprophet</th>\n",
       "      <th>...</th>\n",
       "      <th>lgb+huber</th>\n",
       "      <th>lgb+lasso</th>\n",
       "      <th>lgb+earth</th>\n",
       "      <th>cat+prophet</th>\n",
       "      <th>cat+neuralprophet</th>\n",
       "      <th>cat+ridge</th>\n",
       "      <th>cat+linear</th>\n",
       "      <th>cat+huber</th>\n",
       "      <th>cat+lasso</th>\n",
       "      <th>cat+earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>398.229524</td>\n",
       "      <td>387.109530</td>\n",
       "      <td>400.891323</td>\n",
       "      <td>389.401183</td>\n",
       "      <td>377.085603</td>\n",
       "      <td>394.695132</td>\n",
       "      <td>421.778439</td>\n",
       "      <td>421.457105</td>\n",
       "      <td>407.552307</td>\n",
       "      <td>...</td>\n",
       "      <td>402.340641</td>\n",
       "      <td>416.432563</td>\n",
       "      <td>437.923014</td>\n",
       "      <td>387.745316</td>\n",
       "      <td>381.743350</td>\n",
       "      <td>399.686929</td>\n",
       "      <td>378.005871</td>\n",
       "      <td>381.232535</td>\n",
       "      <td>391.505893</td>\n",
       "      <td>429.545444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>618.086474</td>\n",
       "      <td>585.982956</td>\n",
       "      <td>629.079360</td>\n",
       "      <td>614.685957</td>\n",
       "      <td>546.613722</td>\n",
       "      <td>574.210632</td>\n",
       "      <td>693.600452</td>\n",
       "      <td>639.374543</td>\n",
       "      <td>602.028419</td>\n",
       "      <td>...</td>\n",
       "      <td>581.058317</td>\n",
       "      <td>596.429322</td>\n",
       "      <td>698.177055</td>\n",
       "      <td>606.303949</td>\n",
       "      <td>592.890192</td>\n",
       "      <td>636.617677</td>\n",
       "      <td>608.118423</td>\n",
       "      <td>550.300338</td>\n",
       "      <td>574.533162</td>\n",
       "      <td>691.640672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>166.660175</td>\n",
       "      <td>172.824084</td>\n",
       "      <td>171.644030</td>\n",
       "      <td>166.097509</td>\n",
       "      <td>170.384181</td>\n",
       "      <td>176.546429</td>\n",
       "      <td>179.148883</td>\n",
       "      <td>184.948792</td>\n",
       "      <td>184.642697</td>\n",
       "      <td>...</td>\n",
       "      <td>181.531597</td>\n",
       "      <td>183.913997</td>\n",
       "      <td>191.816982</td>\n",
       "      <td>168.499298</td>\n",
       "      <td>163.948743</td>\n",
       "      <td>169.896578</td>\n",
       "      <td>159.900016</td>\n",
       "      <td>168.011467</td>\n",
       "      <td>165.976105</td>\n",
       "      <td>187.043729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>685.069914</td>\n",
       "      <td>659.764751</td>\n",
       "      <td>699.779369</td>\n",
       "      <td>672.665215</td>\n",
       "      <td>628.723807</td>\n",
       "      <td>685.795290</td>\n",
       "      <td>653.107101</td>\n",
       "      <td>710.512264</td>\n",
       "      <td>679.263792</td>\n",
       "      <td>...</td>\n",
       "      <td>666.180502</td>\n",
       "      <td>692.407408</td>\n",
       "      <td>663.194054</td>\n",
       "      <td>674.747533</td>\n",
       "      <td>711.969117</td>\n",
       "      <td>703.378151</td>\n",
       "      <td>656.267077</td>\n",
       "      <td>643.906978</td>\n",
       "      <td>718.067960</td>\n",
       "      <td>628.957633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1086.501983</td>\n",
       "      <td>1066.686211</td>\n",
       "      <td>1100.623873</td>\n",
       "      <td>1070.758780</td>\n",
       "      <td>1020.266688</td>\n",
       "      <td>1027.244515</td>\n",
       "      <td>1153.995552</td>\n",
       "      <td>1098.847716</td>\n",
       "      <td>1079.567756</td>\n",
       "      <td>...</td>\n",
       "      <td>1037.102922</td>\n",
       "      <td>1021.759780</td>\n",
       "      <td>1143.389727</td>\n",
       "      <td>1083.855991</td>\n",
       "      <td>1138.388506</td>\n",
       "      <td>1102.113216</td>\n",
       "      <td>1065.684067</td>\n",
       "      <td>1019.460813</td>\n",
       "      <td>1041.388151</td>\n",
       "      <td>1149.493893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>866.890374</td>\n",
       "      <td>870.664734</td>\n",
       "      <td>855.677868</td>\n",
       "      <td>787.584748</td>\n",
       "      <td>780.688636</td>\n",
       "      <td>785.835145</td>\n",
       "      <td>794.947778</td>\n",
       "      <td>870.279411</td>\n",
       "      <td>882.615215</td>\n",
       "      <td>...</td>\n",
       "      <td>794.905856</td>\n",
       "      <td>781.846082</td>\n",
       "      <td>803.376585</td>\n",
       "      <td>902.263466</td>\n",
       "      <td>934.793736</td>\n",
       "      <td>861.476220</td>\n",
       "      <td>795.606171</td>\n",
       "      <td>798.146644</td>\n",
       "      <td>807.971371</td>\n",
       "      <td>805.373778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>238.179020</td>\n",
       "      <td>220.758589</td>\n",
       "      <td>249.883101</td>\n",
       "      <td>231.255040</td>\n",
       "      <td>227.315271</td>\n",
       "      <td>238.081734</td>\n",
       "      <td>275.293112</td>\n",
       "      <td>256.921390</td>\n",
       "      <td>250.143313</td>\n",
       "      <td>...</td>\n",
       "      <td>251.363516</td>\n",
       "      <td>258.865774</td>\n",
       "      <td>278.478359</td>\n",
       "      <td>221.734181</td>\n",
       "      <td>239.537180</td>\n",
       "      <td>249.043946</td>\n",
       "      <td>230.177105</td>\n",
       "      <td>220.194302</td>\n",
       "      <td>236.904705</td>\n",
       "      <td>268.842560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1019.996594</td>\n",
       "      <td>1001.414032</td>\n",
       "      <td>1002.783008</td>\n",
       "      <td>930.821515</td>\n",
       "      <td>929.370239</td>\n",
       "      <td>954.108197</td>\n",
       "      <td>1118.037589</td>\n",
       "      <td>1021.642765</td>\n",
       "      <td>1027.145268</td>\n",
       "      <td>...</td>\n",
       "      <td>955.151420</td>\n",
       "      <td>955.756545</td>\n",
       "      <td>1134.767626</td>\n",
       "      <td>1084.373312</td>\n",
       "      <td>1061.831596</td>\n",
       "      <td>990.854295</td>\n",
       "      <td>928.865988</td>\n",
       "      <td>892.861471</td>\n",
       "      <td>950.412003</td>\n",
       "      <td>1102.640941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1548.091731</td>\n",
       "      <td>1503.435303</td>\n",
       "      <td>1495.903674</td>\n",
       "      <td>1379.112188</td>\n",
       "      <td>1410.418727</td>\n",
       "      <td>1389.409444</td>\n",
       "      <td>2527.605319</td>\n",
       "      <td>1533.912727</td>\n",
       "      <td>1511.691847</td>\n",
       "      <td>...</td>\n",
       "      <td>1388.283904</td>\n",
       "      <td>1361.602545</td>\n",
       "      <td>2553.101421</td>\n",
       "      <td>1656.433689</td>\n",
       "      <td>1583.992582</td>\n",
       "      <td>1486.805718</td>\n",
       "      <td>1388.805555</td>\n",
       "      <td>1489.644351</td>\n",
       "      <td>1391.865343</td>\n",
       "      <td>2578.552016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>417.523185</td>\n",
       "      <td>446.496090</td>\n",
       "      <td>428.613132</td>\n",
       "      <td>401.771702</td>\n",
       "      <td>379.003243</td>\n",
       "      <td>400.229462</td>\n",
       "      <td>509.803392</td>\n",
       "      <td>427.009212</td>\n",
       "      <td>469.153016</td>\n",
       "      <td>...</td>\n",
       "      <td>400.974842</td>\n",
       "      <td>415.416497</td>\n",
       "      <td>508.629815</td>\n",
       "      <td>455.976096</td>\n",
       "      <td>528.685132</td>\n",
       "      <td>442.687995</td>\n",
       "      <td>412.333740</td>\n",
       "      <td>441.675864</td>\n",
       "      <td>424.289772</td>\n",
       "      <td>499.618765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  xgb+prophet  xgb+neuralprophet    xgb+ridge   xgb+linear  \\\n",
       "0     2019-01-01   398.229524         387.109530   400.891323   389.401183   \n",
       "1     2019-01-01   618.086474         585.982956   629.079360   614.685957   \n",
       "2     2019-01-01   166.660175         172.824084   171.644030   166.097509   \n",
       "3     2019-01-01   685.069914         659.764751   699.779369   672.665215   \n",
       "4     2019-01-01  1086.501983        1066.686211  1100.623873  1070.758780   \n",
       "...          ...          ...                ...          ...          ...   \n",
       "6565  2019-12-31   866.890374         870.664734   855.677868   787.584748   \n",
       "6566  2019-12-31   238.179020         220.758589   249.883101   231.255040   \n",
       "6567  2019-12-31  1019.996594        1001.414032  1002.783008   930.821515   \n",
       "6568  2019-12-31  1548.091731        1503.435303  1495.903674  1379.112188   \n",
       "6569  2019-12-31   417.523185         446.496090   428.613132   401.771702   \n",
       "\n",
       "        xgb+huber    xgb+lasso    xgb+earth  lgb+prophet  lgb+neuralprophet  \\\n",
       "0      377.085603   394.695132   421.778439   421.457105         407.552307   \n",
       "1      546.613722   574.210632   693.600452   639.374543         602.028419   \n",
       "2      170.384181   176.546429   179.148883   184.948792         184.642697   \n",
       "3      628.723807   685.795290   653.107101   710.512264         679.263792   \n",
       "4     1020.266688  1027.244515  1153.995552  1098.847716        1079.567756   \n",
       "...           ...          ...          ...          ...                ...   \n",
       "6565   780.688636   785.835145   794.947778   870.279411         882.615215   \n",
       "6566   227.315271   238.081734   275.293112   256.921390         250.143313   \n",
       "6567   929.370239   954.108197  1118.037589  1021.642765        1027.145268   \n",
       "6568  1410.418727  1389.409444  2527.605319  1533.912727        1511.691847   \n",
       "6569   379.003243   400.229462   509.803392   427.009212         469.153016   \n",
       "\n",
       "      ...    lgb+huber    lgb+lasso    lgb+earth  cat+prophet  \\\n",
       "0     ...   402.340641   416.432563   437.923014   387.745316   \n",
       "1     ...   581.058317   596.429322   698.177055   606.303949   \n",
       "2     ...   181.531597   183.913997   191.816982   168.499298   \n",
       "3     ...   666.180502   692.407408   663.194054   674.747533   \n",
       "4     ...  1037.102922  1021.759780  1143.389727  1083.855991   \n",
       "...   ...          ...          ...          ...          ...   \n",
       "6565  ...   794.905856   781.846082   803.376585   902.263466   \n",
       "6566  ...   251.363516   258.865774   278.478359   221.734181   \n",
       "6567  ...   955.151420   955.756545  1134.767626  1084.373312   \n",
       "6568  ...  1388.283904  1361.602545  2553.101421  1656.433689   \n",
       "6569  ...   400.974842   415.416497   508.629815   455.976096   \n",
       "\n",
       "      cat+neuralprophet    cat+ridge   cat+linear    cat+huber    cat+lasso  \\\n",
       "0            381.743350   399.686929   378.005871   381.232535   391.505893   \n",
       "1            592.890192   636.617677   608.118423   550.300338   574.533162   \n",
       "2            163.948743   169.896578   159.900016   168.011467   165.976105   \n",
       "3            711.969117   703.378151   656.267077   643.906978   718.067960   \n",
       "4           1138.388506  1102.113216  1065.684067  1019.460813  1041.388151   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "6565         934.793736   861.476220   795.606171   798.146644   807.971371   \n",
       "6566         239.537180   249.043946   230.177105   220.194302   236.904705   \n",
       "6567        1061.831596   990.854295   928.865988   892.861471   950.412003   \n",
       "6568        1583.992582  1486.805718  1388.805555  1489.644351  1391.865343   \n",
       "6569         528.685132   442.687995   412.333740   441.675864   424.289772   \n",
       "\n",
       "        cat+earth  \n",
       "0      429.545444  \n",
       "1      691.640672  \n",
       "2      187.043729  \n",
       "3      628.957633  \n",
       "4     1149.493893  \n",
       "...           ...  \n",
       "6565   805.373778  \n",
       "6566   268.842560  \n",
       "6567  1102.640941  \n",
       "6568  2578.552016  \n",
       "6569   499.618765  \n",
       "\n",
       "[6570 rows x 22 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c9625e53-042f-49fa-922b-9b44f8af20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = adjusted_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d196a654-2a9a-4341-b65d-2f8d757ebb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date'] = pd.to_datetime(X.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8df52a5a-5079-4aa8-ada5-6ea37411fbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['date'] = X['date'].map(dt.datetime.toordinal)\n",
    "model.fit(X,y) # this is the lasso regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2bb1a3e-89f7-4bb7-8620-4319f6d130a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['date'] = X['date'].map(dt.datetime.toordinal)\n",
    "X_test['date'] = pd.to_datetime(X_test.date)\n",
    "X_test['date'] = X_test['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "27698b74-5d49-480c-bcee-56e055378030",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "77d7f19f-ea3f-4047-9cef-6b034d7d252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_tv_preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399b3ce-d536-42d7-93e6-33feb155d432",
   "metadata": {},
   "source": [
    "Naive SMAPE was 4.152715109788985"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8cb02-37f7-4962-9794-2b767d84ecdd",
   "metadata": {},
   "source": [
    "Below had been 4.384919101043075 with XGBoost included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3b2b186f-0a9f-4747-bc91-fce6fef552c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.389347857315039"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=lasso_tv_preds, y_true=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb03e02-064d-4408-a744-09377b3fea44",
   "metadata": {},
   "source": [
    "Below had been 4.27663983822924 with XGBoost included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d6327110-14ab-44b1-a2e7-45d06338c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.254092788311878"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X,y)\n",
    "ridge_test_preds = ridge.predict(X_test)\n",
    "ridge_tv_preds = ridge.predict(X)\n",
    "SMAPE(y_pred=ridge_tv_preds, y_true=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "668396b5-2e10-47d5-a0c4-2492c68dc01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "73cb734a-e9fd-4782-a9cc-a93577f311fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'num_sold'] = ridge_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "746817e6-0989-4166-8311-63b95c95c654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26298</td>\n",
       "      <td>378.586742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26299</td>\n",
       "      <td>612.019972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26300</td>\n",
       "      <td>159.287186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26301</td>\n",
       "      <td>665.461693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26302</td>\n",
       "      <td>1076.410400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     num_sold\n",
       "0   26298   378.586742\n",
       "1   26299   612.019972\n",
       "2   26300   159.287186\n",
       "3   26301   665.461693\n",
       "4   26302  1076.410400"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6f0b610a-3c6b-4036-9eac-f840d5164db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"20220125_forecasts+Earth-Big3-GBMs-residuals_ridge_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f8d52-714e-48a3-a57f-75a1a34674a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = pd.read_csv(subpath/'LB-4.40223__20220124_forecasts_lasso_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4c6a098b-2880-4cff-ab7a-f003aa627100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26298</td>\n",
       "      <td>378.586742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26299</td>\n",
       "      <td>612.019972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26300</td>\n",
       "      <td>159.287186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26301</td>\n",
       "      <td>665.461693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26302</td>\n",
       "      <td>1076.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>812.698251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>231.127064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>946.133632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>1426.518856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>422.689902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id     num_sold\n",
       "0      26298   378.586742\n",
       "1      26299   612.019972\n",
       "2      26300   159.287186\n",
       "3      26301   665.461693\n",
       "4      26302  1076.410400\n",
       "...      ...          ...\n",
       "6565   32863   812.698251\n",
       "6566   32864   231.127064\n",
       "6567   32865   946.133632\n",
       "6568   32866  1426.518856\n",
       "6569   32867   422.689902\n",
       "\n",
       "[6570 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d92fe031-e6f4-4843-94f5-7f76f257d5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26298</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26299</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26300</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26301</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26302</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  num_sold\n",
       "0      26298       379\n",
       "1      26299       612\n",
       "2      26300       159\n",
       "3      26301       665\n",
       "4      26302      1076\n",
       "...      ...       ...\n",
       "6565   32863       813\n",
       "6566   32864       231\n",
       "6567   32865       946\n",
       "6568   32866      1427\n",
       "6569   32867       423\n",
       "\n",
       "[6570 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['num_sold'] = sample_df['num_sold'].apply(round)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6a93a0c7-02fc-4bd1-8fa1-70d21e88b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/'20220125_forecasts+earth_ridge_preds_rounded.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
