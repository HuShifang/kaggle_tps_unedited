{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f0fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "# if '/sf/' in pwd:\n",
    "#     COLAB, SAGE = False, False\n",
    "# elif 'google.colab' in str(get_ipython()):\n",
    "#     COLAB, SAGE = True, False # do colab-specific installs later\n",
    "# else:\n",
    "#     COLAB, SAGE = False, True\n",
    "    \n",
    "CONTEXT = 'local' # or 'colab', 'sage', 'kaggle'\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93bc1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca937fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series\n",
    "import tsfresh\n",
    "\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "# from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel\n",
    "from darts.metrics import smape\n",
    "\n",
    "import holidays\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8621393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import (\n",
    "    NaiveSeasonal,\n",
    "    NaiveDrift,\n",
    "#     Prophet, # on 20220108 postponing this due to df vs ts object wrinkles\n",
    "    ExponentialSmoothing,\n",
    "    ARIMA,\n",
    "    AutoARIMA,\n",
    "    RegressionEnsembleModel,\n",
    "    RegressionModel,\n",
    "    Theta,\n",
    "    FFT\n",
    ")\n",
    "\n",
    "from prophet import Prophet # for now, just imporing the native API\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767bd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "# from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# widedeep\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e971367",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONTEXT == 'colab':\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    root = Path('') # TODO\n",
    "\n",
    "elif CONTEXT == 'sage':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "elif CONTEXT == 'kaggle':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "else: # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4f1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aee7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac79a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27af34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-François Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdaebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "#     'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "df_train = pd.read_csv(datapath/'train.csv')\n",
    "df_test = pd.read_csv(datapath/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4314e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "\n",
    "countries = ['Sweden', 'Finland', 'Norway']\n",
    "stores = ['KaggleMart', 'KaggleRama']\n",
    "products = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d3f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if date is a holiday    \n",
    "def isHoliday(country, date):\n",
    "    # h/t @sumeetbohra for following (https://www.kaggle.com/sumeetbohra/eda-dataviz-fe-lightgbm)\n",
    "    country_holidays = holidays.CountryHoliday(country, years = date.year)\n",
    "    return int(date in country_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "626cdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['isHoliday'] = df_train.apply(lambda x: isHoliday(x['country'], x['date'].date()), axis = 1)\n",
    "# df_test['isHoliday'] = df_test.apply(lambda x: isHoliday(x['country'], x['date'].date()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c215e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norway_2018 = holidays.CountryHoliday('Norway', years=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b88383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norway_2018.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb9373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in native Prophet API, holidays must be a DataFrame with \"ds\" and \"holiday\" columns.\n",
    "# holidays_train = pd.DataFrame({\n",
    "#     'ds': df_train['date'],\n",
    "#     'holiday': df_train['isHoliday']\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b635da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id       date  country       store         product  num_sold\n",
      "26278   26278 2018-12-30   Sweden  KaggleRama      Kaggle Hat      2138\n",
      "26279   26279 2018-12-30   Sweden  KaggleRama  Kaggle Sticker       587\n",
      "26280   26280 2018-12-31  Finland  KaggleMart      Kaggle Mug       469\n",
      "26281   26281 2018-12-31  Finland  KaggleMart      Kaggle Hat       822\n",
      "26282   26282 2018-12-31  Finland  KaggleMart  Kaggle Sticker       238\n",
      "26283   26283 2018-12-31  Finland  KaggleRama      Kaggle Mug       831\n",
      "26284   26284 2018-12-31  Finland  KaggleRama      Kaggle Hat      1231\n",
      "26285   26285 2018-12-31  Finland  KaggleRama  Kaggle Sticker       360\n",
      "26286   26286 2018-12-31   Norway  KaggleMart      Kaggle Mug       728\n",
      "26287   26287 2018-12-31   Norway  KaggleMart      Kaggle Hat      1124\n",
      "26288   26288 2018-12-31   Norway  KaggleMart  Kaggle Sticker       351\n",
      "26289   26289 2018-12-31   Norway  KaggleRama      Kaggle Mug      1383\n",
      "26290   26290 2018-12-31   Norway  KaggleRama      Kaggle Hat      2128\n",
      "26291   26291 2018-12-31   Norway  KaggleRama  Kaggle Sticker       561\n",
      "26292   26292 2018-12-31   Sweden  KaggleMart      Kaggle Mug       570\n",
      "26293   26293 2018-12-31   Sweden  KaggleMart      Kaggle Hat       823\n",
      "26294   26294 2018-12-31   Sweden  KaggleMart  Kaggle Sticker       250\n",
      "26295   26295 2018-12-31   Sweden  KaggleRama      Kaggle Mug      1004\n",
      "26296   26296 2018-12-31   Sweden  KaggleRama      Kaggle Hat      1441\n",
      "26297   26297 2018-12-31   Sweden  KaggleRama  Kaggle Sticker       388"
     ]
    }
   ],
   "source": [
    "df_train.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f5f73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'general_random_state': SEED,\n",
    "    'model_goal': 'forecasting', # or 'residual', in boosted hybrids\n",
    "#     'cross_validation_type': 'holdout',\n",
    "#     'validation_set_size': 0.25,\n",
    "}\n",
    "\n",
    "# following are only applicable for residual models in time series context\n",
    "# folds = 5\n",
    "# training_params['cross_val_strategy'] = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6069cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will add kwargs later\n",
    "model_params = {\n",
    "    'architecture': 'NeuralProphet',\n",
    "    'library': 'neuralprophet',\n",
    "    'hyperparams': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d72c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['baseline', 'forecasting', 'neuralprophet'],\n",
    "    'notes': \"Baseline run for Neural Prophet via native API as forecaster, following @gunesevitan's notebook.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b9526d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    ('2015-01-01', '2018-01-01'),\n",
    "    ('2018-01-01', '2019-01-01'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd1b9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "#     'holidays':holidays_train, # will add this in-function\n",
    "    'n_changepoints':10,\n",
    "    'changepoint_range':0.4,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_prior_scale':25,\n",
    "    'holidays_prior_scale':100,\n",
    "    'changepoint_prior_scale':0.01,\n",
    "    'interval_width':0.5,\n",
    "    'uncertainty_samples':False\n",
    "}\n",
    "\n",
    "neuralprophet_kwargs = {\n",
    "    'growth':'linear',\n",
    "    'n_changepoints':10,\n",
    "    'changepoints_range':0.4,\n",
    "    'trend_reg':1,\n",
    "    'trend_reg_threshold':False,\n",
    "    'yearly_seasonality':True,\n",
    "    'weekly_seasonality':True,\n",
    "    'daily_seasonality':False,\n",
    "    'seasonality_mode':'additive',\n",
    "    'seasonality_reg':1,\n",
    "    'n_forecasts':365,\n",
    "    'normalize':'off'\n",
    "}\n",
    "\n",
    "model_params['hyperparams'] = str(neuralprophet_kwargs)\n",
    "model_params['holiday_source'] = 'Prophet builtin for each country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36007eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- alter as needed later\n",
    "exmodel_config = {\n",
    "    **dataset_params,\n",
    "    **training_params,\n",
    "    **model_params \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aeaff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id       date  country       store         product  num_sold\n",
      "0           0 2015-01-01  Finland  KaggleMart      Kaggle Mug       329\n",
      "1           1 2015-01-01  Finland  KaggleMart      Kaggle Hat       520\n",
      "2           2 2015-01-01  Finland  KaggleMart  Kaggle Sticker       146\n",
      "3           3 2015-01-01  Finland  KaggleRama      Kaggle Mug       572\n",
      "4           4 2015-01-01  Finland  KaggleRama      Kaggle Hat       911\n",
      "...       ...        ...      ...         ...             ...       ...\n",
      "26293   26293 2018-12-31   Sweden  KaggleMart      Kaggle Hat       823\n",
      "26294   26294 2018-12-31   Sweden  KaggleMart  Kaggle Sticker       250\n",
      "26295   26295 2018-12-31   Sweden  KaggleRama      Kaggle Mug      1004\n",
      "26296   26296 2018-12-31   Sweden  KaggleRama      Kaggle Hat      1441\n",
      "26297   26297 2018-12-31   Sweden  KaggleRama  Kaggle Sticker       388\n",
      "\n",
      "[26298 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dbc4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet(**neuralprophet_kwargs)\n",
    "model.add_country_holidays(country_name=country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49667b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet(**neuralprophet_kwargs)\n",
    "model.add_country_holidays(country_name='finland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03002996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet(**neuralprophet_kwargs)\n",
    "model = model.add_country_holidays(country_name='finland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4104fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet(**neuralprophet_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "349385b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.add_country_holidays(country_name='finland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a757846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.add_country_holidays(country_name='Finland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa1e546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<neuralprophet.forecaster.NeuralProphet at 0x7f008beee430>"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17870002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b35015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df_train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1860356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.rename(columns={'date': 'ds', 'num_sold': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8aba9bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id         ds  country       store         product     y\n",
      "0           0 2015-01-01  Finland  KaggleMart      Kaggle Mug   329\n",
      "1           1 2015-01-01  Finland  KaggleMart      Kaggle Hat   520\n",
      "2           2 2015-01-01  Finland  KaggleMart  Kaggle Sticker   146\n",
      "3           3 2015-01-01  Finland  KaggleRama      Kaggle Mug   572\n",
      "4           4 2015-01-01  Finland  KaggleRama      Kaggle Hat   911\n",
      "...       ...        ...      ...         ...             ...   ...\n",
      "26293   26293 2018-12-31   Sweden  KaggleMart      Kaggle Hat   823\n",
      "26294   26294 2018-12-31   Sweden  KaggleMart  Kaggle Sticker   250\n",
      "26295   26295 2018-12-31   Sweden  KaggleRama      Kaggle Mug  1004\n",
      "26296   26296 2018-12-31   Sweden  KaggleRama      Kaggle Hat  1441\n",
      "26297   26297 2018-12-31   Sweden  KaggleRama  Kaggle Sticker   388\n",
      "\n",
      "[26298 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f03ec318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac923d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "country, store, product = 'Finland', 'KaggleRama', 'Kaggle Mug'\n",
    "train_idx = (df_train['country'] == country) &\\\n",
    "            (df_train['store'] == store) &\\\n",
    "            (df_train['product'] == product)\n",
    "\n",
    "train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49f1a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ds     y\n",
      "0    2015-01-01   572\n",
      "1    2015-01-02   544\n",
      "2    2015-01-03   579\n",
      "3    2015-01-04   582\n",
      "4    2015-01-05   423\n",
      "...         ...   ...\n",
      "1456 2018-12-27   652\n",
      "1457 2018-12-28   895\n",
      "1458 2018-12-29  1398\n",
      "1459 2018-12-30  1241\n",
      "1460 2018-12-31   831\n",
      "\n",
      "[1461 rows x 2 columns]"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e44e4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SmoothL1Loss         MAE        RMSE   RegLoss\n",
      "0      351.387625  351.887628  363.100771  0.000000\n",
      "1      343.869949  344.369951  355.944993  0.000000\n",
      "2      334.414336  334.914334  346.301075  0.000000\n",
      "3      321.596716  322.096714  333.332584  0.000000\n",
      "4      304.170013  304.670015  316.462346  0.000000\n",
      "..            ...         ...         ...       ...\n",
      "159     25.333783   25.825522   50.915792  0.533805\n",
      "160     25.329484   25.820796   50.420712  0.535413\n",
      "161     25.328154   25.819373   51.387434  0.536585\n",
      "162     25.325885   25.817041   49.360127  0.537391\n",
      "163     25.325257   25.816413   50.275099  0.537793\n",
      "\n",
      "[164 rows x 4 columns]"
     ]
    }
   ],
   "source": [
    "model.fit(train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e819f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country, store, product = 'Finland', 'KaggleRama', 'Kaggle Mug'\n",
    "store, product = 'KaggleRama', 'Kaggle Mug'\n",
    "for country in ['Sweden', 'Finland']:\n",
    "    \n",
    "    train_idx = (df_train['country'] == country) &\\\n",
    "                (df_train['store'] == store) &\\\n",
    "                (df_train['product'] == product)\n",
    "\n",
    "    train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "    train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "    \n",
    "    model = NeuralProphet(**neuralprophet_kwargs)\n",
    "    model = model.add_country_holidays(country_name=country)\n",
    "    model.fit(train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93e7f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=folds, \n",
    "            df_train=df_train, df_test=df_test, wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test_predictions = model.predict(test[['ds']])['yhat']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train, df_test, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bb26e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_prophet, df_test_prophet = exdarts_trainer(model)\n",
    "# df_train_prophet, df_test_prophet, train_smape_prophet, val_smape_prophet = prophet_trainer(wandb_tracked=True)\n",
    "df_train_preds, df_test_preds, train_smape, val_smape = trainer(model_kwargs=neuralprophet_kwargs, wandb_tracked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4201c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=folds, \n",
    "            df_train=df_train, df_test=df_test, wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test_predictions = model.predict(test)['yhat']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train, df_test, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2d97067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_prophet, df_test_prophet = exdarts_trainer(model)\n",
    "# df_train_prophet, df_test_prophet, train_smape_prophet, val_smape_prophet = prophet_trainer(wandb_tracked=True)\n",
    "df_train_preds, df_test_preds, train_smape, val_smape = trainer(model_kwargs=neuralprophet_kwargs, wandb_tracked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3892b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      row_id       date  country       store         product\n",
      "0      26298 2019-01-01  Finland  KaggleMart      Kaggle Mug\n",
      "1      26299 2019-01-01  Finland  KaggleMart      Kaggle Hat\n",
      "2      26300 2019-01-01  Finland  KaggleMart  Kaggle Sticker\n",
      "3      26301 2019-01-01  Finland  KaggleRama      Kaggle Mug\n",
      "4      26302 2019-01-01  Finland  KaggleRama      Kaggle Hat\n",
      "...      ...        ...      ...         ...             ...\n",
      "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat\n",
      "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker\n",
      "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug\n",
      "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat\n",
      "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker\n",
      "\n",
      "[6570 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0513b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=folds, \n",
    "            df_train=df_train, df_test=df_test, wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test_predictions = model.predict(test)['yhat1']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train, df_test, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16e7760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2552k1qc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 87758... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3217c4e52f7347a3960d8712033ae762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>('Sweden', 'KaggleMart', 'Kaggle Mug')_valid_smape</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>('Sweden', 'KaggleMart', 'Kaggle Mug')_valid_smape</td><td>6.37445</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">nb_20220110_112051</strong>: <a href=\"https://wandb.ai/hushifang/202201_Kaggle_tabular_playground/runs/2552k1qc\" target=\"_blank\">https://wandb.ai/hushifang/202201_Kaggle_tabular_playground/runs/2552k1qc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220110_114643-2552k1qc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2552k1qc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202201_Kaggle_tabular_playground/runs/fkdbo3nh\" target=\"_blank\">nb_20220110_112051</a></strong> to <a href=\"https://wandb.ai/hushifang/202201_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba69436ffe24488c8069d4d30a5283c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb80991192c4148a86feaf260ce392d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7426d2b6ad8846308fb1c47a49e049b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_train_prophet, df_test_prophet = exdarts_trainer(model)\n",
    "# df_train_prophet, df_test_prophet, train_smape_prophet, val_smape_prophet = prophet_trainer(wandb_tracked=True)\n",
    "df_train_preds, df_test_preds, train_smape, val_smape = trainer(model_kwargs=neuralprophet_kwargs, wandb_tracked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0857d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "test = test.rename(columns={'date': 'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f65c500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country, store, product = 'Finland','KaggleRama','Kaggle Mug'\n",
    "\n",
    "test_idx = (df_test['country'] == country) &\\\n",
    "           (df_test['store'] == store) &\\\n",
    "           (df_test['product'] == product)\n",
    "\n",
    "test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "test = test.rename(columns={'date': 'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60348473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds\n",
      "0   2019-01-01\n",
      "1   2019-01-02\n",
      "2   2019-01-03\n",
      "3   2019-01-04\n",
      "4   2019-01-05\n",
      "..         ...\n",
      "360 2019-12-27\n",
      "361 2019-12-28\n",
      "362 2019-12-29\n",
      "363 2019-12-30\n",
      "364 2019-12-31\n",
      "\n",
      "[365 rows x 1 columns]"
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f2d5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "country, store, product = 'Finland','KaggleRama','Kaggle Mug'\n",
    "\n",
    "\n",
    "train_idx = (df_train['country'] == country) &\\\n",
    "            (df_train['store'] == store) &\\\n",
    "            (df_train['product'] == product)\n",
    "\n",
    "# redefine the training set in the local (holdout) sense\n",
    "train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "# rename the columns for standardization (this seems conventional)\n",
    "train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "model.fit(train, freq='D') # neuralprophet\n",
    "train_predictions = model.predict(train)['yhat1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7223f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff4c591312432d8c77c2a9dcf9c302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2342d7ac01c64174ac65be4990e5ab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194f66f911cb4c039ba16d662361f7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "country, store, product = 'Finland','KaggleRama','Kaggle Mug'\n",
    "\n",
    "\n",
    "train_idx = (df_train['country'] == country) &\\\n",
    "            (df_train['store'] == store) &\\\n",
    "            (df_train['product'] == product)\n",
    "\n",
    "# redefine the training set in the local (holdout) sense\n",
    "train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "# rename the columns for standardization (this seems conventional)\n",
    "train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "model = NeuralProphet(**neuralprophet_kwargs)\n",
    "\n",
    "model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "model.fit(train, freq='D') # neuralprophet\n",
    "preds = model.predict(train)\n",
    "# train_predictions = model.predict(train)['yhat1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6d1e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ds     y       yhat1   residual1       trend  season_yearly  \\\n",
      "0    2015-01-01   572  572.008484    0.008484  289.030365      83.774315   \n",
      "1    2015-01-02   544  363.212463 -180.787537  289.086853      84.421844   \n",
      "2    2015-01-03   579  426.405579 -152.594421  289.143372      84.905701   \n",
      "3    2015-01-04   582  427.496857 -154.503143  289.199860      85.223648   \n",
      "4    2015-01-05   423  351.151917  -71.848083  289.256348      85.374649   \n",
      "...         ...   ...         ...         ...         ...            ...   \n",
      "1456 2018-12-27   652  452.827393 -199.172607  397.604401      78.235565   \n",
      "1457 2018-12-28   895  467.013397 -427.986603  397.679443      79.630188   \n",
      "1458 2018-12-29  1398  530.999329 -867.000671  397.754456      80.888367   \n",
      "1459 2018-12-30  1241  532.905396 -708.094604  397.829468      82.002609   \n",
      "1460 2018-12-31   831  457.391846 -373.608154  397.904480      82.966431   \n",
      "\n",
      "      season_weekly  events_additive  event_2. pääsiäispäivä  \\\n",
      "0        -23.012571       222.216385                     0.0   \n",
      "1        -10.296243         0.000000                     0.0   \n",
      "2         52.356510         0.000000                     0.0   \n",
      "3         53.073353         0.000000                     0.0   \n",
      "4        -23.479082         0.000000                     0.0   \n",
      "...             ...              ...                     ...   \n",
      "1456     -23.012571         0.000000                     0.0   \n",
      "1457     -10.296243         0.000000                     0.0   \n",
      "1458      52.356510         0.000000                     0.0   \n",
      "1459      53.073353         0.000000                     0.0   \n",
      "1460     -23.479082         0.000000                     0.0   \n",
      "\n",
      "      event_Helatorstai  ...  event_Joulupäivä  event_Juhannusaatto  \\\n",
      "0                   0.0  ...               0.0                  0.0   \n",
      "1                   0.0  ...               0.0                  0.0   \n",
      "2                   0.0  ...               0.0                  0.0   \n",
      "3                   0.0  ...               0.0                  0.0   \n",
      "4                   0.0  ...               0.0                  0.0   \n",
      "...                 ...  ...               ...                  ...   \n",
      "1456                0.0  ...               0.0                  0.0   \n",
      "1457                0.0  ...               0.0                  0.0   \n",
      "1458                0.0  ...               0.0                  0.0   \n",
      "1459                0.0  ...               0.0                  0.0   \n",
      "1460                0.0  ...               0.0                  0.0   \n",
      "\n",
      "      event_Juhannuspäivä  event_Loppiainen  event_Pitkäperjantai  \\\n",
      "0                     0.0               0.0                   0.0   \n",
      "1                     0.0               0.0                   0.0   \n",
      "2                     0.0               0.0                   0.0   \n",
      "3                     0.0               0.0                   0.0   \n",
      "4                     0.0               0.0                   0.0   \n",
      "...                   ...               ...                   ...   \n",
      "1456                  0.0               0.0                   0.0   \n",
      "1457                  0.0               0.0                   0.0   \n",
      "1458                  0.0               0.0                   0.0   \n",
      "1459                  0.0               0.0                   0.0   \n",
      "1460                  0.0               0.0                   0.0   \n",
      "\n",
      "      event_Pyhäinpäivä  event_Pääsiäispäivä  event_Tapaninpäivä  \\\n",
      "0                   0.0                  0.0                 0.0   \n",
      "1                   0.0                  0.0                 0.0   \n",
      "2                   0.0                  0.0                 0.0   \n",
      "3                   0.0                  0.0                 0.0   \n",
      "4                   0.0                  0.0                 0.0   \n",
      "...                 ...                  ...                 ...   \n",
      "1456                0.0                  0.0                 0.0   \n",
      "1457                0.0                  0.0                 0.0   \n",
      "1458                0.0                  0.0                 0.0   \n",
      "1459                0.0                  0.0                 0.0   \n",
      "1460                0.0                  0.0                 0.0   \n",
      "\n",
      "      event_Uudenvuodenpäivä  event_Vappu  \n",
      "0                 222.216385          0.0  \n",
      "1                   0.000000          0.0  \n",
      "2                   0.000000          0.0  \n",
      "3                   0.000000          0.0  \n",
      "4                   0.000000          0.0  \n",
      "...                      ...          ...  \n",
      "1456                0.000000          0.0  \n",
      "1457                0.000000          0.0  \n",
      "1458                0.000000          0.0  \n",
      "1459                0.000000          0.0  \n",
      "1460                0.000000          0.0  \n",
      "\n",
      "[1461 rows x 23 columns]"
     ]
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c21238f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = (df_test['country'] == country) &\\\n",
    "           (df_test['store'] == store) &\\\n",
    "           (df_test['product'] == product)\n",
    "\n",
    "test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "test = test.rename(columns={'date': 'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f62281ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1de6f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['y'] = np.nan\n",
    "test_preds = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b7aa26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds   y       yhat1  residual1       trend  season_yearly  \\\n",
      "0   2019-01-01 NaN  680.735229        NaN  397.979523      83.774315   \n",
      "1   2019-01-02 NaN  457.069427        NaN  398.054535      84.421844   \n",
      "2   2019-01-03 NaN  460.022675        NaN  398.129547      84.905701   \n",
      "3   2019-01-04 NaN  473.131958        NaN  398.204559      85.223648   \n",
      "4   2019-01-05 NaN  536.010742        NaN  398.279602      85.374649   \n",
      "..         ...  ..         ...        ...         ...            ...   \n",
      "360 2019-12-27 NaN  492.557190        NaN  424.986908      77.866539   \n",
      "361 2019-12-28 NaN  556.712463        NaN  425.061920      79.294014   \n",
      "362 2019-12-29 NaN  558.797363        NaN  425.136963      80.587036   \n",
      "363 2019-12-30 NaN  483.470825        NaN  425.211975      81.737923   \n",
      "364 2019-12-31 NaN  484.791870        NaN  425.286987      82.739899   \n",
      "\n",
      "     season_weekly  events_additive  event_2. pääsiäispäivä  \\\n",
      "0       -23.235020       222.216385                     0.0   \n",
      "1       -25.406948         0.000000                     0.0   \n",
      "2       -23.012571         0.000000                     0.0   \n",
      "3       -10.296243         0.000000                     0.0   \n",
      "4        52.356510         0.000000                     0.0   \n",
      "..             ...              ...                     ...   \n",
      "360     -10.296243         0.000000                     0.0   \n",
      "361      52.356510         0.000000                     0.0   \n",
      "362      53.073353         0.000000                     0.0   \n",
      "363     -23.479082         0.000000                     0.0   \n",
      "364     -23.235020         0.000000                     0.0   \n",
      "\n",
      "     event_Helatorstai  ...  event_Joulupäivä  event_Juhannusaatto  \\\n",
      "0                  0.0  ...               0.0                  0.0   \n",
      "1                  0.0  ...               0.0                  0.0   \n",
      "2                  0.0  ...               0.0                  0.0   \n",
      "3                  0.0  ...               0.0                  0.0   \n",
      "4                  0.0  ...               0.0                  0.0   \n",
      "..                 ...  ...               ...                  ...   \n",
      "360                0.0  ...               0.0                  0.0   \n",
      "361                0.0  ...               0.0                  0.0   \n",
      "362                0.0  ...               0.0                  0.0   \n",
      "363                0.0  ...               0.0                  0.0   \n",
      "364                0.0  ...               0.0                  0.0   \n",
      "\n",
      "     event_Juhannuspäivä  event_Loppiainen  event_Pitkäperjantai  \\\n",
      "0                    0.0               0.0                   0.0   \n",
      "1                    0.0               0.0                   0.0   \n",
      "2                    0.0               0.0                   0.0   \n",
      "3                    0.0               0.0                   0.0   \n",
      "4                    0.0               0.0                   0.0   \n",
      "..                   ...               ...                   ...   \n",
      "360                  0.0               0.0                   0.0   \n",
      "361                  0.0               0.0                   0.0   \n",
      "362                  0.0               0.0                   0.0   \n",
      "363                  0.0               0.0                   0.0   \n",
      "364                  0.0               0.0                   0.0   \n",
      "\n",
      "     event_Pyhäinpäivä  event_Pääsiäispäivä  event_Tapaninpäivä  \\\n",
      "0                  0.0                  0.0                 0.0   \n",
      "1                  0.0                  0.0                 0.0   \n",
      "2                  0.0                  0.0                 0.0   \n",
      "3                  0.0                  0.0                 0.0   \n",
      "4                  0.0                  0.0                 0.0   \n",
      "..                 ...                  ...                 ...   \n",
      "360                0.0                  0.0                 0.0   \n",
      "361                0.0                  0.0                 0.0   \n",
      "362                0.0                  0.0                 0.0   \n",
      "363                0.0                  0.0                 0.0   \n",
      "364                0.0                  0.0                 0.0   \n",
      "\n",
      "     event_Uudenvuodenpäivä  event_Vappu  \n",
      "0                222.216385          0.0  \n",
      "1                  0.000000          0.0  \n",
      "2                  0.000000          0.0  \n",
      "3                  0.000000          0.0  \n",
      "4                  0.000000          0.0  \n",
      "..                      ...          ...  \n",
      "360                0.000000          0.0  \n",
      "361                0.000000          0.0  \n",
      "362                0.000000          0.0  \n",
      "363                0.000000          0.0  \n",
      "364                0.000000          0.0  \n",
      "\n",
      "[365 rows x 23 columns]"
     ]
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f4afb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_kwargs=neuralprophet_kwargs, countries=countries, stores=stores, products=products, folds=folds, \n",
    "            df_train=df_train, df_test=df_test, wandb_tracked=False):\n",
    "    train_smape = 0\n",
    "    val_smape = 0\n",
    "    \n",
    "    if wandb_tracked:\n",
    "#         exmodel_config['arch'] = arch\n",
    "#         exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202201_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )\n",
    "    \n",
    "    for country in countries:\n",
    "        for store in stores:\n",
    "            for product in products:\n",
    "                for fold, (start, end) in enumerate(folds):\n",
    "                    # Skip iteration if it's the last fold\n",
    "                    if fold == len(folds) - 1:\n",
    "                        continue\n",
    "\n",
    "                    # put only those rows in that are in the training window and have the correct country, store, and product\n",
    "                    train_idx = (df_train['date'] >= start) &\\\n",
    "                                (df_train['date'] < end) &\\\n",
    "                                (df_train['country'] == country) &\\\n",
    "                                (df_train['store'] == store) &\\\n",
    "                                (df_train['product'] == product)\n",
    "\n",
    "                    # redefine the training set in the local (holdout) sense\n",
    "                    train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n",
    "                              (df_train['date'] < folds[fold + 1][1]) &\\\n",
    "                              (df_train['country'] == country) &\\\n",
    "                              (df_train['store'] == store) &\\\n",
    "                              (df_train['product'] == product)\n",
    "\n",
    "                    val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n",
    "\n",
    "                    # rename the columns for standardization (this seems conventional)\n",
    "                    train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "                    val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n",
    "\n",
    "#                     model = Prophet(**prophet_kwargs)\n",
    "                    model = NeuralProphet(**model_kwargs)\n",
    "\n",
    "                    model = model.add_country_holidays(country_name=country) # uses FacebookProphet or NeuralProphet API to add holidays\n",
    "                    print(train.columns)\n",
    "                    model.fit(train, freq='D') # neuralprophet\n",
    "                    # prophet\n",
    "#                     train_predictions = model.predict(train[['ds']])['yhat']\n",
    "#                     val_predictions = model.predict(val[['ds']])['yhat']\n",
    "                    # neuralprophet\n",
    "                    train_predictions = model.predict(train)['yhat1']\n",
    "                    val_predictions = model.predict(val)['yhat1']\n",
    "                    df_train.loc[train_idx, 'prophet_forecast'] = train_predictions.values\n",
    "                    df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n",
    "\n",
    "                    train_score = SMAPE(train['y'].values, train_predictions.values)\n",
    "                    val_score = SMAPE(val['y'].values, val_predictions.values)\n",
    "            \n",
    "                    if wandb_tracked:\n",
    "                        wandb.log({f\"{(country,store,product)}_valid_smape\": val_score})\n",
    "            \n",
    "                    train_smape += train_score\n",
    "                    val_smape += val_score\n",
    "            \n",
    "                    print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n",
    "                    print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n",
    "\n",
    "                    test_idx = (df_test['country'] == country) &\\\n",
    "                               (df_test['store'] == store) &\\\n",
    "                               (df_test['product'] == product)\n",
    "                    test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n",
    "                    \n",
    "                    test = test.rename(columns={'date': 'ds'})\n",
    "                    test['y'] = np.nan\n",
    "                    test_predictions = model.predict(test)['yhat1']\n",
    "                    \n",
    "                    \n",
    "                    df_test.loc[test_idx, 'neuralprophet_forecast'] = test_predictions.values\n",
    "    \n",
    "    train_smape /= (3*2*3)\n",
    "    val_smape /= (3*2*3)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_train_smape': train_smape, 'overall_valid_smape': val_smape})\n",
    "        wandb.finish()\n",
    "    return df_train, df_test, train_smape, val_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "431eb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_prophet, df_test_prophet = exdarts_trainer(model)\n",
    "# df_train_prophet, df_test_prophet, train_smape_prophet, val_smape_prophet = prophet_trainer(wandb_tracked=True)\n",
    "df_train_preds, df_test_preds, train_smape, val_smape = trainer(model_kwargs=neuralprophet_kwargs, wandb_tracked=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
