{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# XGBoost 20210926 GPU sweep\n",
    "Trying after building GPU version locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_qtimPUchWD",
   "metadata": {
    "id": "U_qtimPUchWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {
    "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {
    "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb"
   },
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {
    "id": "16849bd2-428c-497b-ba3b-675002f8d041"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
    "outputId": "6bd53922-c4d7-43ce-c04f-ac1079087966"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
    "outputId": "5483656e-2943-4d97-b5d4-65cfb9795430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    # !pip install category_encoders\n",
    "    # !pip install catboost\n",
    "#     !pip install --upgrade -q lightgbm\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    # !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    # ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    # !pip install cmake --upgrade\n",
    "    # # !pip install sklearn --upgrade\n",
    "    # !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    # %cd /content/xgboost\n",
    "    # !mkdir build\n",
    "    # %cd build\n",
    "    # !cmake .. -DUSE_CUDA=ON\n",
    "    # !make -j4\n",
    "    # %cd /content/xgboost/python-package\n",
    "    # !python setup.py install --use-cuda --use-nccl\n",
    "    # !/opt/bin/nvidia-smi\n",
    "    # !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {
    "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd"
   },
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {
    "id": "a01e85f7-d602-4dde-bef9-611683cd74c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "# import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {
    "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe"
   },
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {
    "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351"
   },
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67530ca9-6317-48be-bf6c-8621158b0020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
    "outputId": "76d62b41-4171-40fa-936c-4481a9fdab36"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {
    "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {
    "id": "fbec2e77-2081-4815-ac6d-39f2a2616386"
   },
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f08480-1725-4520-8995-92b76b8f2cea",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "    'optuna_trials': 100,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for XGBoost on GPU with Optuna\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {
    "id": "a52d9012-34f1-435a-ba16-4416e0d4a286"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ca14-2718-49d9-89e2-91d55f72d706",
   "metadata": {
    "id": "c912a62f-970a-48b4-b428-d886f2612fc2"
   },
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6625d6-7561-48a2-acb0-6efb3c371005",
   "metadata": {
    "id": "7f6625d6-7561-48a2-acb0-6efb3c371005"
   },
   "outputs": [],
   "source": [
    "X_source = 'X_NaNcounts_SummaryStats_imputed-Median-wIndicators-StandardScaled.feather'\n",
    "X_train = pd.read_feather(datapath/X_source) \n",
    "y_train = load(datapath/'y.joblib')    \n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "X = np.array(X_train)#[:50000]\n",
    "y = np.array(y_train)#[:50000]\n",
    "\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8330d84d-3c72-4cca-b95a-739712014dd3",
   "metadata": {
    "id": "8330d84d-3c72-4cca-b95a-739712014dd3"
   },
   "outputs": [],
   "source": [
    "exmodel_config['feature_count'] = X.shape[1]\n",
    "exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "exmodel_config['instance_count'] = X.shape[0]\n",
    "exmodel_config['X_source'] = X_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {
    "id": "69ff4abf-560b-450e-a7a5-040878b66565"
   },
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "       \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 900, 6000), # was 900-4500 for CPU\n",
    "        'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 30),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "        'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "        'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 10),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.1, 30)\n",
    "    }  \n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "              })\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_xgboost_20210926.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sweep_xgboost_20210926_210045</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3gm90sry\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3gm90sry</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210926_210818-3gm90sry</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-26 21:08:39,589]\u001b[0m A new study created in memory with name: xgboost_20210926\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name='xgboost_20210926')\n",
    "\n",
    "# study = load(datapath/f'optuna_lightgbm_study_5trials_20210922.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "F1cSVFH9gkW_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/Software/xgboost/python-package/xgboost/sklearn.py:1212: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[33m[W 2021-09-26 21:09:14,938]\u001b[0m Trial 0 failed because of the following error: AttributeError('/home/sf/anaconda3/envs/tabular-gpu/lib/libxgboost.so: undefined symbol: XGDMatrixCreateFromDense')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sf/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-14-dd543109ae44>\", line 40, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/sklearn.py\", line 1219, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/sklearn.py\", line 284, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/sklearn.py\", line 1233, in <lambda>\n",
      "    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/core.py\", line 616, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/data.py\", line 698, in dispatch_data_backend\n",
      "    return _from_numpy_array(data, missing, threads, feature_names,\n",
      "  File \"/home/sf/Software/xgboost/python-package/xgboost/data.py\", line 179, in _from_numpy_array\n",
      "    _LIB.XGDMatrixCreateFromDense(\n",
      "  File \"/home/sf/anaconda3/envs/tabular-gpu/lib/python3.8/ctypes/__init__.py\", line 386, in __getattr__\n",
      "    func = self.__getitem__(name)\n",
      "  File \"/home/sf/anaconda3/envs/tabular-gpu/lib/python3.8/ctypes/__init__.py\", line 391, in __getitem__\n",
      "    func = self._FuncPtr((name_or_ordinal, self))\n",
      "AttributeError: /home/sf/anaconda3/envs/tabular-gpu/lib/libxgboost.so: undefined symbol: XGDMatrixCreateFromDense\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "/home/sf/anaconda3/envs/tabular-gpu/lib/libxgboost.so: undefined symbol: XGDMatrixCreateFromDense",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a80626ada418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_jobs = multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{x*5} trials complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'optuna_xgboost_study_{x*5}trials_20210926.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_xgboost_study_best-thru-{x*5}trials_20210922.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-dd543109ae44>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m     )    \n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, label_transform)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0mlabel_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         return _from_numpy_array(data, missing, threads, feature_names,\n\u001b[0m\u001b[1;32m    699\u001b[0m                                  feature_types)\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/xgboost/python-package/xgboost/data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     _check_call(\n\u001b[0;32m--> 179\u001b[0;31m         _LIB.XGDMatrixCreateFromDense(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0m_array_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-gpu/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FuncPtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: /home/sf/anaconda3/envs/tabular-gpu/lib/libxgboost.so: undefined symbol: XGDMatrixCreateFromDense"
     ]
    }
   ],
   "source": [
    "for x in range(1,21):\n",
    "    study.optimize(objective, n_trials = 5, callbacks = [wandbc]) #n_jobs = multiprocessing.cpu_count())\n",
    "    print(f\"{x*5} trials complete\")\n",
    "    dump(study, filename=datapath/f'optuna_xgboost_study_{x*5}trials_20210926.joblib')\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_xgboost_study_best-thru-{x*5}trials_20210922.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a746ff-c0e1-4218-8809-f102a58d2491",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "dump(study, filename=datapath/'optuna_xgboost_500trials-complete_20210926.joblib')\n",
    "dump(study.best_trial.params, filename=datapath/'optuna_xgboost_all-500trials-best_20210926.joblib')\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e398cb-f0f4-4400-8fe7-9012b4bc33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
