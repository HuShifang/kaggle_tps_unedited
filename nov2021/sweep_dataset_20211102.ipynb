{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing Sweep\n",
    "Trying to set up a new template for a notebook that will run a simple 5-fold cross-validation XGBoost model on a variety of dataset permutations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "COLAB = False\n",
    "USE_GPU = True\n",
    "libraries = ['xgboost', 'lightgbm', 'catboost', 'widedeep-SAINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d99557a-45cc-404f-9ade-862ae78bcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"dataset_sweep_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if COLAB:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "#     !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "#     !pip install category_encoders\n",
    "    \n",
    "    if 'catboost' in libraries:\n",
    "        !pip install catboost\n",
    "    \n",
    "    if 'xgboost' in libraries:\n",
    "        if USE_GPU: \n",
    "            # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "            !pip install cmake --upgrade\n",
    "            # !pip install sklearn --upgrade\n",
    "            !git clone --recursive https://github.com/dmlc/xgboost\n",
    "            %cd /content/xgboost\n",
    "            !mkdir build\n",
    "            %cd build\n",
    "            !cmake .. -DUSE_CUDA=ON\n",
    "            !make -j4\n",
    "            %cd /content/xgboost/python-package\n",
    "            !python setup.py install --use-cuda --use-nccl\n",
    "            !/opt/bin/nvidia-smi\n",
    "            !pip install shap\n",
    "        else:\n",
    "            !pip install --upgrade xgboost\n",
    "    if 'lightgbm' in libraries:\n",
    "        if USE_GPU:\n",
    "            # lighgbm gpu compatible\n",
    "            !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "            ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "        else:\n",
    "            !pip install --upgrade lightgbm\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler#, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "\n",
    "# from boruta import BorutaPy\n",
    "# from BorutaShap import BorutaShap\n",
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06d805c2-2c35-4a45-8f80-7ff819fb05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad41f0c-4a5c-470a-bda3-98152c30bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ca5f75-d4f8-43cd-b23a-46c87a4c9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the full training data set to get the feature correlations to target, for K-means clustering later\n",
    "df = pd.read_feather(datapath/'train.feather')\n",
    "# df_corr = df.corr() # getting the correlations of the features\n",
    "# corr_target = df_corr.loc['target':'target'] # pulling out just the correlation of features with the target, as a 1-row df (for Series, it'd be df_corr.loc['target'])\n",
    "corr_target = load(datapath/'feature_correlations_with_target.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4b3642-38c5-434f-b029-0023d5d33467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f34    0.135270\n",
       "f55    0.113889\n",
       "f43    0.109418\n",
       "f71    0.107687\n",
       "f80    0.106964\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812a21a9-ad34-40a2-9aa9-f06c1d68e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_target_x = corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "# corr_target_abs = abs(corr_target_x) # just interested in magnitudes here\n",
    "# corr_sorted = corr_target_abs.sort_values(by='target', axis=1, ascending=False) # df columns of useful values by correlation with target, will be modified later\n",
    "y = df.target # pulling out the dependent variable\n",
    "X = df.drop('target', axis=1) # isolating the independent variables\n",
    "del df # cleaning up memory\n",
    "# categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # there aren't any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a30a0-786e-4d24-8a48-aeaefecc3a10",
   "metadata": {},
   "source": [
    "## Parameters for Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f5ba3e-7883-4d96-9220-6dfc063a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 20211004, thru 106 trials on unaltered original dataset\n",
    "# params = {\n",
    "#     'n_estimators': 3878,\n",
    "#     'max_depth': 4,\n",
    "#     'learning_rate': 0.024785857161974977,\n",
    "#     'reg_alpha': 26.867682044658245,\n",
    "#     'reg_lambda': 10.839759074147148,\n",
    "#     'subsample': 0.8208581489835881,\n",
    "#     'min_child_weight': 8.829122644339664,\n",
    "#     'colsample_bytree': 0.906420714280384,\n",
    "#     'gamma': 1.472322916021486\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae642005-791f-4ba2-a529-501bd2e94c0d",
   "metadata": {},
   "source": [
    "# Feature Selection Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0c5eba-c314-47ae-8bbe-7da26af02276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = load(altdatapath/'X_boruta_200iter_filtered_green.joblib')\n",
    "# type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac21ce42-a882-4e2c-a8c4-c1b1438fcff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bdf = pd.DataFrame(b, index=X.index).join(y)\n",
    "# bdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b19679-1488-437e-9140-d300c83fcf24",
   "metadata": {},
   "source": [
    "(Following cells generate the correlations for the different feature selections, so that the process need not be repeated each iteration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7781d7-daf3-4376-9018-f5687687ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = load(altdatapath/'X_boruta_200iter_filtered_green.joblib')\n",
    "# bdf = pd.DataFrame(b, index=X.index).join(y)\n",
    "# bdf.head()\n",
    "# bdf_corr = bdf.corr()\n",
    "# bdf_corr_target = bdf_corr.loc['target':'target']\n",
    "# bdf_corr_target_x = bdf_corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "# bdf_corr_target_abs = abs(bdf_corr_target_x) # just interested in magnitudes here\n",
    "# bdf_corr_sorted = bdf_corr_target_abs.sort_values(by='target', axis=1, ascending=False)\n",
    "# dump(bdf_corr_sorted, altdatapath/'X_boruta_200iter_filtered_green_corr_sorted.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92e8b38-e735-4d16-9cef-c2fd52cdbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del b, bdf, bdf_corr_target, bdf_corr_target_x, bdf_corr_target_abs, bdf_corr_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108991f2-9ec7-4217-b1c0-936c848fc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = pd.read_feather(altdatapath/'X_boruta_shap_200trials.feather')\n",
    "# bdf = b.join(y)\n",
    "# # bdf.head()\n",
    "# bdf_corr = bdf.corr()\n",
    "# bdf_corr_target = bdf_corr.loc['target':'target']\n",
    "# bdf_corr_target_x = bdf_corr_target.drop('target', axis=1) # dropping the trivial 1.00 autocorrelation\n",
    "# bdf_corr_target_abs = abs(bdf_corr_target_x) # just interested in magnitudes here\n",
    "# bdf_corr_sorted = bdf_corr_target_abs.sort_values(by='target', axis=1, ascending=False)\n",
    "# dump(bdf_corr_sorted, altdatapath/'X_boruta_shap_200trials_corr_sorted.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e3dc59-21bb-49c5-9535-83ee0edb3506",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial, X=X, y=y): # categoricals=categoricals, corr_sorted=corr_sorted):\n",
    "\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "\n",
    "    # use the original 286-feature dataset, or the 136-feature BorutaShap selected one\n",
    "#     dataset = trial.suggest_categorical('dataset', ['X_orig.feather', 'X_boruta_shap_200trials.feather']) \n",
    "#     train_source = altdatapath/'X_orig.feather'\n",
    "    # train_source = altdatapath/'train-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' #'X_boruta_shap_200trials.feather'\n",
    "#     X = pd.read_feather(path=train_source)\n",
    "#     y = load(datapath/'y.joblib')\n",
    "    \n",
    "#     # decides whether binary-encoded categoricals are encoded or not\n",
    "#     cardinality_min = trial.suggest_categorical('cardinality_min', [0, 2]) \n",
    "    \n",
    "    # scaling\n",
    "    scaler_type = trial.suggest_categorical('scaler', [StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler])\n",
    "                                       \n",
    "    # ------------------\n",
    "    \n",
    "#     # encoding\n",
    "#     encoder_name = trial.suggest_categorical('encoder_name', ['woe', 'catboost', 'james-stein', 'loo', 'mestimate', 'target', 'hashing', None])\n",
    "#     if encoder_name:\n",
    "#         encode_before_kmeans = trial.suggest_categorical('encode_before_kmeans', [True, False]) # determines order\n",
    "    \n",
    "#     # define dict of encoders, with names as keys and implementations as values\n",
    "#     encoders = {\n",
    "#         'woe': ce.WOEEncoder(cols=categoricals),\n",
    "#         'catboost': ce.CatBoostEncoder(cols=categoricals),\n",
    "#         'james-stein': ce.JamesSteinEncoder(cols=categoricals),\n",
    "#         'loo': ce.LeaveOneOutEncoder(cols=categoricals),\n",
    "#         'mestimate': ce.MEstimateEncoder(cols=categoricals),\n",
    "#         'target': ce.TargetEncoder(cols=categoricals),\n",
    "#         'hashing': ce.HashingEncoder(cols=categoricals),\n",
    "#     }\n",
    "    \n",
    "#     # ----------------\n",
    "    \n",
    "#     # feature selection setup -- applied before preprocessing\n",
    "#     feature_selection = trial.suggest_categorical('feature_selection', ['BorutaShap', 'Boruta', None])\n",
    "#     k_means_method = trial.suggest_categorical('k_means_method', [25, 50, 100, 'k-means++', None]) # K-Means initialization method\n",
    "    \n",
    "#     # now, switch datasets if feature selection is implemented; regardless, prepare appropriate K-Means setup (to be implemented later, in folds)\n",
    "#     if feature_selection: # create a subset of features if appropriate\n",
    "#         if feature_selection == 'BorutaShap':\n",
    "#             X = pd.read_feather(altdatapath/'X_boruta_shap_200trials.feather') # :: pd.DataFrame\n",
    "#             categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # not touching already binary encoded vars\n",
    "#             # k-means cluster feature generation setup \n",
    "#             if k_means_method:\n",
    "#                 corr_sorted = load(altdatapath/'X_boruta_shap_200trials_corr_sorted.joblib') # load prepared correlations\n",
    "#                 k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "#                 useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "#         elif feature_selection == 'Boruta':\n",
    "#             X = pd.DataFrame(load(altdatapath/'X_boruta_200iter_filtered_green.joblib'), index=X.index)\n",
    "#             if k_means_method:\n",
    "#                 corr_sorted = load(altdatapath/'X_boruta_200iter_filtered_green_corr_sorted.joblib') # load prepared correlations\n",
    "#                 k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "#                 useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "#             categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9 and X[f].nunique() > 2] # not touching already binary encoded vars\n",
    "#     else:\n",
    "#         if k_means_method:\n",
    "#             k_means_clusters = trial.suggest_int('k_means_clusters', 6, 12) # for grabbing the most useful features from `corr_sorted`\n",
    "#             useful_features = list(corr_sorted.columns[:k_means_clusters])\n",
    "    \n",
    "#     # -------------------------\n",
    "    \n",
    "#     # PCA dimensionality reduction setup -- applied at end of preprocessing\n",
    "#     pca_components = trial.suggest_categorical('pca_components', [50, 75, 'mle', None, 'NO'])\n",
    "    \n",
    "    # define k-fold splitter\n",
    "    kfold = KFold(n_splits=5, shuffle=False)\n",
    "        \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "            \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        print(f\"FOLD {fold}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "        \n",
    "        y_train, y_valid = y[train_ids], y[valid_ids] # slicing syntax works on both pandas.Series and numpy.ndarray\n",
    "        # category_encoders expects pandas.DataFrames\n",
    "        X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for slicing\n",
    "        \n",
    "        \n",
    "        # now, apply preprocessing\n",
    "        scaler = scaler_type()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "    \n",
    "        \n",
    "#         if encoder_name: # if categorical encoding to be applied to high cardinality (2<x<100,000) categoricals...\n",
    "#             if k_means_method: # if k-means proceeding\n",
    "#                 if encode_before_kmeans: # do category encoding, then clustering\n",
    "#                     # category encoding for high-cardinality categoricals\n",
    "#                     encoder = encoders[encoder_name]\n",
    "#                     X_train = encoder.fit_transform(X_train, y_train)\n",
    "#                     X_valid = encoder.transform(X_valid)\n",
    "\n",
    "#                     # k-means cluster feature generation\n",
    "#                     cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "#                     if k_means_method == 'k-means++':\n",
    "#                         kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "#                     else:\n",
    "#                         kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "#                     # fit on the training set only\n",
    "#                     X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "#                     X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "#                     # convert numpy.ndarrays back to properly-labeled pandas.DataFrames\n",
    "#                     X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "#                     X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "#                     # join the cluster-distance features to the training and validation sets\n",
    "#                     X_train = X_train.join(X_train_clusters)\n",
    "#                     X_valid = X_valid.join(X_valid_clusters)\n",
    "\n",
    "#                 else: # do k-means clustering, then do category encoding\n",
    "#                     cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "#                     if k_means_method == 'k-means++':\n",
    "#                         kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "#                     else:\n",
    "#                         kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "#                     X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "#                     X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "#                     X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "#                     X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "#                     X_train = X_train.join(X_train_clusters)\n",
    "#                     X_valid = X_valid.join(X_valid_clusters)\n",
    "\n",
    "#                     encoder = encoders[encoder_name]\n",
    "#                     X_train = encoder.fit_transform(X_train, y_train)\n",
    "#                     X_valid = encoder.transform(X_valid)\n",
    "            \n",
    "#             else: # category encoding, but no k-means\n",
    "#                 encoder = encoders[encoder_name]\n",
    "#                 X_train = encoder.fit_transform(X_train, y_train)\n",
    "#                 X_valid = encoder.transform(X_valid)\n",
    "                \n",
    "#         else: # no category encoding\n",
    "#             if k_means_method: # if still doing k-means\n",
    "#                 # k-means cluster feature generation\n",
    "#                 cluster_cols = [f\"cluster{i+1}\" for i in range(k_means_clusters)]\n",
    "#                 if k_means_method == 'k-means++':\n",
    "#                     kmeans = KMeans(n_clusters=k_means_clusters, init=\"k-means++\", max_iter=1000, random_state=SEED,n_jobs=-1)\n",
    "#                 else:\n",
    "#                     kmeans = KMeans(n_clusters=k_means_clusters, n_init=k_means_method, max_iter=1000, random_state=SEED, n_jobs=-1)\n",
    "#                 # fit on the training set only\n",
    "#                 X_train_clusters = kmeans.fit_transform(X_train[useful_features])\n",
    "#                 X_valid_clusters = kmeans.transform(X_valid[useful_features])\n",
    "#                 # convert numpy.ndarrays back to properly-labeled pandas.DataFrames\n",
    "#                 X_train_clusters = pd.DataFrame(X_train_clusters, columns=cluster_cols, index=X_train.index)\n",
    "#                 X_valid_clusters = pd.DataFrame(X_valid_clusters, columns=cluster_cols, index=X_valid.index)\n",
    "#                 # join the cluster-distance features to the training and validation sets\n",
    "#                 X_train = X_train.join(X_train_clusters)\n",
    "#                 X_valid = X_valid.join(X_valid_clusters)\n",
    "            \n",
    "        \n",
    "#         # now, PCA dimensionality reduction\n",
    "#         if pca_components != 'NO':\n",
    "#             pca = PCA(n_components=pca_components, random_state=42)\n",
    "#             X_train = pca.fit_transform(X_train)\n",
    "#             X_valid = pca.transform(X_valid)\n",
    "            \n",
    "        # define models\n",
    "        model = XGBClassifier(\n",
    "            booster='gbtree',\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=42,\n",
    "            # n_jobs=-1, \n",
    "            verbosity=1, \n",
    "            objective='binary:logistic',\n",
    "            # **params\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "        # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "        oof_preds.extend(y_valid_preds)\n",
    "        oof_y.extend(y_valid)\n",
    "\n",
    "\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "#         dump(model, Path(runpath/f\"{library}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for is {model_valid_auc}\")\n",
    "    \n",
    "    return model_valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aac6b1dd-5c9d-4f95-985c-4250d78d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"arch\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for preprocessing techniques on dataset -- scaling only\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0ce509-11c3-4c1e-847b-89a50dc4ade7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "4e88b8c2-11ec-493d-8fdb-f97cd2f0243a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find dataset_sweep_20211102.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1nd6u34a\" target=\"_blank\">dataset_sweep_20211102_184239</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5124950-57e7-45e0-842a-a6eb01b2383d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "outputId": "05b7ce12-dc98-4d38-fd83-a0578ec37531",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-02 18:43:05,558]\u001b[0m A new study created in memory with name: dataset_20211102\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed=int(SEED)), study_name='dataset_20211102')\n",
    "# study = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ee181bd-8c5b-4468-bc76-22c5dacd7142",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXQWM6Otmxma",
    "outputId": "d4b74ae6-6552-4b2f-a4e0-d9999874ab06",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:43:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.7201557997326132\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:43:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.7216802468693998\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:43:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.718687907572845\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:43:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.7179025978449444\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.7114363503740138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-02 18:43:25,499]\u001b[0m Trial 0 finished with value: 0.7240968345002873 and parameters: {'scaler': <class 'sklearn.preprocessing._data.MinMaxScaler'>}. Best is trial 0 with value: 0.7240968345002873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7240968345002873\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:43:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.7204444230609365\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:43:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.721680558581767\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:43:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.7189166409394918\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:43:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.7181395378188599\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:43:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.7113361277030196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-02 18:43:41,301]\u001b[0m Trial 1 finished with value: 0.7242674437944308 and parameters: {'scaler': <class 'sklearn.preprocessing._data.RobustScaler'>}. Best is trial 1 with value: 0.7242674437944308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7242674437944308\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:43:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.7204444230609365\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:43:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.721680558581767\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:43:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.7189166409394918\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:43:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.7181395378188599\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:43:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.7113361277030196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-02 18:43:57,059]\u001b[0m Trial 2 finished with value: 0.7242674437944308 and parameters: {'scaler': <class 'sklearn.preprocessing._data.RobustScaler'>}. Best is trial 1 with value: 0.7242674437944308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7242674437944308\n",
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[18:43:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 0 is 0.7204444230609365\n",
      "FOLD 1\n",
      "---------------------------------------------------\n",
      "[18:44:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 1 is 0.721680558581767\n",
      "FOLD 2\n",
      "---------------------------------------------------\n",
      "[18:44:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 2 is 0.7189166409394918\n",
      "FOLD 3\n",
      "---------------------------------------------------\n",
      "[18:44:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 3 is 0.7181395378188599\n",
      "FOLD 4\n",
      "---------------------------------------------------\n",
      "[18:44:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Valid AUC for fold 4 is 0.7113361277030196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-02 18:44:08,896]\u001b[0m Trial 3 finished with value: 0.7242674437944308 and parameters: {'scaler': <class 'sklearn.preprocessing._data.StandardScaler'>}. Best is trial 1 with value: 0.7242674437944308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7242674437944308\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'studypath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-94dda027bb8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_jobs = multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudypath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'optuna-dataset_study-scaling_only-trial5_20211102.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'studypath' is not defined"
     ]
    }
   ],
   "source": [
    "for x in range(1, 5):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc]) #n_jobs = multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816db5fb-6525-4144-abfe-3ee3bced0a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/studies/optuna-dataset_study-scaling_only-trial5_20211102.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(study, filename=studypath/f'optuna-dataset_study-scaling_only-trial5_20211102.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35c0b945-2e29-48f0-9cf9-7de44f5b0afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': sklearn.preprocessing._data.RobustScaler}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf062650-04df-4d32-a443-9e5e9c198b93",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18267... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>value</td><td>▁███</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>scaler</td><td>sklearn.preprocessin...</td></tr><tr><td>value</td><td>0.72427</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dataset_sweep_20211102_184239</strong>: <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1nd6u34a\" target=\"_blank\">https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1nd6u34a</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211102_184239-1nd6u34a/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'best_dataset_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa0381-a9e3-483f-a9bc-b41ad6d04468",
   "metadata": {},
   "source": [
    "So, the best of the sweep was trial 6 with AUC of 0.8529520938646249, but the straight-up analysis without any bells and whistles gets 0.8566651115202035. \n",
    "\n",
    "Conclusion: best to forget about preprocessing. $\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
