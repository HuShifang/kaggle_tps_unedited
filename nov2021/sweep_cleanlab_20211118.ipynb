{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "Header for notebooks -- customize as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d84988-5ddb-40d9-bc12-826012acb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_cleanlab_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "# from BorutaShap import BorutaShap\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957d1322-cdac-411a-9754-9deb360cea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from torchmetrics import AUROC\n",
    "# import torch\n",
    "# from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55072fd2-dcc0-4169-a6f8-54d9b76ab432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880b9f33-b517-40ef-a3e6-049dcc52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9e0d-1301-4ade-a63d-9f3d298c2255",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba521a1a-8c41-4b9b-becd-36eb62739ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f63ee2-a167-4111-9b44-bf67c8240603",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad459104-e31a-4aa0-8a9a-bb279e2b9944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    # 'train_source': str(datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_orig.joblib'),\n",
    "    # 'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "# X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac6b1dd-5c9d-4f95-985c-4250d78d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    \"arch\": 'lightgbm',\n",
    "    \"type\": 'sweep',\n",
    "    \"denoising\": \"cleanlab\",\n",
    "    \"level\": 1,\n",
    "    'random_state': SEED,\n",
    "    'tuner': \"Optuna\",\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    'scaler': str(RobustScaler()),\n",
    "    **dataset_params\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for CleanLab hyperparams\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ff05f8-b823-4ed5-9afd-bfd5f5d1d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        #                     device_type='cpu',\n",
    "        #                     n_jobs=-1,\n",
    "        #                 eval_metric='auc',\n",
    "        device_type='gpu',\n",
    "        max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "        gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce68c312-9dcb-4b25-96f1-779eab6dabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X=X, y=y, model=lgb_model):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rp_params = {\n",
    "        'prune_method': trial.suggest_categorical('prune_method', ['prune_by_noise_rate', 'prune_by_class', 'both']),\n",
    "        'converge_latent_estimates': trial.suggest_categorical('converge_latent_estimates', [True, False]),\n",
    "        'pulearning': trial.suggest_categorical('pulearning', [0,1,None])\n",
    "    }\n",
    "    \n",
    "    \n",
    "    rp = LearningWithNoisyLabels(clf=lgb_model, **rp_params)\n",
    "    rp.fit(X_train, y_train)\n",
    "    preds = rp.predict_proba(X_valid)[:,1]\n",
    "    valid_auc = roc_auc_score(y_true=y_valid, y_score=preds)\n",
    "    print(f\"Valid AUC score for is {valid_auc}\")\n",
    "    return valid_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0ce509-11c3-4c1e-847b-89a50dc4ade7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "4e88b8c2-11ec-493d-8fdb-f97cd2f0243a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1aw8jgza\" target=\"_blank\">sweep_cleanlab_20211118_145932</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5124950-57e7-45e0-842a-a6eb01b2383d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "outputId": "05b7ce12-dc98-4d38-fd83-a0578ec37531",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 14:59:38,878]\u001b[0m A new study created in memory with name: cleanlab_20211118\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed=int(SEED)), study_name='cleanlab_20211118')\n",
    "# study = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee181bd-8c5b-4468-bc76-22c5dacd7142",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXQWM6Otmxma",
    "outputId": "d4b74ae6-6552-4b2f-a4e0-d9999874ab06",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 14:59:54,501]\u001b[0m Trial 0 finished with value: 0.7202770549886881 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True, 'pulearning': None}. Best is trial 0 with value: 0.7202770549886881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7202770549886881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:00:08,040]\u001b[0m Trial 1 finished with value: 0.7197124054723177 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True, 'pulearning': 0}. Best is trial 0 with value: 0.7202770549886881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7197124054723177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:00:22,779]\u001b[0m Trial 2 finished with value: 0.720419834660914 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 2 with value: 0.720419834660914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.720419834660914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:00:36,199]\u001b[0m Trial 3 finished with value: 0.7192350353289598 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False, 'pulearning': 1}. Best is trial 2 with value: 0.720419834660914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7192350353289598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:00:49,879]\u001b[0m Trial 4 finished with value: 0.724119967966238 and parameters: {'prune_method': 'both', 'converge_latent_estimates': True, 'pulearning': 1}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.724119967966238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:01:02,968]\u001b[0m Trial 5 finished with value: 0.7198632599410275 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True, 'pulearning': 0}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7198632599410275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:01:16,366]\u001b[0m Trial 6 finished with value: 0.7203339047455115 and parameters: {'prune_method': 'both', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7203339047455115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:01:29,047]\u001b[0m Trial 7 finished with value: 0.7193737491245816 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False, 'pulearning': 1}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7193737491245816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:01:42,447]\u001b[0m Trial 8 finished with value: 0.7196990737090969 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': True, 'pulearning': 0}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7196990737090969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:01:55,972]\u001b[0m Trial 9 finished with value: 0.7197984287411806 and parameters: {'prune_method': 'prune_by_class', 'converge_latent_estimates': False, 'pulearning': 1}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7197984287411806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:02:08,563]\u001b[0m Trial 10 finished with value: 0.7198927801944912 and parameters: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': True, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7198927801944912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:02:21,352]\u001b[0m Trial 11 finished with value: 0.7204227244506201 and parameters: {'prune_method': 'both', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7204227244506201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:02:34,089]\u001b[0m Trial 12 finished with value: 0.7201589725856447 and parameters: {'prune_method': 'both', 'converge_latent_estimates': True, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7201589725856447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:02:48,030]\u001b[0m Trial 13 finished with value: 0.7204413167924674 and parameters: {'prune_method': 'both', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7204413167924674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:03:00,956]\u001b[0m Trial 14 finished with value: 0.7200748074951835 and parameters: {'prune_method': 'both', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7200748074951835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:03:13,890]\u001b[0m Trial 15 finished with value: 0.7201925456573416 and parameters: {'prune_method': 'both', 'converge_latent_estimates': True, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7201925456573416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:03:26,526]\u001b[0m Trial 16 finished with value: 0.7201536703313662 and parameters: {'prune_method': 'prune_by_noise_rate', 'converge_latent_estimates': True, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7201536703313662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-18 15:03:39,327]\u001b[0m Trial 17 finished with value: 0.7202078992453572 and parameters: {'prune_method': 'both', 'converge_latent_estimates': False, 'pulearning': None}. Best is trial 4 with value: 0.724119967966238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid AUC score for is 0.7202078992453572\n"
     ]
    }
   ],
   "source": [
    "# for x in range(1, 250):\n",
    "#     study.optimize(objective, n_trials = 2, callbacks = [wandbc]) #n_jobs = multiprocessing.cpu_count())\n",
    "#     dump(study, filename=studypath/f'optuna-dataset_study-feature_reduction-20211108.joblib')\n",
    "\n",
    "study.optimize(objective, n_trials=18, callbacks=[wandbc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0886ba-b59f-47f7-a6c4-a0dedfad0280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23042... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>converge_latent_estimates</td><td>██▁▁██▁▁█▁█▁█▁▁██▁</td></tr><tr><td>pulearning</td><td>▁██▁█▁█</td></tr><tr><td>value</td><td>▂▂▃▁█▂▃▁▂▂▂▃▂▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>converge_latent_estimates</td><td>False</td></tr><tr><td>prune_method</td><td>both</td></tr><tr><td>value</td><td>0.72021</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sweep_cleanlab_20211118_145932</strong>: <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1aw8jgza\" target=\"_blank\">https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/1aw8jgza</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211118_145933-1aw8jgza/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17812159-24a7-4101-b56d-d212ae8f4507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prune_method': 'both', 'converge_latent_estimates': True, 'pulearning': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97af370d-0d61-4755-9db8-48eda2ef013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/studies/cleanlab_lgboost_20211118.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(study, Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/studies/cleanlab_lgboost_20211118.joblib')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
