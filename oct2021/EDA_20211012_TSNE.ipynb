{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# Dataset Sweep usign XGBoost on GPU\n",
    "Trying different variations on the dataset using PCA, other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_qtimPUchWD",
   "metadata": {
    "id": "U_qtimPUchWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {
    "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {
    "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb"
   },
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {
    "id": "16849bd2-428c-497b-ba3b-675002f8d041"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
    "outputId": "6bd53922-c4d7-43ce-c04f-ac1079087966"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
    "outputId": "5483656e-2943-4d97-b5d4-65cfb9795430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    # !pip install category_encoders\n",
    "    # !pip install catboost\n",
    "#     !pip install --upgrade -q lightgbm\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    # !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    # ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    # !pip install cmake --upgrade\n",
    "    # # !pip install sklearn --upgrade\n",
    "    # !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    # %cd /content/xgboost\n",
    "    # !mkdir build\n",
    "    # %cd build\n",
    "    # !cmake .. -DUSE_CUDA=ON\n",
    "    # !make -j4\n",
    "    # %cd /content/xgboost/python-package\n",
    "    # !python setup.py install --use-cuda --use-nccl\n",
    "    # !/opt/bin/nvidia-smi\n",
    "    # !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {
    "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd"
   },
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {
    "id": "a01e85f7-d602-4dde-bef9-611683cd74c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "# import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accfe297-1d47-41bd-9c84-a819d5e565f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {
    "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe"
   },
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {
    "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351"
   },
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67530ca9-6317-48be-bf6c-8621158b0020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
    "outputId": "76d62b41-4171-40fa-936c-4481a9fdab36"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "#     datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'optuna_studies'\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {
    "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {
    "id": "fbec2e77-2081-4815-ac6d-39f2a2616386"
   },
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f08480-1725-4520-8995-92b76b8f2cea",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for preprocessing techniques on dataset\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {
    "id": "a52d9012-34f1-435a-ba16-4416e0d4a286"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ca14-2718-49d9-89e2-91d55f72d706",
   "metadata": {
    "id": "c912a62f-970a-48b4-b428-d886f2612fc2"
   },
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6919aac1-15d6-4b41-9871-f547602a91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {
    "id": "69ff4abf-560b-450e-a7a5-040878b66565"
   },
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993947ab-fae6-4d7e-b73a-eb4e171ea61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 285)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cb1b5b-73c9-45d2-943a-5361328f07df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 285)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b055e2b-ebbb-4d36-b995-7a50d4adbc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f275</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178216</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>0.390170</td>\n",
       "      <td>0.324221</td>\n",
       "      <td>0.221722</td>\n",
       "      <td>0.738894</td>\n",
       "      <td>0.582588</td>\n",
       "      <td>0.343770</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.476455</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.283146</td>\n",
       "      <td>0.598020</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.283467</td>\n",
       "      <td>0.721575</td>\n",
       "      <td>0.268990</td>\n",
       "      <td>0.208373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159721</td>\n",
       "      <td>0.451202</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.365274</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.413502</td>\n",
       "      <td>0.249318</td>\n",
       "      <td>0.642339</td>\n",
       "      <td>0.411104</td>\n",
       "      <td>0.246891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182424</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.095344</td>\n",
       "      <td>0.327742</td>\n",
       "      <td>0.741830</td>\n",
       "      <td>0.358711</td>\n",
       "      <td>0.270077</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>0.297742</td>\n",
       "      <td>0.252829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229329</td>\n",
       "      <td>0.336513</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>0.300913</td>\n",
       "      <td>0.668738</td>\n",
       "      <td>0.481586</td>\n",
       "      <td>0.545660</td>\n",
       "      <td>0.667849</td>\n",
       "      <td>0.546045</td>\n",
       "      <td>0.202731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.178216  0.435617  0.010230  0.202074  0.390170  0.324221  0.221722   \n",
       "1  0.181250  0.476455  0.022413  0.283146  0.598020  0.349508  0.283467   \n",
       "2  0.159721  0.451202  0.259649  0.365274  0.594634  0.413502  0.249318   \n",
       "3  0.182424  0.520976  0.095344  0.327742  0.741830  0.358711  0.270077   \n",
       "4  0.229329  0.336513  0.023511  0.300913  0.668738  0.481586  0.545660   \n",
       "\n",
       "         f7        f8        f9  ...  f275  f276  f277  f278  f279  f280  \\\n",
       "0  0.738894  0.582588  0.343770  ...     1     0     0     0     0     0   \n",
       "1  0.721575  0.268990  0.208373  ...     0     0     0     0     0     0   \n",
       "2  0.642339  0.411104  0.246891  ...     0     0     0     0     0     0   \n",
       "3  0.601662  0.297742  0.252829  ...     0     0     0     0     0     1   \n",
       "4  0.667849  0.546045  0.202731  ...     0     0     0     0     1     0   \n",
       "\n",
       "   f281  f282  f283  f284  \n",
       "0     1     1     1     0  \n",
       "1     0     0     0     0  \n",
       "2     1     0     0     0  \n",
       "3     1     0     0     0  \n",
       "4     0     1     0     0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7e10c6-8474-46e3-884e-a91c021dc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=55, random_state=42)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7807dc43-8ff4-46f3-8f96-d852a7accd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a99fdac3-08a4-4132-8d13-ca89df68ca98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000000 samples in 0.037s...\n",
      "[t-SNE] Computed neighbors for 1000000 samples in 19480.483s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 28000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 29000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 30000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 31000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 32000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 33000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 34000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 35000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 36000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 37000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 38000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 39000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 40000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 41000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 42000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 43000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 44000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 45000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 46000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 47000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 48000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 49000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 50000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 51000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 52000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 53000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 54000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 55000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 56000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 57000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 58000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 59000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 60000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 61000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 62000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 63000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 64000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 65000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 66000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 67000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 68000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 69000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 70000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 71000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 72000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 73000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 74000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 75000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 76000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 77000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 78000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 79000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 80000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 81000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 82000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 83000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 84000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 85000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 86000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 87000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 88000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 89000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 90000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 91000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 92000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 93000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 94000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 95000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 96000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 97000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 98000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 99000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 100000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 101000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 102000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 103000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 104000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 105000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 106000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 107000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 108000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 109000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 110000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 111000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 112000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 113000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 114000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 115000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 116000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 117000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 118000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 119000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 120000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 121000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 122000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 123000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 124000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 125000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 126000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 127000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 128000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 129000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 130000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 131000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 132000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 133000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 134000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 135000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 136000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 137000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 138000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 139000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 140000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 141000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 142000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 143000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 144000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 145000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 146000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 147000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 148000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 149000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 150000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 151000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 152000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 153000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 154000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 155000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 156000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 157000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 158000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 159000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 160000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 161000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 162000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 163000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 164000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 165000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 166000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 167000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 168000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 169000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 170000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 171000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 172000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 173000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 174000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 175000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 176000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 177000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 178000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 179000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 180000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 181000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 182000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 183000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 184000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 185000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 186000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 187000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 188000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 189000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 190000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 191000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 192000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 193000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 194000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 195000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 196000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 197000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 198000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 199000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 200000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 201000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 202000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 203000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 204000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 205000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 206000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 207000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 208000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 209000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 210000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 211000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 212000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 213000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 214000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 215000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 216000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 217000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 218000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 219000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 220000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 221000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 222000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 223000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 224000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 225000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 226000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 227000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 228000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 229000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 230000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 231000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 232000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 233000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 234000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 235000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 236000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 237000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 238000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 239000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 240000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 241000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 242000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 243000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 244000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 245000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 246000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 247000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 248000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 249000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 250000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 251000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 252000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 253000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 254000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 255000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 256000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 257000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 258000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 259000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 260000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 261000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 262000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 263000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 264000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 265000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 266000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 267000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 268000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 269000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 270000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 271000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 272000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 273000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 274000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 275000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 276000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 277000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 278000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 279000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 280000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 281000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 282000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 283000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 284000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 285000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 286000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 287000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 288000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 289000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 290000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 291000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 292000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 293000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 294000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 295000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 296000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 297000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 298000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 299000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 300000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 301000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 302000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 303000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 304000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 305000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 306000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 307000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 308000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 309000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 310000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 311000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 312000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 313000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 314000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 315000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 316000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 317000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 318000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 319000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 320000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 321000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 322000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 323000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 324000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 325000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 326000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 327000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 328000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 329000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 330000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 331000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 332000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 333000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 334000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 335000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 336000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 337000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 338000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 339000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 340000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 341000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 342000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 343000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 344000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 345000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 346000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 347000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 348000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 349000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 350000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 351000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 352000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 353000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 354000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 355000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 356000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 357000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 358000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 359000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 360000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 361000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 362000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 363000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 364000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 365000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 366000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 367000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 368000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 369000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 370000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 371000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 372000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 373000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 374000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 375000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 376000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 377000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 378000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 379000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 380000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 381000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 382000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 383000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 384000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 385000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 386000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 387000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 388000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 389000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 390000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 391000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 392000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 393000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 394000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 395000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 396000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 397000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 398000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 399000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 400000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 401000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 402000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 403000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 404000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 405000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 406000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 407000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 408000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 409000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 410000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 411000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 412000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 413000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 414000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 415000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 416000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 417000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 418000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 419000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 420000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 421000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 422000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 423000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 424000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 425000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 426000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 427000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 428000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 429000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 430000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 431000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 432000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 433000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 434000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 435000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 436000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 437000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 438000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 439000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 440000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 441000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 442000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 443000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 444000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 445000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 446000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 447000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 448000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 449000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 450000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 451000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 452000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 453000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 454000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 455000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 456000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 457000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 458000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 459000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 460000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 461000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 462000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 463000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 464000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 465000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 466000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 467000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 468000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 469000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 470000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 471000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 472000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 473000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 474000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 475000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 476000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 477000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 478000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 479000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 480000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 481000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 482000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 483000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 484000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 485000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 486000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 487000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 488000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 489000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 490000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 491000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 492000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 493000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 494000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 495000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 496000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 497000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 498000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 499000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 500000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 501000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 502000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 503000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 504000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 505000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 506000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 507000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 508000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 509000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 510000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 511000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 512000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 513000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 514000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 515000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 516000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 517000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 518000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 519000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 520000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 521000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 522000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 523000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 524000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 525000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 526000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 527000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 528000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 529000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 530000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 531000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 532000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 533000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 534000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 535000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 536000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 537000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 538000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 539000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 540000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 541000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 542000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 543000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 544000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 545000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 546000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 547000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 548000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 549000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 550000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 551000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 552000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 553000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 554000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 555000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 556000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 557000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 558000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 559000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 560000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 561000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 562000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 563000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 564000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 565000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 566000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 567000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 568000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 569000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 570000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 571000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 572000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 573000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 574000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 575000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 576000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 577000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 578000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 579000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 580000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 581000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 582000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 583000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 584000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 585000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 586000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 587000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 588000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 589000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 590000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 591000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 592000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 593000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 594000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 595000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 596000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 597000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 598000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 599000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 600000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 601000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 602000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 603000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 604000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 605000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 606000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 607000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 608000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 609000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 610000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 611000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 612000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 613000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 614000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 615000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 616000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 617000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 618000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 619000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 620000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 621000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 622000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 623000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 624000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 625000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 626000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 627000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 628000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 629000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 630000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 631000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 632000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 633000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 634000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 635000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 636000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 637000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 638000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 639000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 640000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 641000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 642000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 643000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 644000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 645000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 646000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 647000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 648000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 649000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 650000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 651000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 652000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 653000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 654000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 655000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 656000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 657000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 658000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 659000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 660000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 661000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 662000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 663000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 664000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 665000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 666000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 667000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 668000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 669000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 670000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 671000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 672000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 673000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 674000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 675000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 676000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 677000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 678000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 679000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 680000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 681000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 682000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 683000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 684000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 685000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 686000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 687000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 688000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 689000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 690000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 691000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 692000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 693000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 694000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 695000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 696000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 697000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 698000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 699000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 700000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 701000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 702000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 703000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 704000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 705000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 706000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 707000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 708000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 709000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 710000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 711000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 712000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 713000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 714000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 715000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 716000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 717000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 718000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 719000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 720000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 721000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 722000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 723000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 724000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 725000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 726000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 727000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 728000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 729000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 730000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 731000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 732000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 733000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 734000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 735000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 736000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 737000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 738000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 739000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 740000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 741000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 742000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 743000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 744000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 745000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 746000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 747000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 748000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 749000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 750000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 751000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 752000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 753000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 754000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 755000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 756000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 757000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 758000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 759000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 760000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 761000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 762000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 763000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 764000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 765000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 766000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 767000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 768000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 769000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 770000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 771000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 772000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 773000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 774000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 775000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 776000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 777000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 778000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 779000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 780000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 781000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 782000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 783000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 784000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 785000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 786000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 787000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 788000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 789000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 790000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 791000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 792000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 793000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 794000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 795000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 796000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 797000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 798000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 799000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 800000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 801000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 802000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 803000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 804000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 805000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 806000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 807000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 808000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 809000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 810000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 811000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 812000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 813000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 814000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 815000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 816000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 817000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 818000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 819000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 820000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 821000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 822000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 823000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 824000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 825000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 826000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 827000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 828000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 829000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 830000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 831000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 832000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 833000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 834000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 835000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 836000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 837000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 838000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 839000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 840000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 841000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 842000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 843000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 844000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 845000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 846000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 847000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 848000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 849000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 850000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 851000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 852000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 853000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 854000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 855000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 856000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 857000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 858000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 859000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 860000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 861000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 862000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 863000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 864000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 865000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 866000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 867000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 868000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 869000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 870000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 871000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 872000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 873000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 874000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 875000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 876000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 877000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 878000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 879000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 880000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 881000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 882000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 883000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 884000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 885000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 886000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 887000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 888000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 889000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 890000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 891000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 892000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 893000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 894000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 895000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 896000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 897000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 898000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 899000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 900000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 901000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 902000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 903000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 904000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 905000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 906000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 907000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 908000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 909000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 910000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 911000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 912000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 913000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 914000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 915000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 916000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 917000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 918000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 919000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 920000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 921000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 922000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 923000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 924000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 925000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 926000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 927000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 928000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 929000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 930000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 931000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 932000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 933000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 934000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 935000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 936000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 937000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 938000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 939000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 940000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 941000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 942000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 943000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 944000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 945000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 946000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 947000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 948000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 949000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 950000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 951000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 952000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 953000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 954000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 955000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 956000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 957000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 958000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 959000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 960000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 961000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 962000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 963000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 964000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 965000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 966000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 967000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 968000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 969000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 970000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 971000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 972000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 973000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 974000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 975000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 976000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 977000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 978000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 979000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 980000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 981000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 982000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 983000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 984000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 985000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 986000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 987000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 988000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 989000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 990000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 991000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 992000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 993000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 994000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 995000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 996000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 997000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 998000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 999000 / 1000000\n",
      "[t-SNE] Computed conditional probabilities for sample 1000000 / 1000000\n",
      "[t-SNE] Mean sigma: 0.743292\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 146.203506\n",
      "[t-SNE] KL divergence after 150 iterations: 9.758556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/202110120920_TSNE_manifold.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne = TSNE(\n",
    "    n_components=2, \n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_embedded = tsne.fit_transform(X_pca)\n",
    "\n",
    "manifold = {\n",
    "    'method': 'TSNE',\n",
    "    'input': X_pca,\n",
    "    'parameters': str(tsne.get_params),\n",
    "    'output': X_embedded\n",
    "}\n",
    "\n",
    "dump(manifold, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/202110120920_TSNE_manifold.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07992560-5ad6-476a-b86e-1fcd774da1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a38ab301-66dd-4c70-b710-76eadab5b10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16013098e-07, -1.01638484e-07],\n",
       "       [-8.30949816e-08, -1.73992944e-07],\n",
       "       [-1.99455300e-07, -3.86524768e-08],\n",
       "       [-1.89531079e-07, -9.15922893e-09],\n",
       "       [-2.94285314e-07,  6.71537981e-09],\n",
       "       [-1.54592684e-07, -6.86213895e-08],\n",
       "       [-1.22330533e-07, -2.95670972e-08],\n",
       "       [-9.01422510e-08, -2.61739963e-09],\n",
       "       [-3.33780463e-07, -2.12644863e-07],\n",
       "       [-1.20533770e-07, -7.06108771e-09]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c40d07-adfa-4962-b6bf-b1a114c07952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(X_embedded, index=[i for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3ad7ead-566b-4e6d-a882-61f849ff7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "# instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    verbosity=1,\n",
    "    tree_method='gpu_hist',\n",
    "    booster='gbtree', # not bothering with dart for time reasons\n",
    "    random_state=SEED,\n",
    "    **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e3000f1-35e5-4bf7-8cac-ce351fc498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "080b7113-4389-484b-85b0-1206d99861d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_embedded), type(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b68e1908-a301-4939-8b01-3635133e5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_embedded, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec43ce0-12e4-44c3-86a4-1b1125250a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.6042069686110977\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a56c16-13f3-4e44-b6b4-fe32d587ee73",
   "metadata": {},
   "source": [
    "**I think this is a dead-end -- that's pretty terrible performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "    \n",
    "#     pca_components = trial.suggest_int('pca_components', 50, 285)\n",
    "    pca = PCA(n_components=pca_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "    \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 900, 6000), # was 900-4500 for CPU\n",
    "#         'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "#         'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 30),\n",
    "#         'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "# #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "#         'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 10),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "#         'gamma': trial.suggest_uniform('gamma', 0.1, 30)\n",
    "#     }  \n",
    "\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    "    )    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "              })\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_xgboost_20211010.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/2b286ehp\" target=\"_blank\">sweep_xgboost_20211010_115658</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-10 11:57:06,723]\u001b[0m A new study created in memory with name: pca_20211010\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"pca_{datetime.now().strftime('%Y%m%d')}\")\n",
    "\n",
    "# study = load(studypath/f\"optuna_xgboost_study_106trials_20211004.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02e3b84-ee16-48b9-94db-c738b408a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a454cc8-f135-4d36-8b6c-a964f4b52288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3860cbd2-1d08-4b2e-ac53-92b8a2ce016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Error thrown by xgboost trainer.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.core.XGBoostError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8ad6db-2722-4f04-bd51-4b795bec93c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ed3ac943a45fa8dc339194d2cab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:57:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 1; dropping {'pca_components': 138, 'value': 0.8283967087232865}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8283967087232865\n",
      "\u001b[32m[I 2021-10-10 11:59:12,446]\u001b[0m Trial 0 finished with value: 0.8283967087232865 and parameters: {'pca_components': 138}. Best is trial 0 with value: 0.8283967087232865.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c995da28a1d44a78001aca7668f1bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 2; dropping {'pca_components': 274, 'value': 0.8472107426301871}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472107426301871\n",
      "\u001b[32m[I 2021-10-10 12:02:45,979]\u001b[0m Trial 1 finished with value: 0.8472107426301871 and parameters: {'pca_components': 274}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fccb3fa1d664c2c9182df86e0916f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 3; dropping {'pca_components': 222, 'value': 0.8411313966895685}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8411313966895685\n",
      "\u001b[32m[I 2021-10-10 12:06:07,082]\u001b[0m Trial 2 finished with value: 0.8411313966895685 and parameters: {'pca_components': 222}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa85acfc834a6eb8f4993b66a345d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 4; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:09:03,422]\u001b[0m Trial 3 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeb5cbc6d8f498aaeafbcbd5baf86c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 5; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:10:25,360]\u001b[0m Trial 4 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ed1965573401a893b3bcf5d741830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 6; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:11:46,686]\u001b[0m Trial 5 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5122220c3f24f86abb9c62111e5b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 7; dropping {'pca_components': 63, 'value': 0.7904181686815366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.7904181686815366\n",
      "\u001b[32m[I 2021-10-10 12:12:47,694]\u001b[0m Trial 6 finished with value: 0.7904181686815366 and parameters: {'pca_components': 63}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add254087a4548f8943e78283019acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 8; dropping {'pca_components': 254, 'value': 0.8452885185751505}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8452885185751505\n",
      "\u001b[32m[I 2021-10-10 12:15:43,607]\u001b[0m Trial 7 finished with value: 0.8452885185751505 and parameters: {'pca_components': 254}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa23627f1d4045d888d13dfda8f652fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 9; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:18:38,689]\u001b[0m Trial 8 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5422d08b044f46318acef3ee9a059d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 10; dropping {'pca_components': 217, 'value': 0.8409412517853502}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8409412517853502\n",
      "\u001b[32m[I 2021-10-10 12:21:58,921]\u001b[0m Trial 9 finished with value: 0.8409412517853502 and parameters: {'pca_components': 217}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5828e8c8e4c4e88ada0bcfd0a1e657c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 11; dropping {'pca_components': 281, 'value': 0.8474176983005992}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474176983005992\n",
      "\u001b[32m[I 2021-10-10 12:25:32,672]\u001b[0m Trial 10 finished with value: 0.8474176983005992 and parameters: {'pca_components': 281}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d792ab5b54f7e94cac11539cb2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 12; dropping {'pca_components': 270, 'value': 0.8462401528718595}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8462401528718595\n",
      "\u001b[32m[I 2021-10-10 12:29:05,642]\u001b[0m Trial 11 finished with value: 0.8462401528718595 and parameters: {'pca_components': 270}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ede0e145554dab8b24e39e112f384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 13; dropping {'pca_components': 278, 'value': 0.8472224222376469}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472224222376469\n",
      "\u001b[32m[I 2021-10-10 12:32:39,229]\u001b[0m Trial 12 finished with value: 0.8472224222376469 and parameters: {'pca_components': 278}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c03a5fab942cc8bc82dedea9ea5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 14; dropping {'pca_components': 239, 'value': 0.8446363408619656}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8446363408619656\n",
      "\u001b[32m[I 2021-10-10 12:35:35,341]\u001b[0m Trial 13 finished with value: 0.8446363408619656 and parameters: {'pca_components': 239}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8986b171a6b14e7db312199a0ada6e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 15; dropping {'pca_components': 283, 'value': 0.8474194357944366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474194357944366\n",
      "\u001b[32m[I 2021-10-10 12:39:09,826]\u001b[0m Trial 14 finished with value: 0.8474194357944366 and parameters: {'pca_components': 283}. Best is trial 14 with value: 0.8474194357944366.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5e682ca174a228a244baa13a8c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31be9a9972d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e2748e41b07>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpca_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca_components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m285\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     dump(pca60, edapath/'PCA_60.joblibg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# sign flipping is done inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             U, S, Vt = randomized_svd(X, n_components=n_components,\n\u001b[0m\u001b[1;32m    549\u001b[0m                                       \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                       \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     Q = randomized_range_finder(\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Sample the range of A using by linear projection of Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Extract an orthonormal basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'economic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    162\u001b[0m                       lwork=lwork, overwrite_a=1)\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'economic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         Q, = safecall(gor_un_gqr, \"gorgqr/gungqr\", qr, tau, lwork=lwork,\n\u001b[0m\u001b[1;32m    165\u001b[0m                       overwrite_a=1)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36msafecall\u001b[0;34m(f, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lwork'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ValueError(\"illegal value in %dth argument of internal %s\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(1,200):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=True, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=datapath/f\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d6fb3-b4b3-40bd-8ff9-e2919c234f7d",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "# dump(study, filename=datapath/f\"optuna_xgboost_100trials-complete_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# dump(study.best_trial.params, filename=datapath/f\"optuna_lightgbm_all-500trials-best_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e398cb-f0f4-4400-8fe7-9012b4bc33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
