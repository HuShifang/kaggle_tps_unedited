{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "Header for notebooks -- customize as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d84988-5ddb-40d9-bc12-826012acb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"cleanlab_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "# from BorutaShap import BorutaShap\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957d1322-cdac-411a-9754-9deb360cea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from torchmetrics import AUROC\n",
    "# import torch\n",
    "# from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55072fd2-dcc0-4169-a6f8-54d9b76ab432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880b9f33-b517-40ef-a3e6-049dcc52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9e0d-1301-4ade-a63d-9f3d298c2255",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba521a1a-8c41-4b9b-becd-36eb62739ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f63ee2-a167-4111-9b44-bf67c8240603",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad459104-e31a-4aa0-8a9a-bb279e2b9944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    # 'train_source': str(datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_orig.joblib'),\n",
    "    # 'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "# X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac6b1dd-5c9d-4f95-985c-4250d78d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    \"arch\": 'lightgbm',\n",
    "    # \"type\": 'sweep',\n",
    "    # \"denoising\": \"cleanlab\",\n",
    "    \"level\": 1,\n",
    "    'random_state': SEED,\n",
    "    # 'tuner': \"Optuna\",\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    'scaler': str(RobustScaler()),\n",
    "    **dataset_params\n",
    "}\n",
    "\n",
    "wandb_config = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['experiment'],\n",
    "    'notes': \"Going to try CleanLab with the 'best' params from the previous sweep, but wanting to see what the actual LB score is, and how it compares to the noisy one. Using a default LGBMClassfier with holdout on robust-scaled original dataset.\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ce4d6-5c82-40c5-97ba-7c751e1abf6f",
   "metadata": {},
   "source": [
    "## LGBM Model and Noisy Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1d702b-f01a-4900-88b5-65df54a89eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3sw3r26n\" target=\"_blank\">cleanlab_20211122_145249</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3sw3r26n?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f735419d760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"202111_Kaggle_tabular_playground\",\n",
    "    save_code=True,\n",
    "    tags=wandb_config['tags'],\n",
    "    name=wandb_config['name'],\n",
    "    notes=wandb_config['notes'],\n",
    "    config=exmodel_config\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89ff05f8-b823-4ed5-9afd-bfd5f5d1d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        #                     device_type='cpu',\n",
    "        #                     n_jobs=-1,\n",
    "        #                 eval_metric='auc',\n",
    "        device_type='gpu',\n",
    "        max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "        gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0f0a4f-7bda-4066-b48a-5777c4d0fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99c53d73-9e34-4cb0-811a-d9e0ebfdb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c9352b8-a43c-4f06-b986-b6d210b92b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27296268,  0.01579322, -0.19031588, ...,  0.50363337,\n",
       "         0.17720313, -0.58369832],\n",
       "       [-0.18106382,  0.2410393 ,  5.30773161, ...,  0.24955035,\n",
       "        -0.48450355, -0.62285755],\n",
       "       [ 6.07300903, -0.85078822,  0.17280319, ..., -0.62764574,\n",
       "        -0.67894852,  0.73726127],\n",
       "       ...,\n",
       "       [ 4.18856991, -0.68824246,  0.21225385, ...,  0.88726112,\n",
       "         6.19955807, -0.09918299],\n",
       "       [-0.300117  ,  0.13080398, -0.54802214, ..., -0.3979886 ,\n",
       "        -0.01474   ,  0.22398866],\n",
       "       [-0.29279129,  0.62179137,  0.07317624, ...,  0.14508993,\n",
       "        12.038684  ,  0.6437292 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e3b9416-6efd-41a9-8969-614ce263813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27745959, -0.79095855,  3.57879036, ...,  0.40431588,\n",
       "         0.30027418,  0.45467042],\n",
       "       [-0.35032922, -0.36662758, -0.83368479, ...,  0.48734142,\n",
       "        -0.59656634,  9.97028335],\n",
       "       [ 2.07990909,  0.20997962, -0.0127639 , ..., -0.80240405,\n",
       "        -0.22697866,  0.23615553],\n",
       "       ...,\n",
       "       [ 0.80633635,  0.39936366,  0.49845399, ...,  0.68680344,\n",
       "        -1.04204429,  0.24502101],\n",
       "       [-0.06863608, -0.27843164, -0.36283929, ...,  0.18702425,\n",
       "         0.57010813, -0.05371796],\n",
       "       [-0.3620719 , -0.30144763, -0.06982129, ..., -0.73907299,\n",
       "        -1.0792864 ,  0.24365673]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07d1a2b1-6526-4083-95f6-ce1109730622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(device_type='gpu', gpu_use_dp=False, max_bin=63,\n",
       "               objective='binary', random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fdd0309-6a25-44f4-a7c2-25e1c5d430c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322242958171294"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lgb_model.predict_proba(X_valid)[:,1]\n",
    "valid_auc = roc_auc_score(y_true=y_valid, y_score=preds)\n",
    "valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce68c312-9dcb-4b25-96f1-779eab6dabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X=X, y=y, model=lgb_model):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rp_params = {\n",
    "        # 'prune_method': trial.suggest_categorical('prune_method', ['prune_by_noise_rate', 'prune_by_class', 'both']),\n",
    "        # 'converge_latent_estimates': trial.suggest_categorical('converge_latent_estimates', [True, False]),\n",
    "        # 'pulearning': trial.suggest_categorical('pulearning', [0,1,None])\n",
    "        'prune_method': 'both',\n",
    "        'converge_latent_estimates': True,\n",
    "        'pulearning': 1,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    rp = LearningWithNoisyLabels(clf=lgb_model, **rp_params)\n",
    "    rp.fit(X_train, y_train)\n",
    "    preds = rp.predict_proba(X_valid)[:,1]\n",
    "    valid_auc = roc_auc_score(y_true=y_valid, y_score=preds)\n",
    "    print(f\"Valid AUC score for is {valid_auc}\")\n",
    "    return valid_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc13e99-5fd3-4366-ab2b-944b21092fb4",
   "metadata": {},
   "source": [
    "Best params from LightGBM sweep before (using Optuna) were:\n",
    "```python\n",
    "{'prune_method': 'both', 'converge_latent_estimates': True, 'pulearning': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97af370d-0d61-4755-9db8-48eda2ef013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/studies/cleanlab_lgboost_20211118.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(study, Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/studies/cleanlab_lgboost_20211118.joblib')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
