{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Setting up a more robust baseline notebook, suitable for use with all of the \"Big Three\" (XGBoost, CatBoost, LightGBM) libraries and on either Google Colab or the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"baseline_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    !pip install category_encoders\n",
    "    !pip install catboost\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    !pip install cmake --upgrade\n",
    "    # !pip install sklearn --upgrade\n",
    "    !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    %cd /content/xgboost\n",
    "    !mkdir build\n",
    "    %cd build\n",
    "    !cmake .. -DUSE_CUDA=ON\n",
    "    !make -j4\n",
    "    %cd /content/xgboost/python-package\n",
    "    !python setup.py install --use-cuda --use-nccl\n",
    "    !/opt/bin/nvidia-smi\n",
    "    !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import KNNImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08408fca-654d-4f30-87c0-b8f31cb1717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')    \n",
    "    \n",
    "# load the version of the dataset with imputations; X and y were stored separately, as feather and joblib respectively\n",
    "X = pd.read_feather(datapath/'X_StandardScaled_KNNImputed_5NN.feather') \n",
    "y = load(datapath/'y.joblib')    \n",
    "X.index.name = 'id'\n",
    "y.index.name = 'id'\n",
    "\n",
    "# # here's how to load the original, unaltered dataset and separate features from targets\n",
    "# df = pd.read_feather(path=dataset_path/'dataset_df.feather') # this is the unaltered original dataset\n",
    "# features = [x for x in df.columns if x != 'claim']\n",
    "# X = df[features]\n",
    "# y = df.claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59020939-0ca1-4e0d-9af3-9fb122646ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f109</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>-2.336057</td>\n",
       "      <td>-0.640028</td>\n",
       "      <td>-0.865135</td>\n",
       "      <td>-0.108153</td>\n",
       "      <td>-4.793134</td>\n",
       "      <td>-1.164104</td>\n",
       "      <td>-0.602909</td>\n",
       "      <td>-0.602437</td>\n",
       "      <td>-0.520139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965180</td>\n",
       "      <td>0.414373</td>\n",
       "      <td>-0.364292</td>\n",
       "      <td>-0.482119</td>\n",
       "      <td>-0.878642</td>\n",
       "      <td>-0.635844</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-1.210113</td>\n",
       "      <td>1.122438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245597</td>\n",
       "      <td>-0.316947</td>\n",
       "      <td>1.208458</td>\n",
       "      <td>0.354270</td>\n",
       "      <td>1.065282</td>\n",
       "      <td>-0.360618</td>\n",
       "      <td>0.079180</td>\n",
       "      <td>-0.745021</td>\n",
       "      <td>0.885596</td>\n",
       "      <td>0.459871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939498</td>\n",
       "      <td>-1.982493</td>\n",
       "      <td>2.337448</td>\n",
       "      <td>-0.516377</td>\n",
       "      <td>0.237215</td>\n",
       "      <td>-0.673335</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>-0.522752</td>\n",
       "      <td>-0.664832</td>\n",
       "      <td>-0.674975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.016108</td>\n",
       "      <td>-2.413280</td>\n",
       "      <td>-0.492762</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>1.063769</td>\n",
       "      <td>0.115233</td>\n",
       "      <td>0.530570</td>\n",
       "      <td>-0.047807</td>\n",
       "      <td>-0.768160</td>\n",
       "      <td>1.043223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662936</td>\n",
       "      <td>0.762045</td>\n",
       "      <td>-0.971575</td>\n",
       "      <td>-0.518246</td>\n",
       "      <td>0.632622</td>\n",
       "      <td>-0.195099</td>\n",
       "      <td>-0.282497</td>\n",
       "      <td>-0.630488</td>\n",
       "      <td>-0.038341</td>\n",
       "      <td>-0.373060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.426856</td>\n",
       "      <td>-2.315919</td>\n",
       "      <td>-0.512583</td>\n",
       "      <td>-0.828360</td>\n",
       "      <td>1.476518</td>\n",
       "      <td>3.561044</td>\n",
       "      <td>-1.181820</td>\n",
       "      <td>-0.340658</td>\n",
       "      <td>-0.740081</td>\n",
       "      <td>-0.532388</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.376995</td>\n",
       "      <td>-0.803706</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.506544</td>\n",
       "      <td>-1.792552</td>\n",
       "      <td>-0.629638</td>\n",
       "      <td>-0.265100</td>\n",
       "      <td>-0.635201</td>\n",
       "      <td>0.294645</td>\n",
       "      <td>-0.108728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.597496</td>\n",
       "      <td>1.073064</td>\n",
       "      <td>-0.651186</td>\n",
       "      <td>0.455018</td>\n",
       "      <td>0.275424</td>\n",
       "      <td>-0.159085</td>\n",
       "      <td>0.719322</td>\n",
       "      <td>-0.902730</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>-0.514415</td>\n",
       "      <td>...</td>\n",
       "      <td>1.773967</td>\n",
       "      <td>0.338317</td>\n",
       "      <td>-0.608098</td>\n",
       "      <td>-0.498863</td>\n",
       "      <td>-0.216082</td>\n",
       "      <td>-0.641494</td>\n",
       "      <td>2.384546</td>\n",
       "      <td>-0.635402</td>\n",
       "      <td>0.477433</td>\n",
       "      <td>-0.804986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3        f4        f5        f6        f7  \\\n",
       "id                                                                         \n",
       "0   0.422121 -2.336057 -0.640028 -0.865135 -0.108153 -4.793134 -1.164104   \n",
       "1   0.245597 -0.316947  1.208458  0.354270  1.065282 -0.360618  0.079180   \n",
       "2   2.016108 -2.413280 -0.492762  0.333754  1.063769  0.115233  0.530570   \n",
       "3   1.426856 -2.315919 -0.512583 -0.828360  1.476518  3.561044 -1.181820   \n",
       "4   0.597496  1.073064 -0.651186  0.455018  0.275424 -0.159085  0.719322   \n",
       "\n",
       "          f8        f9       f10  ...      f109      f110      f111      f112  \\\n",
       "id                                ...                                           \n",
       "0  -0.602909 -0.602437 -0.520139  ... -0.965180  0.414373 -0.364292 -0.482119   \n",
       "1  -0.745021  0.885596  0.459871  ...  1.939498 -1.982493  2.337448 -0.516377   \n",
       "2  -0.047807 -0.768160  1.043223  ... -0.662936  0.762045 -0.971575 -0.518246   \n",
       "3  -0.340658 -0.740081 -0.532388  ... -1.376995 -0.803706 -0.005727 -0.506544   \n",
       "4  -0.902730  0.043314 -0.514415  ...  1.773967  0.338317 -0.608098 -0.498863   \n",
       "\n",
       "        f113      f114      f115      f116      f117      f118  \n",
       "id                                                              \n",
       "0  -0.878642 -0.635844  0.006302 -0.622475 -1.210113  1.122438  \n",
       "1   0.237215 -0.673335  0.326417 -0.522752 -0.664832 -0.674975  \n",
       "2   0.632622 -0.195099 -0.282497 -0.630488 -0.038341 -0.373060  \n",
       "3  -1.792552 -0.629638 -0.265100 -0.635201  0.294645 -0.108728  \n",
       "4  -0.216082 -0.641494  2.384546 -0.635402  0.477433 -0.804986  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08bd3364-0f44-45fb-bdbb-0748fe2d68e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4940261-a267-4f16-af3d-5bbc56958459",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "### General and Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "    \"scaler\": StandardScaler, # TODO: experiment with others (but imputation may be slow)\n",
    "    \"scale_b4_impute\": True,\n",
    "    \"imputer\": KNNImputer,\n",
    "    \"knn_imputer_n_neighbors\": 5, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': 42,\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7341ba-22c1-4887-bbda-ff2c7504bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configurator(library, gpu_available=True):#, config=universal_config):\n",
    "    \"\"\"\n",
    "    Function that provide task-specific or general preference arguments for the various models. \n",
    "    \n",
    "    At first, will rely largely on defaults for hyperparameters, but later this function \n",
    "    can be supplemented later with optimal values, as they're learned in sweeps.\n",
    "    .\n",
    "    \n",
    "    Rationale: creating a helper function will allow more experimentation later, and also\n",
    "    composite runs that cycle through a series of models.\n",
    "    \n",
    "    :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "    :return config: A dict that supplements default hyperparameter values with 1) \n",
    "                    task-appropriate ones, and perhaps later 2) optimal hyperparameter values.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "#     if library == 'xgboost':\n",
    "#         config['model'] = XGBClassifier()\n",
    "#     elif library == 'lightgbm':\n",
    "#         config['model'] = LGBMClassifier()\n",
    "#     elif library == 'catboost':\n",
    "#         config['model'] = CatBoostClassifier()\n",
    "#     else:\n",
    "#         print(\"Invalid library\")\n",
    "#         return None\n",
    "    \n",
    "    # library-specific config\n",
    "#     if config['model'] in [XGBClassfier, LGBMClassifier]:\n",
    "    if library in ['xgboost', 'lightgbm']:\n",
    "#         config['reg_alpha'] = None\n",
    "        config['n_jobs'] = -1\n",
    "        config['n_estimators'] = 300\n",
    "\n",
    "#     if config['model'] == XGBClassifier:\n",
    "    if library == 'xgboost':\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "#         config['model'] = XGBClassifier\n",
    "        config['verbosity'] = 1\n",
    "        config['objective'] = 'binary:logistic'\n",
    "#         config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "#         config['eval_metric'] = 'logloss',\n",
    "        config['tree_method'] = 'gpu_hist' if (gpu_available and colab) else 'auto' \n",
    "#         config['reg_alpha'] = \n",
    "\n",
    "#     if config['model'] == LGBMClassifier:\n",
    "    if library == 'lightgbm':\n",
    "#         config['model'] = LGBMClassifier\n",
    "        config['objective'] = 'binary'\n",
    "        config['eval_metric'] = ['auc', 'logloss']\n",
    "        config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "        config['device_type'] = 'cuda' if (gpu_available and colab) else 'cpu' # 'gpu' also possible, 'cpu' is default\n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "    if library == 'catboost':\n",
    "#         config['model'] = CatBoostClassifier\n",
    "        config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "        config['custom_metrics'] = ['Logloss', 'AUC'] # objective (loss fn) must be singular, defaults to Logloss\n",
    "        config['n_estimators'] = 1000 # logged as \"iterations\" otherwise\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9b4dd2-f63c-47df-979e-cb372b57e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_config(model, config=universal_config):\n",
    "#     \"\"\"\n",
    "#     Function that will take a dict containing universal defaults and then flesh them out\n",
    "#     based on the model specified via argument, and return a new, completed configuration \n",
    "#     dict.\n",
    "    \n",
    "#     Rationale: creating a helper function will allow more experimentation later, and also\n",
    "#     composite runs that cycle through a series of models.\n",
    "    \n",
    "#     :param model: A model from [XGBClassifier, LGBMClassifier, CatBoostClassifier]\n",
    "#     :return config: A dict that fleshes out the basic, universal default config dict with\n",
    "#                     additional, model-specific values.\n",
    "#     \"\"\"\n",
    "#     config['model'] = model\n",
    "    \n",
    "#     # library-specific config\n",
    "#     if config['model'] in [XGBClassfier, LGBMClassifier]:\n",
    "#         config['reg_alpha'] = None\n",
    "#         config['n_jobs'] = -1\n",
    "\n",
    "#     if config['model'] == XGBClassifier:\n",
    "#         config['tree_method'] = 'auto'\n",
    "#         config['booster'] = 'gbtree' # or 'dart'\n",
    "#         config['verbosity'] = 1\n",
    "#         config['objective'] = 'binary:logistic'\n",
    "#         config['eval_metric'] = ['auc', 'logloss', 'aucpr'],\n",
    "#         config['reg_alpha'] = \n",
    "\n",
    "#     if config['model'] == LGBMClassifier:\n",
    "#         config['objective'] = 'binary'\n",
    "#         config['metric'] = 'auc'\n",
    "#         config['boosting_type'] = 'gbdt' # or 'dart'\n",
    "\n",
    "#     if config['model'] == CatBoostClassifier:\n",
    "#         config['task_type'] = 'GPU' if gpu_available else 'CPU'\n",
    "#         config['eval_metrics'] = ['Logloss', 'AUC']\n",
    "\n",
    "#     return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5f215-b585-4f7b-afac-36e49ee28c8f",
   "metadata": {},
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a928e1-0a18-4c91-b9bb-a32846e39e5b",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_run = {\n",
    "    # wandb config:\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}_{exmodel_config['library']}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['baseline'],\n",
    "    'notes': \"Initial runs of each model-type, with sane defaults.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f8d1-d303-4420-b671-51fcbff98594",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Scaling has already occurred -- used `StandardScaler` as a precursor to using `KNNImputer(n_neighbors=5)`, on the premise that imputation would proceed more quickly if things were already scaled. I may try different permutations of this later: using `IterativeImputer` instead, before or after scaling, potentially with different scalers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77e37c-8f76-44b2-9e04-7fa02430ce96",
   "metadata": {},
   "source": [
    "# Feature Creation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb77f573-e284-49a7-96a8-bb33b5b44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the polynomialfeatures generated with `PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)`\n",
    "# X_np = np.load(datapath/'X_poly_unscaled.npy')\n",
    "# X = pd.DataFrame(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e905f6-f5e4-4848-98e3-ddc846ab4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e4c99-64d4-4506-b208-397ce736eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2728178c-5214-4c6c-ab86-5d63aeb2c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cbdaa47-cab5-441b-885d-d21b33c604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly_names = poly.get_feature_names(X.columns)\n",
    "# # X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f6bd0c-1121-4430-966d-7a318d925d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c528d2-2148-409f-9489-254358a4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(X_poly, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0682b3-1fef-4c54-9a33-99f659a2c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[features[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638002ad-9266-44d6-8302-ebce2a6f7b06",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24391812-dce3-4513-bd38-ee95694730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_valid, y_train, y_valid, model_config, \n",
    "                                              random_state=42,\n",
    "                                              exmodel_config=exmodel_config, \n",
    "                                              config_run=config_run):#, scaler): # passed in via config dict for now\n",
    "    \"\"\"\n",
    "    Basic training function. Note that some of the options passed via the argument are\n",
    "    in fact hard-coded in, to avoid inconveniences.\n",
    "    :param X_train: the training set features\n",
    "    :param X_valid: the validation set features\n",
    "    :param y_train: the training set targets\n",
    "    :param y_valid: the validation set targets\n",
    "    :param random_state: for reproducibility\n",
    "    :param exmodel_config: dict containing configuration details including the library \n",
    "                            (thus model) used, preprocessing, and cross-validation\n",
    "    :param model_config: dict containing hyperparameter specifications for the model\n",
    "    :param config_run: dict containing wandb run configuration (name, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"202109_Kaggle_tabular_playground\",\n",
    "        save_code=True,\n",
    "        tags=config_run['tags'],\n",
    "        name=config_run['name'],\n",
    "        notes=config_run['notes'],\n",
    "        config=exmodel_config)   \n",
    "        \n",
    "    # applying hold-out before scaling\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=config['test_size'], \n",
    "#                                                           random_state=config['random_state']\n",
    "#                                                          )\n",
    "    \n",
    "    # strictly speaking should do the below, but doing beforehand faster and fine in this context\n",
    "    # scaling (i.e. normalizing)\n",
    "#     scaler = config['scaler']()\n",
    "#     X_train_s = scaler.fit_transform(X_train)\n",
    "#     X_valid_s = scaler.fit_transform(X_valid)\n",
    "    \n",
    "    # selecting features\n",
    "#     selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                           k=config['k_best'])\n",
    "#     X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "#     X_valid_fs = X_valid_s[:, selector.get_support()] # ensures same features are used in validation\n",
    "\n",
    "    if exmodel_config['library'] == 'xgboost':\n",
    "        model = XGBClassifier(\n",
    "#             tree_method=config['tree_method'],\n",
    "#             booster=config['booster'],\n",
    "#             n_estimators=config['n_estimators'], \n",
    "#             max_depth=config['max_depth'],\n",
    "#             learning_rate=config['learning_rate'], \n",
    "#             subsample=config['subsample'],\n",
    "#             reg_alpha=config['reg_alpha'],\n",
    "#             reg_lambda=config['reg_lambda'],\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'], \n",
    "            verbosity=model_config['verbosity'], \n",
    "            objective=model_config['objective'],\n",
    "#             eval_metric=model_config['eval_metric'],\n",
    "            tree_method=model_config['tree_method'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "\n",
    "\n",
    "    elif exmodel_config['library'] == 'lightgbm':\n",
    "        model = LGBMClassifier(\n",
    "#             boosting_type=model_config['boosting_type'],\n",
    "#             max_depth=model_config['max_depth']\n",
    "            # TODO\n",
    "            random_state=random_state,\n",
    "            n_jobs=model_config['n_jobs'],\n",
    "            objective=model_config['objective'],\n",
    "            eval_metric=model_config['eval_metric'],\n",
    "            boosting_type=model_config['boosting_type'],\n",
    "            device_type=model_config['device_type'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],\n",
    "#                                     eval_metric=model_config['eval_metric'],\n",
    "                 )\n",
    "        \n",
    "    elif exmodel_config['library'] == 'catboost':\n",
    "        print(\"CatBoost, therefore no WandB callback.\")\n",
    "        model = CatBoostClassifier(\n",
    "#             n_estimators=config['n_estimators'],\n",
    "#             learning_rate=config['learning_rate'],\n",
    "#             max_depth=config['max_depth'],\n",
    "            task_type=model_config['task_type'],\n",
    "    #         n_jobs=config['n_jobs'],\n",
    "    #         verbosity=config['verbosity'],\n",
    "    #         subsample=config['subsample'],\n",
    "            n_estimators=model_config['n_estimators'],\n",
    "            random_state=random_state,\n",
    "            # objective='Logloss', # default, accepts only one\n",
    "#             custom_metrics=model_config['custom_metrics'],\n",
    "    #         bootstrap_type=config['bootstrap_type'],\n",
    "    #         device:config['device']\n",
    "        ) \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_loss = log_loss(y_train, y_train_pred)\n",
    "        train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "        wandb.log({'train_loss': train_loss, 'train_auc': train_auc})\n",
    "\n",
    "    if exmodel_config['library'] == 'catboost':\n",
    "        print(model.get_all_params())\n",
    "        wandb.log(model.get_all_params())\n",
    "    else:\n",
    "        wandb.log(model.get_params()) # logging model parameters, trying bare-invocation rather than params: model.get_params()\n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "#     mse = mean_squared_error(y_valid, y_pred)\n",
    "#     rmse = math.sqrt(abs(mse))\n",
    "    valid_loss = log_loss(y_valid, y_pred)\n",
    "    valid_auc = roc_auc_score(y_valid, y_pred)\n",
    "    wandb.log({'valid_loss':valid_loss, 'valid_auc':valid_auc})\n",
    "    print(f\"Valid log-loss is {valid_loss}\\nValid AUC is {valid_auc}\")   \n",
    "#     wandb.finish()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_config, X=X, y=y, start_fold=0, exmodel_config=exmodel_config, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    if exmodel_config['kfolds'] == 1:\n",
    "        print(\"Proceeding with holdout\")\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=exmodel_config['test_size'], \n",
    "                                                      random_state=random_state,\n",
    "                                                     )\n",
    "        model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "        wandb.finish()\n",
    "        \n",
    "    else:\n",
    "        kfold = config['kfold_strategy'](n_splits=kfolds, shuffle=True, random_state=random_state)\n",
    "        models = {}\n",
    "        model_path = Path(datapath/f\"models/{config_run['name']}_{exmodel_config['kfolds']}folds/\")\n",
    "        (model_path).mkdir(exist_ok=True)\n",
    "        for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "            if fold < start_fold:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"FOLD {fold}\")\n",
    "                print(\"---------------------------------------------------\")\n",
    "                X, y = X.to_numpy(), y.to_numpy()\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "                model = train(X_train, X_valid, y_train, y_valid, exmodel_config=exmodel_config, \n",
    "                                                    model_config=model_config,\n",
    "                                                    config_run=config_run)\n",
    "                wandb.log({'fold': fold})\n",
    "                models[fold] = model\n",
    "                dump(model, Path(model_path/f\"{exmodel_config['library']}_fold{fold}_model.joblib\"))\n",
    "                wandb.finish()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92835afb-3ff2-42c6-964c-cfeede2c5990",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eca9ba-a778-476b-90ab-508d6a06a6a5",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edc7d8-76db-4e2e-8517-c7b5a24f8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, let's do the initial baseline for each of the Big Three libraries, largely using their own defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314eca54-a032-44dc-b6cf-39eed84f77ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with holdout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1cyoyqro\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1cyoyqro</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121038-1cyoyqro</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log-loss is 14.897247976385017\n",
      "Valid AUC is 0.5686107548995396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 800220<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.21MB of 0.21MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121038-1cyoyqro/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121038-1cyoyqro/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>objective</td><td>binary:logistic</td></tr><tr><td>use_label_encoder</td><td>True</td></tr><tr><td>base_score</td><td>0.5</td></tr><tr><td>booster</td><td>gbtree</td></tr><tr><td>colsample_bylevel</td><td>1</td></tr><tr><td>colsample_bynode</td><td>1</td></tr><tr><td>colsample_bytree</td><td>1</td></tr><tr><td>gamma</td><td>0</td></tr><tr><td>gpu_id</td><td>-1</td></tr><tr><td>importance_type</td><td>gain</td></tr><tr><td>learning_rate</td><td>0.3</td></tr><tr><td>max_delta_step</td><td>0</td></tr><tr><td>max_depth</td><td>6</td></tr><tr><td>min_child_weight</td><td>1</td></tr><tr><td>missing</td><td>nan</td></tr><tr><td>monotone_constraints</td><td>()</td></tr><tr><td>n_estimators</td><td>300</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_parallel_tree</td><td>1</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0</td></tr><tr><td>reg_lambda</td><td>1</td></tr><tr><td>scale_pos_weight</td><td>1</td></tr><tr><td>subsample</td><td>1</td></tr><tr><td>tree_method</td><td>auto</td></tr><tr><td>validate_parameters</td><td>1</td></tr><tr><td>verbosity</td><td>1</td></tr><tr><td>_runtime</td><td>356</td></tr><tr><td>_timestamp</td><td>1630869394</td></tr><tr><td>_step</td><td>301</td></tr><tr><td>valid_loss</td><td>14.89725</td></tr><tr><td>valid_auc</td><td>0.56861</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>use_label_encoder</td><td>▁</td></tr><tr><td>base_score</td><td>▁</td></tr><tr><td>colsample_bylevel</td><td>▁</td></tr><tr><td>colsample_bynode</td><td>▁</td></tr><tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>gamma</td><td>▁</td></tr><tr><td>gpu_id</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_delta_step</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>missing</td><td></td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_parallel_tree</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>scale_pos_weight</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>validate_parameters</td><td>▁</td></tr><tr><td>verbosity</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1cyoyqro\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1cyoyqro</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with holdout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1iphxwl9\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1iphxwl9</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121642-1iphxwl9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Valid log-loss is 14.707761213430858\n",
      "Valid AUC is 0.5740003485969962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 801220<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.21MB of 0.21MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121642-1iphxwl9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121642-1iphxwl9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>colsample_bytree</td><td>1.0</td></tr><tr><td>importance_type</td><td>split</td></tr><tr><td>learning_rate</td><td>0.1</td></tr><tr><td>max_depth</td><td>-1</td></tr><tr><td>min_child_samples</td><td>20</td></tr><tr><td>min_child_weight</td><td>0.001</td></tr><tr><td>min_split_gain</td><td>0.0</td></tr><tr><td>n_estimators</td><td>300</td></tr><tr><td>n_jobs</td><td>-1</td></tr><tr><td>num_leaves</td><td>31</td></tr><tr><td>objective</td><td>binary</td></tr><tr><td>random_state</td><td>42</td></tr><tr><td>reg_alpha</td><td>0.0</td></tr><tr><td>reg_lambda</td><td>0.0</td></tr><tr><td>silent</td><td>True</td></tr><tr><td>subsample</td><td>1.0</td></tr><tr><td>subsample_for_bin</td><td>200000</td></tr><tr><td>subsample_freq</td><td>0</td></tr><tr><td>device_type</td><td>cpu</td></tr><tr><td>_runtime</td><td>65</td></tr><tr><td>_timestamp</td><td>1630869467</td></tr><tr><td>_step</td><td>301</td></tr><tr><td>valid_loss</td><td>14.70776</td></tr><tr><td>valid_auc</td><td>0.574</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>colsample_bytree</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>max_depth</td><td>▁</td></tr><tr><td>min_child_samples</td><td>▁</td></tr><tr><td>min_child_weight</td><td>▁</td></tr><tr><td>min_split_gain</td><td>▁</td></tr><tr><td>n_estimators</td><td>▁</td></tr><tr><td>n_jobs</td><td>▁</td></tr><tr><td>num_leaves</td><td>▁</td></tr><tr><td>random_state</td><td>▁</td></tr><tr><td>reg_alpha</td><td>▁</td></tr><tr><td>reg_lambda</td><td>▁</td></tr><tr><td>silent</td><td>▁</td></tr><tr><td>subsample</td><td>▁</td></tr><tr><td>subsample_for_bin</td><td>▁</td></tr><tr><td>subsample_freq</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1iphxwl9\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1iphxwl9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for library in ['xgboost', 'lightgbm']:\n",
    "    exmodel_config['library'] = library\n",
    "    model_config = model_configurator(library)\n",
    "    cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bb7f7e8-31d2-419e-b3df-e9503d561040",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with holdout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3bcrw94k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 801456<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.33MB of 0.33MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121803-3bcrw94k/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_121803-3bcrw94k/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3bcrw94k\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/3bcrw94k</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3bcrw94k). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1h0k2s3t\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1h0k2s3t</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_122026-1h0k2s3t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost, therefore no WandB callback.\n",
      "Learning rate set to 0.023395\n",
      "0:\tlearn: 0.6930814\ttotal: 12.7ms\tremaining: 12.7s\n",
      "1:\tlearn: 0.6930192\ttotal: 25.6ms\tremaining: 12.8s\n",
      "2:\tlearn: 0.6929592\ttotal: 38.3ms\tremaining: 12.7s\n",
      "3:\tlearn: 0.6929019\ttotal: 50.9ms\tremaining: 12.7s\n",
      "4:\tlearn: 0.6928489\ttotal: 63.3ms\tremaining: 12.6s\n",
      "5:\tlearn: 0.6927949\ttotal: 76.2ms\tremaining: 12.6s\n",
      "6:\tlearn: 0.6927445\ttotal: 88.1ms\tremaining: 12.5s\n",
      "7:\tlearn: 0.6926960\ttotal: 101ms\tremaining: 12.5s\n",
      "8:\tlearn: 0.6926489\ttotal: 113ms\tremaining: 12.5s\n",
      "9:\tlearn: 0.6925985\ttotal: 127ms\tremaining: 12.5s\n",
      "10:\tlearn: 0.6925548\ttotal: 139ms\tremaining: 12.5s\n",
      "11:\tlearn: 0.6925096\ttotal: 152ms\tremaining: 12.5s\n",
      "12:\tlearn: 0.6924269\ttotal: 164ms\tremaining: 12.4s\n",
      "13:\tlearn: 0.6923828\ttotal: 177ms\tremaining: 12.5s\n",
      "14:\tlearn: 0.6923395\ttotal: 190ms\tremaining: 12.5s\n",
      "15:\tlearn: 0.6922961\ttotal: 203ms\tremaining: 12.5s\n",
      "16:\tlearn: 0.6922546\ttotal: 215ms\tremaining: 12.4s\n",
      "17:\tlearn: 0.6922165\ttotal: 227ms\tremaining: 12.4s\n",
      "18:\tlearn: 0.6921771\ttotal: 239ms\tremaining: 12.3s\n",
      "19:\tlearn: 0.6921398\ttotal: 250ms\tremaining: 12.2s\n",
      "20:\tlearn: 0.6921020\ttotal: 261ms\tremaining: 12.2s\n",
      "21:\tlearn: 0.6920209\ttotal: 271ms\tremaining: 12s\n",
      "22:\tlearn: 0.6919492\ttotal: 282ms\tremaining: 12s\n",
      "23:\tlearn: 0.6919126\ttotal: 293ms\tremaining: 11.9s\n",
      "24:\tlearn: 0.6918228\ttotal: 304ms\tremaining: 11.9s\n",
      "25:\tlearn: 0.6917871\ttotal: 316ms\tremaining: 11.8s\n",
      "26:\tlearn: 0.6917195\ttotal: 325ms\tremaining: 11.7s\n",
      "27:\tlearn: 0.6916867\ttotal: 337ms\tremaining: 11.7s\n",
      "28:\tlearn: 0.6916535\ttotal: 348ms\tremaining: 11.6s\n",
      "29:\tlearn: 0.6916221\ttotal: 358ms\tremaining: 11.6s\n",
      "30:\tlearn: 0.6915892\ttotal: 369ms\tremaining: 11.5s\n",
      "31:\tlearn: 0.6915591\ttotal: 379ms\tremaining: 11.5s\n",
      "32:\tlearn: 0.6915261\ttotal: 390ms\tremaining: 11.4s\n",
      "33:\tlearn: 0.6914944\ttotal: 402ms\tremaining: 11.4s\n",
      "34:\tlearn: 0.6914632\ttotal: 412ms\tremaining: 11.4s\n",
      "35:\tlearn: 0.6914324\ttotal: 423ms\tremaining: 11.3s\n",
      "36:\tlearn: 0.6914041\ttotal: 433ms\tremaining: 11.3s\n",
      "37:\tlearn: 0.6913736\ttotal: 444ms\tremaining: 11.2s\n",
      "38:\tlearn: 0.6913085\ttotal: 454ms\tremaining: 11.2s\n",
      "39:\tlearn: 0.6912255\ttotal: 465ms\tremaining: 11.1s\n",
      "40:\tlearn: 0.6911978\ttotal: 476ms\tremaining: 11.1s\n",
      "41:\tlearn: 0.6911676\ttotal: 488ms\tremaining: 11.1s\n",
      "42:\tlearn: 0.6910985\ttotal: 498ms\tremaining: 11.1s\n",
      "43:\tlearn: 0.6910334\ttotal: 508ms\tremaining: 11s\n",
      "44:\tlearn: 0.6909498\ttotal: 520ms\tremaining: 11s\n",
      "45:\tlearn: 0.6909215\ttotal: 530ms\tremaining: 11s\n",
      "46:\tlearn: 0.6908919\ttotal: 541ms\tremaining: 11s\n",
      "47:\tlearn: 0.6908643\ttotal: 552ms\tremaining: 11s\n",
      "48:\tlearn: 0.6908057\ttotal: 564ms\tremaining: 10.9s\n",
      "49:\tlearn: 0.6907781\ttotal: 575ms\tremaining: 10.9s\n",
      "50:\tlearn: 0.6907514\ttotal: 586ms\tremaining: 10.9s\n",
      "51:\tlearn: 0.6907245\ttotal: 597ms\tremaining: 10.9s\n",
      "52:\tlearn: 0.6906986\ttotal: 608ms\tremaining: 10.9s\n",
      "53:\tlearn: 0.6906390\ttotal: 618ms\tremaining: 10.8s\n",
      "54:\tlearn: 0.6906111\ttotal: 630ms\tremaining: 10.8s\n",
      "55:\tlearn: 0.6905864\ttotal: 640ms\tremaining: 10.8s\n",
      "56:\tlearn: 0.6905590\ttotal: 651ms\tremaining: 10.8s\n",
      "57:\tlearn: 0.6905314\ttotal: 662ms\tremaining: 10.7s\n",
      "58:\tlearn: 0.6904732\ttotal: 671ms\tremaining: 10.7s\n",
      "59:\tlearn: 0.6903954\ttotal: 683ms\tremaining: 10.7s\n",
      "60:\tlearn: 0.6903712\ttotal: 694ms\tremaining: 10.7s\n",
      "61:\tlearn: 0.6903158\ttotal: 704ms\tremaining: 10.7s\n",
      "62:\tlearn: 0.6902893\ttotal: 715ms\tremaining: 10.6s\n",
      "63:\tlearn: 0.6902649\ttotal: 726ms\tremaining: 10.6s\n",
      "64:\tlearn: 0.6902390\ttotal: 736ms\tremaining: 10.6s\n",
      "65:\tlearn: 0.6902139\ttotal: 746ms\tremaining: 10.6s\n",
      "66:\tlearn: 0.6901889\ttotal: 757ms\tremaining: 10.5s\n",
      "67:\tlearn: 0.6901255\ttotal: 766ms\tremaining: 10.5s\n",
      "68:\tlearn: 0.6901026\ttotal: 777ms\tremaining: 10.5s\n",
      "69:\tlearn: 0.6900767\ttotal: 787ms\tremaining: 10.5s\n",
      "70:\tlearn: 0.6900555\ttotal: 798ms\tremaining: 10.4s\n",
      "71:\tlearn: 0.6900313\ttotal: 808ms\tremaining: 10.4s\n",
      "72:\tlearn: 0.6900082\ttotal: 819ms\tremaining: 10.4s\n",
      "73:\tlearn: 0.6899850\ttotal: 828ms\tremaining: 10.4s\n",
      "74:\tlearn: 0.6899619\ttotal: 840ms\tremaining: 10.4s\n",
      "75:\tlearn: 0.6899368\ttotal: 850ms\tremaining: 10.3s\n",
      "76:\tlearn: 0.6898804\ttotal: 860ms\tremaining: 10.3s\n",
      "77:\tlearn: 0.6898574\ttotal: 869ms\tremaining: 10.3s\n",
      "78:\tlearn: 0.6898356\ttotal: 880ms\tremaining: 10.3s\n",
      "79:\tlearn: 0.6898131\ttotal: 892ms\tremaining: 10.3s\n",
      "80:\tlearn: 0.6897917\ttotal: 903ms\tremaining: 10.2s\n",
      "81:\tlearn: 0.6897712\ttotal: 915ms\tremaining: 10.2s\n",
      "82:\tlearn: 0.6897222\ttotal: 924ms\tremaining: 10.2s\n",
      "83:\tlearn: 0.6897022\ttotal: 934ms\tremaining: 10.2s\n",
      "84:\tlearn: 0.6896781\ttotal: 945ms\tremaining: 10.2s\n",
      "85:\tlearn: 0.6896556\ttotal: 956ms\tremaining: 10.2s\n",
      "86:\tlearn: 0.6896350\ttotal: 966ms\tremaining: 10.1s\n",
      "87:\tlearn: 0.6896181\ttotal: 977ms\tremaining: 10.1s\n",
      "88:\tlearn: 0.6895965\ttotal: 987ms\tremaining: 10.1s\n",
      "89:\tlearn: 0.6895765\ttotal: 998ms\tremaining: 10.1s\n",
      "90:\tlearn: 0.6895189\ttotal: 1.01s\tremaining: 10.1s\n",
      "91:\tlearn: 0.6894492\ttotal: 1.02s\tremaining: 10.1s\n",
      "92:\tlearn: 0.6893818\ttotal: 1.03s\tremaining: 10s\n",
      "93:\tlearn: 0.6893617\ttotal: 1.04s\tremaining: 10s\n",
      "94:\tlearn: 0.6893398\ttotal: 1.05s\tremaining: 10s\n",
      "95:\tlearn: 0.6893192\ttotal: 1.06s\tremaining: 10s\n",
      "96:\tlearn: 0.6892988\ttotal: 1.07s\tremaining: 10s\n",
      "97:\tlearn: 0.6892778\ttotal: 1.08s\tremaining: 9.99s\n",
      "98:\tlearn: 0.6892584\ttotal: 1.1s\tremaining: 9.98s\n",
      "99:\tlearn: 0.6892370\ttotal: 1.11s\tremaining: 9.99s\n",
      "100:\tlearn: 0.6892175\ttotal: 1.12s\tremaining: 9.97s\n",
      "101:\tlearn: 0.6891967\ttotal: 1.13s\tremaining: 9.96s\n",
      "102:\tlearn: 0.6891762\ttotal: 1.14s\tremaining: 9.96s\n",
      "103:\tlearn: 0.6891559\ttotal: 1.15s\tremaining: 9.94s\n",
      "104:\tlearn: 0.6891365\ttotal: 1.16s\tremaining: 9.92s\n",
      "105:\tlearn: 0.6891179\ttotal: 1.18s\tremaining: 9.91s\n",
      "106:\tlearn: 0.6890954\ttotal: 1.19s\tremaining: 9.9s\n",
      "107:\tlearn: 0.6890278\ttotal: 1.2s\tremaining: 9.88s\n",
      "108:\tlearn: 0.6890075\ttotal: 1.21s\tremaining: 9.87s\n",
      "109:\tlearn: 0.6889894\ttotal: 1.22s\tremaining: 9.87s\n",
      "110:\tlearn: 0.6889241\ttotal: 1.23s\tremaining: 9.84s\n",
      "111:\tlearn: 0.6889020\ttotal: 1.24s\tremaining: 9.82s\n",
      "112:\tlearn: 0.6888835\ttotal: 1.25s\tremaining: 9.82s\n",
      "113:\tlearn: 0.6888647\ttotal: 1.26s\tremaining: 9.8s\n",
      "114:\tlearn: 0.6888068\ttotal: 1.27s\tremaining: 9.79s\n",
      "115:\tlearn: 0.6887846\ttotal: 1.28s\tremaining: 9.78s\n",
      "116:\tlearn: 0.6887674\ttotal: 1.29s\tremaining: 9.77s\n",
      "117:\tlearn: 0.6887425\ttotal: 1.3s\tremaining: 9.76s\n",
      "118:\tlearn: 0.6887244\ttotal: 1.32s\tremaining: 9.74s\n",
      "119:\tlearn: 0.6887048\ttotal: 1.33s\tremaining: 9.73s\n",
      "120:\tlearn: 0.6886531\ttotal: 1.34s\tremaining: 9.72s\n",
      "121:\tlearn: 0.6886067\ttotal: 1.35s\tremaining: 9.7s\n",
      "122:\tlearn: 0.6885882\ttotal: 1.36s\tremaining: 9.7s\n",
      "123:\tlearn: 0.6885382\ttotal: 1.37s\tremaining: 9.68s\n",
      "124:\tlearn: 0.6885189\ttotal: 1.38s\tremaining: 9.67s\n",
      "125:\tlearn: 0.6885010\ttotal: 1.39s\tremaining: 9.65s\n",
      "126:\tlearn: 0.6884830\ttotal: 1.4s\tremaining: 9.64s\n",
      "127:\tlearn: 0.6884649\ttotal: 1.41s\tremaining: 9.63s\n",
      "128:\tlearn: 0.6884209\ttotal: 1.42s\tremaining: 9.62s\n",
      "129:\tlearn: 0.6884027\ttotal: 1.44s\tremaining: 9.61s\n",
      "130:\tlearn: 0.6883860\ttotal: 1.45s\tremaining: 9.59s\n",
      "131:\tlearn: 0.6883674\ttotal: 1.46s\tremaining: 9.58s\n",
      "132:\tlearn: 0.6883167\ttotal: 1.47s\tremaining: 9.57s\n",
      "133:\tlearn: 0.6882969\ttotal: 1.48s\tremaining: 9.57s\n",
      "134:\tlearn: 0.6882803\ttotal: 1.49s\tremaining: 9.57s\n",
      "135:\tlearn: 0.6882336\ttotal: 1.5s\tremaining: 9.55s\n",
      "136:\tlearn: 0.6882166\ttotal: 1.51s\tremaining: 9.54s\n",
      "137:\tlearn: 0.6881985\ttotal: 1.52s\tremaining: 9.52s\n",
      "138:\tlearn: 0.6881821\ttotal: 1.53s\tremaining: 9.51s\n",
      "139:\tlearn: 0.6881640\ttotal: 1.55s\tremaining: 9.5s\n",
      "140:\tlearn: 0.6881467\ttotal: 1.56s\tremaining: 9.49s\n",
      "141:\tlearn: 0.6881300\ttotal: 1.57s\tremaining: 9.48s\n",
      "142:\tlearn: 0.6880672\ttotal: 1.58s\tremaining: 9.46s\n",
      "143:\tlearn: 0.6880476\ttotal: 1.59s\tremaining: 9.45s\n",
      "144:\tlearn: 0.6880303\ttotal: 1.6s\tremaining: 9.45s\n",
      "145:\tlearn: 0.6880127\ttotal: 1.61s\tremaining: 9.43s\n",
      "146:\tlearn: 0.6879945\ttotal: 1.62s\tremaining: 9.42s\n",
      "147:\tlearn: 0.6879766\ttotal: 1.64s\tremaining: 9.45s\n",
      "148:\tlearn: 0.6879593\ttotal: 1.66s\tremaining: 9.47s\n",
      "149:\tlearn: 0.6879136\ttotal: 1.67s\tremaining: 9.46s\n",
      "150:\tlearn: 0.6878963\ttotal: 1.68s\tremaining: 9.46s\n",
      "151:\tlearn: 0.6878537\ttotal: 1.69s\tremaining: 9.44s\n",
      "152:\tlearn: 0.6878364\ttotal: 1.7s\tremaining: 9.44s\n",
      "153:\tlearn: 0.6878188\ttotal: 1.72s\tremaining: 9.42s\n",
      "154:\tlearn: 0.6878030\ttotal: 1.73s\tremaining: 9.4s\n",
      "155:\tlearn: 0.6877877\ttotal: 1.74s\tremaining: 9.39s\n",
      "156:\tlearn: 0.6877724\ttotal: 1.75s\tremaining: 9.38s\n",
      "157:\tlearn: 0.6877539\ttotal: 1.76s\tremaining: 9.37s\n",
      "158:\tlearn: 0.6876913\ttotal: 1.77s\tremaining: 9.36s\n",
      "159:\tlearn: 0.6876736\ttotal: 1.78s\tremaining: 9.35s\n",
      "160:\tlearn: 0.6876569\ttotal: 1.79s\tremaining: 9.34s\n",
      "161:\tlearn: 0.6876416\ttotal: 1.8s\tremaining: 9.33s\n",
      "162:\tlearn: 0.6875959\ttotal: 1.81s\tremaining: 9.31s\n",
      "163:\tlearn: 0.6875344\ttotal: 1.82s\tremaining: 9.29s\n",
      "164:\tlearn: 0.6875195\ttotal: 1.83s\tremaining: 9.28s\n",
      "165:\tlearn: 0.6874593\ttotal: 1.84s\tremaining: 9.26s\n",
      "166:\tlearn: 0.6874432\ttotal: 1.85s\tremaining: 9.25s\n",
      "167:\tlearn: 0.6874263\ttotal: 1.87s\tremaining: 9.25s\n",
      "168:\tlearn: 0.6873615\ttotal: 1.88s\tremaining: 9.23s\n",
      "169:\tlearn: 0.6873463\ttotal: 1.89s\tremaining: 9.22s\n",
      "170:\tlearn: 0.6873295\ttotal: 1.9s\tremaining: 9.2s\n",
      "171:\tlearn: 0.6873138\ttotal: 1.91s\tremaining: 9.2s\n",
      "172:\tlearn: 0.6872979\ttotal: 1.92s\tremaining: 9.19s\n",
      "173:\tlearn: 0.6872828\ttotal: 1.93s\tremaining: 9.17s\n",
      "174:\tlearn: 0.6872674\ttotal: 1.94s\tremaining: 9.15s\n",
      "175:\tlearn: 0.6872511\ttotal: 1.95s\tremaining: 9.14s\n",
      "176:\tlearn: 0.6872343\ttotal: 1.96s\tremaining: 9.13s\n",
      "177:\tlearn: 0.6872199\ttotal: 1.98s\tremaining: 9.12s\n",
      "178:\tlearn: 0.6871849\ttotal: 1.99s\tremaining: 9.11s\n",
      "179:\tlearn: 0.6871686\ttotal: 2s\tremaining: 9.1s\n",
      "180:\tlearn: 0.6871528\ttotal: 2.01s\tremaining: 9.09s\n",
      "181:\tlearn: 0.6871382\ttotal: 2.02s\tremaining: 9.08s\n",
      "182:\tlearn: 0.6871246\ttotal: 2.03s\tremaining: 9.06s\n",
      "183:\tlearn: 0.6871094\ttotal: 2.04s\tremaining: 9.05s\n",
      "184:\tlearn: 0.6870943\ttotal: 2.05s\tremaining: 9.04s\n",
      "185:\tlearn: 0.6870792\ttotal: 2.06s\tremaining: 9.03s\n",
      "186:\tlearn: 0.6870649\ttotal: 2.08s\tremaining: 9.02s\n",
      "187:\tlearn: 0.6870502\ttotal: 2.09s\tremaining: 9.01s\n",
      "188:\tlearn: 0.6870085\ttotal: 2.1s\tremaining: 9s\n",
      "189:\tlearn: 0.6869933\ttotal: 2.11s\tremaining: 8.99s\n",
      "190:\tlearn: 0.6869817\ttotal: 2.12s\tremaining: 8.98s\n",
      "191:\tlearn: 0.6869666\ttotal: 2.13s\tremaining: 8.96s\n",
      "192:\tlearn: 0.6869125\ttotal: 2.15s\tremaining: 8.98s\n",
      "193:\tlearn: 0.6868978\ttotal: 2.17s\tremaining: 9s\n",
      "194:\tlearn: 0.6868856\ttotal: 2.18s\tremaining: 9s\n",
      "195:\tlearn: 0.6868337\ttotal: 2.19s\tremaining: 8.98s\n",
      "196:\tlearn: 0.6868196\ttotal: 2.21s\tremaining: 8.99s\n",
      "197:\tlearn: 0.6868048\ttotal: 2.23s\tremaining: 9.01s\n",
      "198:\tlearn: 0.6867905\ttotal: 2.24s\tremaining: 9.03s\n",
      "199:\tlearn: 0.6867553\ttotal: 2.26s\tremaining: 9.02s\n",
      "200:\tlearn: 0.6867406\ttotal: 2.27s\tremaining: 9.01s\n",
      "201:\tlearn: 0.6867263\ttotal: 2.28s\tremaining: 9.02s\n",
      "202:\tlearn: 0.6866663\ttotal: 2.3s\tremaining: 9.03s\n",
      "203:\tlearn: 0.6866524\ttotal: 2.31s\tremaining: 9.03s\n",
      "204:\tlearn: 0.6866351\ttotal: 2.33s\tremaining: 9.02s\n",
      "205:\tlearn: 0.6866212\ttotal: 2.34s\tremaining: 9.03s\n",
      "206:\tlearn: 0.6866071\ttotal: 2.36s\tremaining: 9.04s\n",
      "207:\tlearn: 0.6865928\ttotal: 2.37s\tremaining: 9.03s\n",
      "208:\tlearn: 0.6865778\ttotal: 2.39s\tremaining: 9.04s\n",
      "209:\tlearn: 0.6865624\ttotal: 2.4s\tremaining: 9.04s\n",
      "210:\tlearn: 0.6865495\ttotal: 2.42s\tremaining: 9.03s\n",
      "211:\tlearn: 0.6865340\ttotal: 2.43s\tremaining: 9.04s\n",
      "212:\tlearn: 0.6865199\ttotal: 2.45s\tremaining: 9.05s\n",
      "213:\tlearn: 0.6865060\ttotal: 2.47s\tremaining: 9.06s\n",
      "214:\tlearn: 0.6864526\ttotal: 2.48s\tremaining: 9.06s\n",
      "215:\tlearn: 0.6864383\ttotal: 2.5s\tremaining: 9.07s\n",
      "216:\tlearn: 0.6863870\ttotal: 2.52s\tremaining: 9.08s\n",
      "217:\tlearn: 0.6863727\ttotal: 2.53s\tremaining: 9.09s\n",
      "218:\tlearn: 0.6863239\ttotal: 2.55s\tremaining: 9.09s\n",
      "219:\tlearn: 0.6863096\ttotal: 2.57s\tremaining: 9.11s\n",
      "220:\tlearn: 0.6862964\ttotal: 2.58s\tremaining: 9.11s\n",
      "221:\tlearn: 0.6862815\ttotal: 2.6s\tremaining: 9.12s\n",
      "222:\tlearn: 0.6862676\ttotal: 2.62s\tremaining: 9.14s\n",
      "223:\tlearn: 0.6862538\ttotal: 2.64s\tremaining: 9.16s\n",
      "224:\tlearn: 0.6862228\ttotal: 2.66s\tremaining: 9.17s\n",
      "225:\tlearn: 0.6862093\ttotal: 2.68s\tremaining: 9.18s\n",
      "226:\tlearn: 0.6861946\ttotal: 2.7s\tremaining: 9.19s\n",
      "227:\tlearn: 0.6861468\ttotal: 2.72s\tremaining: 9.2s\n",
      "228:\tlearn: 0.6861347\ttotal: 2.73s\tremaining: 9.21s\n",
      "229:\tlearn: 0.6861207\ttotal: 2.75s\tremaining: 9.22s\n",
      "230:\tlearn: 0.6861063\ttotal: 2.77s\tremaining: 9.23s\n",
      "231:\tlearn: 0.6860908\ttotal: 2.79s\tremaining: 9.24s\n",
      "232:\tlearn: 0.6860775\ttotal: 2.81s\tremaining: 9.25s\n",
      "233:\tlearn: 0.6860425\ttotal: 2.83s\tremaining: 9.26s\n",
      "234:\tlearn: 0.6860289\ttotal: 2.85s\tremaining: 9.27s\n",
      "235:\tlearn: 0.6860152\ttotal: 2.86s\tremaining: 9.27s\n",
      "236:\tlearn: 0.6860005\ttotal: 2.88s\tremaining: 9.28s\n",
      "237:\tlearn: 0.6859508\ttotal: 2.9s\tremaining: 9.27s\n",
      "238:\tlearn: 0.6859385\ttotal: 2.91s\tremaining: 9.28s\n",
      "239:\tlearn: 0.6859252\ttotal: 2.93s\tremaining: 9.29s\n",
      "240:\tlearn: 0.6859132\ttotal: 2.95s\tremaining: 9.29s\n",
      "241:\tlearn: 0.6858662\ttotal: 2.97s\tremaining: 9.3s\n",
      "242:\tlearn: 0.6858292\ttotal: 2.98s\tremaining: 9.28s\n",
      "243:\tlearn: 0.6858156\ttotal: 3s\tremaining: 9.29s\n",
      "244:\tlearn: 0.6858035\ttotal: 3.02s\tremaining: 9.3s\n",
      "245:\tlearn: 0.6857910\ttotal: 3.03s\tremaining: 9.29s\n",
      "246:\tlearn: 0.6857772\ttotal: 3.04s\tremaining: 9.27s\n",
      "247:\tlearn: 0.6857638\ttotal: 3.06s\tremaining: 9.27s\n",
      "248:\tlearn: 0.6857504\ttotal: 3.08s\tremaining: 9.28s\n",
      "249:\tlearn: 0.6857380\ttotal: 3.1s\tremaining: 9.29s\n",
      "250:\tlearn: 0.6857253\ttotal: 3.12s\tremaining: 9.3s\n",
      "251:\tlearn: 0.6857119\ttotal: 3.13s\tremaining: 9.3s\n",
      "252:\tlearn: 0.6856995\ttotal: 3.15s\tremaining: 9.31s\n",
      "253:\tlearn: 0.6856865\ttotal: 3.17s\tremaining: 9.32s\n",
      "254:\tlearn: 0.6856733\ttotal: 3.19s\tremaining: 9.32s\n",
      "255:\tlearn: 0.6856607\ttotal: 3.21s\tremaining: 9.32s\n",
      "256:\tlearn: 0.6856485\ttotal: 3.23s\tremaining: 9.33s\n",
      "257:\tlearn: 0.6856351\ttotal: 3.25s\tremaining: 9.33s\n",
      "258:\tlearn: 0.6856213\ttotal: 3.26s\tremaining: 9.34s\n",
      "259:\tlearn: 0.6856088\ttotal: 3.28s\tremaining: 9.35s\n",
      "260:\tlearn: 0.6855635\ttotal: 3.3s\tremaining: 9.35s\n",
      "261:\tlearn: 0.6855514\ttotal: 3.31s\tremaining: 9.34s\n",
      "262:\tlearn: 0.6855376\ttotal: 3.33s\tremaining: 9.35s\n",
      "263:\tlearn: 0.6855005\ttotal: 3.35s\tremaining: 9.35s\n",
      "264:\tlearn: 0.6854879\ttotal: 3.37s\tremaining: 9.35s\n",
      "265:\tlearn: 0.6854749\ttotal: 3.39s\tremaining: 9.36s\n",
      "266:\tlearn: 0.6854588\ttotal: 3.41s\tremaining: 9.36s\n",
      "267:\tlearn: 0.6854465\ttotal: 3.43s\tremaining: 9.36s\n",
      "268:\tlearn: 0.6854337\ttotal: 3.45s\tremaining: 9.37s\n",
      "269:\tlearn: 0.6854216\ttotal: 3.46s\tremaining: 9.36s\n",
      "270:\tlearn: 0.6854094\ttotal: 3.48s\tremaining: 9.36s\n",
      "271:\tlearn: 0.6853966\ttotal: 3.5s\tremaining: 9.37s\n",
      "272:\tlearn: 0.6853838\ttotal: 3.52s\tremaining: 9.37s\n",
      "273:\tlearn: 0.6853723\ttotal: 3.54s\tremaining: 9.37s\n",
      "274:\tlearn: 0.6853596\ttotal: 3.55s\tremaining: 9.36s\n",
      "275:\tlearn: 0.6853479\ttotal: 3.57s\tremaining: 9.36s\n",
      "276:\tlearn: 0.6853363\ttotal: 3.59s\tremaining: 9.37s\n",
      "277:\tlearn: 0.6853241\ttotal: 3.61s\tremaining: 9.37s\n",
      "278:\tlearn: 0.6853118\ttotal: 3.63s\tremaining: 9.37s\n",
      "279:\tlearn: 0.6853002\ttotal: 3.64s\tremaining: 9.37s\n",
      "280:\tlearn: 0.6852573\ttotal: 3.66s\tremaining: 9.37s\n",
      "281:\tlearn: 0.6852460\ttotal: 3.68s\tremaining: 9.37s\n",
      "282:\tlearn: 0.6852330\ttotal: 3.7s\tremaining: 9.37s\n",
      "283:\tlearn: 0.6852219\ttotal: 3.72s\tremaining: 9.37s\n",
      "284:\tlearn: 0.6852092\ttotal: 3.74s\tremaining: 9.37s\n",
      "285:\tlearn: 0.6851972\ttotal: 3.75s\tremaining: 9.36s\n",
      "286:\tlearn: 0.6851872\ttotal: 3.76s\tremaining: 9.35s\n",
      "287:\tlearn: 0.6851754\ttotal: 3.78s\tremaining: 9.34s\n",
      "288:\tlearn: 0.6851631\ttotal: 3.8s\tremaining: 9.35s\n",
      "289:\tlearn: 0.6851499\ttotal: 3.82s\tremaining: 9.34s\n",
      "290:\tlearn: 0.6851380\ttotal: 3.83s\tremaining: 9.33s\n",
      "291:\tlearn: 0.6851258\ttotal: 3.85s\tremaining: 9.33s\n",
      "292:\tlearn: 0.6851133\ttotal: 3.87s\tremaining: 9.34s\n",
      "293:\tlearn: 0.6850685\ttotal: 3.89s\tremaining: 9.33s\n",
      "294:\tlearn: 0.6850545\ttotal: 3.9s\tremaining: 9.31s\n",
      "295:\tlearn: 0.6850434\ttotal: 3.91s\tremaining: 9.29s\n",
      "296:\tlearn: 0.6850315\ttotal: 3.92s\tremaining: 9.29s\n",
      "297:\tlearn: 0.6850195\ttotal: 3.94s\tremaining: 9.29s\n",
      "298:\tlearn: 0.6850079\ttotal: 3.95s\tremaining: 9.27s\n",
      "299:\tlearn: 0.6849632\ttotal: 3.96s\tremaining: 9.25s\n",
      "300:\tlearn: 0.6849515\ttotal: 3.97s\tremaining: 9.23s\n",
      "301:\tlearn: 0.6849405\ttotal: 3.99s\tremaining: 9.21s\n",
      "302:\tlearn: 0.6849277\ttotal: 4s\tremaining: 9.2s\n",
      "303:\tlearn: 0.6849160\ttotal: 4.01s\tremaining: 9.18s\n",
      "304:\tlearn: 0.6849048\ttotal: 4.03s\tremaining: 9.18s\n",
      "305:\tlearn: 0.6848899\ttotal: 4.04s\tremaining: 9.16s\n",
      "306:\tlearn: 0.6848782\ttotal: 4.05s\tremaining: 9.14s\n",
      "307:\tlearn: 0.6848677\ttotal: 4.06s\tremaining: 9.12s\n",
      "308:\tlearn: 0.6848271\ttotal: 4.07s\tremaining: 9.11s\n",
      "309:\tlearn: 0.6848167\ttotal: 4.09s\tremaining: 9.11s\n",
      "310:\tlearn: 0.6848046\ttotal: 4.11s\tremaining: 9.1s\n",
      "311:\tlearn: 0.6847694\ttotal: 4.12s\tremaining: 9.08s\n",
      "312:\tlearn: 0.6847351\ttotal: 4.13s\tremaining: 9.08s\n",
      "313:\tlearn: 0.6847010\ttotal: 4.15s\tremaining: 9.07s\n",
      "314:\tlearn: 0.6846891\ttotal: 4.16s\tremaining: 9.06s\n",
      "315:\tlearn: 0.6846772\ttotal: 4.17s\tremaining: 9.04s\n",
      "316:\tlearn: 0.6846658\ttotal: 4.18s\tremaining: 9.02s\n",
      "317:\tlearn: 0.6846537\ttotal: 4.2s\tremaining: 9s\n",
      "318:\tlearn: 0.6846430\ttotal: 4.21s\tremaining: 8.98s\n",
      "319:\tlearn: 0.6846286\ttotal: 4.22s\tremaining: 8.96s\n",
      "320:\tlearn: 0.6846173\ttotal: 4.23s\tremaining: 8.94s\n",
      "321:\tlearn: 0.6846068\ttotal: 4.24s\tremaining: 8.92s\n",
      "322:\tlearn: 0.6845940\ttotal: 4.25s\tremaining: 8.91s\n",
      "323:\tlearn: 0.6845831\ttotal: 4.27s\tremaining: 8.9s\n",
      "324:\tlearn: 0.6845718\ttotal: 4.28s\tremaining: 8.89s\n",
      "325:\tlearn: 0.6845449\ttotal: 4.29s\tremaining: 8.87s\n",
      "326:\tlearn: 0.6845332\ttotal: 4.3s\tremaining: 8.86s\n",
      "327:\tlearn: 0.6845217\ttotal: 4.31s\tremaining: 8.84s\n",
      "328:\tlearn: 0.6845109\ttotal: 4.33s\tremaining: 8.82s\n",
      "329:\tlearn: 0.6844998\ttotal: 4.34s\tremaining: 8.81s\n",
      "330:\tlearn: 0.6844892\ttotal: 4.36s\tremaining: 8.81s\n",
      "331:\tlearn: 0.6844782\ttotal: 4.37s\tremaining: 8.79s\n",
      "332:\tlearn: 0.6844680\ttotal: 4.38s\tremaining: 8.77s\n",
      "333:\tlearn: 0.6844314\ttotal: 4.39s\tremaining: 8.75s\n",
      "334:\tlearn: 0.6843893\ttotal: 4.4s\tremaining: 8.73s\n",
      "335:\tlearn: 0.6843776\ttotal: 4.41s\tremaining: 8.72s\n",
      "336:\tlearn: 0.6843662\ttotal: 4.43s\tremaining: 8.71s\n",
      "337:\tlearn: 0.6843557\ttotal: 4.44s\tremaining: 8.7s\n",
      "338:\tlearn: 0.6843260\ttotal: 4.46s\tremaining: 8.69s\n",
      "339:\tlearn: 0.6843159\ttotal: 4.46s\tremaining: 8.67s\n",
      "340:\tlearn: 0.6843064\ttotal: 4.48s\tremaining: 8.65s\n",
      "341:\tlearn: 0.6842952\ttotal: 4.49s\tremaining: 8.64s\n",
      "342:\tlearn: 0.6842696\ttotal: 4.5s\tremaining: 8.62s\n",
      "343:\tlearn: 0.6842595\ttotal: 4.51s\tremaining: 8.6s\n",
      "344:\tlearn: 0.6842319\ttotal: 4.52s\tremaining: 8.59s\n",
      "345:\tlearn: 0.6842214\ttotal: 4.54s\tremaining: 8.57s\n",
      "346:\tlearn: 0.6842109\ttotal: 4.55s\tremaining: 8.56s\n",
      "347:\tlearn: 0.6842000\ttotal: 4.57s\tremaining: 8.56s\n",
      "348:\tlearn: 0.6841473\ttotal: 4.58s\tremaining: 8.54s\n",
      "349:\tlearn: 0.6841369\ttotal: 4.59s\tremaining: 8.53s\n",
      "350:\tlearn: 0.6841246\ttotal: 4.6s\tremaining: 8.51s\n",
      "351:\tlearn: 0.6841139\ttotal: 4.61s\tremaining: 8.49s\n",
      "352:\tlearn: 0.6841011\ttotal: 4.63s\tremaining: 8.48s\n",
      "353:\tlearn: 0.6840908\ttotal: 4.64s\tremaining: 8.46s\n",
      "354:\tlearn: 0.6840806\ttotal: 4.65s\tremaining: 8.44s\n",
      "355:\tlearn: 0.6840700\ttotal: 4.66s\tremaining: 8.43s\n",
      "356:\tlearn: 0.6840591\ttotal: 4.67s\tremaining: 8.41s\n",
      "357:\tlearn: 0.6840471\ttotal: 4.69s\tremaining: 8.4s\n",
      "358:\tlearn: 0.6840039\ttotal: 4.7s\tremaining: 8.39s\n",
      "359:\tlearn: 0.6839928\ttotal: 4.71s\tremaining: 8.38s\n",
      "360:\tlearn: 0.6839824\ttotal: 4.72s\tremaining: 8.36s\n",
      "361:\tlearn: 0.6839716\ttotal: 4.73s\tremaining: 8.34s\n",
      "362:\tlearn: 0.6839612\ttotal: 4.75s\tremaining: 8.33s\n",
      "363:\tlearn: 0.6839498\ttotal: 4.76s\tremaining: 8.31s\n",
      "364:\tlearn: 0.6839381\ttotal: 4.77s\tremaining: 8.29s\n",
      "365:\tlearn: 0.6839267\ttotal: 4.78s\tremaining: 8.28s\n",
      "366:\tlearn: 0.6839163\ttotal: 4.79s\tremaining: 8.26s\n",
      "367:\tlearn: 0.6839066\ttotal: 4.8s\tremaining: 8.24s\n",
      "368:\tlearn: 0.6838960\ttotal: 4.81s\tremaining: 8.23s\n",
      "369:\tlearn: 0.6838556\ttotal: 4.82s\tremaining: 8.21s\n",
      "370:\tlearn: 0.6838457\ttotal: 4.83s\tremaining: 8.19s\n",
      "371:\tlearn: 0.6838363\ttotal: 4.84s\tremaining: 8.17s\n",
      "372:\tlearn: 0.6838260\ttotal: 4.85s\tremaining: 8.16s\n",
      "373:\tlearn: 0.6838162\ttotal: 4.86s\tremaining: 8.14s\n",
      "374:\tlearn: 0.6837796\ttotal: 4.87s\tremaining: 8.12s\n",
      "375:\tlearn: 0.6837407\ttotal: 4.88s\tremaining: 8.11s\n",
      "376:\tlearn: 0.6837304\ttotal: 4.89s\tremaining: 8.09s\n",
      "377:\tlearn: 0.6837010\ttotal: 4.91s\tremaining: 8.07s\n",
      "378:\tlearn: 0.6836453\ttotal: 4.92s\tremaining: 8.05s\n",
      "379:\tlearn: 0.6836362\ttotal: 4.93s\tremaining: 8.04s\n",
      "380:\tlearn: 0.6835870\ttotal: 4.94s\tremaining: 8.02s\n",
      "381:\tlearn: 0.6835787\ttotal: 4.95s\tremaining: 8s\n",
      "382:\tlearn: 0.6835638\ttotal: 4.96s\tremaining: 7.99s\n",
      "383:\tlearn: 0.6835539\ttotal: 4.97s\tremaining: 7.97s\n",
      "384:\tlearn: 0.6835440\ttotal: 4.98s\tremaining: 7.96s\n",
      "385:\tlearn: 0.6835339\ttotal: 4.99s\tremaining: 7.94s\n",
      "386:\tlearn: 0.6835232\ttotal: 5s\tremaining: 7.93s\n",
      "387:\tlearn: 0.6835099\ttotal: 5.02s\tremaining: 7.92s\n",
      "388:\tlearn: 0.6834741\ttotal: 5.03s\tremaining: 7.9s\n",
      "389:\tlearn: 0.6834635\ttotal: 5.04s\tremaining: 7.88s\n",
      "390:\tlearn: 0.6834533\ttotal: 5.05s\tremaining: 7.87s\n",
      "391:\tlearn: 0.6833855\ttotal: 5.07s\tremaining: 7.87s\n",
      "392:\tlearn: 0.6833749\ttotal: 5.09s\tremaining: 7.87s\n",
      "393:\tlearn: 0.6833663\ttotal: 5.11s\tremaining: 7.86s\n",
      "394:\tlearn: 0.6833563\ttotal: 5.13s\tremaining: 7.86s\n",
      "395:\tlearn: 0.6833472\ttotal: 5.15s\tremaining: 7.85s\n",
      "396:\tlearn: 0.6833368\ttotal: 5.16s\tremaining: 7.84s\n",
      "397:\tlearn: 0.6833269\ttotal: 5.18s\tremaining: 7.84s\n",
      "398:\tlearn: 0.6833164\ttotal: 5.2s\tremaining: 7.83s\n",
      "399:\tlearn: 0.6833065\ttotal: 5.21s\tremaining: 7.81s\n",
      "400:\tlearn: 0.6832780\ttotal: 5.22s\tremaining: 7.79s\n",
      "401:\tlearn: 0.6832691\ttotal: 5.23s\tremaining: 7.78s\n",
      "402:\tlearn: 0.6832585\ttotal: 5.24s\tremaining: 7.76s\n",
      "403:\tlearn: 0.6832485\ttotal: 5.25s\tremaining: 7.75s\n",
      "404:\tlearn: 0.6832154\ttotal: 5.26s\tremaining: 7.73s\n",
      "405:\tlearn: 0.6832052\ttotal: 5.27s\tremaining: 7.71s\n",
      "406:\tlearn: 0.6831951\ttotal: 5.28s\tremaining: 7.7s\n",
      "407:\tlearn: 0.6831856\ttotal: 5.29s\tremaining: 7.68s\n",
      "408:\tlearn: 0.6831756\ttotal: 5.3s\tremaining: 7.67s\n",
      "409:\tlearn: 0.6831660\ttotal: 5.32s\tremaining: 7.65s\n",
      "410:\tlearn: 0.6831563\ttotal: 5.33s\tremaining: 7.63s\n",
      "411:\tlearn: 0.6831469\ttotal: 5.34s\tremaining: 7.62s\n",
      "412:\tlearn: 0.6831380\ttotal: 5.35s\tremaining: 7.6s\n",
      "413:\tlearn: 0.6831270\ttotal: 5.36s\tremaining: 7.58s\n",
      "414:\tlearn: 0.6831174\ttotal: 5.37s\tremaining: 7.57s\n",
      "415:\tlearn: 0.6831085\ttotal: 5.39s\tremaining: 7.57s\n",
      "416:\tlearn: 0.6830862\ttotal: 5.4s\tremaining: 7.55s\n",
      "417:\tlearn: 0.6830761\ttotal: 5.41s\tremaining: 7.54s\n",
      "418:\tlearn: 0.6830658\ttotal: 5.42s\tremaining: 7.52s\n",
      "419:\tlearn: 0.6830312\ttotal: 5.43s\tremaining: 7.5s\n",
      "420:\tlearn: 0.6830210\ttotal: 5.45s\tremaining: 7.49s\n",
      "421:\tlearn: 0.6830113\ttotal: 5.46s\tremaining: 7.48s\n",
      "422:\tlearn: 0.6829844\ttotal: 5.48s\tremaining: 7.48s\n",
      "423:\tlearn: 0.6829747\ttotal: 5.5s\tremaining: 7.47s\n",
      "424:\tlearn: 0.6829651\ttotal: 5.51s\tremaining: 7.45s\n",
      "425:\tlearn: 0.6829560\ttotal: 5.52s\tremaining: 7.44s\n",
      "426:\tlearn: 0.6829480\ttotal: 5.53s\tremaining: 7.42s\n",
      "427:\tlearn: 0.6829402\ttotal: 5.54s\tremaining: 7.41s\n",
      "428:\tlearn: 0.6828912\ttotal: 5.55s\tremaining: 7.39s\n",
      "429:\tlearn: 0.6828814\ttotal: 5.57s\tremaining: 7.38s\n",
      "430:\tlearn: 0.6828718\ttotal: 5.58s\tremaining: 7.36s\n",
      "431:\tlearn: 0.6828626\ttotal: 5.59s\tremaining: 7.34s\n",
      "432:\tlearn: 0.6828527\ttotal: 5.6s\tremaining: 7.33s\n",
      "433:\tlearn: 0.6828435\ttotal: 5.61s\tremaining: 7.31s\n",
      "434:\tlearn: 0.6828356\ttotal: 5.62s\tremaining: 7.3s\n",
      "435:\tlearn: 0.6828096\ttotal: 5.63s\tremaining: 7.28s\n",
      "436:\tlearn: 0.6828002\ttotal: 5.64s\tremaining: 7.26s\n",
      "437:\tlearn: 0.6827907\ttotal: 5.65s\tremaining: 7.25s\n",
      "438:\tlearn: 0.6827814\ttotal: 5.66s\tremaining: 7.23s\n",
      "439:\tlearn: 0.6827714\ttotal: 5.67s\tremaining: 7.22s\n",
      "440:\tlearn: 0.6827473\ttotal: 5.68s\tremaining: 7.2s\n",
      "441:\tlearn: 0.6827368\ttotal: 5.69s\tremaining: 7.19s\n",
      "442:\tlearn: 0.6827286\ttotal: 5.7s\tremaining: 7.17s\n",
      "443:\tlearn: 0.6827013\ttotal: 5.71s\tremaining: 7.16s\n",
      "444:\tlearn: 0.6826935\ttotal: 5.72s\tremaining: 7.14s\n",
      "445:\tlearn: 0.6826504\ttotal: 5.73s\tremaining: 7.12s\n",
      "446:\tlearn: 0.6826414\ttotal: 5.75s\tremaining: 7.11s\n",
      "447:\tlearn: 0.6826312\ttotal: 5.76s\tremaining: 7.1s\n",
      "448:\tlearn: 0.6826041\ttotal: 5.77s\tremaining: 7.08s\n",
      "449:\tlearn: 0.6825788\ttotal: 5.78s\tremaining: 7.07s\n",
      "450:\tlearn: 0.6825693\ttotal: 5.79s\tremaining: 7.05s\n",
      "451:\tlearn: 0.6825450\ttotal: 5.8s\tremaining: 7.04s\n",
      "452:\tlearn: 0.6825358\ttotal: 5.81s\tremaining: 7.02s\n",
      "453:\tlearn: 0.6825271\ttotal: 5.82s\tremaining: 7s\n",
      "454:\tlearn: 0.6825052\ttotal: 5.83s\tremaining: 6.99s\n",
      "455:\tlearn: 0.6824961\ttotal: 5.84s\tremaining: 6.97s\n",
      "456:\tlearn: 0.6824874\ttotal: 5.85s\tremaining: 6.96s\n",
      "457:\tlearn: 0.6824524\ttotal: 5.86s\tremaining: 6.94s\n",
      "458:\tlearn: 0.6824111\ttotal: 5.88s\tremaining: 6.92s\n",
      "459:\tlearn: 0.6824027\ttotal: 5.89s\tremaining: 6.91s\n",
      "460:\tlearn: 0.6823932\ttotal: 5.9s\tremaining: 6.9s\n",
      "461:\tlearn: 0.6823846\ttotal: 5.91s\tremaining: 6.88s\n",
      "462:\tlearn: 0.6823664\ttotal: 5.92s\tremaining: 6.87s\n",
      "463:\tlearn: 0.6823388\ttotal: 5.93s\tremaining: 6.85s\n",
      "464:\tlearn: 0.6823169\ttotal: 5.94s\tremaining: 6.84s\n",
      "465:\tlearn: 0.6823070\ttotal: 5.95s\tremaining: 6.82s\n",
      "466:\tlearn: 0.6822857\ttotal: 5.96s\tremaining: 6.8s\n",
      "467:\tlearn: 0.6822760\ttotal: 5.97s\tremaining: 6.79s\n",
      "468:\tlearn: 0.6822524\ttotal: 5.99s\tremaining: 6.78s\n",
      "469:\tlearn: 0.6822324\ttotal: 6s\tremaining: 6.77s\n",
      "470:\tlearn: 0.6822229\ttotal: 6.01s\tremaining: 6.75s\n",
      "471:\tlearn: 0.6822141\ttotal: 6.02s\tremaining: 6.74s\n",
      "472:\tlearn: 0.6821966\ttotal: 6.03s\tremaining: 6.72s\n",
      "473:\tlearn: 0.6821874\ttotal: 6.04s\tremaining: 6.71s\n",
      "474:\tlearn: 0.6821792\ttotal: 6.06s\tremaining: 6.69s\n",
      "475:\tlearn: 0.6821533\ttotal: 6.07s\tremaining: 6.68s\n",
      "476:\tlearn: 0.6821452\ttotal: 6.08s\tremaining: 6.67s\n",
      "477:\tlearn: 0.6821370\ttotal: 6.09s\tremaining: 6.65s\n",
      "478:\tlearn: 0.6821285\ttotal: 6.1s\tremaining: 6.64s\n",
      "479:\tlearn: 0.6820880\ttotal: 6.11s\tremaining: 6.62s\n",
      "480:\tlearn: 0.6820675\ttotal: 6.12s\tremaining: 6.61s\n",
      "481:\tlearn: 0.6820581\ttotal: 6.13s\tremaining: 6.59s\n",
      "482:\tlearn: 0.6820492\ttotal: 6.14s\tremaining: 6.58s\n",
      "483:\tlearn: 0.6820410\ttotal: 6.15s\tremaining: 6.56s\n",
      "484:\tlearn: 0.6820013\ttotal: 6.16s\tremaining: 6.55s\n",
      "485:\tlearn: 0.6819944\ttotal: 6.17s\tremaining: 6.53s\n",
      "486:\tlearn: 0.6819855\ttotal: 6.18s\tremaining: 6.52s\n",
      "487:\tlearn: 0.6819771\ttotal: 6.2s\tremaining: 6.5s\n",
      "488:\tlearn: 0.6819687\ttotal: 6.21s\tremaining: 6.49s\n",
      "489:\tlearn: 0.6819597\ttotal: 6.22s\tremaining: 6.47s\n",
      "490:\tlearn: 0.6819501\ttotal: 6.23s\tremaining: 6.46s\n",
      "491:\tlearn: 0.6819410\ttotal: 6.24s\tremaining: 6.44s\n",
      "492:\tlearn: 0.6819321\ttotal: 6.25s\tremaining: 6.43s\n",
      "493:\tlearn: 0.6819239\ttotal: 6.26s\tremaining: 6.41s\n",
      "494:\tlearn: 0.6818863\ttotal: 6.27s\tremaining: 6.4s\n",
      "495:\tlearn: 0.6818788\ttotal: 6.28s\tremaining: 6.38s\n",
      "496:\tlearn: 0.6818713\ttotal: 6.29s\tremaining: 6.37s\n",
      "497:\tlearn: 0.6818466\ttotal: 6.3s\tremaining: 6.36s\n",
      "498:\tlearn: 0.6818380\ttotal: 6.32s\tremaining: 6.34s\n",
      "499:\tlearn: 0.6818290\ttotal: 6.33s\tremaining: 6.33s\n",
      "500:\tlearn: 0.6818196\ttotal: 6.34s\tremaining: 6.31s\n",
      "501:\tlearn: 0.6818118\ttotal: 6.35s\tremaining: 6.3s\n",
      "502:\tlearn: 0.6818012\ttotal: 6.36s\tremaining: 6.29s\n",
      "503:\tlearn: 0.6817921\ttotal: 6.37s\tremaining: 6.27s\n",
      "504:\tlearn: 0.6817833\ttotal: 6.38s\tremaining: 6.26s\n",
      "505:\tlearn: 0.6817738\ttotal: 6.39s\tremaining: 6.24s\n",
      "506:\tlearn: 0.6817668\ttotal: 6.41s\tremaining: 6.23s\n",
      "507:\tlearn: 0.6817573\ttotal: 6.42s\tremaining: 6.22s\n",
      "508:\tlearn: 0.6817486\ttotal: 6.43s\tremaining: 6.2s\n",
      "509:\tlearn: 0.6817404\ttotal: 6.44s\tremaining: 6.19s\n",
      "510:\tlearn: 0.6817324\ttotal: 6.45s\tremaining: 6.17s\n",
      "511:\tlearn: 0.6817238\ttotal: 6.46s\tremaining: 6.16s\n",
      "512:\tlearn: 0.6817123\ttotal: 6.47s\tremaining: 6.14s\n",
      "513:\tlearn: 0.6817033\ttotal: 6.48s\tremaining: 6.13s\n",
      "514:\tlearn: 0.6816929\ttotal: 6.5s\tremaining: 6.12s\n",
      "515:\tlearn: 0.6816848\ttotal: 6.51s\tremaining: 6.1s\n",
      "516:\tlearn: 0.6816768\ttotal: 6.52s\tremaining: 6.09s\n",
      "517:\tlearn: 0.6816677\ttotal: 6.53s\tremaining: 6.07s\n",
      "518:\tlearn: 0.6816590\ttotal: 6.54s\tremaining: 6.06s\n",
      "519:\tlearn: 0.6816509\ttotal: 6.55s\tremaining: 6.04s\n",
      "520:\tlearn: 0.6816433\ttotal: 6.56s\tremaining: 6.03s\n",
      "521:\tlearn: 0.6816347\ttotal: 6.57s\tremaining: 6.02s\n",
      "522:\tlearn: 0.6816272\ttotal: 6.58s\tremaining: 6s\n",
      "523:\tlearn: 0.6816179\ttotal: 6.59s\tremaining: 5.99s\n",
      "524:\tlearn: 0.6816097\ttotal: 6.6s\tremaining: 5.97s\n",
      "525:\tlearn: 0.6816020\ttotal: 6.61s\tremaining: 5.96s\n",
      "526:\tlearn: 0.6815680\ttotal: 6.62s\tremaining: 5.94s\n",
      "527:\tlearn: 0.6815379\ttotal: 6.63s\tremaining: 5.93s\n",
      "528:\tlearn: 0.6815303\ttotal: 6.64s\tremaining: 5.91s\n",
      "529:\tlearn: 0.6815222\ttotal: 6.65s\tremaining: 5.9s\n",
      "530:\tlearn: 0.6815154\ttotal: 6.66s\tremaining: 5.88s\n",
      "531:\tlearn: 0.6815057\ttotal: 6.67s\tremaining: 5.87s\n",
      "532:\tlearn: 0.6814990\ttotal: 6.68s\tremaining: 5.86s\n",
      "533:\tlearn: 0.6814758\ttotal: 6.69s\tremaining: 5.84s\n",
      "534:\tlearn: 0.6814474\ttotal: 6.7s\tremaining: 5.83s\n",
      "535:\tlearn: 0.6814391\ttotal: 6.71s\tremaining: 5.81s\n",
      "536:\tlearn: 0.6814317\ttotal: 6.72s\tremaining: 5.8s\n",
      "537:\tlearn: 0.6814234\ttotal: 6.73s\tremaining: 5.78s\n",
      "538:\tlearn: 0.6814011\ttotal: 6.74s\tremaining: 5.77s\n",
      "539:\tlearn: 0.6813931\ttotal: 6.75s\tremaining: 5.75s\n",
      "540:\tlearn: 0.6813849\ttotal: 6.76s\tremaining: 5.74s\n",
      "541:\tlearn: 0.6813760\ttotal: 6.77s\tremaining: 5.72s\n",
      "542:\tlearn: 0.6813670\ttotal: 6.79s\tremaining: 5.71s\n",
      "543:\tlearn: 0.6813546\ttotal: 6.8s\tremaining: 5.7s\n",
      "544:\tlearn: 0.6813479\ttotal: 6.81s\tremaining: 5.68s\n",
      "545:\tlearn: 0.6813182\ttotal: 6.82s\tremaining: 5.67s\n",
      "546:\tlearn: 0.6813094\ttotal: 6.83s\tremaining: 5.66s\n",
      "547:\tlearn: 0.6813015\ttotal: 6.84s\tremaining: 5.64s\n",
      "548:\tlearn: 0.6812416\ttotal: 6.85s\tremaining: 5.63s\n",
      "549:\tlearn: 0.6812335\ttotal: 6.86s\tremaining: 5.62s\n",
      "550:\tlearn: 0.6812260\ttotal: 6.88s\tremaining: 5.6s\n",
      "551:\tlearn: 0.6812176\ttotal: 6.89s\tremaining: 5.59s\n",
      "552:\tlearn: 0.6812099\ttotal: 6.9s\tremaining: 5.58s\n",
      "553:\tlearn: 0.6812026\ttotal: 6.91s\tremaining: 5.56s\n",
      "554:\tlearn: 0.6811938\ttotal: 6.92s\tremaining: 5.55s\n",
      "555:\tlearn: 0.6811857\ttotal: 6.93s\tremaining: 5.54s\n",
      "556:\tlearn: 0.6811767\ttotal: 6.94s\tremaining: 5.52s\n",
      "557:\tlearn: 0.6811685\ttotal: 6.96s\tremaining: 5.51s\n",
      "558:\tlearn: 0.6811609\ttotal: 6.98s\tremaining: 5.51s\n",
      "559:\tlearn: 0.6811525\ttotal: 6.99s\tremaining: 5.49s\n",
      "560:\tlearn: 0.6811451\ttotal: 7s\tremaining: 5.48s\n",
      "561:\tlearn: 0.6811363\ttotal: 7.01s\tremaining: 5.47s\n",
      "562:\tlearn: 0.6811286\ttotal: 7.03s\tremaining: 5.45s\n",
      "563:\tlearn: 0.6811194\ttotal: 7.04s\tremaining: 5.44s\n",
      "564:\tlearn: 0.6811111\ttotal: 7.05s\tremaining: 5.43s\n",
      "565:\tlearn: 0.6811031\ttotal: 7.06s\tremaining: 5.42s\n",
      "566:\tlearn: 0.6810950\ttotal: 7.07s\tremaining: 5.4s\n",
      "567:\tlearn: 0.6810874\ttotal: 7.08s\tremaining: 5.39s\n",
      "568:\tlearn: 0.6810792\ttotal: 7.1s\tremaining: 5.38s\n",
      "569:\tlearn: 0.6810714\ttotal: 7.11s\tremaining: 5.36s\n",
      "570:\tlearn: 0.6810631\ttotal: 7.12s\tremaining: 5.35s\n",
      "571:\tlearn: 0.6810349\ttotal: 7.13s\tremaining: 5.33s\n",
      "572:\tlearn: 0.6810271\ttotal: 7.14s\tremaining: 5.32s\n",
      "573:\tlearn: 0.6810192\ttotal: 7.15s\tremaining: 5.31s\n",
      "574:\tlearn: 0.6810086\ttotal: 7.16s\tremaining: 5.29s\n",
      "575:\tlearn: 0.6810012\ttotal: 7.17s\tremaining: 5.28s\n",
      "576:\tlearn: 0.6809936\ttotal: 7.18s\tremaining: 5.26s\n",
      "577:\tlearn: 0.6809856\ttotal: 7.19s\tremaining: 5.25s\n",
      "578:\tlearn: 0.6809775\ttotal: 7.2s\tremaining: 5.24s\n",
      "579:\tlearn: 0.6809520\ttotal: 7.21s\tremaining: 5.22s\n",
      "580:\tlearn: 0.6809438\ttotal: 7.22s\tremaining: 5.21s\n",
      "581:\tlearn: 0.6809351\ttotal: 7.24s\tremaining: 5.2s\n",
      "582:\tlearn: 0.6808986\ttotal: 7.25s\tremaining: 5.18s\n",
      "583:\tlearn: 0.6808893\ttotal: 7.26s\tremaining: 5.17s\n",
      "584:\tlearn: 0.6808806\ttotal: 7.27s\tremaining: 5.16s\n",
      "585:\tlearn: 0.6808487\ttotal: 7.28s\tremaining: 5.14s\n",
      "586:\tlearn: 0.6808410\ttotal: 7.29s\tremaining: 5.13s\n",
      "587:\tlearn: 0.6808333\ttotal: 7.3s\tremaining: 5.12s\n",
      "588:\tlearn: 0.6808259\ttotal: 7.31s\tremaining: 5.1s\n",
      "589:\tlearn: 0.6808180\ttotal: 7.32s\tremaining: 5.09s\n",
      "590:\tlearn: 0.6807878\ttotal: 7.33s\tremaining: 5.08s\n",
      "591:\tlearn: 0.6807799\ttotal: 7.35s\tremaining: 5.06s\n",
      "592:\tlearn: 0.6807722\ttotal: 7.36s\tremaining: 5.05s\n",
      "593:\tlearn: 0.6807642\ttotal: 7.37s\tremaining: 5.04s\n",
      "594:\tlearn: 0.6807563\ttotal: 7.38s\tremaining: 5.02s\n",
      "595:\tlearn: 0.6807483\ttotal: 7.39s\tremaining: 5.01s\n",
      "596:\tlearn: 0.6807400\ttotal: 7.41s\tremaining: 5s\n",
      "597:\tlearn: 0.6807300\ttotal: 7.42s\tremaining: 4.99s\n",
      "598:\tlearn: 0.6807219\ttotal: 7.43s\tremaining: 4.97s\n",
      "599:\tlearn: 0.6807129\ttotal: 7.45s\tremaining: 4.96s\n",
      "600:\tlearn: 0.6806843\ttotal: 7.46s\tremaining: 4.95s\n",
      "601:\tlearn: 0.6806742\ttotal: 7.47s\tremaining: 4.94s\n",
      "602:\tlearn: 0.6806667\ttotal: 7.48s\tremaining: 4.92s\n",
      "603:\tlearn: 0.6806596\ttotal: 7.49s\tremaining: 4.91s\n",
      "604:\tlearn: 0.6806517\ttotal: 7.5s\tremaining: 4.9s\n",
      "605:\tlearn: 0.6806436\ttotal: 7.51s\tremaining: 4.88s\n",
      "606:\tlearn: 0.6806362\ttotal: 7.52s\tremaining: 4.87s\n",
      "607:\tlearn: 0.6806085\ttotal: 7.53s\tremaining: 4.86s\n",
      "608:\tlearn: 0.6805782\ttotal: 7.54s\tremaining: 4.84s\n",
      "609:\tlearn: 0.6805699\ttotal: 7.55s\tremaining: 4.83s\n",
      "610:\tlearn: 0.6805626\ttotal: 7.57s\tremaining: 4.82s\n",
      "611:\tlearn: 0.6805548\ttotal: 7.58s\tremaining: 4.8s\n",
      "612:\tlearn: 0.6805476\ttotal: 7.58s\tremaining: 4.79s\n",
      "613:\tlearn: 0.6805400\ttotal: 7.6s\tremaining: 4.78s\n",
      "614:\tlearn: 0.6805314\ttotal: 7.61s\tremaining: 4.76s\n",
      "615:\tlearn: 0.6805232\ttotal: 7.62s\tremaining: 4.75s\n",
      "616:\tlearn: 0.6805162\ttotal: 7.63s\tremaining: 4.74s\n",
      "617:\tlearn: 0.6805093\ttotal: 7.64s\tremaining: 4.72s\n",
      "618:\tlearn: 0.6805010\ttotal: 7.65s\tremaining: 4.71s\n",
      "619:\tlearn: 0.6804830\ttotal: 7.66s\tremaining: 4.7s\n",
      "620:\tlearn: 0.6804747\ttotal: 7.67s\tremaining: 4.68s\n",
      "621:\tlearn: 0.6804670\ttotal: 7.68s\tremaining: 4.67s\n",
      "622:\tlearn: 0.6804587\ttotal: 7.69s\tremaining: 4.66s\n",
      "623:\tlearn: 0.6804508\ttotal: 7.71s\tremaining: 4.64s\n",
      "624:\tlearn: 0.6804425\ttotal: 7.71s\tremaining: 4.63s\n",
      "625:\tlearn: 0.6804339\ttotal: 7.72s\tremaining: 4.62s\n",
      "626:\tlearn: 0.6804270\ttotal: 7.74s\tremaining: 4.6s\n",
      "627:\tlearn: 0.6804197\ttotal: 7.75s\tremaining: 4.59s\n",
      "628:\tlearn: 0.6804110\ttotal: 7.76s\tremaining: 4.58s\n",
      "629:\tlearn: 0.6804041\ttotal: 7.77s\tremaining: 4.56s\n",
      "630:\tlearn: 0.6803963\ttotal: 7.78s\tremaining: 4.55s\n",
      "631:\tlearn: 0.6803875\ttotal: 7.79s\tremaining: 4.54s\n",
      "632:\tlearn: 0.6803800\ttotal: 7.8s\tremaining: 4.52s\n",
      "633:\tlearn: 0.6803726\ttotal: 7.81s\tremaining: 4.51s\n",
      "634:\tlearn: 0.6803655\ttotal: 7.82s\tremaining: 4.5s\n",
      "635:\tlearn: 0.6803582\ttotal: 7.83s\tremaining: 4.48s\n",
      "636:\tlearn: 0.6803486\ttotal: 7.84s\tremaining: 4.47s\n",
      "637:\tlearn: 0.6803404\ttotal: 7.86s\tremaining: 4.46s\n",
      "638:\tlearn: 0.6803327\ttotal: 7.87s\tremaining: 4.45s\n",
      "639:\tlearn: 0.6803266\ttotal: 7.88s\tremaining: 4.43s\n",
      "640:\tlearn: 0.6803200\ttotal: 7.89s\tremaining: 4.42s\n",
      "641:\tlearn: 0.6803121\ttotal: 7.9s\tremaining: 4.41s\n",
      "642:\tlearn: 0.6803052\ttotal: 7.91s\tremaining: 4.39s\n",
      "643:\tlearn: 0.6802779\ttotal: 7.92s\tremaining: 4.38s\n",
      "644:\tlearn: 0.6802704\ttotal: 7.93s\tremaining: 4.37s\n",
      "645:\tlearn: 0.6802535\ttotal: 7.95s\tremaining: 4.36s\n",
      "646:\tlearn: 0.6802460\ttotal: 7.96s\tremaining: 4.34s\n",
      "647:\tlearn: 0.6802232\ttotal: 7.97s\tremaining: 4.33s\n",
      "648:\tlearn: 0.6801960\ttotal: 7.98s\tremaining: 4.32s\n",
      "649:\tlearn: 0.6801863\ttotal: 7.99s\tremaining: 4.3s\n",
      "650:\tlearn: 0.6801787\ttotal: 8.01s\tremaining: 4.29s\n",
      "651:\tlearn: 0.6801582\ttotal: 8.02s\tremaining: 4.28s\n",
      "652:\tlearn: 0.6801503\ttotal: 8.03s\tremaining: 4.26s\n",
      "653:\tlearn: 0.6801133\ttotal: 8.04s\tremaining: 4.25s\n",
      "654:\tlearn: 0.6801068\ttotal: 8.04s\tremaining: 4.24s\n",
      "655:\tlearn: 0.6800978\ttotal: 8.06s\tremaining: 4.22s\n",
      "656:\tlearn: 0.6800901\ttotal: 8.07s\tremaining: 4.21s\n",
      "657:\tlearn: 0.6800611\ttotal: 8.08s\tremaining: 4.2s\n",
      "658:\tlearn: 0.6800379\ttotal: 8.09s\tremaining: 4.18s\n",
      "659:\tlearn: 0.6800302\ttotal: 8.1s\tremaining: 4.17s\n",
      "660:\tlearn: 0.6800023\ttotal: 8.11s\tremaining: 4.16s\n",
      "661:\tlearn: 0.6799957\ttotal: 8.12s\tremaining: 4.14s\n",
      "662:\tlearn: 0.6799664\ttotal: 8.13s\tremaining: 4.13s\n",
      "663:\tlearn: 0.6799591\ttotal: 8.14s\tremaining: 4.12s\n",
      "664:\tlearn: 0.6799518\ttotal: 8.15s\tremaining: 4.11s\n",
      "665:\tlearn: 0.6799441\ttotal: 8.16s\tremaining: 4.09s\n",
      "666:\tlearn: 0.6799344\ttotal: 8.17s\tremaining: 4.08s\n",
      "667:\tlearn: 0.6799264\ttotal: 8.18s\tremaining: 4.07s\n",
      "668:\tlearn: 0.6799189\ttotal: 8.19s\tremaining: 4.05s\n",
      "669:\tlearn: 0.6799112\ttotal: 8.2s\tremaining: 4.04s\n",
      "670:\tlearn: 0.6798821\ttotal: 8.21s\tremaining: 4.03s\n",
      "671:\tlearn: 0.6798745\ttotal: 8.22s\tremaining: 4.01s\n",
      "672:\tlearn: 0.6798666\ttotal: 8.23s\tremaining: 4s\n",
      "673:\tlearn: 0.6798599\ttotal: 8.24s\tremaining: 3.99s\n",
      "674:\tlearn: 0.6798532\ttotal: 8.26s\tremaining: 3.98s\n",
      "675:\tlearn: 0.6798419\ttotal: 8.27s\tremaining: 3.96s\n",
      "676:\tlearn: 0.6798336\ttotal: 8.28s\tremaining: 3.95s\n",
      "677:\tlearn: 0.6798254\ttotal: 8.29s\tremaining: 3.94s\n",
      "678:\tlearn: 0.6798013\ttotal: 8.3s\tremaining: 3.92s\n",
      "679:\tlearn: 0.6797848\ttotal: 8.31s\tremaining: 3.91s\n",
      "680:\tlearn: 0.6797699\ttotal: 8.32s\tremaining: 3.9s\n",
      "681:\tlearn: 0.6797615\ttotal: 8.33s\tremaining: 3.88s\n",
      "682:\tlearn: 0.6797545\ttotal: 8.34s\tremaining: 3.87s\n",
      "683:\tlearn: 0.6797472\ttotal: 8.36s\tremaining: 3.86s\n",
      "684:\tlearn: 0.6797405\ttotal: 8.37s\tremaining: 3.85s\n",
      "685:\tlearn: 0.6797331\ttotal: 8.38s\tremaining: 3.83s\n",
      "686:\tlearn: 0.6797260\ttotal: 8.39s\tremaining: 3.82s\n",
      "687:\tlearn: 0.6797202\ttotal: 8.4s\tremaining: 3.81s\n",
      "688:\tlearn: 0.6796928\ttotal: 8.41s\tremaining: 3.8s\n",
      "689:\tlearn: 0.6796852\ttotal: 8.43s\tremaining: 3.79s\n",
      "690:\tlearn: 0.6796759\ttotal: 8.44s\tremaining: 3.77s\n",
      "691:\tlearn: 0.6796707\ttotal: 8.45s\tremaining: 3.76s\n",
      "692:\tlearn: 0.6796636\ttotal: 8.46s\tremaining: 3.75s\n",
      "693:\tlearn: 0.6796544\ttotal: 8.47s\tremaining: 3.74s\n",
      "694:\tlearn: 0.6796482\ttotal: 8.48s\tremaining: 3.72s\n",
      "695:\tlearn: 0.6796399\ttotal: 8.5s\tremaining: 3.71s\n",
      "696:\tlearn: 0.6796253\ttotal: 8.51s\tremaining: 3.7s\n",
      "697:\tlearn: 0.6795972\ttotal: 8.52s\tremaining: 3.69s\n",
      "698:\tlearn: 0.6795897\ttotal: 8.53s\tremaining: 3.67s\n",
      "699:\tlearn: 0.6795825\ttotal: 8.54s\tremaining: 3.66s\n",
      "700:\tlearn: 0.6795744\ttotal: 8.55s\tremaining: 3.65s\n",
      "701:\tlearn: 0.6795662\ttotal: 8.56s\tremaining: 3.63s\n",
      "702:\tlearn: 0.6795590\ttotal: 8.57s\tremaining: 3.62s\n",
      "703:\tlearn: 0.6795400\ttotal: 8.58s\tremaining: 3.61s\n",
      "704:\tlearn: 0.6795338\ttotal: 8.59s\tremaining: 3.6s\n",
      "705:\tlearn: 0.6795265\ttotal: 8.6s\tremaining: 3.58s\n",
      "706:\tlearn: 0.6795198\ttotal: 8.61s\tremaining: 3.57s\n",
      "707:\tlearn: 0.6795120\ttotal: 8.62s\tremaining: 3.56s\n",
      "708:\tlearn: 0.6795053\ttotal: 8.63s\tremaining: 3.54s\n",
      "709:\tlearn: 0.6794968\ttotal: 8.64s\tremaining: 3.53s\n",
      "710:\tlearn: 0.6794909\ttotal: 8.65s\tremaining: 3.52s\n",
      "711:\tlearn: 0.6794838\ttotal: 8.66s\tremaining: 3.5s\n",
      "712:\tlearn: 0.6794767\ttotal: 8.67s\tremaining: 3.49s\n",
      "713:\tlearn: 0.6794559\ttotal: 8.68s\tremaining: 3.48s\n",
      "714:\tlearn: 0.6794464\ttotal: 8.69s\tremaining: 3.46s\n",
      "715:\tlearn: 0.6794391\ttotal: 8.71s\tremaining: 3.45s\n",
      "716:\tlearn: 0.6794328\ttotal: 8.72s\tremaining: 3.44s\n",
      "717:\tlearn: 0.6794262\ttotal: 8.73s\tremaining: 3.43s\n",
      "718:\tlearn: 0.6794185\ttotal: 8.74s\tremaining: 3.42s\n",
      "719:\tlearn: 0.6794118\ttotal: 8.76s\tremaining: 3.4s\n",
      "720:\tlearn: 0.6794059\ttotal: 8.77s\tremaining: 3.39s\n",
      "721:\tlearn: 0.6793791\ttotal: 8.78s\tremaining: 3.38s\n",
      "722:\tlearn: 0.6793726\ttotal: 8.79s\tremaining: 3.37s\n",
      "723:\tlearn: 0.6793653\ttotal: 8.8s\tremaining: 3.35s\n",
      "724:\tlearn: 0.6793580\ttotal: 8.81s\tremaining: 3.34s\n",
      "725:\tlearn: 0.6793508\ttotal: 8.82s\tremaining: 3.33s\n",
      "726:\tlearn: 0.6793354\ttotal: 8.83s\tremaining: 3.32s\n",
      "727:\tlearn: 0.6793285\ttotal: 8.84s\tremaining: 3.3s\n",
      "728:\tlearn: 0.6793210\ttotal: 8.85s\tremaining: 3.29s\n",
      "729:\tlearn: 0.6793136\ttotal: 8.86s\tremaining: 3.28s\n",
      "730:\tlearn: 0.6792804\ttotal: 8.87s\tremaining: 3.27s\n",
      "731:\tlearn: 0.6792713\ttotal: 8.88s\tremaining: 3.25s\n",
      "732:\tlearn: 0.6792638\ttotal: 8.9s\tremaining: 3.24s\n",
      "733:\tlearn: 0.6792572\ttotal: 8.92s\tremaining: 3.23s\n",
      "734:\tlearn: 0.6792515\ttotal: 8.93s\tremaining: 3.22s\n",
      "735:\tlearn: 0.6792438\ttotal: 8.94s\tremaining: 3.21s\n",
      "736:\tlearn: 0.6792188\ttotal: 8.95s\tremaining: 3.19s\n",
      "737:\tlearn: 0.6792009\ttotal: 8.97s\tremaining: 3.18s\n",
      "738:\tlearn: 0.6791940\ttotal: 8.98s\tremaining: 3.17s\n",
      "739:\tlearn: 0.6791620\ttotal: 8.99s\tremaining: 3.16s\n",
      "740:\tlearn: 0.6791562\ttotal: 9s\tremaining: 3.15s\n",
      "741:\tlearn: 0.6791484\ttotal: 9.01s\tremaining: 3.13s\n",
      "742:\tlearn: 0.6791419\ttotal: 9.02s\tremaining: 3.12s\n",
      "743:\tlearn: 0.6791315\ttotal: 9.03s\tremaining: 3.11s\n",
      "744:\tlearn: 0.6791250\ttotal: 9.04s\tremaining: 3.09s\n",
      "745:\tlearn: 0.6791146\ttotal: 9.05s\tremaining: 3.08s\n",
      "746:\tlearn: 0.6790894\ttotal: 9.06s\tremaining: 3.07s\n",
      "747:\tlearn: 0.6790817\ttotal: 9.07s\tremaining: 3.06s\n",
      "748:\tlearn: 0.6790741\ttotal: 9.08s\tremaining: 3.04s\n",
      "749:\tlearn: 0.6790508\ttotal: 9.09s\tremaining: 3.03s\n",
      "750:\tlearn: 0.6790428\ttotal: 9.1s\tremaining: 3.02s\n",
      "751:\tlearn: 0.6790347\ttotal: 9.11s\tremaining: 3s\n",
      "752:\tlearn: 0.6790286\ttotal: 9.12s\tremaining: 2.99s\n",
      "753:\tlearn: 0.6790214\ttotal: 9.13s\tremaining: 2.98s\n",
      "754:\tlearn: 0.6790148\ttotal: 9.14s\tremaining: 2.97s\n",
      "755:\tlearn: 0.6790077\ttotal: 9.15s\tremaining: 2.95s\n",
      "756:\tlearn: 0.6790014\ttotal: 9.16s\tremaining: 2.94s\n",
      "757:\tlearn: 0.6789943\ttotal: 9.17s\tremaining: 2.93s\n",
      "758:\tlearn: 0.6789862\ttotal: 9.19s\tremaining: 2.92s\n",
      "759:\tlearn: 0.6789590\ttotal: 9.2s\tremaining: 2.9s\n",
      "760:\tlearn: 0.6789526\ttotal: 9.21s\tremaining: 2.89s\n",
      "761:\tlearn: 0.6789466\ttotal: 9.22s\tremaining: 2.88s\n",
      "762:\tlearn: 0.6789258\ttotal: 9.23s\tremaining: 2.87s\n",
      "763:\tlearn: 0.6789202\ttotal: 9.24s\tremaining: 2.85s\n",
      "764:\tlearn: 0.6789116\ttotal: 9.25s\tremaining: 2.84s\n",
      "765:\tlearn: 0.6789021\ttotal: 9.26s\tremaining: 2.83s\n",
      "766:\tlearn: 0.6788963\ttotal: 9.27s\tremaining: 2.82s\n",
      "767:\tlearn: 0.6788888\ttotal: 9.28s\tremaining: 2.8s\n",
      "768:\tlearn: 0.6788820\ttotal: 9.29s\tremaining: 2.79s\n",
      "769:\tlearn: 0.6788724\ttotal: 9.3s\tremaining: 2.78s\n",
      "770:\tlearn: 0.6788652\ttotal: 9.31s\tremaining: 2.77s\n",
      "771:\tlearn: 0.6788564\ttotal: 9.32s\tremaining: 2.75s\n",
      "772:\tlearn: 0.6788497\ttotal: 9.33s\tremaining: 2.74s\n",
      "773:\tlearn: 0.6788425\ttotal: 9.35s\tremaining: 2.73s\n",
      "774:\tlearn: 0.6788353\ttotal: 9.36s\tremaining: 2.72s\n",
      "775:\tlearn: 0.6788280\ttotal: 9.37s\tremaining: 2.7s\n",
      "776:\tlearn: 0.6788181\ttotal: 9.38s\tremaining: 2.69s\n",
      "777:\tlearn: 0.6787926\ttotal: 9.39s\tremaining: 2.68s\n",
      "778:\tlearn: 0.6787861\ttotal: 9.4s\tremaining: 2.67s\n",
      "779:\tlearn: 0.6787805\ttotal: 9.41s\tremaining: 2.65s\n",
      "780:\tlearn: 0.6787725\ttotal: 9.42s\tremaining: 2.64s\n",
      "781:\tlearn: 0.6787663\ttotal: 9.43s\tremaining: 2.63s\n",
      "782:\tlearn: 0.6787598\ttotal: 9.45s\tremaining: 2.62s\n",
      "783:\tlearn: 0.6787531\ttotal: 9.46s\tremaining: 2.6s\n",
      "784:\tlearn: 0.6787459\ttotal: 9.47s\tremaining: 2.59s\n",
      "785:\tlearn: 0.6787398\ttotal: 9.48s\tremaining: 2.58s\n",
      "786:\tlearn: 0.6787329\ttotal: 9.49s\tremaining: 2.57s\n",
      "787:\tlearn: 0.6787260\ttotal: 9.5s\tremaining: 2.56s\n",
      "788:\tlearn: 0.6787189\ttotal: 9.51s\tremaining: 2.54s\n",
      "789:\tlearn: 0.6787115\ttotal: 9.53s\tremaining: 2.53s\n",
      "790:\tlearn: 0.6787052\ttotal: 9.54s\tremaining: 2.52s\n",
      "791:\tlearn: 0.6786985\ttotal: 9.55s\tremaining: 2.51s\n",
      "792:\tlearn: 0.6786903\ttotal: 9.56s\tremaining: 2.49s\n",
      "793:\tlearn: 0.6786833\ttotal: 9.57s\tremaining: 2.48s\n",
      "794:\tlearn: 0.6786768\ttotal: 9.59s\tremaining: 2.47s\n",
      "795:\tlearn: 0.6786700\ttotal: 9.61s\tremaining: 2.46s\n",
      "796:\tlearn: 0.6786631\ttotal: 9.62s\tremaining: 2.45s\n",
      "797:\tlearn: 0.6786570\ttotal: 9.63s\tremaining: 2.44s\n",
      "798:\tlearn: 0.6786468\ttotal: 9.64s\tremaining: 2.42s\n",
      "799:\tlearn: 0.6786274\ttotal: 9.65s\tremaining: 2.41s\n",
      "800:\tlearn: 0.6786207\ttotal: 9.67s\tremaining: 2.4s\n",
      "801:\tlearn: 0.6786138\ttotal: 9.69s\tremaining: 2.39s\n",
      "802:\tlearn: 0.6786081\ttotal: 9.71s\tremaining: 2.38s\n",
      "803:\tlearn: 0.6786007\ttotal: 9.72s\tremaining: 2.37s\n",
      "804:\tlearn: 0.6785944\ttotal: 9.73s\tremaining: 2.36s\n",
      "805:\tlearn: 0.6785880\ttotal: 9.74s\tremaining: 2.34s\n",
      "806:\tlearn: 0.6785812\ttotal: 9.75s\tremaining: 2.33s\n",
      "807:\tlearn: 0.6785726\ttotal: 9.76s\tremaining: 2.32s\n",
      "808:\tlearn: 0.6785669\ttotal: 9.77s\tremaining: 2.31s\n",
      "809:\tlearn: 0.6785426\ttotal: 9.78s\tremaining: 2.29s\n",
      "810:\tlearn: 0.6785363\ttotal: 9.79s\tremaining: 2.28s\n",
      "811:\tlearn: 0.6785302\ttotal: 9.81s\tremaining: 2.27s\n",
      "812:\tlearn: 0.6785239\ttotal: 9.82s\tremaining: 2.26s\n",
      "813:\tlearn: 0.6785165\ttotal: 9.83s\tremaining: 2.25s\n",
      "814:\tlearn: 0.6785081\ttotal: 9.84s\tremaining: 2.23s\n",
      "815:\tlearn: 0.6785013\ttotal: 9.85s\tremaining: 2.22s\n",
      "816:\tlearn: 0.6784951\ttotal: 9.87s\tremaining: 2.21s\n",
      "817:\tlearn: 0.6784888\ttotal: 9.88s\tremaining: 2.2s\n",
      "818:\tlearn: 0.6784830\ttotal: 9.89s\tremaining: 2.19s\n",
      "819:\tlearn: 0.6784756\ttotal: 9.9s\tremaining: 2.17s\n",
      "820:\tlearn: 0.6784693\ttotal: 9.92s\tremaining: 2.16s\n",
      "821:\tlearn: 0.6784632\ttotal: 9.93s\tremaining: 2.15s\n",
      "822:\tlearn: 0.6784571\ttotal: 9.94s\tremaining: 2.14s\n",
      "823:\tlearn: 0.6784507\ttotal: 9.95s\tremaining: 2.13s\n",
      "824:\tlearn: 0.6784453\ttotal: 9.96s\tremaining: 2.11s\n",
      "825:\tlearn: 0.6784394\ttotal: 9.97s\tremaining: 2.1s\n",
      "826:\tlearn: 0.6784156\ttotal: 9.98s\tremaining: 2.09s\n",
      "827:\tlearn: 0.6784097\ttotal: 9.99s\tremaining: 2.08s\n",
      "828:\tlearn: 0.6784033\ttotal: 10s\tremaining: 2.06s\n",
      "829:\tlearn: 0.6783967\ttotal: 10s\tremaining: 2.05s\n",
      "830:\tlearn: 0.6783909\ttotal: 10s\tremaining: 2.04s\n",
      "831:\tlearn: 0.6783844\ttotal: 10s\tremaining: 2.03s\n",
      "832:\tlearn: 0.6783777\ttotal: 10s\tremaining: 2.01s\n",
      "833:\tlearn: 0.6783720\ttotal: 10.1s\tremaining: 2s\n",
      "834:\tlearn: 0.6783656\ttotal: 10.1s\tremaining: 1.99s\n",
      "835:\tlearn: 0.6783583\ttotal: 10.1s\tremaining: 1.98s\n",
      "836:\tlearn: 0.6783374\ttotal: 10.1s\tremaining: 1.96s\n",
      "837:\tlearn: 0.6783300\ttotal: 10.1s\tremaining: 1.95s\n",
      "838:\tlearn: 0.6783239\ttotal: 10.1s\tremaining: 1.94s\n",
      "839:\tlearn: 0.6783151\ttotal: 10.1s\tremaining: 1.93s\n",
      "840:\tlearn: 0.6782918\ttotal: 10.1s\tremaining: 1.92s\n",
      "841:\tlearn: 0.6782859\ttotal: 10.1s\tremaining: 1.9s\n",
      "842:\tlearn: 0.6782794\ttotal: 10.2s\tremaining: 1.89s\n",
      "843:\tlearn: 0.6782736\ttotal: 10.2s\tremaining: 1.88s\n",
      "844:\tlearn: 0.6782677\ttotal: 10.2s\tremaining: 1.87s\n",
      "845:\tlearn: 0.6782599\ttotal: 10.2s\tremaining: 1.85s\n",
      "846:\tlearn: 0.6782534\ttotal: 10.2s\tremaining: 1.84s\n",
      "847:\tlearn: 0.6782475\ttotal: 10.2s\tremaining: 1.83s\n",
      "848:\tlearn: 0.6782416\ttotal: 10.2s\tremaining: 1.82s\n",
      "849:\tlearn: 0.6782161\ttotal: 10.2s\tremaining: 1.8s\n",
      "850:\tlearn: 0.6782096\ttotal: 10.3s\tremaining: 1.79s\n",
      "851:\tlearn: 0.6781959\ttotal: 10.3s\tremaining: 1.78s\n",
      "852:\tlearn: 0.6781667\ttotal: 10.3s\tremaining: 1.77s\n",
      "853:\tlearn: 0.6781452\ttotal: 10.3s\tremaining: 1.76s\n",
      "854:\tlearn: 0.6781388\ttotal: 10.3s\tremaining: 1.75s\n",
      "855:\tlearn: 0.6781321\ttotal: 10.3s\tremaining: 1.74s\n",
      "856:\tlearn: 0.6781238\ttotal: 10.3s\tremaining: 1.72s\n",
      "857:\tlearn: 0.6781183\ttotal: 10.3s\tremaining: 1.71s\n",
      "858:\tlearn: 0.6781112\ttotal: 10.4s\tremaining: 1.7s\n",
      "859:\tlearn: 0.6781050\ttotal: 10.4s\tremaining: 1.69s\n",
      "860:\tlearn: 0.6780904\ttotal: 10.4s\tremaining: 1.68s\n",
      "861:\tlearn: 0.6780843\ttotal: 10.4s\tremaining: 1.67s\n",
      "862:\tlearn: 0.6780772\ttotal: 10.4s\tremaining: 1.65s\n",
      "863:\tlearn: 0.6780719\ttotal: 10.4s\tremaining: 1.64s\n",
      "864:\tlearn: 0.6780495\ttotal: 10.4s\tremaining: 1.63s\n",
      "865:\tlearn: 0.6780388\ttotal: 10.5s\tremaining: 1.62s\n",
      "866:\tlearn: 0.6780177\ttotal: 10.5s\tremaining: 1.6s\n",
      "867:\tlearn: 0.6780127\ttotal: 10.5s\tremaining: 1.59s\n",
      "868:\tlearn: 0.6780069\ttotal: 10.5s\tremaining: 1.58s\n",
      "869:\tlearn: 0.6780004\ttotal: 10.5s\tremaining: 1.57s\n",
      "870:\tlearn: 0.6779938\ttotal: 10.5s\tremaining: 1.56s\n",
      "871:\tlearn: 0.6779872\ttotal: 10.5s\tremaining: 1.55s\n",
      "872:\tlearn: 0.6779814\ttotal: 10.6s\tremaining: 1.54s\n",
      "873:\tlearn: 0.6779739\ttotal: 10.6s\tremaining: 1.52s\n",
      "874:\tlearn: 0.6779682\ttotal: 10.6s\tremaining: 1.51s\n",
      "875:\tlearn: 0.6779617\ttotal: 10.6s\tremaining: 1.5s\n",
      "876:\tlearn: 0.6779562\ttotal: 10.6s\tremaining: 1.49s\n",
      "877:\tlearn: 0.6779323\ttotal: 10.7s\tremaining: 1.48s\n",
      "878:\tlearn: 0.6779251\ttotal: 10.7s\tremaining: 1.47s\n",
      "879:\tlearn: 0.6779196\ttotal: 10.7s\tremaining: 1.46s\n",
      "880:\tlearn: 0.6779121\ttotal: 10.7s\tremaining: 1.45s\n",
      "881:\tlearn: 0.6779052\ttotal: 10.7s\tremaining: 1.44s\n",
      "882:\tlearn: 0.6778996\ttotal: 10.8s\tremaining: 1.43s\n",
      "883:\tlearn: 0.6778923\ttotal: 10.8s\tremaining: 1.41s\n",
      "884:\tlearn: 0.6778860\ttotal: 10.8s\tremaining: 1.4s\n",
      "885:\tlearn: 0.6778804\ttotal: 10.8s\tremaining: 1.39s\n",
      "886:\tlearn: 0.6778741\ttotal: 10.8s\tremaining: 1.38s\n",
      "887:\tlearn: 0.6778675\ttotal: 10.8s\tremaining: 1.37s\n",
      "888:\tlearn: 0.6778469\ttotal: 10.9s\tremaining: 1.36s\n",
      "889:\tlearn: 0.6778402\ttotal: 10.9s\tremaining: 1.34s\n",
      "890:\tlearn: 0.6778341\ttotal: 10.9s\tremaining: 1.33s\n",
      "891:\tlearn: 0.6778292\ttotal: 10.9s\tremaining: 1.32s\n",
      "892:\tlearn: 0.6778225\ttotal: 10.9s\tremaining: 1.31s\n",
      "893:\tlearn: 0.6778041\ttotal: 10.9s\tremaining: 1.3s\n",
      "894:\tlearn: 0.6777977\ttotal: 11s\tremaining: 1.29s\n",
      "895:\tlearn: 0.6777762\ttotal: 11s\tremaining: 1.27s\n",
      "896:\tlearn: 0.6777709\ttotal: 11s\tremaining: 1.26s\n",
      "897:\tlearn: 0.6777643\ttotal: 11s\tremaining: 1.25s\n",
      "898:\tlearn: 0.6777582\ttotal: 11s\tremaining: 1.24s\n",
      "899:\tlearn: 0.6777530\ttotal: 11.1s\tremaining: 1.23s\n",
      "900:\tlearn: 0.6777470\ttotal: 11.1s\tremaining: 1.22s\n",
      "901:\tlearn: 0.6777403\ttotal: 11.1s\tremaining: 1.21s\n",
      "902:\tlearn: 0.6777340\ttotal: 11.1s\tremaining: 1.19s\n",
      "903:\tlearn: 0.6777274\ttotal: 11.1s\tremaining: 1.18s\n",
      "904:\tlearn: 0.6777209\ttotal: 11.2s\tremaining: 1.17s\n",
      "905:\tlearn: 0.6777130\ttotal: 11.2s\tremaining: 1.16s\n",
      "906:\tlearn: 0.6777062\ttotal: 11.2s\tremaining: 1.15s\n",
      "907:\tlearn: 0.6777010\ttotal: 11.2s\tremaining: 1.14s\n",
      "908:\tlearn: 0.6776778\ttotal: 11.2s\tremaining: 1.12s\n",
      "909:\tlearn: 0.6776714\ttotal: 11.2s\tremaining: 1.11s\n",
      "910:\tlearn: 0.6776654\ttotal: 11.3s\tremaining: 1.1s\n",
      "911:\tlearn: 0.6776594\ttotal: 11.3s\tremaining: 1.09s\n",
      "912:\tlearn: 0.6776345\ttotal: 11.3s\tremaining: 1.08s\n",
      "913:\tlearn: 0.6776286\ttotal: 11.3s\tremaining: 1.06s\n",
      "914:\tlearn: 0.6776227\ttotal: 11.3s\tremaining: 1.05s\n",
      "915:\tlearn: 0.6776024\ttotal: 11.4s\tremaining: 1.04s\n",
      "916:\tlearn: 0.6775841\ttotal: 11.4s\tremaining: 1.03s\n",
      "917:\tlearn: 0.6775774\ttotal: 11.4s\tremaining: 1.02s\n",
      "918:\tlearn: 0.6775555\ttotal: 11.4s\tremaining: 1s\n",
      "919:\tlearn: 0.6775504\ttotal: 11.4s\tremaining: 993ms\n",
      "920:\tlearn: 0.6775425\ttotal: 11.4s\tremaining: 981ms\n",
      "921:\tlearn: 0.6775365\ttotal: 11.5s\tremaining: 970ms\n",
      "922:\tlearn: 0.6775310\ttotal: 11.5s\tremaining: 958ms\n",
      "923:\tlearn: 0.6775241\ttotal: 11.5s\tremaining: 946ms\n",
      "924:\tlearn: 0.6775181\ttotal: 11.5s\tremaining: 934ms\n",
      "925:\tlearn: 0.6775106\ttotal: 11.5s\tremaining: 922ms\n",
      "926:\tlearn: 0.6775049\ttotal: 11.6s\tremaining: 910ms\n",
      "927:\tlearn: 0.6774875\ttotal: 11.6s\tremaining: 898ms\n",
      "928:\tlearn: 0.6774820\ttotal: 11.6s\tremaining: 886ms\n",
      "929:\tlearn: 0.6774732\ttotal: 11.6s\tremaining: 874ms\n",
      "930:\tlearn: 0.6774671\ttotal: 11.6s\tremaining: 862ms\n",
      "931:\tlearn: 0.6774616\ttotal: 11.6s\tremaining: 850ms\n",
      "932:\tlearn: 0.6774559\ttotal: 11.7s\tremaining: 838ms\n",
      "933:\tlearn: 0.6774500\ttotal: 11.7s\tremaining: 826ms\n",
      "934:\tlearn: 0.6774298\ttotal: 11.7s\tremaining: 814ms\n",
      "935:\tlearn: 0.6774219\ttotal: 11.7s\tremaining: 802ms\n",
      "936:\tlearn: 0.6774163\ttotal: 11.7s\tremaining: 789ms\n",
      "937:\tlearn: 0.6774105\ttotal: 11.8s\tremaining: 777ms\n",
      "938:\tlearn: 0.6774050\ttotal: 11.8s\tremaining: 765ms\n",
      "939:\tlearn: 0.6773995\ttotal: 11.8s\tremaining: 753ms\n",
      "940:\tlearn: 0.6773915\ttotal: 11.8s\tremaining: 741ms\n",
      "941:\tlearn: 0.6773848\ttotal: 11.8s\tremaining: 729ms\n",
      "942:\tlearn: 0.6773790\ttotal: 11.9s\tremaining: 716ms\n",
      "943:\tlearn: 0.6773734\ttotal: 11.9s\tremaining: 704ms\n",
      "944:\tlearn: 0.6773687\ttotal: 11.9s\tremaining: 692ms\n",
      "945:\tlearn: 0.6773631\ttotal: 11.9s\tremaining: 679ms\n",
      "946:\tlearn: 0.6773576\ttotal: 11.9s\tremaining: 667ms\n",
      "947:\tlearn: 0.6773398\ttotal: 11.9s\tremaining: 655ms\n",
      "948:\tlearn: 0.6773340\ttotal: 12s\tremaining: 643ms\n",
      "949:\tlearn: 0.6773287\ttotal: 12s\tremaining: 630ms\n",
      "950:\tlearn: 0.6773224\ttotal: 12s\tremaining: 618ms\n",
      "951:\tlearn: 0.6773162\ttotal: 12s\tremaining: 606ms\n",
      "952:\tlearn: 0.6772991\ttotal: 12s\tremaining: 593ms\n",
      "953:\tlearn: 0.6772942\ttotal: 12s\tremaining: 581ms\n",
      "954:\tlearn: 0.6772878\ttotal: 12.1s\tremaining: 569ms\n",
      "955:\tlearn: 0.6772799\ttotal: 12.1s\tremaining: 556ms\n",
      "956:\tlearn: 0.6772727\ttotal: 12.1s\tremaining: 544ms\n",
      "957:\tlearn: 0.6772673\ttotal: 12.1s\tremaining: 531ms\n",
      "958:\tlearn: 0.6772620\ttotal: 12.1s\tremaining: 519ms\n",
      "959:\tlearn: 0.6772563\ttotal: 12.2s\tremaining: 507ms\n",
      "960:\tlearn: 0.6772515\ttotal: 12.2s\tremaining: 494ms\n",
      "961:\tlearn: 0.6772455\ttotal: 12.2s\tremaining: 482ms\n",
      "962:\tlearn: 0.6772403\ttotal: 12.2s\tremaining: 469ms\n",
      "963:\tlearn: 0.6772336\ttotal: 12.2s\tremaining: 457ms\n",
      "964:\tlearn: 0.6772275\ttotal: 12.3s\tremaining: 444ms\n",
      "965:\tlearn: 0.6772219\ttotal: 12.3s\tremaining: 432ms\n",
      "966:\tlearn: 0.6772167\ttotal: 12.3s\tremaining: 419ms\n",
      "967:\tlearn: 0.6772108\ttotal: 12.3s\tremaining: 407ms\n",
      "968:\tlearn: 0.6772042\ttotal: 12.3s\tremaining: 394ms\n",
      "969:\tlearn: 0.6771986\ttotal: 12.3s\tremaining: 382ms\n",
      "970:\tlearn: 0.6771924\ttotal: 12.4s\tremaining: 369ms\n",
      "971:\tlearn: 0.6771867\ttotal: 12.4s\tremaining: 356ms\n",
      "972:\tlearn: 0.6771805\ttotal: 12.4s\tremaining: 344ms\n",
      "973:\tlearn: 0.6771745\ttotal: 12.4s\tremaining: 331ms\n",
      "974:\tlearn: 0.6771688\ttotal: 12.4s\tremaining: 318ms\n",
      "975:\tlearn: 0.6771619\ttotal: 12.4s\tremaining: 305ms\n",
      "976:\tlearn: 0.6771557\ttotal: 12.4s\tremaining: 293ms\n",
      "977:\tlearn: 0.6771500\ttotal: 12.4s\tremaining: 280ms\n",
      "978:\tlearn: 0.6771447\ttotal: 12.5s\tremaining: 267ms\n",
      "979:\tlearn: 0.6771391\ttotal: 12.5s\tremaining: 255ms\n",
      "980:\tlearn: 0.6771323\ttotal: 12.5s\tremaining: 242ms\n",
      "981:\tlearn: 0.6771273\ttotal: 12.5s\tremaining: 229ms\n",
      "982:\tlearn: 0.6771118\ttotal: 12.5s\tremaining: 217ms\n",
      "983:\tlearn: 0.6771063\ttotal: 12.5s\tremaining: 204ms\n",
      "984:\tlearn: 0.6770986\ttotal: 12.5s\tremaining: 191ms\n",
      "985:\tlearn: 0.6770925\ttotal: 12.6s\tremaining: 178ms\n",
      "986:\tlearn: 0.6770872\ttotal: 12.6s\tremaining: 166ms\n",
      "987:\tlearn: 0.6770817\ttotal: 12.6s\tremaining: 153ms\n",
      "988:\tlearn: 0.6770703\ttotal: 12.6s\tremaining: 140ms\n",
      "989:\tlearn: 0.6770646\ttotal: 12.6s\tremaining: 127ms\n",
      "990:\tlearn: 0.6770567\ttotal: 12.6s\tremaining: 115ms\n",
      "991:\tlearn: 0.6770496\ttotal: 12.7s\tremaining: 102ms\n",
      "992:\tlearn: 0.6770447\ttotal: 12.7s\tremaining: 89.3ms\n",
      "993:\tlearn: 0.6770389\ttotal: 12.7s\tremaining: 76.6ms\n",
      "994:\tlearn: 0.6770322\ttotal: 12.7s\tremaining: 63.9ms\n",
      "995:\tlearn: 0.6770258\ttotal: 12.7s\tremaining: 51.1ms\n",
      "996:\tlearn: 0.6770194\ttotal: 12.7s\tremaining: 38.3ms\n",
      "997:\tlearn: 0.6770125\ttotal: 12.8s\tremaining: 25.6ms\n",
      "998:\tlearn: 0.6770072\ttotal: 12.8s\tremaining: 12.8ms\n",
      "999:\tlearn: 0.6770012\ttotal: 12.8s\tremaining: 0us\n",
      "{'nan_mode': 'Min', 'gpu_ram_part': 0.95, 'eval_metric': 'Logloss', 'iterations': 1000, 'leaf_estimation_method': 'Newton', 'observations_to_bootstrap': 'TestOnly', 'grow_policy': 'SymmetricTree', 'boosting_type': 'Plain', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'devices': '-1', 'pinned_memory_bytes': '104857600', 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'gpu_cat_features_storage': 'GpuRam', 'fold_size_loss_normalization': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'use_best_model': False, 'meta_l2_frequency': 0, 'class_names': [0, 1], 'random_seed': 42, 'depth': 6, 'border_count': 128, 'min_fold_size': 100, 'data_partition': 'DocParallel', 'bagging_temperature': 1, 'classes_count': 0, 'auto_class_weights': 'None', 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'min_data_in_leaf': 1, 'add_ridge_penalty_to_loss_function': False, 'loss_function': 'Logloss', 'learning_rate': 0.023395000025629997, 'meta_l2_exponent': 1, 'score_function': 'Cosine', 'task_type': 'GPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'Bayesian', 'max_leaves': 64}\n",
      "Valid log-loss is 14.984139625712748\n",
      "Valid AUC is 0.5660538572366811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 801837<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_122026-1h0k2s3t/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210905_122026-1h0k2s3t/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>14.58574</td></tr><tr><td>train_auc</td><td>0.57762</td></tr><tr><td>_runtime</td><td>20</td></tr><tr><td>_timestamp</td><td>1630869652</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>nan_mode</td><td>Min</td></tr><tr><td>gpu_ram_part</td><td>0.95</td></tr><tr><td>eval_metric</td><td>Logloss</td></tr><tr><td>iterations</td><td>1000</td></tr><tr><td>leaf_estimation_method</td><td>Newton</td></tr><tr><td>observations_to_bootstrap</td><td>TestOnly</td></tr><tr><td>grow_policy</td><td>SymmetricTree</td></tr><tr><td>boosting_type</td><td>Plain</td></tr><tr><td>feature_border_type</td><td>GreedyLogSum</td></tr><tr><td>bayesian_matrix_reg</td><td>0.1</td></tr><tr><td>devices</td><td>-1</td></tr><tr><td>pinned_memory_bytes</td><td>104857600</td></tr><tr><td>l2_leaf_reg</td><td>3</td></tr><tr><td>random_strength</td><td>1</td></tr><tr><td>rsm</td><td>1</td></tr><tr><td>boost_from_average</td><td>False</td></tr><tr><td>gpu_cat_features_storage</td><td>GpuRam</td></tr><tr><td>fold_size_loss_normalization</td><td>False</td></tr><tr><td>model_size_reg</td><td>0.5</td></tr><tr><td>use_best_model</td><td>False</td></tr><tr><td>meta_l2_frequency</td><td>0</td></tr><tr><td>random_seed</td><td>42</td></tr><tr><td>depth</td><td>6</td></tr><tr><td>border_count</td><td>128</td></tr><tr><td>min_fold_size</td><td>100</td></tr><tr><td>data_partition</td><td>DocParallel</td></tr><tr><td>bagging_temperature</td><td>1</td></tr><tr><td>classes_count</td><td>0</td></tr><tr><td>auto_class_weights</td><td>None</td></tr><tr><td>leaf_estimation_backtracking</td><td>AnyImprovement</td></tr><tr><td>best_model_min_trees</td><td>1</td></tr><tr><td>min_data_in_leaf</td><td>1</td></tr><tr><td>add_ridge_penalty_to_loss_function</td><td>False</td></tr><tr><td>loss_function</td><td>Logloss</td></tr><tr><td>learning_rate</td><td>0.0234</td></tr><tr><td>meta_l2_exponent</td><td>1</td></tr><tr><td>score_function</td><td>Cosine</td></tr><tr><td>task_type</td><td>GPU</td></tr><tr><td>leaf_estimation_iterations</td><td>10</td></tr><tr><td>bootstrap_type</td><td>Bayesian</td></tr><tr><td>max_leaves</td><td>64</td></tr><tr><td>valid_loss</td><td>14.98414</td></tr><tr><td>valid_auc</td><td>0.56605</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁</td></tr><tr><td>train_auc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>gpu_ram_part</td><td>▁</td></tr><tr><td>iterations</td><td>▁</td></tr><tr><td>bayesian_matrix_reg</td><td>▁</td></tr><tr><td>l2_leaf_reg</td><td>▁</td></tr><tr><td>random_strength</td><td>▁</td></tr><tr><td>rsm</td><td>▁</td></tr><tr><td>boost_from_average</td><td>▁</td></tr><tr><td>fold_size_loss_normalization</td><td>▁</td></tr><tr><td>model_size_reg</td><td>▁</td></tr><tr><td>use_best_model</td><td>▁</td></tr><tr><td>meta_l2_frequency</td><td>▁</td></tr><tr><td>random_seed</td><td>▁</td></tr><tr><td>depth</td><td>▁</td></tr><tr><td>border_count</td><td>▁</td></tr><tr><td>min_fold_size</td><td>▁</td></tr><tr><td>bagging_temperature</td><td>▁</td></tr><tr><td>classes_count</td><td>▁</td></tr><tr><td>best_model_min_trees</td><td>▁</td></tr><tr><td>min_data_in_leaf</td><td>▁</td></tr><tr><td>add_ridge_penalty_to_loss_function</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr><tr><td>meta_l2_exponent</td><td>▁</td></tr><tr><td>leaf_estimation_iterations</td><td>▁</td></tr><tr><td>max_leaves</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr><tr><td>valid_auc</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline_20210905_121037</strong>: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1h0k2s3t\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/1h0k2s3t</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpu_available = True\n",
    "exmodel_config['library'] = 'catboost'\n",
    "model_config = model_configurator('catboost')\n",
    "cross_validation(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da35eb82-0dd5-4379-a4d8-8cd4e6675cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "#             n_estimators=config['n_estimators'],\n",
    "#             learning_rate=config['learning_rate'],\n",
    "#             max_depth=config['max_depth'],\n",
    "            task_type=model_config['task_type'],\n",
    "    #         n_jobs=config['n_jobs'],\n",
    "    #         verbosity=config['verbosity'],\n",
    "    #         subsample=config['subsample'],\n",
    "            random_state=42,\n",
    "            # objective='Logloss', # default, accepts only one\n",
    "#             custom_metrics=model_config['custom_metrics'],\n",
    "    #         bootstrap_type=config['bootstrap_type'],\n",
    "    #         device:config['device']\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21237a8f-6424-483a-930b-7f69bd361689",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2bde48e12fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mget_all_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \"\"\"\n\u001b[1;32m   3027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3028\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3029\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_plain_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "print(model.get_all_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0333a-b1cb-45bd-adc2-e6563ae31770",
   "metadata": {},
   "source": [
    "# K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620e090-0d15-4e14-96a6-07322b99c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a17679c-152f-4aff-a1dd-d09ab727ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUALLY probably better to save those as pickles or .npy files; I'll generate them later, regardless\n",
    "# results = {} # for storing k-fold models' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd996d02-2530-4a40-84ec-01f8cde635da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=config['k_folds'], shuffle=True, random_state=config['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e75f832-d012-4021-9628-984209569b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "529afca9-85db-4499-a909-089fb2f10899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(f\"./models/{config_run['name']}_{config['k_folds']}folds/\")\n",
    "(model_path).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81b675b9-3eef-4546-a638-0418ce991653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find XGBoost_ensemble_20210831_no_feature_gen.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.33193748555472\n",
      "RMSE is 7.83147096563313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493223<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_094442-8tgmhqf1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.33194</td></tr><tr><td>rmse</td><td>7.83147</td></tr><tr><td>_runtime</td><td>1591</td></tr><tr><td>_timestamp</td><td>1630429873</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/8tgmhqf1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 62.24235031226011\n",
      "RMSE is 7.889382124872651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 493899<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_101118-oi91peop/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>62.24235</td></tr><tr><td>rmse</td><td>7.88938</td></tr><tr><td>_runtime</td><td>1539</td></tr><tr><td>_timestamp</td><td>1630431417</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/oi91peop</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.81231376886642\n",
      "RMSE is 7.862080753138218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494220<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_103701-2597ytpa/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.81231</td></tr><tr><td>rmse</td><td>7.86208</td></tr><tr><td>_runtime</td><td>1551</td></tr><tr><td>_timestamp</td><td>1630432972</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/2597ytpa</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.666720656537805\n",
      "RMSE is 7.852816097206008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494521<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_110256-e5ojrtx2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.66672</td></tr><tr><td>rmse</td><td>7.85282</td></tr><tr><td>_runtime</td><td>1548</td></tr><tr><td>_timestamp</td><td>1630434524</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/e5ojrtx2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 61.61926325055153\n",
      "RMSE is 7.849793834907484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 494841<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/wandb/run-20210831_112848-1xbs3nm8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>61.61926</td></tr><tr><td>rmse</td><td>7.84979</td></tr><tr><td>_runtime</td><td>1533</td></tr><tr><td>_timestamp</td><td>1630436061</td></tr><tr><td>_step</td><td>401</td></tr><tr><td>fold</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>mse</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>_runtime</td><td>▁▁</td></tr><tr><td>_timestamp</td><td>▁▁</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>fold</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">XGBoost_ensemble_20210831_no_feature_gen_094441</strong>: <a href=\"https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8\" target=\"_blank\">https://wandb.ai/hushifang/202108_Kaggle_tabular_playground/runs/1xbs3nm8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#     if fold == 0:\n",
    "#         continue\n",
    "#     else:\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    X_train, X_valid = X_scaled[train_ids], X_scaled[valid_ids] # requires X to be a numpy.ndarray\n",
    "    y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "    model = train(X_train, X_valid, y_train, y_valid, config)\n",
    "    wandb.log({'fold': fold})\n",
    "    models[fold] = model\n",
    "    dump(model, Path(model_path/f\"xgboost_fold{fold}_model.joblib\"))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e972a4-67b9-4fd8-96b1-6525e805f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     dump(preds, f\"./preds/{config_rn['name']}/xgboost_fold{fold}_preds.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02baf90b-01bc-4945-b64c-5af0c6e309be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e394bc6-29fe-4033-a850-bf6d55883b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(datapath/'test.csv', index_col='id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e85f83d-b5a3-4c9e-b654-dfd743f2966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250000</th>\n",
       "      <td>0.812665</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.239120</td>\n",
       "      <td>-0.893251</td>\n",
       "      <td>295.5770</td>\n",
       "      <td>15.87120</td>\n",
       "      <td>23.04360</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>29.898000</td>\n",
       "      <td>1.11394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>-422.332</td>\n",
       "      <td>-1.44630</td>\n",
       "      <td>1.69075</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>-3.010570</td>\n",
       "      <td>1.94664</td>\n",
       "      <td>0.529470</td>\n",
       "      <td>1.386950</td>\n",
       "      <td>8.78767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250001</th>\n",
       "      <td>0.190344</td>\n",
       "      <td>131</td>\n",
       "      <td>-0.501361</td>\n",
       "      <td>0.801921</td>\n",
       "      <td>64.8866</td>\n",
       "      <td>3.09703</td>\n",
       "      <td>344.80500</td>\n",
       "      <td>0.807194</td>\n",
       "      <td>38.421900</td>\n",
       "      <td>1.09695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377179</td>\n",
       "      <td>10352.200</td>\n",
       "      <td>21.06270</td>\n",
       "      <td>1.84351</td>\n",
       "      <td>0.251895</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>11.79390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250002</th>\n",
       "      <td>0.919671</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.057382</td>\n",
       "      <td>0.901419</td>\n",
       "      <td>11961.2000</td>\n",
       "      <td>16.39650</td>\n",
       "      <td>273.24000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>1.15222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>3224.020</td>\n",
       "      <td>-2.25287</td>\n",
       "      <td>1.55100</td>\n",
       "      <td>-0.559157</td>\n",
       "      <td>17.838600</td>\n",
       "      <td>1.83385</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>2.336870</td>\n",
       "      <td>9.05400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250003</th>\n",
       "      <td>0.860985</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.549509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>7501.6000</td>\n",
       "      <td>2.80698</td>\n",
       "      <td>71.08170</td>\n",
       "      <td>0.792136</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>1.20157</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>9689.760</td>\n",
       "      <td>14.77150</td>\n",
       "      <td>1.41390</td>\n",
       "      <td>0.329272</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>2.23251</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>1.359470</td>\n",
       "      <td>4.84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250004</th>\n",
       "      <td>0.313229</td>\n",
       "      <td>89</td>\n",
       "      <td>0.588509</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>2931.2600</td>\n",
       "      <td>4.34986</td>\n",
       "      <td>1.57187</td>\n",
       "      <td>1.118300</td>\n",
       "      <td>7.754630</td>\n",
       "      <td>1.16807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>2693.350</td>\n",
       "      <td>44.18050</td>\n",
       "      <td>1.58020</td>\n",
       "      <td>-0.191021</td>\n",
       "      <td>26.253000</td>\n",
       "      <td>2.68238</td>\n",
       "      <td>0.361923</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>3.70660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f0   f1        f2        f3          f4        f5         f6  \\\n",
       "id                                                                           \n",
       "250000  0.812665   15 -1.239120 -0.893251    295.5770  15.87120   23.04360   \n",
       "250001  0.190344  131 -0.501361  0.801921     64.8866   3.09703  344.80500   \n",
       "250002  0.919671   19 -0.057382  0.901419  11961.2000  16.39650  273.24000   \n",
       "250003  0.860985   19 -0.549509  0.471799   7501.6000   2.80698   71.08170   \n",
       "250004  0.313229   89  0.588509  0.167705   2931.2600   4.34986    1.57187   \n",
       "\n",
       "              f7         f8       f9  ...       f90        f91       f92  \\\n",
       "id                                    ...                                  \n",
       "250000  0.942256  29.898000  1.11394  ...  0.446389   -422.332  -1.44630   \n",
       "250001  0.807194  38.421900  1.09695  ...  0.377179  10352.200  21.06270   \n",
       "250002 -0.003300  37.940000  1.15222  ...  0.990140   3224.020  -2.25287   \n",
       "250003  0.792136   0.395235  1.20157  ...  1.396880   9689.760  14.77150   \n",
       "250004  1.118300   7.754630  1.16807  ...  0.862502   2693.350  44.18050   \n",
       "\n",
       "            f93       f94        f95      f96       f97       f98       f99  \n",
       "id                                                                           \n",
       "250000  1.69075  1.059300  -3.010570  1.94664  0.529470  1.386950   8.78767  \n",
       "250001  1.84351  0.251895   4.440570  1.90309  0.248534  0.863881  11.79390  \n",
       "250002  1.55100 -0.559157  17.838600  1.83385  0.931796  2.336870   9.05400  \n",
       "250003  1.41390  0.329272   0.802437  2.23251  0.893348  1.359470   4.84833  \n",
       "250004  1.58020 -0.191021  26.253000  2.68238  0.361923  1.532800   3.70660  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ec520-259f-44d2-ad33-7b8c22621132",
   "metadata": {},
   "source": [
    "(Here's where encapsulating the transformations in a pipeline would come in handy. But I'll do it manually for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ec74e4-ccb8-43b4-b910-3df1542aaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in test_df.columns if x != 'loss']\n",
    "X_test = test_df[features] # this is just for naming consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725cd3e-f883-4d20-837a-9f557b2122a9",
   "metadata": {},
   "source": [
    "Now, let's get the features the model was trained on and subset the test set's features accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f66e579-7f01-46e5-a47c-580c8f5d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation polynomial features\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
    "# X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1817e3a-7d90-4bc2-8c47-e97806f7dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_poly_names = poly.get_feature_names(X_test.columns)\n",
    "# X_poly_names[100:150]\n",
    "# features = pd.read_csv('X_candidates_20210827.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d6bc49-d478-4f59-84d2-5e23e3e236db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks = [feature in X_test_poly_names for feature in features]\n",
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa68187e-271a-4df1-ae02-a2bb5d62c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = pd.DataFrame(X_test_poly, columns=X_test_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1020ad9b-1b05-49b8-b89b-c90362c256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final = X_test_final[features[1:]]\n",
    "X_test_final = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c226e-1ef7-4e03-91a1-06fbb73139f0",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "Now, going to scale using `MaxAbsScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21da840a-caa6-4d76-a542-c1315a593346",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = config['scaler']()\n",
    "X_test_scaled = scaler.fit_transform(X_test_final)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3cbac-0995-4015-9940-fe3e8ec94724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8929a3a1-56ca-4f20-a44f-e3877c6dabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# # scaling (i.e. normalizing)\n",
    "# scaler = config['scaler']()\n",
    "# X_train_s = scaler.fit_transform(X_train)\n",
    "# X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# # selecting features\n",
    "# selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "#                                       k=config['k_best'])\n",
    "# X_train_fs = selector.fit_transform(X_train_s, y_train)\n",
    "# X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "# model = XGBRegressor(\n",
    "#     tree_method=config['tree_method'],\n",
    "#     booster=config['booster'],\n",
    "#     n_estimators=config['n_estimators'], \n",
    "#     max_depth=config['max_depth'],\n",
    "#     learning_rate=config['learning_rate'], \n",
    "#     test_size=config['test_size'],\n",
    "#     subsample=config['subsample'],\n",
    "#     random_state=config['random_state'],\n",
    "#     n_jobs=config['n_jobs'], \n",
    "#     verbosity=config['verbosity'], \n",
    "# )\n",
    "# #     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "# model.fit(X_train_fs, y_train)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b151abea-d9b0-48eb-969f-5c342fc13474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 1: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 2: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 3: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1),\n",
       " 4: XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=1)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348db7c-c494-4616-a08f-55016fac5351",
   "metadata": {},
   "source": [
    "Now, iterate over the dict containing the models trained on the 5 folds, and store the predictions in a new dict `preds`\n",
    "**OR**\n",
    "load from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d608ff29-4ceb-43cb-a0bb-e1450c0b8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = {}\n",
    "# saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/inference_ensemble_20210828_204126_5folds/')\n",
    "# for fold in range(5):\n",
    "#     loaded_models[fold] = load(filename=Path(saved_models_path/f'xgboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285899b2-0b2e-4db3-9b1e-a0d8328b84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa072384-5154-4d54-8ddf-5452e9323882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "for fold in models.keys():\n",
    "    preds[fold] = models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a464a1c-9ca8-4a07-9cdb-18af399cf95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d6e6414-5f72-4a48-b5a1-a8d24486bbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc067fb9-ae8e-4b33-9d75-e5405043aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eca32f6-2267-4c98-9aa9-c4a31d69bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "       9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9d2f4b8-2356-4916-a091-45793db784ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c957ce26-bbf5-4aee-bccd-988f2471db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.007940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.532623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.855750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.124434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.444796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.007940\n",
       "1  250001  4.532623\n",
       "2  250002  7.855750\n",
       "3  250003  7.124434\n",
       "4  250004  7.444796"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4cc6d50-92bc-4295-9acc-5d345eb96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b13044-ddb7-4bfb-bdbc-71a42172efc1",
   "metadata": {},
   "source": [
    "# Ensembling with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85c2ffdf-6f70-4fbd-880d-2145c5e13ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_models = {}\n",
    "saved_models_path = Path('/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/aug2021/models/CatBoost_ensemble_20210831_144245_5folds/')\n",
    "for fold in range(5):\n",
    "    catboost_models[fold] = load(filename=Path(saved_models_path/f'catboost_fold{fold}_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22852978-0c80-413e-900d-363b6055661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <catboost.core.CatBoostRegressor at 0x7f1b154ecfa0>,\n",
       " 1: <catboost.core.CatBoostRegressor at 0x7f1b1548a880>,\n",
       " 2: <catboost.core.CatBoostRegressor at 0x7f1b154ec0a0>,\n",
       " 3: <catboost.core.CatBoostRegressor at 0x7f1b1548ac40>,\n",
       " 4: <catboost.core.CatBoostRegressor at 0x7f1b154ecdf0>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa291c7b-61c6-4ec4-928a-f01225ce68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = {}\n",
    "for fold in catboost_models.keys():\n",
    "    catboost_preds[fold] = catboost_models[fold].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e8099a5-b1aa-4aa0-926e-0d493a0dffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_catboost_preds = (catboost_preds[0] + catboost_preds[1] + catboost_preds[2] + catboost_preds[3] + catboost_preds[4]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b1883aa-4b27-4ae8-bf84-44eef2de90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = 0.6 * final_catboost_preds + 0.4 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30feee22-238b-4807-93df-9c005d91491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.40583658, 4.58774964, 8.32465697, 7.18375788, 7.13135284,\n",
       "        9.67367649, 9.96252577, 5.89393404, 7.22270917, 7.53612671]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f43e0f1-ada2-4299-9b96-10987b073f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_preds = 0.65 * final_catboost_preds + 0.35 * final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdf4700f-a87a-472a-9228-726c9d76748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.4389943 , 4.5923435 , 8.36373235, 7.18870129, 7.10523255,\n",
       "        9.67708804, 9.96419843, 5.87235472, 7.23656006, 7.52442615]),\n",
       " array([8.67110053, 4.62450053, 8.6372614 , 7.22330665, 6.92239076,\n",
       "        9.70097104, 9.97590847, 5.72130089, 7.33351626, 7.44252341]),\n",
       " array([8.00794  , 4.5326233, 7.85575  , 7.1244345, 7.444796 , 9.632734 ,\n",
       "        9.9424515, 6.1528835, 7.0564985, 7.6765313], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ensemble_preds[:10], final_catboost_preds[:10], final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c04c606-ea73-4744-8b7a-b71deef61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = final_ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f9f1b0b-9153-4607-b199-28b79d2db7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.438994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.592343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>8.363732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>7.188701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.105233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.438994\n",
       "1  250001  4.592343\n",
       "2  250002  8.363732\n",
       "3  250003  7.188701\n",
       "4  250004  7.105233"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c9f3ab0-a385-416c-9fd8-be27c4301874",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('XGBoost0.35-Catboost0.65_ensemble_20210831_no_feature_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67df4d3-54f8-43fe-9f14-d3751986a58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment - fitting model on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8331118-e7a3-4578-8e43-cf93067c6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:15] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"test_size\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1522, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=400, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             test_size=0.2, tree_method='auto', validate_parameters=1,\n",
       "             verbosity=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying hold-out before scaling\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                       test_size=config['test_size'], \n",
    "#                                                       random_state=config['random_state']\n",
    "#                                                      )\n",
    "# scaling (i.e. normalizing)\n",
    "scaler = config['scaler']()\n",
    "X_s = scaler.fit_transform(X)\n",
    "X_test_s = scaler.fit_transform(X_test)\n",
    "\n",
    "# selecting features\n",
    "selector = config['feature_selector'](score_func=config[\"feature_selection_scoring\"], \n",
    "                                      k=config['k_best'])\n",
    "X_fs = selector.fit_transform(X_s, y)\n",
    "X_test_fs = X_test_s[:, selector.get_support()]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    tree_method=config['tree_method'],\n",
    "    booster=config['booster'],\n",
    "    n_estimators=config['n_estimators'], \n",
    "    max_depth=config['max_depth'],\n",
    "    learning_rate=config['learning_rate'], \n",
    "    test_size=config['test_size'],\n",
    "    subsample=config['subsample'],\n",
    "    random_state=config['random_state'],\n",
    "    n_jobs=config['n_jobs'], \n",
    "    verbosity=config['verbosity'], \n",
    ")\n",
    "#     wandb.log({'params': model.get_params()}) # logging model parameters\n",
    "model.fit(X_fs, y)#, callbacks=[wandb.xgboost.wandb_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90ba24b-75cd-4c2d-a2cf-fe7bf16b3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db93b42-8460-4793-bd0f-60ddb1d7e84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bfc7e54-043d-4abb-818e-503846c0f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'loss'] = y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50b58c49-59e9-4751-8373-98536c9a121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>8.027956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>4.305676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>7.300106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>6.988875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>7.316631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      loss\n",
       "0  250000  8.027956\n",
       "1  250001  4.305676\n",
       "2  250002  7.300106\n",
       "3  250003  6.988875\n",
       "4  250004  7.316631"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41d0f44a-2ca7-486f-9197-48534a35043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('202108241211_XGBoost_fullset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
