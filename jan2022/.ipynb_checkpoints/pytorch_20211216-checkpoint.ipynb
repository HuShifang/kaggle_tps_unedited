{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "20211202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "SAGE = False # if notebook will be used on Amazon SageMaker\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a1b04-72db-4d9f-abae-b9c3bd5a3587",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score#, log_loss, roc_auc_score\n",
    "\n",
    "# eda\n",
    "import missingno\n",
    "import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "import cleanlab\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "# widedeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef8a92-b59f-4ef4-914f-5dce28bb8c8c",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f463683d-4dd3-4c72-b4eb-96f27c51cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    if SAGE:\n",
    "        root = Path('/home/studio-lab-user/sagemaker-studiolab-notebooks')\n",
    "    else:\n",
    "        root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/dec2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    checkpath = root/'checkpoints'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath, checkpath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9e0d-1301-4ade-a63d-9f3d298c2255",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba521a1a-8c41-4b9b-becd-36eb62739ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3f6bf0-8338-4cde-8ab7-5bfd9c6ff317",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf3757f-7a87-47ef-b221-e6f8dd7113a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid weight leakage.\n",
    "    h/t Christian Versloot (https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/)\n",
    "    '''\n",
    "    # print(\"Resetting weights\")\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            # print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc27764-fd0b-4781-81c5-6887f81b55f7",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde7818e-d829-436b-a0a5-2691b53a6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad459104-e31a-4aa0-8a9a-bb279e2b9944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "# dataset_params = {\n",
    "#     'train_source': str(datapath/'X_orig.feather'),\n",
    "#     'target_source': str(datapath/'y_orig.joblib'),\n",
    "#     'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "#     # 'scaler': str(RobustScaler()),\n",
    "#     # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "#     # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "# }   \n",
    "\n",
    "# # referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# # dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# # dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# # now, load the datasets and generate more metadata from them\n",
    "# # X = load(dataset_params['train_source'])\n",
    "# X = pd.read_feather(dataset_params['train_source'])\n",
    "# y = load(dataset_params['target_source'])\n",
    "# # X_test = load(dataset_params['test_source'])\n",
    "# X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "# # reduce memory usage\n",
    "# X = reduce_memory_usage(X)\n",
    "# X_test = reduce_memory_usage(X)\n",
    "\n",
    "# # metadata logging\n",
    "# dataset_params['feature_count'] = X.shape[1]\n",
    "# dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe08f0f6-2aa1-4a7f-83da-8b3e5445a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv(datapath/'train.csv', low_memory=False)\n",
    "# test_df = pd.read_csv(datapath/'test.csv', low_memory=False)\n",
    "# data_df = reduce_memory_usage(data_df)\n",
    "# test_df = reduce_memory_usage(test_df)\n",
    "# data_df.to_feather(datapath/'train.feather')\n",
    "# test_df.to_feather(datapath/'test.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789d994-1ae1-4d36-80a4-455d8398db50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d647e8af-e065-4ea8-aa6c-5d158791904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- alter as needed later\n",
    "exmodel_config = {\n",
    "    'general_random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    # **dataset_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338dffc-f3b3-4a5b-a038-2562e617c1ee",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512ee5ac-2240-4788-887f-cacc98087084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feather_file, root_dir=datapath):\n",
    "        '''\n",
    "        Loads the data from a CSV (or in this case a feather) file\n",
    "        - feather_file:pathlib.Path - Path to the .feather file containing data\n",
    "        - root_dir:pathlib.Path - Path to the root directory for the data\n",
    "                '''\n",
    "        self.df = pd.read_feather(root_dir/feather_file) # makes the digits available\n",
    "        self.feather_file = feather_file # attribute for later inspection\n",
    "        self.root_dir = root_dir # attribute for later inspection\n",
    "        # self.transforms = transforms \n",
    "        # CONSIDER: whether to do feature engineering at all; whether to use GaussScaler\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): # handles the case where idx is a tensor\n",
    "            idx = idx.tolist() # converts it to a list\n",
    "        # data = np.array(self.df.iloc[idx, :-1]) # fetches all but the label as a np.ndarray\n",
    "        \n",
    "        # create torch tensors on the GPU (if available)\n",
    "        data = torch.tensor(self.df.iloc[idx, :-1], device=device, dtype=torch.float32)\n",
    "        label = torch.tensor(self.df.iloc[idx, -1], device=device, dtype=torch.float32)\n",
    "        # label = self.df.iloc[idx, -1] # fetches the label as a np.int8\n",
    "        # img = np.expand_dims(img, axis=0) # adding a channel dimension before the others\n",
    "            \n",
    "        # if self.transforms: # expects transforms to be in A.Compose(transforms=[...]) form\n",
    "        #     augmented = self.transforms(image=img) # returns dict of {'image': ...}\n",
    "        #     data_tensor = augmented['image'] \n",
    "        \n",
    "        # return {'label': label, 'image': data_tensor}\n",
    "        return {'label': label, 'data':data}\n",
    "        \n",
    "    # def viz(self, idx:int):\n",
    "    #     '''\n",
    "    #     Visualizes a single item from the dataset using matplotlib\n",
    "    #     '''\n",
    "    #     if not isinstance(idx, int):\n",
    "    #         print(\"Argument must be an integer.\")\n",
    "    #         return None\n",
    "    #     item = self.__getitem__(idx)\n",
    "    #     print(item['label'])\n",
    "    #     plt.imshow(np.transpose(item['image'].numpy(), axes=(1,2,0)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650adca7-216e-48e4-a6d3-8a0d10f59220",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ForestDataset(root_dir=datapath, feather_file=datapath/'train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba0df58-c15d-4ba4-8fc4-5292c691fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ForestDataset(root_dir=datapath, feather_file=datapath/'test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39b37bda-7da8-4869-b759-2fad7f12e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1., device='cuda:0'),\n",
       " 'data': tensor([0.0000e+00, 3.1890e+03, 4.0000e+01, 8.0000e+00, 3.0000e+01, 1.3000e+01,\n",
       "         3.2700e+03, 2.0600e+02, 2.3400e+02, 1.9300e+02, 4.8730e+03, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00], device='cuda:0')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11840776-ef9e-44cf-8acb-852ef9de796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fe5dfb-146a-475c-90ff-c98be0f569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df.iloc[:,-1].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab758b-e782-4fe8-8563-5fde8208f0e3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398f9a32-6cbf-474d-83c6-8d594715e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestModel(nn.Module):\n",
    "    def __init__(self, out_dim=7, num_features=55):\n",
    "        super(ForestModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_features, out_features=40)\n",
    "        self.fc2 = nn.Linear(in_features=40, out_features=28)\n",
    "        self.fc3 = nn.Linear(in_features=28, out_features=15)\n",
    "        self.fc4 = nn.Linear(in_features=15, out_features=7)\n",
    "        self.drop = nn.AlphaDropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x\n",
    "        x = F.selu(self.fc1(x))\n",
    "        x = F.selu(self.fc2(x))\n",
    "        x = F.selu(self.fc3(x))\n",
    "        scores = self.drop(self.fc4(x))\n",
    "        return scores\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37649ca6-5498-4c0f-9421-9cf33d99deb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MNISTModel(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Based on Jean-Francois Puget's STFT Transformer for the 2021 BirdCLEF competition.\n",
    "#     - backbone_name:str -- a string that will be passed to timm.create_model to create a model meant to do the lion's share of the processing\n",
    "#     - out_dim:int=10 -- the number of dimensions in the output; here, 10, for the probability of each digit-class\n",
    "#     - embedding_size:int=5 -- the number of dimensions in the embedding; various rules of thumb converge to 5 given the 10 categories\n",
    "#     - pretrained:bool=True -- whether or not to use a pretrained backbone model\n",
    "    \n",
    "#     \"\"\"\n",
    "#     def __init__(self, backbone_name:str='resnext50_32x4d', out_dim=10, embedding_size=5, pretrained=True):\n",
    "#         super(MNISTModel, self).__init__()\n",
    "#         self.backbone_name = backbone_name # this should be a string that will be passed to timm.create_model -- NOT an instance of the Backbone class\n",
    "#         self.out_dim = out_dim # WHAT DOES THIS REALLY REPRESENT?\n",
    "#         self.embedding_size = embedding_size\n",
    "#         self.backbone = Backbone(backbone_name, pretrained=pretrained) # a constructor-wrapper around timm.create_model that handles differing head-layers\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d(1) # presumably 1 is fine b/c we want a probability at the end\n",
    "#         self.neck = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(in_features=self.backbone.out_features, out_features=self.embedding_size, bias=False),#bias=True), (Karpathy - A Recipe for Training Neural Networks (20190425))\n",
    "# #             nn.BatchNorm1d(self.embedding_size), # won't work with shape (1,512) i.e. single-channel data, b/c needs non-1 value for all dims\n",
    "#             nn.LayerNorm(self.embedding_size), # will work with (1,512) shape\n",
    "#             nn.PReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.head = nn.Linear(self.embedding_size, out_dim) # TODO: inspect this, see if it's outputting logits, probs, or preds\n",
    "#         # self.head = nn.Linear(\n",
    "        \n",
    "#     def forward(self, data, get_embeddings=False, get_attentions=False):\n",
    "# #         print(f\"Input data has shape {data.shape}\")# and the value is:\\n{data}\")\n",
    "# #         x = data[0] # the first item in the incoming tuple, i.e. the tensor\n",
    "# #         print(f\"x.shape is {x.shape}\")\n",
    "# #         x = x.unsqueeze(1) # adding in a channel -- assumes input doesn't have that dim\n",
    "# #         print(f\"After unsqueeze(1), x.shape is {x.shape}\")\n",
    "# #         print(x.shape)\n",
    "# #         x = x.expand(-1, 3, -1, -1) # inflates input to be three-channel\n",
    "# #         print(f\"After x.expand(-1,3,-1,-1), x.shape is {x.shape}\")\n",
    "# #         x = x.expand(3,-1,-1)\n",
    "#         x = data\n",
    "#         x = self.backbone(x)\n",
    "# #         print(f\"After the backbone, x.shape is {x.shape}\")\n",
    "#         if 'vit' not in self.backbone_name:\n",
    "#             x = self.global_pool(x) \n",
    "#             x = x[:,:,0,0] # in timm implementations, this is replaced with the layer torch.nn.Flatten\n",
    "#             # tensor shape here is (1,2048)\n",
    "#         x = self.neck(x)\n",
    "#         # tensor shape here is (1,5)\n",
    "#         # return x\n",
    "#         logits = self.head(x)\n",
    "#         return logits # this outputs the unnormalized scores for the 10 classes; pass the tensor to F.softmax for probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7179e0-9b1f-45c1-b500-1e8ad44b57d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9080929-99bd-484e-833e-d69e84da8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForestModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be31e0ae-762d-443c-bc15-e25dbc4ca2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ForestModel                              --\n",
       "├─Linear: 1-1                            2,240\n",
       "├─Linear: 1-2                            1,148\n",
       "├─Linear: 1-3                            435\n",
       "├─Linear: 1-4                            112\n",
       "├─AlphaDropout: 1-5                      --\n",
       "=================================================================\n",
       "Total params: 3,935\n",
       "Trainable params: 3,935\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe61d35-bd07-407e-b4e7-ae24f1d05708",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.randn(1,55, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "107a6933-af1a-4a06-b89c-3c15a3d69712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1940,  2.1614, -0.1721,  0.8491, -1.9244,  0.6530, -0.6494, -0.8175,\n",
       "          0.5280, -1.2753, -1.6621, -0.3033, -0.0926,  0.1992, -1.1204,  1.8577,\n",
       "         -0.7145,  0.6881,  0.7968, -0.0334,  1.4917, -0.5165, -0.2541,  1.4746,\n",
       "         -0.3260, -1.1600,  2.3551, -0.6924,  0.1837, -1.1835, -1.8029, -1.5808,\n",
       "          0.8387,  1.4192,  0.6469,  0.4253, -1.5892,  0.6223,  1.6898, -0.6648,\n",
       "          0.9425,  0.0783,  0.0847, -0.1408,  0.3316, -0.5890, -1.0723,  0.0954,\n",
       "         -0.3347, -0.5258, -0.8776,  0.3938,  0.1640, -0.1977,  1.0104]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab38130-8bd8-4a4c-bcd9-5b08d858fc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0595,  0.0101,  0.5060,  0.6401, -1.0595,  0.4837, -1.0595]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b2d34bf-8f0e-4e97-9840-a6d3c264146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e8d4eea-5db7-492c-94b0-c1bf9d6d4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "bs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81507262-6882-4e39-8213-6f92acacf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=dataset, batch_size=bs, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "757e24da-f393-46dc-9511-d1ff043326fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41db29be-a9be-4ceb-9177-ce97a82187f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trainloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1173a970-bdfa-4bb0-8a22-dcddaa331bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2251a3e-31dc-47d5-9dbb-a4ffba7d8c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acc14004-0733-4a20-9fd0-d35fbe83614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-8e7db6f49aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "data = data.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "beabbafb-f35d-42ee-8ec5-803406a5daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs has shape torch.Size([55]), dtype torch.float32, and device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-743ce4b80ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(f\"Outputs is type {outputs.dtype}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "inputs = data['data']#.to(dtype=torch.float32)\n",
    "print(f\"inputs has shape {inputs.shape}, dtype {inputs.dtype}, and device {inputs.device}\")\n",
    "targets = data['label'].to(dtype=torch.long).unsqueeze(0)\n",
    "# print(f\"type(inputs) = {inputs.dtype}, type(targets) = {targets.dtype}\")\n",
    "# inputs = inputs.to(device)\n",
    "# targets = targets.to(device)\n",
    "optimizer.zero_grad()\n",
    "outputs = model(inputs)\n",
    "# outputs = outputs.to(device)\n",
    "# print(f\"Targets are: {targets}\")\n",
    "# print(f\"Outputs are: {outputs}\")\n",
    "# print(f\"Outputs is type {outputs.dtype}\")\n",
    "\n",
    "loss = loss_function(outputs, targets)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33df6faa-7eee-458f-a83c-96859544383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -1.0595, -17.9349,  -1.0595, -24.7569,  -1.0595, -36.4029,  -1.0595],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d56e27a-bbdc-4a63-bc1a-b243f17c0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5f7bcc7-cb4a-4b45-a475-0a4e4927a7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75bc67f2-25ce-4945-b375-4a1fa99657ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a5cc0c30202d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "F.cross_entropy(target=targets, input=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ddf7581-be97-4da9-9837-1526417f5eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "alt_targets = torch.tensor([1], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83b2ee0a-cb22-42e4-a030-a893d71d9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d084fd33a462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "F.cross_entropy(target=alt_targets, input=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3674e643-5143-455f-bc72-d2f91e18e45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee35b8-595a-46e5-b4f6-802855f1992f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e77f1da-c80b-4a9f-bfcd-95710b4d9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Beginning epoch 0\n",
      "inputs has shape torch.Size([512, 55]), dtype torch.float32, and device cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /tmp/pip-req-build-1_ic8ial/aten/src/THC/generic/THCTensorMath.cu:29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4253c0d81ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# print(f\"Outputs is type {outputs.dtype}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# because it's a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /tmp/pip-req-build-1_ic8ial/aten/src/THC/generic/THCTensorMath.cu:29"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "    \n",
    "    trainloader = DataLoader(dataset=dataset, sampler=train_subsampler, batch_size=bs, num_workers=0,)# pin_memory=True,)\n",
    "    validloader = DataLoader(dataset=dataset, sampler=valid_subsampler, batch_size=bs, num_workers=0,)# pin_memory=True,)\n",
    "    \n",
    "    model.apply(reset_weights) # resetting weights so that you don't have fold leakage\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        print(f\"Beginning epoch {epoch}\")\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs = data['data']#.to(dtype=torch.float32)\n",
    "            print(f\"inputs has shape {inputs.shape}, dtype {inputs.dtype}, and device {inputs.device}\")\n",
    "            targets = data['label'].to(dtype=torch.long)\n",
    "            # print(f\"type(inputs) = {inputs.dtype}, type(targets) = {targets.dtype}\")\n",
    "            # inputs = inputs.to(device)\n",
    "            # targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # outputs = outputs.to(device)\n",
    "            # print(f\"Targets are: {targets}\")\n",
    "            # print(f\"Outputs are: {outputs}\")\n",
    "            # print(f\"Outputs is type {outputs.dtype}\")\n",
    "            \n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() # because it's a tensor\n",
    "        train_loss /= len(trainloader.dataset)\n",
    "        print(f\"Training loss is {train_loss}\")\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for i, data in enumerate(validloader):\n",
    "            inputs = data['data']#.to(dtype=torch.float32)\n",
    "            targets = data['label'].to(dtype=torch.long)\n",
    "            # print(f\"type(inputs) = {inputs.dtype}, type(targets) = {targets.dtype}\")\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # optimizer.zero_grad() # only for training\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(f\"Targets are: {targets}\")\n",
    "            # print(f\"Outputs are: {outputs}\")\n",
    "            # print(f\"Outputs is type {outputs.dtype}\")\n",
    "            loss = loss_function(outputs, targets)\n",
    "            # loss.backward() # only for training\n",
    "            # optimizer.step() # only for training\n",
    "            valid_loss += loss.item() # because it's a tensor\n",
    "            correct = torch.eq(torch.max(F.softmax(outputs, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(validloader.dataset)\n",
    "        \n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, train_loss, valid_loss, num_correct / num_examples))\n",
    "    torch.save(model.state_dict(), checkpath)/f'resnext50_fold{fold}.pth'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
