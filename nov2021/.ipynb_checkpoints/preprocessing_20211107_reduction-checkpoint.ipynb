{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecdedba-fd6e-4e6a-ab87-68108468b4fc",
   "metadata": {},
   "source": [
    "# 20211106 Feature Reduction\n",
    "Going to try PCA, UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848329c7-20b7-45c3-888d-63ed7279ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fdbcb2-424d-413a-a2f8-fda29d34660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b700b2a9-c6f3-4a90-8388-b0786496198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac63a2-b6f3-47e0-9d2c-3db5e4df7b73",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fa5891-cd96-4972-a73e-c17589841610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b22baff-8382-4d45-9c29-bad772996ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /tmp/pip-req-build-1_ic8ial/c10/cuda/CUDAFunctions.cpp:115.)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0c537d-5a49-4888-936f-455d58d883b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7fe21-6d37-480d-9edb-8aad255eb5a9",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89819f0-d4be-46a3-90a3-b90f10626778",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f32fb7-d18d-459b-80a9-516e407409ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d263f3d-28d5-4e0d-b2ec-f7bf0942f356",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c647bab-e6c5-42e9-b489-64d890a47ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "exmodel_config = {\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "#     'random_state': SEED,\n",
    "#     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     'subsample': 1,\n",
    "    'cross_val_strategy': KFold, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 5, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94d24c-51de-4fda-b920-b7bb1aaab669",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f6197-3010-4e72-b6a6-1c55dd5b2069",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e847fffd-2ff7-4050-8545-711c6d15a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exmodel_config['scaler']:\n",
    "#     scaler = exmodel_config['scaler']()\n",
    "#     scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6666c03-3a95-4726-b740-17d0b88ed40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = datapath/'test.feather'\n",
    "# # test_source = altdatapath/'test-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' # altdatapath/'X_test_boruta_shap_200trials.feather'\n",
    "exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "# # boruta = load(altdatapath/'boruta_shap.joblib')\n",
    "# # X_test_enc = \n",
    "# # X_test = X_test.iloc[:, 1:] # only if loading the original test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054bc60e-2db1-4e10-b25b-165ae6f6540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "# X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c0e7a3-ad91-4853-9b0e-35ca3d2f937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'X_orig.feather'\n",
    "# train_source = altdatapath/'train-WITH-KMeans_12cluster_kmeans++_maxiter1000_rs42.feather' #'X_boruta_shap_200trials.feather'\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "X = pd.read_feather(path=train_source)\n",
    "# if 'target' in X.columns:\n",
    "#     X = X.drop(['target'], axis=1)\n",
    "# df.index.name = 'id'\n",
    "# y = np.array(df.target)\n",
    "y = load(datapath/'y_orig.joblib')\n",
    "# features = [x for x in df.columns if x != 'target']\n",
    "# X = df[features] # passing X as a pd.DataFrame to the trainer below, rather than as an np.ndarray\n",
    "# X_train = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3514e0-553a-46df-bb9a-e7c950026650",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_np = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5306a53-33b1-48fe-92ae-88e7d271f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X_np, columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11215c5a-e5e3-4d5e-8908-e00b0c4910d6",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91ed7d-6f12-4c8c-ae46-6f6eefcb5546",
   "metadata": {},
   "source": [
    "Let's try something like the pipeline cited as \"typical\" on the [UMAP FAQ page](https://umap-learn.readthedocs.io/en/latest/faq.html):\n",
    "\n",
    "> Consider a typical pipeline: high-dimensional embedding (300+) => PCA to reduce to 50 dimensions => UMAP to reduce to 10-20 dimensions => HDBSCAN for clustering / some plain algorithm for classification;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae113837-dea8-470f-bbfa-537b38dbac3c",
   "metadata": {},
   "source": [
    "## 1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68a01d-eff8-4c23-8020-3689d368436a",
   "metadata": {},
   "source": [
    "I'll skip the \"high-dimensional embedding\" part insofar as I don't have any categorical variables. And I'll let `mle` determine the number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a8daa5-0e40-4b3e-a58d-babaa85c864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1a0bbc-f449-4198-9e4f-8c799e5737ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components='mle', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c2e3feb-37f3-4193-833c-df0b293daef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/datasets/pca_mle-RobustScaled_orig_trainset.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.fit_transform(X)\n",
    "dump(pca, datapath/'pca_mle-RobustScaled_orig_trainset.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c08cd79-884b-48fe-bf7f-7bf627d000d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.712092</td>\n",
       "      <td>-3.039303</td>\n",
       "      <td>-1.987172</td>\n",
       "      <td>-0.578403</td>\n",
       "      <td>-1.370641</td>\n",
       "      <td>11.474382</td>\n",
       "      <td>-2.379167</td>\n",
       "      <td>-0.937235</td>\n",
       "      <td>-2.594491</td>\n",
       "      <td>-2.151906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179098</td>\n",
       "      <td>0.271471</td>\n",
       "      <td>0.298934</td>\n",
       "      <td>-0.224963</td>\n",
       "      <td>-0.132194</td>\n",
       "      <td>-0.284666</td>\n",
       "      <td>-0.558664</td>\n",
       "      <td>-0.252547</td>\n",
       "      <td>-0.440240</td>\n",
       "      <td>0.479289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.495624</td>\n",
       "      <td>-0.795305</td>\n",
       "      <td>-0.558700</td>\n",
       "      <td>0.389478</td>\n",
       "      <td>-1.006746</td>\n",
       "      <td>-1.348991</td>\n",
       "      <td>-1.043400</td>\n",
       "      <td>-1.305068</td>\n",
       "      <td>-0.761200</td>\n",
       "      <td>-1.488306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031016</td>\n",
       "      <td>-0.135605</td>\n",
       "      <td>0.196139</td>\n",
       "      <td>0.388194</td>\n",
       "      <td>0.199077</td>\n",
       "      <td>-0.085138</td>\n",
       "      <td>-0.392932</td>\n",
       "      <td>0.342501</td>\n",
       "      <td>-0.295981</td>\n",
       "      <td>-0.953330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.928110</td>\n",
       "      <td>-2.377723</td>\n",
       "      <td>-1.526275</td>\n",
       "      <td>-0.318966</td>\n",
       "      <td>-1.614533</td>\n",
       "      <td>-2.112136</td>\n",
       "      <td>-1.716707</td>\n",
       "      <td>3.218080</td>\n",
       "      <td>-0.495027</td>\n",
       "      <td>-0.747700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100588</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>-0.485187</td>\n",
       "      <td>-0.541339</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.035050</td>\n",
       "      <td>0.944401</td>\n",
       "      <td>-0.025735</td>\n",
       "      <td>0.098342</td>\n",
       "      <td>0.308155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.964916</td>\n",
       "      <td>-1.004537</td>\n",
       "      <td>-2.112259</td>\n",
       "      <td>-0.417141</td>\n",
       "      <td>-1.870255</td>\n",
       "      <td>-1.997467</td>\n",
       "      <td>-1.606478</td>\n",
       "      <td>-1.895262</td>\n",
       "      <td>0.203275</td>\n",
       "      <td>-1.368667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508566</td>\n",
       "      <td>0.954413</td>\n",
       "      <td>0.406270</td>\n",
       "      <td>0.462892</td>\n",
       "      <td>0.092340</td>\n",
       "      <td>0.261099</td>\n",
       "      <td>1.077867</td>\n",
       "      <td>0.381276</td>\n",
       "      <td>0.527398</td>\n",
       "      <td>0.233128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.440551</td>\n",
       "      <td>1.783703</td>\n",
       "      <td>-1.128116</td>\n",
       "      <td>0.151530</td>\n",
       "      <td>-1.305119</td>\n",
       "      <td>-1.391343</td>\n",
       "      <td>-0.766827</td>\n",
       "      <td>-0.897287</td>\n",
       "      <td>-0.753682</td>\n",
       "      <td>-1.993990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154709</td>\n",
       "      <td>-0.707765</td>\n",
       "      <td>-0.268428</td>\n",
       "      <td>-0.617855</td>\n",
       "      <td>0.337783</td>\n",
       "      <td>0.176240</td>\n",
       "      <td>0.828138</td>\n",
       "      <td>-0.663256</td>\n",
       "      <td>-0.886622</td>\n",
       "      <td>-0.314749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4          5         6   \\\n",
       "0 -0.712092 -3.039303 -1.987172 -0.578403 -1.370641  11.474382 -2.379167   \n",
       "1 -1.495624 -0.795305 -0.558700  0.389478 -1.006746  -1.348991 -1.043400   \n",
       "2 -0.928110 -2.377723 -1.526275 -0.318966 -1.614533  -2.112136 -1.716707   \n",
       "3 -0.964916 -1.004537 -2.112259 -0.417141 -1.870255  -1.997467 -1.606478   \n",
       "4 -0.440551  1.783703 -1.128116  0.151530 -1.305119  -1.391343 -0.766827   \n",
       "\n",
       "         7         8         9   ...        89        90        91        92  \\\n",
       "0 -0.937235 -2.594491 -2.151906  ... -0.179098  0.271471  0.298934 -0.224963   \n",
       "1 -1.305068 -0.761200 -1.488306  ... -0.031016 -0.135605  0.196139  0.388194   \n",
       "2  3.218080 -0.495027 -0.747700  ...  0.100588  0.352500 -0.485187 -0.541339   \n",
       "3 -1.895262  0.203275 -1.368667  ...  0.508566  0.954413  0.406270  0.462892   \n",
       "4 -0.897287 -0.753682 -1.993990  ... -0.154709 -0.707765 -0.268428 -0.617855   \n",
       "\n",
       "         93        94        95        96        97        98  \n",
       "0 -0.132194 -0.284666 -0.558664 -0.252547 -0.440240  0.479289  \n",
       "1  0.199077 -0.085138 -0.392932  0.342501 -0.295981 -0.953330  \n",
       "2  0.000051 -0.035050  0.944401 -0.025735  0.098342  0.308155  \n",
       "3  0.092340  0.261099  1.077867  0.381276  0.527398  0.233128  \n",
       "4  0.337783  0.176240  0.828138 -0.663256 -0.886622 -0.314749  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca_df = pd.DataFrame(X_pca, index=X.index)\n",
    "X_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a953a0ef-16d2-4882-b27f-b0f176fb3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.414343</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.223129</td>\n",
       "      <td>0.219181</td>\n",
       "      <td>-0.549174</td>\n",
       "      <td>0.356604</td>\n",
       "      <td>-0.117173</td>\n",
       "      <td>-0.149785</td>\n",
       "      <td>-0.569723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615937</td>\n",
       "      <td>-0.519509</td>\n",
       "      <td>-0.523000</td>\n",
       "      <td>-1.073580</td>\n",
       "      <td>-0.111175</td>\n",
       "      <td>0.042435</td>\n",
       "      <td>0.625515</td>\n",
       "      <td>-0.282294</td>\n",
       "      <td>0.287257</td>\n",
       "      <td>2.097848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073411</td>\n",
       "      <td>-0.324111</td>\n",
       "      <td>-0.220699</td>\n",
       "      <td>0.301799</td>\n",
       "      <td>0.406584</td>\n",
       "      <td>0.980651</td>\n",
       "      <td>-0.584290</td>\n",
       "      <td>-1.216782</td>\n",
       "      <td>0.824004</td>\n",
       "      <td>-0.258296</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142983</td>\n",
       "      <td>0.432846</td>\n",
       "      <td>-0.487967</td>\n",
       "      <td>1.071220</td>\n",
       "      <td>0.943432</td>\n",
       "      <td>7.115126</td>\n",
       "      <td>-1.115475</td>\n",
       "      <td>-0.041835</td>\n",
       "      <td>-0.812236</td>\n",
       "      <td>-0.388992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.165673</td>\n",
       "      <td>-0.391725</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>-0.178365</td>\n",
       "      <td>-0.372808</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>0.863859</td>\n",
       "      <td>0.518747</td>\n",
       "      <td>-0.268295</td>\n",
       "      <td>-0.021567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882475</td>\n",
       "      <td>1.006638</td>\n",
       "      <td>0.153544</td>\n",
       "      <td>-0.380862</td>\n",
       "      <td>0.548134</td>\n",
       "      <td>-0.833910</td>\n",
       "      <td>-1.213478</td>\n",
       "      <td>-0.217131</td>\n",
       "      <td>0.683318</td>\n",
       "      <td>1.034235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.301555</td>\n",
       "      <td>-0.872802</td>\n",
       "      <td>2.498527</td>\n",
       "      <td>-0.301544</td>\n",
       "      <td>-0.587486</td>\n",
       "      <td>-0.414987</td>\n",
       "      <td>-0.039545</td>\n",
       "      <td>0.787011</td>\n",
       "      <td>0.807038</td>\n",
       "      <td>0.794548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.982719</td>\n",
       "      <td>0.438580</td>\n",
       "      <td>-0.809415</td>\n",
       "      <td>-1.016802</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>-0.273769</td>\n",
       "      <td>-0.812462</td>\n",
       "      <td>-0.286376</td>\n",
       "      <td>-0.185636</td>\n",
       "      <td>-0.156724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.272393</td>\n",
       "      <td>0.460876</td>\n",
       "      <td>0.086985</td>\n",
       "      <td>-0.197278</td>\n",
       "      <td>-0.465605</td>\n",
       "      <td>-0.192678</td>\n",
       "      <td>0.518429</td>\n",
       "      <td>-1.042825</td>\n",
       "      <td>0.356489</td>\n",
       "      <td>-0.301740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573168</td>\n",
       "      <td>-0.192062</td>\n",
       "      <td>-1.052588</td>\n",
       "      <td>0.768968</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>-0.321887</td>\n",
       "      <td>-0.605630</td>\n",
       "      <td>-0.645120</td>\n",
       "      <td>-0.729316</td>\n",
       "      <td>0.165118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.023869  0.414343 -0.003178  0.223129  0.219181 -0.549174  0.356604   \n",
       "1  0.073411 -0.324111 -0.220699  0.301799  0.406584  0.980651 -0.584290   \n",
       "2 -0.165673 -0.391725  0.386256 -0.178365 -0.372808  0.210182  0.863859   \n",
       "3 -0.301555 -0.872802  2.498527 -0.301544 -0.587486 -0.414987 -0.039545   \n",
       "4 -0.272393  0.460876  0.086985 -0.197278 -0.465605 -0.192678  0.518429   \n",
       "\n",
       "         f7        f8        f9  ...       f90       f91       f92       f93  \\\n",
       "0 -0.117173 -0.149785 -0.569723  ... -0.615937 -0.519509 -0.523000 -1.073580   \n",
       "1 -1.216782  0.824004 -0.258296  ...  1.142983  0.432846 -0.487967  1.071220   \n",
       "2  0.518747 -0.268295 -0.021567  ...  0.882475  1.006638  0.153544 -0.380862   \n",
       "3  0.787011  0.807038  0.794548  ... -0.982719  0.438580 -0.809415 -1.016802   \n",
       "4 -1.042825  0.356489 -0.301740  ... -0.573168 -0.192062 -1.052588  0.768968   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.111175  0.042435  0.625515 -0.282294  0.287257  2.097848  \n",
       "1  0.943432  7.115126 -1.115475 -0.041835 -0.812236 -0.388992  \n",
       "2  0.548134 -0.833910 -1.213478 -0.217131  0.683318  1.034235  \n",
       "3 -0.014837 -0.273769 -0.812462 -0.286376 -0.185636 -0.156724  \n",
       "4  0.641618 -0.321887 -0.605630 -0.645120 -0.729316  0.165118  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473efd6-b25b-4fc4-b3ea-fc8dbff3088d",
   "metadata": {},
   "source": [
    "# UMAP\n",
    "Following directions [here](https://umap-learn.readthedocs.io/en/latest/basic_usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c0cbd7-61f2-4e91-82bd-b4d8cb13f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "Tensorflow not installed; ParametricUMAP will be unavailable\n"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8d5b783-cbcb-43e7-9bce-ba3182d01483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP(n_components=10, # low end of typical for feature reduction\n",
    "                    n_neighbors=15, # default value\n",
    "                    random_state=42,\n",
    "                    transform_seed=42,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d76b76d-3f21-4f87-8dfd-dd1c8de37933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/datasets/umap_reducer-20211107-n_comp10-n_neighbors15-rs42.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umapper = reducer.fit(X_pca)\n",
    "dump(reducer, datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32cc388-082e-4af1-9381-0c220cfe450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umapper = load(datapath/'umap_reducer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7252daf3-cde0-4442-b893-5397eb86fde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/datasets/X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = reducer.transform(X_pca)\n",
    "embedding.shape\n",
    "dump(embedding, datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d2a2b1-0967-42b8-b947-e60c5e274e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = load(datapath/'X_orig-RobustScaled-umap_embedding.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5420027-5046-4a2b-88f5-2c82aaba0012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.053730</td>\n",
       "      <td>-1.756666</td>\n",
       "      <td>11.378860</td>\n",
       "      <td>6.936342</td>\n",
       "      <td>6.235762</td>\n",
       "      <td>8.824183</td>\n",
       "      <td>9.119911</td>\n",
       "      <td>3.103356</td>\n",
       "      <td>9.724831</td>\n",
       "      <td>3.719539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.554933</td>\n",
       "      <td>-0.268288</td>\n",
       "      <td>7.588934</td>\n",
       "      <td>7.686738</td>\n",
       "      <td>6.930284</td>\n",
       "      <td>8.368870</td>\n",
       "      <td>7.913663</td>\n",
       "      <td>0.505868</td>\n",
       "      <td>8.038529</td>\n",
       "      <td>3.076725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963801</td>\n",
       "      <td>-0.150520</td>\n",
       "      <td>10.355945</td>\n",
       "      <td>7.051244</td>\n",
       "      <td>6.157423</td>\n",
       "      <td>10.085479</td>\n",
       "      <td>8.593321</td>\n",
       "      <td>2.286653</td>\n",
       "      <td>10.166838</td>\n",
       "      <td>3.171345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.592505</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>13.213996</td>\n",
       "      <td>5.814211</td>\n",
       "      <td>6.522682</td>\n",
       "      <td>9.577888</td>\n",
       "      <td>9.720708</td>\n",
       "      <td>0.139408</td>\n",
       "      <td>10.984689</td>\n",
       "      <td>0.582962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.186720</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>10.237234</td>\n",
       "      <td>7.400344</td>\n",
       "      <td>6.294910</td>\n",
       "      <td>9.111214</td>\n",
       "      <td>8.108749</td>\n",
       "      <td>1.990173</td>\n",
       "      <td>10.146399</td>\n",
       "      <td>2.383465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3         4          5         6  \\\n",
       "0  2.053730 -1.756666  11.378860  6.936342  6.235762   8.824183  9.119911   \n",
       "1  1.554933 -0.268288   7.588934  7.686738  6.930284   8.368870  7.913663   \n",
       "2  0.963801 -0.150520  10.355945  7.051244  6.157423  10.085479  8.593321   \n",
       "3  1.592505  0.211458  13.213996  5.814211  6.522682   9.577888  9.720708   \n",
       "4  1.186720  0.064047  10.237234  7.400344  6.294910   9.111214  8.108749   \n",
       "\n",
       "          7          8         9  \n",
       "0  3.103356   9.724831  3.719539  \n",
       "1  0.505868   8.038529  3.076725  \n",
       "2  2.286653  10.166838  3.171345  \n",
       "3  0.139408  10.984689  0.582962  \n",
       "4  1.990173  10.146399  2.383465  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df = pd.DataFrame(embedding)\n",
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070dc85-24da-4ece-9779-9344084f7ebf",
   "metadata": {},
   "source": [
    "Now let's transform the test set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9346cc-2ee5-4066-8689-0bd1a7092c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "X does not have valid feature names, but PCA was fitted with feature names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/datasets/X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmodel_config X_test.drop('id', axis=1)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "X_test_embedding = reducer.transform(X_test_pca)\n",
    "X_test_embedding_df = pd.DataFrame(X_test_embedding)\n",
    "dump(X_test_embedding_df, datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030abb5a-4aa6-4f97-8af5-3a2d69281daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.805481</td>\n",
       "      <td>0.382892</td>\n",
       "      <td>8.975375</td>\n",
       "      <td>6.223257</td>\n",
       "      <td>6.345812</td>\n",
       "      <td>8.811499</td>\n",
       "      <td>8.968513</td>\n",
       "      <td>2.358689</td>\n",
       "      <td>10.336686</td>\n",
       "      <td>1.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.815467</td>\n",
       "      <td>1.817890</td>\n",
       "      <td>7.038350</td>\n",
       "      <td>7.159169</td>\n",
       "      <td>5.196725</td>\n",
       "      <td>10.220221</td>\n",
       "      <td>8.561192</td>\n",
       "      <td>0.262517</td>\n",
       "      <td>9.995115</td>\n",
       "      <td>1.153083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.864622</td>\n",
       "      <td>0.302617</td>\n",
       "      <td>9.193873</td>\n",
       "      <td>6.061775</td>\n",
       "      <td>6.450215</td>\n",
       "      <td>8.866345</td>\n",
       "      <td>9.312219</td>\n",
       "      <td>2.476474</td>\n",
       "      <td>10.220789</td>\n",
       "      <td>1.538796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.284698</td>\n",
       "      <td>-0.488024</td>\n",
       "      <td>10.264484</td>\n",
       "      <td>7.524199</td>\n",
       "      <td>6.294941</td>\n",
       "      <td>9.432990</td>\n",
       "      <td>8.738018</td>\n",
       "      <td>2.073075</td>\n",
       "      <td>9.901546</td>\n",
       "      <td>3.294871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.239167</td>\n",
       "      <td>0.512479</td>\n",
       "      <td>10.570358</td>\n",
       "      <td>5.112319</td>\n",
       "      <td>6.427414</td>\n",
       "      <td>9.153562</td>\n",
       "      <td>8.228388</td>\n",
       "      <td>2.302179</td>\n",
       "      <td>8.561516</td>\n",
       "      <td>1.759488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3         4          5         6  \\\n",
       "0  1.805481  0.382892   8.975375  6.223257  6.345812   8.811499  8.968513   \n",
       "1  1.815467  1.817890   7.038350  7.159169  5.196725  10.220221  8.561192   \n",
       "2  1.864622  0.302617   9.193873  6.061775  6.450215   8.866345  9.312219   \n",
       "3  1.284698 -0.488024  10.264484  7.524199  6.294941   9.432990  8.738018   \n",
       "4  1.239167  0.512479  10.570358  5.112319  6.427414   9.153562  8.228388   \n",
       "\n",
       "          7          8         9  \n",
       "0  2.358689  10.336686  1.723404  \n",
       "1  0.262517   9.995115  1.153083  \n",
       "2  2.476474  10.220789  1.538796  \n",
       "3  2.073075   9.901546  3.294871  \n",
       "4  2.302179   8.561516  1.759488  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82a0f1d1-2a42-4764-8932-8c9fd5b2ef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"PCA(n_components='mle', random_state=42)\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a94b947-8c4b-43a3-9a6d-e215aa47845a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UMAP(n_components=10, random_state=42, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True})\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7136ec8c-31c7-4adf-9c0f-e2946c0d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmodel_config['pca'] = str(pca)\n",
    "exmodel_config['umap'] = str(reducer)\n",
    "exmodel_config['scaler'] = str(scaler)\n",
    "exmodel_config['type'] = 'preprocessing experiment'\n",
    "exmodel_config['level'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1daccd84-b4b9-4223-9a44-0f25b61d0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exmodel_config['train_source'] = 'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'\n",
    "# exmodel_config['test_source'] = 'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08d4c2-a782-4024-a4ef-585ad863b94f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weights and Biases Run Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0b725-0633-4d7f-a662-4ccb86b0a8b6",
   "metadata": {},
   "source": [
    "Below is the configuration for a Weights and Biases (`wandb`) run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5402d98-7bcd-4e46-b85d-6b0129ca6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb config:\n",
    "wandb_config = {\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'tags': ['preprocessing'],\n",
    "    'notes': \"Running Big Three GBMs with default parameters and a dataset transformed with 1. RobustScaler, 2. PCA (MLE), 3. UMAP (n_neighbors=15, n_components=10)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfa66428-3fb9-410f-9ea5-50785a4bd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X, y, X_test, params:dict={}, start_fold=0, \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "#     if exmodel_config['kfolds'] == 1:\n",
    "#         print(\"Proceeding with holdout\")\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=0.2, \n",
    "#                                                           random_state=SEED)                 \n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    if shuffle_kfolds:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202111_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # setup for serialization\n",
    "    # runpath = Path(modelpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds/\")\n",
    "    # (runpath).mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    # if using deep learning with pytorch-widedeep, do data preprocessing now, before splits\n",
    "    if 'widedeep' in arch:\n",
    "        # NOTE THAT ENCODING NOT DEPLOYED FOR THIS YET\n",
    "        # preprocessing first\n",
    "        wide_cols = [f for f in X.columns if X[f].nunique() == 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() == 2] # binary indicator vars are wide\n",
    "        cont_cols = [f for f in X.columns if X[f].nunique() > 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() > 2] # others are cont\n",
    "\n",
    "        # wide part\n",
    "        # wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "        # X_wide = wide_preprocessor.fit_transform(X)\n",
    "#         print(f\"X_wide.shape = {X_wide.shape}\")\n",
    "#         X_wide = np.array(X_train[wide_cols])\n",
    "        \n",
    "\n",
    "        # deep part\n",
    "        tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols)#, embed_cols=embed_cols, )\n",
    "        X_tab = tab_preprocessor.fit_transform(X)   \n",
    "#         print(f\"X_tab.shape = {X_tab.shape}\")\n",
    "        \n",
    "        # transforming the test set\n",
    "        X_test_wide = wide_preprocessor.transform(X_test)\n",
    "        X_test_tab = tab_preprocessor.transform(X_test)\n",
    "        \n",
    "        # at this point, X_wide, X_tab, X_test_wide, and X_test_tab will all be np.ndarrays\n",
    "    \n",
    "#     else: # if using a GBM, simply convert the pd.DataFrames to np.ndarrays\n",
    "#         X = np.array(X) # CAN YOU USE CATEGORY_ENCODERS ON NP.NDARRAYS?\n",
    "#         X_test = np.array(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#         print(f\"type(train_ids) = {type(train_ids)} and train_ids.shape = {train_ids.shape}\")\n",
    "#         print(f\"type(valid_ids) = {type(valid_ids)} and train_ids.shape = {valid_ids.shape}\")\n",
    "        if fold < start_fold: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if 'widedeep' in arch: # handle wide and deep tabs in parallel\n",
    "                X_train_wide, X_valid_wide = X_wide[train_ids, :], X_wide[valid_ids, :]\n",
    "                X_train_tab, X_valid_tab = X_tab[train_ids, :], X_tab[valid_ids, :]\n",
    "#                 print(f\"X_train_wide.shape = {X_train_wide.shape}\")\n",
    "#                 print(f\"X_train_tab.shape = {X_train_tab.shape}\")\n",
    "#                 print(f\"X_test_wide.shape = {X_test_wide.shape}\")\n",
    "#                 print(f\"X_test_tab.shape = {X_test_tab.shape}\")\n",
    "            else: # handle datasets for GBMs\n",
    "                if isinstance(X, np.ndarray):\n",
    "                    X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                else:\n",
    "                    X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                if encode_cats:\n",
    "                    encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                    encoder.fit(X_train,y_train)\n",
    "                    X_train = encoder.transform(X_train)\n",
    "                    X_valid = encoder.transform(X_valid)\n",
    "                # exmodel_config['feature_count'] = len(X.columns)\n",
    "                    wandb.log({\n",
    "                        'feature_count': X_train.shape[1],\n",
    "                        'instance_count': X_train.shape[0],\n",
    "                        'encoder': str(encoder)\n",
    "                    })\n",
    "#                 exmodel_config['instance_count'] = X_train.shape[0]\n",
    "#                 exmodel_config['encoder'] = str(encoder)\n",
    "#                     X_test = encoder.transform(X_test)\n",
    "#                 y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "            \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            try:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "                    device_type='gpu',\n",
    "                    max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                    gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            except LightGBMError:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "                    device_type='cpu',\n",
    "                    n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "    #                 device_type='gpu',\n",
    "    #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "    #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "        elif 'widedeep' in arch: # only coding for TabMlp right now\n",
    "#             X_train = pd.DataFrame(X_train, columns=[f\"f{x}\" for x in range(X_train.shape[1])])\n",
    "#             X_valid = pd.DataFrame(X_valid, columns=[f\"f{x}\" for x in range(X_valid.shape[1])])\n",
    "#             X_test = pd.DataFrame(X_test, columns=[f\"f{x}\" for x in range(X_test.shape[1])])\n",
    "            \n",
    "            wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "            deeptabular = TabMlp(\n",
    "                mlp_hidden_dims=[64,32],\n",
    "                column_idx=tab_preprocessor.column_idx,\n",
    "            #     embed_input=tab_preprocessor.embeddings_input,\n",
    "                continuous_cols=cont_cols,\n",
    "            )\n",
    "            \n",
    "            # model instantiation and training\n",
    "            model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "            \n",
    "            \n",
    "            n_epochs = 300\n",
    "\n",
    "            # pytorch hyperparams\n",
    "            wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "            deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "            \n",
    "            wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_train_wide.shape[0], epochs=n_epochs)\n",
    "            deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "            \n",
    "            optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "            lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "            \n",
    "            \n",
    "            callbacks = [\n",
    "                LRHistory(n_epochs=n_epochs), \n",
    "            ]\n",
    "            \n",
    "            # trainer\n",
    "            trainer = Trainer(model=model, \n",
    "                              objective='binary', \n",
    "                              metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                              seed=random_state, \n",
    "                              optimizers=optimizers,\n",
    "                              callbacks=callbacks\n",
    "                             )\n",
    "            \n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "            trainer.fit( # this is where problem is beginning\n",
    "                X_wide=X_train_wide,\n",
    "                X_tab=X_train_tab,\n",
    "                target=y_train,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    "            )\n",
    "            \n",
    "            y_valid_preds = trainer.predict_proba(X_wide=X_valid_wide, X_tab=X_valid_tab, batch_size=1024)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            \n",
    "            # test set inference\n",
    "            fold_test_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024)[:,1]\n",
    "            test_preds += fold_test_preds\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_valid_roc_auc': fold_valid_auc})\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for {arch} model is {model_valid_auc}\")\n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_valid_auc': model_valid_auc,\n",
    "                   'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "        dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bdffb03-04c5-440a-9e56-56e75db5ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = ['xgboost', 'lightgbm', 'catboost']#, 'widedeep-tabmlp', 'widedeep-saint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aac258d-44f9-4b10-a91a-756650746dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seeds = [42]#, 1983, 550, 1701, 2063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62ed216e-1a6f-4b66-bee4-43fa8ccbdf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_lv1, test_lv1 = pd.DataFrame(), pd.DataFrame() # initialize dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e804bd28-b956-4722-a95b-a5bb2266b49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07724173-45fd-44f7-b79a-7bb631d47322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5245215d-fd01-4d33-bd7c-c124d4baaba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(embedding)\n",
    "X_test = X_test_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54179f82-2fcb-48ba-a675-9a38da0e40b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find nb_20211107.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/24bsglsv\" target=\"_blank\">nb_20211107_200214</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "---------------------------------------------------\n",
      "[20:04:32] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:04:32] ../src/gbm/gbtree.cc:588: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x178349) [0x7f6c8a644349]\n  [bt] (1) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x179062) [0x7f6c8a645062]\n  [bt] (2) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x17985a) [0x7f6c8a64585a]\n  [bt] (3) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1b3525) [0x7f6c8a67f525]\n  [bt] (4) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x68) [0x7f6c8a565478]\n  [bt] (5) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f6cef00f9dd]\n  [bt] (6) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7f6cef00f067]\n  [bt] (7) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7f6cededcd39]\n  [bt] (8) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x137e5) [0x7f6cededd7e5]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-99f2401bc9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_seeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# update exmodel_config here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         oof_pred, test_pred = cross_validate_model(arch=arch, X=X, y=y, X_test=X_test, \n\u001b[0m\u001b[1;32m      5\u001b[0m                                          \u001b[0mwandb_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-25ab4b7d72f6>\u001b[0m in \u001b[0;36mcross_validate_model\u001b[0;34m(arch, X, y, X_test, params, start_fold, exmodel_config, wandb_config, random_state, shuffle_kfolds, wandb_tracked, encode_cats)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 **params)\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwandb_tracked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \"\"\"\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [20:04:32] ../src/gbm/gbtree.cc:588: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x178349) [0x7f6c8a644349]\n  [bt] (1) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x179062) [0x7f6c8a645062]\n  [bt] (2) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x17985a) [0x7f6c8a64585a]\n  [bt] (3) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1b3525) [0x7f6c8a67f525]\n  [bt] (4) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x68) [0x7f6c8a565478]\n  [bt] (5) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f6cef00f9dd]\n  [bt] (6) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7f6cef00f067]\n  [bt] (7) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7f6cededcd39]\n  [bt] (8) /home/sf/anaconda3/envs/tabular-x/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x137e5) [0x7f6cededd7e5]\n\n"
     ]
    }
   ],
   "source": [
    "for arch in architectures:\n",
    "    for model_seed in model_seeds:\n",
    "        # update exmodel_config here\n",
    "        oof_pred, test_pred = cross_validate_model(arch=arch, X=X, y=y, X_test=X_test, \n",
    "                                         wandb_config=wandb_config,\n",
    "                                         random_state=model_seed,\n",
    "                                         # params=lv1_params[arch],\n",
    "                                         exmodel_config=exmodel_config, \n",
    "                                         wandb_tracked=True\n",
    "                                        )\n",
    "        oof_lv1[f'{arch}{model_seed}'] = oof_pred\n",
    "        test_lv1[f'{arch}{model_seed}'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e238d18-d32b-4f04-bd28-8d1823b81194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
