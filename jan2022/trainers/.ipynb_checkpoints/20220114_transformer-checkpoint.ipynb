{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "20211202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55dfc634-98f0-45b8-bf65-931d28ddb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "# if '/sf/' in pwd:\n",
    "#     COLAB, SAGE = False, False\n",
    "# elif 'google.colab' in str(get_ipython()):\n",
    "#     COLAB, SAGE = True, False # do colab-specific installs later\n",
    "# else:\n",
    "#     COLAB, SAGE = False, True\n",
    "    \n",
    "CONTEXT = 'local' # or 'colab', 'sage', 'kaggle'\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a1fae-dd27-45ff-a494-d3572d5893dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c99bcc4-0451-4896-ba41-78477c3a890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720163c-934a-472a-bdef-40de5b849b3e",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf5b0c8-8b46-41d2-8d6e-e017bfcc5540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "# from sklearn.metrics import accuracy_score#, log_loss, roc_auc_score\n",
    "\n",
    "# eda\n",
    "import missingno\n",
    "# import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import cleanlab\n",
    "\n",
    "# normalization\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58ef079-2b2c-4433-a3c0-f62fdbbcac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# widedeep\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee770b73-8343-4336-889e-f54d6b1e35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series\n",
    "import tsfresh\n",
    "\n",
    "import darts\n",
    "from darts import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968f484e-7cde-4dcf-910b-3038b6f7163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188812f6-26a6-4b9c-b018-094861c5c077",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5b480-e54e-4e88-8826-8b453d3b9cd4",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81678474-39ce-4416-9de5-4ca973454e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONTEXT == 'colab':\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    root = Path('') # TODO\n",
    "\n",
    "elif CONTEXT == 'sage':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "elif CONTEXT == 'kaggle':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "else: # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1c918-7f76-4f7b-b194-7b9e19e4b87e",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9443f858-8b66-4a01-a9ab-aaaf32c54186",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb8923c-bf74-4de6-bffc-e041b8dab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d92853-fc1b-48bc-9236-2777b2209570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ac144e-1440-40cf-b172-bff04134d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-FranÃ§ois Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9054b5-493b-41e4-8918-50d155c7b859",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9479abf7-0a80-4a3a-8fff-ba4504813236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "    'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "test_df = pd.read_csv(datapath/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f59700-6ff7-4b43-a758-4f6981600208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params['feature_count'] = X.shape[1]\n",
    "# dataset_params['instance_count'] = X.shape[0]\n",
    "\n",
    "# # might eventually shift from dict to tuple\n",
    "\n",
    "# # simplest approach: k-v where key is new feature, v is string with the operation to get it\n",
    "# # sacrifices sortability, but could recover that through regexes, and it's much quicker to input\n",
    "# dataset_params['feature_combinations'] = {\n",
    "#     'EHiElv': \"df['Horizontal_Distance_To_Roadways'] * df['Elevation']\",\n",
    "#     'EViElv': \"df['Vertical_Distance_To_Hydrology'] * df['Elevation']\",\n",
    "#     'EVDtH': \"df.Elevation - df.Vertical_Distance_To_Hydrology\",\n",
    "#     'EHDtH': \"df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\",\n",
    "#     'Euclidean_Distance_to_Hydrology': \"(df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\",\n",
    "#     'Manhattan_Distance_to_Hydrology': \"df['Horizontal_Distance_To_Hydrology'] + df['Vertical_Distance_To_Hydrology']\",\n",
    "#     'Hydro_Fire_1': \"df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\",\n",
    "#     'Hydro_Fire_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\",\n",
    "#     'Hydro_Road_1': \"abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Hydro_Road_2': \"abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Fire_Road_1': \"abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\",\n",
    "#     'Fire_Road_2': \"abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\"\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_clipping'] = [\n",
    "#     {\n",
    "#         'features': ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'],\n",
    "#         'range': range(0,256)\n",
    "#     },\n",
    "#     {\n",
    "#         'features': ['Aspect'],\n",
    "#         'range': range(0,360)\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # the features that are just getting the one-hots counted\n",
    "# dataset_params['feature_counts'] = ['Soil_Type*', 'Wilderness_Area*']\n",
    "# dataset_params['feature_complements'] = [\n",
    "#     {\n",
    "#         'old': 'Aspect', \n",
    "#         'new': 'Aspect2',\n",
    "#         'operation': 'If x < 180 return x-180, else return x + 180'\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# dataset_params['feature_indicators'] = {\n",
    "#     'Hillshade_3pm_is_zero': \"(df.Hillshade_3pm == 0).astype(int)\",\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_typecasting'] = {\n",
    "#     'Highwater': \"(df.Vertical_Distance_To_Hydrology < 0).astype(int)\"\n",
    "# }\n",
    "\n",
    "# dataset_params['feature_encodings'] = \"Soil_Type* features concatenated into single 40-bit integers and then five 8-bit integers, and finally to five decimals; see gbms_20211223.ipynb and the section 'Encoding the `Soil_Type` Features'.\"\n",
    "# dataset_params['feature_removals'] = \"Soil_Type* features removed after being encoded\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c4ac3-7332-439d-845d-75221d131842",
   "metadata": {},
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18755070-b567-48a6-bfb6-074c057316c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params = {\n",
    "#     'general_random_state': SEED,\n",
    "# }\n",
    "\n",
    "# folds = 5\n",
    "# training_params['cross_val_strategy'] = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d2cd7-cd67-47b7-af1f-463bd1550cd9",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda3fa7-d8a5-48ac-8bfc-8aca81a11225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc67f393-3cfd-43ba-8d44-a07770ea3dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58824f5-e4f0-496e-94dd-c4ad74a2d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline -- alter as needed later\n",
    "# exmodel_config = {\n",
    "#     'general_random_state': SEED,\n",
    "# #     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     **dataset_params,\n",
    "# #     **training_params,\n",
    "# #     **model_params # perhaps do later\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a1208-433e-4438-8f98-3de95e93af12",
   "metadata": {},
   "source": [
    "## WandB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8155982-c840-4ef5-a78d-15a7f31ed59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wandb config:\n",
    "# wandb_config = {\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'tags': ['EDA'],\n",
    "#     'notes': \"EDA\"\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
