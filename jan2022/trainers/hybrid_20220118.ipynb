{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba48c47a-dd6b-4902-b333-86a223e82418",
   "metadata": {},
   "source": [
    "# Hybrid\n",
    "Going to attempt a hybrid model after the example of [this Teck Meng Wong notebook](https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dfc634-98f0-45b8-bf65-931d28ddb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "# if '/sf/' in pwd:\n",
    "#     COLAB, SAGE = False, False\n",
    "# elif 'google.colab' in str(get_ipython()):\n",
    "#     COLAB, SAGE = True, False # do colab-specific installs later\n",
    "# else:\n",
    "#     COLAB, SAGE = False, True\n",
    "    \n",
    "CONTEXT = 'local' # or 'colab', 'sage', 'kaggle'\n",
    "USE_GPU = True \n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a1fae-dd27-45ff-a494-d3572d5893dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c99bcc4-0451-4896-ba41-78477c3a890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests # for telegram notifications\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720163c-934a-472a-bdef-40de5b849b3e",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf5b0c8-8b46-41d2-8d6e-e017bfcc5540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# metrics\n",
    "# from sklearn.metrics import accuracy_score#, log_loss, roc_auc_score\n",
    "\n",
    "# eda\n",
    "import missingno\n",
    "# import doubtlab \n",
    "\n",
    "# data cleaning\n",
    "# from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "# import cleanlab\n",
    "\n",
    "# normalization\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "# from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "# feature generation\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# import category_encoders as ce\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "# feature reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "\n",
    "# clustering\n",
    "# from sklearn.cluster import DBSCAN, KMeans\n",
    "# import hdbscan\n",
    "\n",
    "# feature selection\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "# import featuretools as ft\n",
    "# from BorutaShap import BorutaShap\n",
    "# from boruta import BorutaPy\n",
    "\n",
    "# tracking \n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"nb_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58ef079-2b2c-4433-a3c0-f62fdbbcac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "\n",
    "# widedeep\n",
    "# from pytorch_widedeep import Trainer\n",
    "# from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "# from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT#, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "# from pytorch_widedeep.metrics import Accuracy\n",
    "# from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee770b73-8343-4336-889e-f54d6b1e35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time series\n",
    "# import tsfresh\n",
    "\n",
    "# import darts\n",
    "# from darts import TimeSeries\n",
    "import holidays\n",
    "import dateutil.easter as easter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968f484e-7cde-4dcf-910b-3038b6f7163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from darts.models import ExponentialSmoothing, AutoARIMA, ARIMA, Prophet, RandomForest, RegressionEnsembleModel, RegressionModel, TFTModel, TCNModel, TransformerModel, NBEATSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188812f6-26a6-4b9c-b018-094861c5c077",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5b480-e54e-4e88-8826-8b453d3b9cd4",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81678474-39ce-4416-9de5-4ca973454e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONTEXT == 'colab':\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    # datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/dec2021/')\n",
    "    root = Path('') # TODO\n",
    "\n",
    "elif CONTEXT == 'sage':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "elif CONTEXT == 'kaggle':\n",
    "    root = Path('') # TODO\n",
    "    \n",
    "else: # if on local machine\n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/jan2022/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'studies'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath, studypath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1c918-7f76-4f7b-b194-7b9e19e4b87e",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9443f858-8b66-4a01-a9ab-aaaf32c54186",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything but the models\n",
    "def seed_everything(seed, pytorch=True, reproducible=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if pytorch:\n",
    "        torch.manual_seed(seed) # set torch CPU seed\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed) # set torch GPU(s) seed(s)\n",
    "        if reproducible and torch.backends.cudnn.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb8923c-bf74-4de6-bffc-e041b8dab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce memory usage by downcasting datatypes in a Pandas DataFrame when possible.\n",
    "    \n",
    "    h/t to Bryan Arnold (https://www.kaggle.com/puremath86/label-correction-experiments-tps-nov-21)\n",
    "    \"\"\"\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d92853-fc1b-48bc-9236-2777b2209570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_api_token = 'your_api_token' # for Galileo (jupyter_watcher_bot) on Telegram\n",
    "tg_chat_id = 'your_chat_id'\n",
    "\n",
    "import requests\n",
    "\n",
    "def send_tg_message(text='Cell execution completed.'):  \n",
    "    \"\"\"\n",
    "    h/t Ivan Dembicki Jr. for the base version \n",
    "    (https://medium.com/@ivan.dembicki.jr/notifications-in-jupyter-notebook-with-telegram-f2e892c55173)\n",
    "    \"\"\"\n",
    "    requests.post('https://api.telegram.org/' +  'bot{}/sendMessage'.format(tg_api_token),\n",
    "                  params=dict(chat_id=tg_chat_id, text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ac144e-1440-40cf-b172-bff04134d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    '''\n",
    "    h/t Jean-François Puget (@CPMP) -- see https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\n",
    "    '''\n",
    "    denominator = (y_true + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb77153-1063-44a4-953f-043a35bd01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/282735\n",
    "def better_than_median(inputs, axis):\n",
    "    \"\"\"Compute the mean of the predictions if there are no outliers,\n",
    "    or the median if there are outliers.\n",
    "\n",
    "    Parameter: inputs = ndarray of shape (n_samples, n_folds)\"\"\"\n",
    "    spread = inputs.max(axis=axis) - inputs.min(axis=axis) \n",
    "    spread_lim = 0.45\n",
    "    print(f\"Inliers:  {(spread < spread_lim).sum():7} -> compute mean\")\n",
    "    print(f\"Outliers: {(spread >= spread_lim).sum():7} -> compute median\")\n",
    "    print(f\"Total:    {len(inputs):7}\")\n",
    "    return np.where(spread < spread_lim,\n",
    "                    np.mean(inputs, axis=axis),\n",
    "                    np.median(inputs, axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3bac0f6-8bb1-453c-b567-398523792a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def plot_periodogram(ts, detrend='linear', ax=None):\n",
    "    from scipy.signal import periodogram\n",
    "    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n",
    "    freqencies, spectrum = periodogram(\n",
    "        ts,\n",
    "        fs=fs,\n",
    "        detrend=detrend,\n",
    "        window=\"boxcar\",\n",
    "        scaling='spectrum',\n",
    "    )\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.step(freqencies, spectrum, color=\"purple\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n",
    "    ax.set_xticklabels(\n",
    "        [\n",
    "            \"Annual (1)\",\n",
    "            \"Semiannual (2)\",\n",
    "            \"Quarterly (4)\",\n",
    "            \"Bimonthly (6)\",\n",
    "            \"Monthly (12)\",\n",
    "            \"Biweekly (26)\",\n",
    "            \"Weekly (52)\",\n",
    "            \"Semiweekly (104)\",\n",
    "        ],\n",
    "        rotation=30,\n",
    "    )\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Periodogram\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a312e2-0175-41b3-a757-a81fb1186fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/teckmengwong/tps2201-hybrid-time-series\n",
    "def fourier_features(index, freq, order):\n",
    "    time = np.arange(len(index), dtype=np.float32)\n",
    "    k = 2 * np.pi * (1 / freq) * time\n",
    "    features = {}\n",
    "    for i in range(1, order + 1):\n",
    "        features.update({\n",
    "            f\"sin_{freq}_{i}\": np.sin(i * k),\n",
    "            f\"cos_{freq}_{i}\": np.cos(i * k),\n",
    "        })\n",
    "    return pd.DataFrame(features, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e560bef-8d90-4f5d-b6b1-4eeb5c0f5b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f704be-62c1-4f86-aec6-3cf2975d64cd",
   "metadata": {},
   "source": [
    "### Original Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ed69e0-b9c6-4017-956f-b19e25238e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    'train_source': str(datapath/'train.csv'),\n",
    "    'target_source': str(datapath/'train.csv'),\n",
    "    'test_source': str(datapath/'test.csv'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "test_df = pd.read_csv(datapath/'test.csv')\n",
    "orig_train_df = train_df.copy()\n",
    "orig_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9603-5103-4261-bbf4-47ad71eb1042",
   "metadata": {},
   "source": [
    "Since the dates are natively `Object` dtype (i.e. strings), we have to convert them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c268a78-b3db-4dbd-beee-790012b3cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model\n",
    "for df in [train_df, test_df]:\n",
    "    df['date'] = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d9b59-f4f9-487b-806d-1f69b7e68450",
   "metadata": {},
   "source": [
    "Provisionally, I'm going to concatenate together the `train_df` and `test_df` for preprocessing, to avoid having to constantly apply transforms twice (since I don't anticipate doing any transforms that might allow data leakage to occur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e13b145-46f1-424b-86db-4a89fabcd0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "# all_df.columns\n",
    "len(all_df) == len(train_df) + len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd562ee-1e89-4e27-83e5-4d1f526b70a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date country       store         product  num_sold\n",
       "6565   32863 2019-12-31  Sweden  KaggleMart      Kaggle Hat       NaN\n",
       "6566   32864 2019-12-31  Sweden  KaggleMart  Kaggle Sticker       NaN\n",
       "6567   32865 2019-12-31  Sweden  KaggleRama      Kaggle Mug       NaN\n",
       "6568   32866 2019-12-31  Sweden  KaggleRama      Kaggle Hat       NaN\n",
       "6569   32867 2019-12-31  Sweden  KaggleRama  Kaggle Sticker       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57249aa-2cec-49be-bbc6-c90773bf541c",
   "metadata": {},
   "source": [
    "### GDP Data\n",
    "Here's data from Carl McBride Ellis ([notebook](https://www.kaggle.com/carlmcbrideellis/gdp-of-finland-norway-and-sweden-2015-2019) and [dataset](https://www.kaggle.com/carlmcbrideellis/gdp-20152019-finland-norway-and-sweden) for doing GDP comparisons. They're frequently used in other entries. I've created a function to add them on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "194cf800-7a26-4e72-a71e-ad0e44887565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gdp_data(df):\n",
    "    gdp_df = pd.read_csv(datapath/'GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n",
    "    gdp_df.set_index('year', inplace=True)\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country]\n",
    "\n",
    "    df['gdp'] = np.log1p(df.apply(get_gdp, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f745cd8-5e1b-4e98-90c1-d68a55b7b3a4",
   "metadata": {},
   "source": [
    "I'll also define here (but perhaps move later) the GDP exponent, which will be used to transform the targets before inference (dividing num_sold by the $GDP^{1.212}$ and then taking the logarithm (after @ambrosm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e373efbe-04ec-4b49-bb89-ab2903e7b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_exponent = 1.2121103201489674 # see https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model for an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66cbab38-f2c9-4e1a-9b32-5a72e4756885",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = add_gdp_data(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7531064c-b43c-4ab2-b990-b8866aa1c0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp  \n",
       "0     5.461456  \n",
       "1     5.461456  \n",
       "2     5.461456  \n",
       "3     5.461456  \n",
       "4     5.461456  \n",
       "...        ...  \n",
       "6565  6.282042  \n",
       "6566  6.282042  \n",
       "6567  6.282042  \n",
       "6568  6.282042  \n",
       "6569  6.282042  \n",
       "\n",
       "[32868 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b86439-2188-4102-9ce4-24cf913c8141",
   "metadata": {},
   "source": [
    "### Label Encoding Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012426d-60f2-484d-b970-4f6e9e7b4501",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3c71c-2040-41b7-afa9-cdecfe882fed",
   "metadata": {},
   "source": [
    "### Time Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebfbaa-3575-4030-bcf2-6ba358035c6e",
   "metadata": {},
   "source": [
    "The goal of this function is to create features that will capture seasonalities -- but **not** trends. The trends will (hopefully) be captured by the deployment of linear forecasting algorithms on raw time series data (consisting exclusively of dates and targets); we want to have seasonalities that the residual models can learn, however -- holidays, weekly patterns, climactic season patterns, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20669349-b517-4f24-9c78-3bc3e3f98427",
   "metadata": {},
   "source": [
    "The cell below will generate the `holidays` library's entries for the three countries. I may want to follow the template of @teckmengwong's code below, and add more holidays -- then, do some feature importance checking, and perhaps whittle down the features accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a03496b7-70e7-4546-a855-899f37d89e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in [holidays.Finland, holidays.Sweden, holidays.Norway]:\n",
    "#     print(c)\n",
    "    for h in c(years = [2019], observed=True).items():\n",
    "#         print(h)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e13f9b94-6c79-4712-80da-e828ed887a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_engineering(df):\n",
    "    '''\n",
    "    Function inspired by / borrowing from @teckmengwong and @ambrosm to create time features that will\n",
    "    capture seasonality.\n",
    "    '''\n",
    "    \n",
    "#     df[YEAR] = df[DATE].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "#     df['week'] = df['date'].dt.week # not used by Teck Meng Wong\n",
    "#     df['day'] = df['date'].dt.day # not used by Teck Meng Wong\n",
    "#     df['day_of_year'] = df['date'].dt.dayofyear # not used by Teck Meng Wong\n",
    "#     df['day_of_month'] = df['date'].dt.days_in_month # not used by Teck Meng Wong\n",
    "#     df['day_of_week'] = df['date'].dt.dayofweek # not used by Teck Meng Wong\n",
    "#    df['weekday'] = df['date'].dt.weekday # not used by Teck Meng Wong\n",
    "    # Teck Meng Wong mapped the integers to first-letters in triplets\n",
    "    # I'm leaving it as integers, where winter=1, spring=2, summer=3, fall=4\n",
    "    df['season'] = ((df['date'].dt.month % 12 + 3) // 3) #.map({1:'DJF', 2: 'MAM', 3:'JJA', 4:'SON'})\n",
    "#     df['month'] = df['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "    df['wd4'] = df['date'].dt.weekday == 4\n",
    "    df['wd56'] = df['date'].dt.weekday >= 5\n",
    "#     df['wd6'] = df['date'].dt.weekday >= 6\n",
    "#     df.loc[(df.date.dt.year != 2016) & (df.date.dt.month >=3), 'day_of_year'] += 1 # fix for leap years\n",
    "    \n",
    "    # 21 days cyclic for lunar\n",
    "    dayofyear = df.date.dt.dayofyear # for convenience\n",
    "    \n",
    "    # here he's creating Fourier features\n",
    "    for k in range(1, 32, 4):\n",
    "        df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n",
    "        df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n",
    "        df[f'finland_sin{k}'] = np.where(df['country'] == 'Finland', df[f'sin{k}'], 0)\n",
    "        df[f'finland_cos{k}'] = np.where(df['country'] == 'Finland', df[f'cos{k}'], 0)\n",
    "        df[f'norway_sin{k}'] = np.where(df['country'] == 'Norway', df[f'sin{k}'], 0)\n",
    "        df[f'norway_cos{k}'] = np.where(df['country'] == 'Norway', df[f'cos{k}'], 0)\n",
    "        df[f'store_sin{k}'] = np.where(df['store'] == 'KaggleMart', df[f'sin{k}'], 0)\n",
    "        df[f'store_cos{k}'] = np.where(df['store'] == 'KaggleMart', df[f'cos{k}'], 0)\n",
    "        df[f'mug_sin{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'sin{k}'], 0)\n",
    "        df[f'mug_cos{k}'] = np.where(df['product'] == 'Kaggle Mug', df[f'cos{k}'], 0)\n",
    "        df[f'sticker_sin{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'sin{k}'], 0)\n",
    "        df[f'sticker_cos{k}'] = np.where(df['product'] == 'Kaggle Sticker', df[f'cos{k}'], 0)\n",
    "    \n",
    "#     df[f'semiweekly_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 14)\n",
    "#     df[f'semiweekly_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 14)\n",
    "#     df[f'lunar_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 21)\n",
    "#     df[f'lunar_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 21)\n",
    "    df[f'season_sin'] = np.sin(dayofyear / 365 * 2 * math.pi * 91.5)\n",
    "    df[f'season_cos'] = np.cos(dayofyear / 365 * 2 * math.pi * 91.5)\n",
    "#     df = pd.concat([df, pd.DataFrame({f'fin{ptr[1]}':\n",
    "#                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Finland')\n",
    "#                                       for ptr in holidays.Finland(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "#     df = pd.concat([df, pd.DataFrame({f'nor{ptr[1]}':\n",
    "#                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Norway')\n",
    "#                                       for ptr in holidays.Norway(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "#     df = pd.concat([df, pd.DataFrame({f'swe{ptr[1]}':\n",
    "#                                       (df.date == pd.Timestamp(ptr[0])) & (df.country == 'Sweden')\n",
    "#                                       for ptr in holidays.Sweden(years = [2015,2016,2017,2018,2019]).items()})], axis=1)\n",
    "\n",
    "    # End of year\n",
    "    # Dec - teckmengwong\n",
    "    for d in range(24, 32):\n",
    "        df[f\"dec{d}\"] = (df.date.dt.month == 12) & (df.date.dt.day == d)\n",
    "    # I'm unsure of the logic of only doing this for Norway\n",
    "    for d in range(24, 32):\n",
    "        df[f\"n-dec{d}\"] = (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "    \n",
    "    # not sure why he's using different date ranges for each country here\n",
    "    # Jan - teckmengwong\n",
    "    for d in range(1, 14):\n",
    "        df[f\"f-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "    for d in range(1, 10):\n",
    "        df[f\"n-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "    for d in range(1, 15):\n",
    "        df[f\"s-jan{d}\"] = (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "    \n",
    "    \n",
    "    # May - tekcmengwong\n",
    "    for d in list(range(1, 10)): # May Day and after, I guess\n",
    "        df[f\"may{d}\"] = (df.date.dt.month == 5) & (df.date.dt.day == d)\n",
    "    for d in list(range(19, 26)):\n",
    "        df[f\"may{d}\"] = (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n",
    "    # June \n",
    "    for d in list(range(8, 14)):\n",
    "        df[f\"june{d}\"] = (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n",
    "    \n",
    "    #Swedish Rock Concert - teckmengwong\n",
    "    #Jun 3, 2015 – Jun 6, 2015\n",
    "    #Jun 8, 2016 – Jun 11, 2016\n",
    "    #Jun 7, 2017 – Jun 10, 2017\n",
    "    #Jun 6, 2018 – Jun 10, 2018\n",
    "    #Jun 5, 2019 – Jun 8, 2019\n",
    "    swed_rock_fest  = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-6')),\n",
    "                                         2016: pd.Timestamp(('2016-06-11')),\n",
    "                                         2017: pd.Timestamp(('2017-06-10')),\n",
    "                                         2018: pd.Timestamp(('2018-06-10')),\n",
    "                                         2019: pd.Timestamp(('2019-06-8'))})\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({f\"swed_rock_fest{d}\":\n",
    "                                      (df.date - swed_rock_fest == np.timedelta64(d, \"D\")) & (df.country == 'Sweden')\n",
    "                                      for d in list(range(-3, 3))})], axis=1)\n",
    "\n",
    "    \n",
    "    # Last Wednesday of June - teckmengwong\n",
    "    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "                                         2016: pd.Timestamp(('2016-06-29')),\n",
    "                                         2017: pd.Timestamp(('2017-06-28')),\n",
    "                                         2018: pd.Timestamp(('2018-06-27')),\n",
    "                                         2019: pd.Timestamp(('2019-06-26'))})\n",
    "    for d in list(range(-4, 6)):\n",
    "        df[f\"wed_june{d}\"] = (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n",
    "        \n",
    "    # First Sunday of November - teckmengwong\n",
    "    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "                                         2016: pd.Timestamp(('2016-11-6')),\n",
    "                                         2017: pd.Timestamp(('2017-11-5')),\n",
    "                                         2018: pd.Timestamp(('2018-11-4')),\n",
    "                                         2019: pd.Timestamp(('2019-11-3'))})\n",
    "    df = pd.concat([df, pd.DataFrame({f\"sun_nov{d}\":\n",
    "                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n",
    "                                      for d in list(range(0, 9))})], axis=1)\n",
    "    \n",
    "    # First half of December (Independence Day of Finland, 6th of December) -teckmengwong\n",
    "    df = pd.concat([df, pd.DataFrame({f\"dec{d}\":\n",
    "                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n",
    "                                      for d in list(range(6, 14))})], axis=1)\n",
    "    \n",
    "    # Easter -teckmengwong\n",
    "    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "    df = pd.concat([df, pd.DataFrame({f\"easter{d}\":\n",
    "                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n",
    "                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7541874-d7b9-4477-9fb2-1af5506c1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_all_df = temporal_engineering(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479e68aa-3417-4671-a9d7-ea2c5d248ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>...</th>\n",
       "      <th>easter47</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp  month  season    wd4  ...  easter47  easter50  easter51  \\\n",
       "0     5.461456      1       1  False  ...     False     False     False   \n",
       "1     5.461456      1       1  False  ...     False     False     False   \n",
       "2     5.461456      1       1  False  ...     False     False     False   \n",
       "3     5.461456      1       1  False  ...     False     False     False   \n",
       "4     5.461456      1       1  False  ...     False     False     False   \n",
       "...        ...    ...     ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042     12       1  False  ...     False     False     False   \n",
       "6566  6.282042     12       1  False  ...     False     False     False   \n",
       "6567  6.282042     12       1  False  ...     False     False     False   \n",
       "6568  6.282042     12       1  False  ...     False     False     False   \n",
       "6569  6.282042     12       1  False  ...     False     False     False   \n",
       "\n",
       "      easter52  easter53  easter54  easter55  easter56  easter57  easter58  \n",
       "0        False     False     False     False     False     False     False  \n",
       "1        False     False     False     False     False     False     False  \n",
       "2        False     False     False     False     False     False     False  \n",
       "3        False     False     False     False     False     False     False  \n",
       "4        False     False     False     False     False     False     False  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6565     False     False     False     False     False     False     False  \n",
       "6566     False     False     False     False     False     False     False  \n",
       "6567     False     False     False     False     False     False     False  \n",
       "6568     False     False     False     False     False     False     False  \n",
       "6569     False     False     False     False     False     False     False  \n",
       "\n",
       "[32868 rows x 246 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09014037-96b4-4037-835b-f9f23b87a7bb",
   "metadata": {},
   "source": [
    "At this point, the `temporal_all_df` DataFrame contains all the time features for both the training and testing sets.\n",
    "* **Todo**: consider not only adding in holidays from `holidays`, but also borrowing ideas from the AmbrosM Linear notebook too (which creates fewer features, populating them instead with temporal distances from the selected holidays)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86376eb-1c0b-4a8b-814d-b77eff89b925",
   "metadata": {},
   "source": [
    "### Target Transformation\n",
    "Now, I'll do the target transformation proposed by @AmbrosM. (I'll do it to the non-encoded DataFrame too, for testing with Prophet and NeuralProphet later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5542ef40-2c0e-4061-8e04-3a64e20cf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [temporal_all_df]:\n",
    "    df['target'] = np.log(df['num_sold'] / df['gdp']**gdp_exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20683a88-cfe1-499f-9ad1-bf15b5fea392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_all_df['target'] = np.log(encoded_all_df['num_sold'] / (encoded_all_df['gdp']**gdp_exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24c415b1-2f0e-4636-9928-ae713a0d74a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.925788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.291321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0          0 2015-01-01  Finland  KaggleMart      Kaggle Mug     329.0   \n",
       "1          1 2015-01-01  Finland  KaggleMart      Kaggle Hat     520.0   \n",
       "2          2 2015-01-01  Finland  KaggleMart  Kaggle Sticker     146.0   \n",
       "3          3 2015-01-01  Finland  KaggleRama      Kaggle Mug     572.0   \n",
       "4          4 2015-01-01  Finland  KaggleRama      Kaggle Hat     911.0   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   32863 2019-12-31   Sweden  KaggleMart      Kaggle Hat       NaN   \n",
       "6566   32864 2019-12-31   Sweden  KaggleMart  Kaggle Sticker       NaN   \n",
       "6567   32865 2019-12-31   Sweden  KaggleRama      Kaggle Mug       NaN   \n",
       "6568   32866 2019-12-31   Sweden  KaggleRama      Kaggle Hat       NaN   \n",
       "6569   32867 2019-12-31   Sweden  KaggleRama  Kaggle Sticker       NaN   \n",
       "\n",
       "           gdp  month  season    wd4  ...  easter50  easter51  easter52  \\\n",
       "0     5.461456      1       1  False  ...     False     False     False   \n",
       "1     5.461456      1       1  False  ...     False     False     False   \n",
       "2     5.461456      1       1  False  ...     False     False     False   \n",
       "3     5.461456      1       1  False  ...     False     False     False   \n",
       "4     5.461456      1       1  False  ...     False     False     False   \n",
       "...        ...    ...     ...    ...  ...       ...       ...       ...   \n",
       "6565  6.282042     12       1  False  ...     False     False     False   \n",
       "6566  6.282042     12       1  False  ...     False     False     False   \n",
       "6567  6.282042     12       1  False  ...     False     False     False   \n",
       "6568  6.282042     12       1  False  ...     False     False     False   \n",
       "6569  6.282042     12       1  False  ...     False     False     False   \n",
       "\n",
       "      easter53  easter54  easter55  easter56  easter57  easter58    target  \n",
       "0        False     False     False     False     False     False  3.738239  \n",
       "1        False     False     False     False     False     False  4.196010  \n",
       "2        False     False     False     False     False     False  2.925788  \n",
       "3        False     False     False     False     False     False  4.291321  \n",
       "4        False     False     False     False     False     False  4.756724  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6565     False     False     False     False     False     False       NaN  \n",
       "6566     False     False     False     False     False     False       NaN  \n",
       "6567     False     False     False     False     False     False       NaN  \n",
       "6568     False     False     False     False     False     False       NaN  \n",
       "6569     False     False     False     False     False     False       NaN  \n",
       "\n",
       "[32868 rows x 247 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d953a5-33b0-401d-aefa-cd78fb6a6840",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d55d72bb-efeb-4b21-afd4-2e848636fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_dict = {feature: LabelEncoder().fit(orig_train_df[feature]) for feature in ['country', 'product', 'store']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39254279-4486-412e-8c57-ba2e01a5c702",
   "metadata": {},
   "source": [
    "Now, we'll do the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b53d76d7-3b31-4e3f-b58a-8e268c9c927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_all_df = temporal_all_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dadb9abd-95b0-4908-afb5-fae9dc6adc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['country', 'product', 'store']:\n",
    "    encoded_all_df[feature] = le_dict[feature].transform(temporal_all_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da434d5-b499-4d24-ae0e-6f58fc8a9f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>...</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.925788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.291321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>32863</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>32864</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>32865</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>32866</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>32867</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.282042</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country  store  product  num_sold       gdp  month  \\\n",
       "0          0 2015-01-01        0      0        1     329.0  5.461456      1   \n",
       "1          1 2015-01-01        0      0        0     520.0  5.461456      1   \n",
       "2          2 2015-01-01        0      0        2     146.0  5.461456      1   \n",
       "3          3 2015-01-01        0      1        1     572.0  5.461456      1   \n",
       "4          4 2015-01-01        0      1        0     911.0  5.461456      1   \n",
       "...      ...        ...      ...    ...      ...       ...       ...    ...   \n",
       "6565   32863 2019-12-31        2      0        0       NaN  6.282042     12   \n",
       "6566   32864 2019-12-31        2      0        2       NaN  6.282042     12   \n",
       "6567   32865 2019-12-31        2      1        1       NaN  6.282042     12   \n",
       "6568   32866 2019-12-31        2      1        0       NaN  6.282042     12   \n",
       "6569   32867 2019-12-31        2      1        2       NaN  6.282042     12   \n",
       "\n",
       "      season    wd4  ...  easter50  easter51  easter52  easter53  easter54  \\\n",
       "0          1  False  ...     False     False     False     False     False   \n",
       "1          1  False  ...     False     False     False     False     False   \n",
       "2          1  False  ...     False     False     False     False     False   \n",
       "3          1  False  ...     False     False     False     False     False   \n",
       "4          1  False  ...     False     False     False     False     False   \n",
       "...      ...    ...  ...       ...       ...       ...       ...       ...   \n",
       "6565       1  False  ...     False     False     False     False     False   \n",
       "6566       1  False  ...     False     False     False     False     False   \n",
       "6567       1  False  ...     False     False     False     False     False   \n",
       "6568       1  False  ...     False     False     False     False     False   \n",
       "6569       1  False  ...     False     False     False     False     False   \n",
       "\n",
       "      easter55  easter56  easter57  easter58    target  \n",
       "0        False     False     False     False  3.738239  \n",
       "1        False     False     False     False  4.196010  \n",
       "2        False     False     False     False  2.925788  \n",
       "3        False     False     False     False  4.291321  \n",
       "4        False     False     False     False  4.756724  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "6565     False     False     False     False       NaN  \n",
       "6566     False     False     False     False       NaN  \n",
       "6567     False     False     False     False       NaN  \n",
       "6568     False     False     False     False       NaN  \n",
       "6569     False     False     False     False       NaN  \n",
       "\n",
       "[32868 rows x 247 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76eb5ed-d638-4879-941e-7b9754459340",
   "metadata": {},
   "source": [
    "### Pseudolabeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ef2c6-14c7-4eaf-af12-5cf752e76fef",
   "metadata": {},
   "source": [
    "I'm not going to try this right now, but I may return to it later -- I note that Teck Meng Wong had some good results with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946e675-76be-45ba-9137-a6642e0e2b55",
   "metadata": {},
   "source": [
    "### Data Splitting, Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3176f-0deb-4477-8f08-2517b9a5cef3",
   "metadata": {},
   "source": [
    "Now that the preprocessing is done, I'm going to split the data back into the train and test sets; then, I'll create a view on the dataframes that omits the year. The year-less dataframes will be suitable for residual learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ec51c66-81b6-4587-bed7-ede9ffef2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = encoded_all_df.drop(columns=['num_sold', 'row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8ac1517-0b40-4c76-b136-7255216d5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df = all_df[:len(orig_train_df)] # training and validation sets\n",
    "test_df = all_df[len(orig_train_df):]\n",
    "# train_df = encoded_all_df.iloc[np.where(encoded_all_df['date'] < '2019-01-01'), :]\n",
    "# test_df = encoded_all_df[[np.where(encoded_all_df['date'] > '2018-12-31')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca9532ef-4a78-4a8d-a474-03b6f270946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = tv_df[tv_df['date'] > '2017-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b95c06d-73cb-492d-9ee8-0c0dc11dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tv_df[tv_df['date'] <= '2017-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8653c0ed-fffc-485a-a1c5-fbb23b8d2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_valid_residual_df = train_and_valid_df.drop(columns=['date'])\n",
    "# test_residual_df = test_df.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee9fa103-f6cb-4743-a10e-1ba8bceddae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_df) + len(train_df) == len(tv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b92520-09d6-4a6e-a37e-8f8a81e0147f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f9ec5-ce1a-48c7-8bb9-2e2b86be8d89",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b33851-3943-41f2-9adb-ebb13d61d966",
   "metadata": {},
   "source": [
    "To start, I'll just try a few models that Teck Meng Wong has proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f86c3a25-87e2-4287-b2ac-933ef1aaa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa44f5a-82ef-4449-9d2c-2434e728b938",
   "metadata": {},
   "source": [
    "Linear models from Scikit-Learn seemingly require that datetime data be converted to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9994fed1-67cb-4f82-a84b-c63c8f8eeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b901d76e-b57a-4a94-8695-a937d16b1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear_df = train_df.copy()\n",
    "valid_linear_df = valid_df.copy()\n",
    "test_linear_df = test_df.copy()\n",
    "\n",
    "train_linear_df['date'] = train_df['date'].map(dt.datetime.toordinal)\n",
    "valid_linear_df['date'] = valid_df['date'].map(dt.datetime.toordinal)\n",
    "test_linear_df['date'] = test_df['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a34deb-03f7-45e3-973b-23c8290bb5f2",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64036884-8146-45b4-859a-7014ed131f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16336894-1af4-45a4-a98d-882104b48941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_linear_df.drop(columns=['target'])\n",
    "y = train_linear_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f2133c-71f6-4a2b-9334-cc6efa89f192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>gdp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>sin1</th>\n",
       "      <th>...</th>\n",
       "      <th>easter47</th>\n",
       "      <th>easter50</th>\n",
       "      <th>easter51</th>\n",
       "      <th>easter52</th>\n",
       "      <th>easter53</th>\n",
       "      <th>easter54</th>\n",
       "      <th>easter55</th>\n",
       "      <th>easter56</th>\n",
       "      <th>easter57</th>\n",
       "      <th>easter58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735599</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>735599</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.461456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19723</th>\n",
       "      <td>736694</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.295301</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>736694</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.295301</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19725</th>\n",
       "      <td>736694</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.295301</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19726</th>\n",
       "      <td>736694</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.295301</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19727</th>\n",
       "      <td>736694</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.295301</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19728 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  country  store  product       gdp  month  season    wd4   wd56  \\\n",
       "0      735599        0      0        1  5.461456      1       1  False  False   \n",
       "1      735599        0      0        0  5.461456      1       1  False  False   \n",
       "2      735599        0      0        2  5.461456      1       1  False  False   \n",
       "3      735599        0      1        1  5.461456      1       1  False  False   \n",
       "4      735599        0      1        0  5.461456      1       1  False  False   \n",
       "...       ...      ...    ...      ...       ...    ...     ...    ...    ...   \n",
       "19723  736694        2      0        0  6.295301     12       1  False   True   \n",
       "19724  736694        2      0        2  6.295301     12       1  False   True   \n",
       "19725  736694        2      1        1  6.295301     12       1  False   True   \n",
       "19726  736694        2      1        0  6.295301     12       1  False   True   \n",
       "19727  736694        2      1        2  6.295301     12       1  False   True   \n",
       "\n",
       "               sin1  ...  easter47  easter50  easter51  easter52  easter53  \\\n",
       "0      1.721336e-02  ...     False     False     False     False     False   \n",
       "1      1.721336e-02  ...     False     False     False     False     False   \n",
       "2      1.721336e-02  ...     False     False     False     False     False   \n",
       "3      1.721336e-02  ...     False     False     False     False     False   \n",
       "4      1.721336e-02  ...     False     False     False     False     False   \n",
       "...             ...  ...       ...       ...       ...       ...       ...   \n",
       "19723 -2.449294e-16  ...     False     False     False     False     False   \n",
       "19724 -2.449294e-16  ...     False     False     False     False     False   \n",
       "19725 -2.449294e-16  ...     False     False     False     False     False   \n",
       "19726 -2.449294e-16  ...     False     False     False     False     False   \n",
       "19727 -2.449294e-16  ...     False     False     False     False     False   \n",
       "\n",
       "       easter54  easter55  easter56  easter57  easter58  \n",
       "0         False     False     False     False     False  \n",
       "1         False     False     False     False     False  \n",
       "2         False     False     False     False     False  \n",
       "3         False     False     False     False     False  \n",
       "4         False     False     False     False     False  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "19723     False     False     False     False     False  \n",
       "19724     False     False     False     False     False  \n",
       "19725     False     False     False     False     False  \n",
       "19726     False     False     False     False     False  \n",
       "19727     False     False     False     False     False  \n",
       "\n",
       "[19728 rows x 244 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15f64e64-c2af-4132-a2bb-e1b6c67242f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "ridge.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b55a8a9-8cd0-448a-9ce3-0aa252bc0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid_linear_df.drop(columns=['target'])\n",
    "y_valid = valid_linear_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6e0b5bf-31e2-4552-8730-c6997893f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_valid_preds = ridge.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d948a714-3f3d-4def-825d-6836b1b714b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.297207111341678"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=ridge_valid_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f922007-d348-4ad0-adbe-7c5ffb0e4f4f",
   "metadata": {},
   "source": [
    "That's not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6506d4a-6d53-41f0-be65-b2c799587c52",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfef0091-7cac-4e4d-a749-ec920eb4ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4433cf81-c7d8-4be0-928b-faca2354ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ceb75d9-c0ca-4558-a6e9-08b37f6add3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "871af5e7-4e3a-4e02-8b5c-bf9e7fcaa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_preds = lasso_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e58180f-c82e-4620-a2d8-be49f1a56034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.719972647663342"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=lasso_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70b621-921f-4a6e-8ed1-e5b4ed50923b",
   "metadata": {},
   "source": [
    "Not so good there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d6c37-1337-411a-a4b6-e1178c5f88a8",
   "metadata": {},
   "source": [
    "#### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7de32574-3f46-41c0-b181-e2491ab895c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_model = HuberRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bb1ecb3-ed7f-4264-8672-95950b4d6634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuberRegressor()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17cc8921-f3df-40bd-b640-483b7956b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_valid_preds = huber_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bacdf430-6c01-48af-aed1-f4ce0fb575cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.808248729247591"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=huber_valid_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb02b4-fd15-41ba-9c42-d7d6157c4ae6",
   "metadata": {},
   "source": [
    "That's not so great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0d278-7f87-4086-93d0-182e729828d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bc0177f-a3e8-45e0-9f7e-b8832ded40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPRegressor(hidden_layer_sizes=(200,100), learning_rate_init=0.01, early_stopping=True, max_iter=300, random_state=42, learning_rate='adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d61ac450-025e-4331-89b8-86ed602361c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 100),\n",
       "             learning_rate='adaptive', learning_rate_init=0.01, max_iter=300,\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f5b7163-f330-46dd-9012-e1d0f36e8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_preds = mlp_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "535ac7ac-1c60-443a-84bf-985cee99e89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.639894056665263"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=mlp_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd597611-01c2-4d6f-865d-149b8b3d6751",
   "metadata": {},
   "source": [
    "Not great, that. Let's try at least one more set of hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d146e558-cf9a-4601-9825-c1c8dc2970ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPRegressor(hidden_layer_sizes=(200,100,50), \n",
    "                         learning_rate_init=0.01, \n",
    "                         early_stopping=True, \n",
    "                         max_iter=300, \n",
    "                         random_state=42, \n",
    "                         learning_rate='adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2dc078c-380b-4569-97ac-f9d42d10a09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 100, 50),\n",
       "             learning_rate='adaptive', learning_rate_init=0.01, max_iter=300,\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82f9b9ed-eeec-48b7-afc3-6a89105cf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_preds = mlp_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58b2c3b9-e362-4e90-b517-6337e2e4d4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.763122872881882"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=mlp_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129fba5-5af8-4493-9342-91b3816cbd91",
   "metadata": {},
   "source": [
    "Marginally better. Let's try one more layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7773d0d-e14e-4dc7-aec9-f3128997a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPRegressor(hidden_layer_sizes=(200,100,50,25), \n",
    "                         learning_rate_init=0.01, \n",
    "                         early_stopping=True, \n",
    "                         max_iter=300, \n",
    "                         random_state=42, \n",
    "                         learning_rate='adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "951d4a1d-dc24-448f-a72c-97fa72f5f2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25),\n",
       "             learning_rate='adaptive', learning_rate_init=0.01, max_iter=300,\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ece28ce1-25e5-4368-8de6-962a7ef54bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_preds = mlp_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef87f26c-179e-4682-9b4c-7c32e5b7c481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.862419246640776"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=mlp_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee122d9-65e0-449c-8de1-13b989d0d1b8",
   "metadata": {},
   "source": [
    "A bit worse there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb18b78-1f4f-4cd7-9d0b-1e67b4593c5e",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50f4dc69-0c91-4e73-b1b8-9ce65d19aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "150f5a37-2c2c-4c7a-a3d3-9bfb2fd6111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca18ca31-5037-432c-b423-16ad8f3a6fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7eba15b0-32d7-4ffd-9e42-8873b4615f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_preds = linreg_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f84001c1-1af4-40f7-8938-ee4795849867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.752939183524428"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMAPE(y_pred=linreg_preds, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f13fe4-d4bc-4c9d-b47d-af437b0b41ba",
   "metadata": {},
   "source": [
    "That's better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0c182-df5d-4a2d-b3e6-30468cd4c6ab",
   "metadata": {},
   "source": [
    "### Pure Time Series (Prophet, NeuralProphet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7d7f5-62db-4832-89f3-c31f9b269ad0",
   "metadata": {},
   "source": [
    "Here, it's necessary to break things up by country, store, and product. So we'll hark to @gunesevitan's notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78697ce3-1b60-45eb-8bb9-9a4f31ab5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Finland', 'Norway', 'Sweden']\n",
    "# countries_encoded = [0,1,2]\n",
    "stores = ['KaggleMart', 'KaggleRama']\n",
    "# stores_encoded = [0,1]\n",
    "products = ['Kaggle Hat', 'Kaggle Mug', 'Kaggle Sticker']\n",
    "# products_encoded = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c228688f-3a06-4ac7-869d-96703c884266",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countries_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-db0abd9234bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries_encoded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstores_encoded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproducts_encoded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countries_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# for country in countries_encoded:\n",
    "#     for store in stores_encoded:\n",
    "#         for product in products_encoded:\n",
    "#             train_idx = train_df['country'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0772e9f-6350-4538-a20b-981581623dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = train_df[['date','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee803b-d117-43ba-983f-aeed97db4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6562e1-b284-46b4-a0f4-95f46e29f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ts = valid_df[['date', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdd0fa-9023-433b-b0ac-c891cf263c3d",
   "metadata": {},
   "source": [
    "If I wanted to throw in a Prophet and/or Neural Prophet run here, I could just rename these `ds` and `y` respectively, and proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ced7f-30c5-4b95-a5b5-ce9c5cc3da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a93d1-da70-45b4-83b9-5fc7a6df1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model = Prophet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758ab25-e9f4-4127-8c52-66d3d7be6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = train_ts.rename(columns={'date': 'ds',\n",
    "                        'target': 'y'}\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea44f9-94ac-4335-ac8f-d827a7bd3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da8e93-2075-4cc2-bbb1-5e8016ae888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model.fit(df=train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbe64c-f0ef-4bcf-a111-3335ec40f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ts = valid_ts.rename(columns={'date': 'ds',\n",
    "                        'target': 'y'}\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3613e1-fbd6-4177-a4d6-32b958768e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = prophet_model.predict(train_ts[['ds']])['yhat']\n",
    "valid_preds = prophet_model.predict(valid_ts[['ds']])['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974f541-32e6-43f5-ab6e-8d05eab7f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMAPE(train_ts['y'].values, train_preds.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5749e8a-6e18-4b0f-8993-41e198f23468",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMAPE(valid_preds.values, valid_ts['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d24247-b857-4082-b76c-8172400def84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46260f5e-f28d-4a6d-a16c-4397ecac5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ts['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374f67b-486f-4e4d-aafa-e0679980ddb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308ac6d-eb3d-4ccc-af6e-307769035ac6",
   "metadata": {},
   "source": [
    "Now, I'm going to try training the GBMs, stripping out the years. I won't -- yet -- make them residual-only, however. I'll double back to the `tv_df`, pre-validation splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13297c8a-88dc-4158-a718-b7600450c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df_gbm = tv_df.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8d1eb75-c7e8-494b-9152-aab30a99d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'store', 'product', 'gdp', 'month', 'season', 'wd4', 'wd56',\n",
       "       'sin1', 'cos1',\n",
       "       ...\n",
       "       'easter50', 'easter51', 'easter52', 'easter53', 'easter54', 'easter55',\n",
       "       'easter56', 'easter57', 'easter58', 'target'],\n",
       "      dtype='object', length=244)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_df_gbm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b0d71-bc6f-4619-bfaf-f43d986664e5",
   "metadata": {},
   "source": [
    "Going to bring over my old cross-trainer function, give it a whirl."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2dbc0bd-313c-4e27-871e-703c03ec757a",
   "metadata": {},
   "source": [
    "training_params = {'cross_val_strategy':}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f179fed-315d-4227-aa0b-f7431f109a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_model(arch:str, X=X, y=y, X_test=X_test, model_params:dict={}, training_params=training_params, dataset_params=dataset_params,\n",
    "                         folds=list(range(folds)), exmodel_config=exmodel_config, wandb_config=wandb_config,  telegram=True, random_state=42, \n",
    "                         wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "    # if exmodel_config['kfolds'] == 1: # holdout case\n",
    "    #     print(\"Proceeding with holdout\")\n",
    "    #     X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "    #                                                           random_state=SEED)                 \n",
    "    # else: # k-fold cross validation case\n",
    "    #     # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    #     # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    #     if shuffle_kfolds:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    #     else:\n",
    "    #         kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    kfold = training_params['cross_val_strategy']\n",
    "    zz\n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(model_params)\n",
    "        wandb.init(\n",
    "            project=\"202112_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    \n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    # test_probs = np.zeros((X_test.shape[0]))\n",
    "    # preprocessing\n",
    "    # if using a GBM, simply use the RobustScaler\n",
    "        # scaler = RobustScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "        if fold not in folds: # skip folds that are already trained, i.e. that haven't been specified\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if isinstance(X, np.ndarray):\n",
    "                X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "            else:\n",
    "                X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                \n",
    "                # scaling\n",
    "                # category_encoding\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "        \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **model_params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            # try:\n",
    "            model = LGBMClassifier(\n",
    "                objective='binary',\n",
    "                random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#                 eval_metric='auc',\n",
    "                device_type='gpu',\n",
    "                max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                **model_params)\n",
    "\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "#             except LightGBMError:\n",
    "#                 model = LGBMClassifier(\n",
    "#                     objective='binary',\n",
    "#                     random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "#     #                 eval_metric='auc',\n",
    "#     #                 device_type='gpu',\n",
    "#     #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "#     #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "#                     **params)\n",
    "                \n",
    "#                 if wandb_tracked:\n",
    "#                     model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "#                 else:\n",
    "#                     model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test)\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **model_params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_valid_preds = model.predict(X_valid)\n",
    "            # y_valid_probs = model.predict_proba(X_valid)[:,1] # this would only take one of 7 cols\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            # oof_probs.extend(y_valid_probs)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict(X_test).flatten()\n",
    "            # test_probs += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_true=y_valid, y_pred=y_valid_preds) # or should be preds?\n",
    "        # fold_confusion = confusion_matrix(y_true=y_valid, y_pred=y_valid_preds)# , labels=list(range(7)))\n",
    "        # fold_log_loss = log_loss(y_pred=y_valid_preds, y_true=y_valid,) #labels=list(range(7)))\n",
    "        # fold_roc_auc = roc_auc_score(y_true=y_valid, y_score=y_valid_probs)\n",
    "        # fold_f1_score = f1_score(\n",
    "        # fold_fbeta_score = fbeta_score(\n",
    "        \n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_accuracy': fold_accuracy,\n",
    "                       # f'fold{fold}_confusion': fold_confusion,\n",
    "                       # f'fold{fold}_log_loss': fold_log_loss,\n",
    "                       # f'fold{fold}_roc_auc': fold_roc_auc,\n",
    "                      })\n",
    "        fold_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for fold {fold} are: \\nAccuracy: {fold_accuracy}\"\n",
    "        print(fold_human_results)\n",
    "        if telegram:\n",
    "            send_tg_message(text=f\"{arch} model's fold {fold} complete.\\n\"+fold_human_results)\n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true=oof_y, y_pred=oof_preds) \n",
    "    # model_confusion = confusion_matrix(y_true=oof_y, y_pred=oof_preds, labels=list(range(7)))\n",
    "    # model_log_loss = log_loss(y_pred=oof_preds, y_true=oof_y, labels=list(range(7)))\n",
    "    # model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    model_human_results = f\"{os.environ['WANDB_NOTEBOOK_NAME']}\\nMetrics for model {arch} are: \\nAccuracy: {model_accuracy}\"\n",
    "    print(model_human_results)\n",
    "    if telegram:\n",
    "        send_tg_message(text=f\"{arch} model run complete.\\n\"+model_human_results)\n",
    "    if wandb_tracked:\n",
    "        wandb.log({f'model_accuracy': fold_accuracy,\n",
    "                   # f'model_confusion': fold_confusion,\n",
    "                   # f'model_log_loss': fold_log_loss,\n",
    "                   # f'model_roc_auc': fold_roc_auc,\n",
    "                   'model_params': str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    # test_probs /= exmodel_config['kfolds']\n",
    "    # test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    # if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "    #     dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds#, model_confusion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174044f-0983-4787-bc06-28a7a985d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc0b7a3-545c-4e72-8e38-e2d5d8606a99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c4ac3-7332-439d-845d-75221d131842",
   "metadata": {},
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18755070-b567-48a6-bfb6-074c057316c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params = {\n",
    "#     'general_random_state': SEED,\n",
    "# }\n",
    "\n",
    "# folds = 5\n",
    "# training_params['cross_val_strategy'] = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d2cd7-cd67-47b7-af1f-463bd1550cd9",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda3fa7-d8a5-48ac-8bfc-8aca81a11225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc67f393-3cfd-43ba-8d44-a07770ea3dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58824f5-e4f0-496e-94dd-c4ad74a2d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline -- alter as needed later\n",
    "# exmodel_config = {\n",
    "#     'general_random_state': SEED,\n",
    "# #     'feature_generation': ['NaN_counts', 'SummaryStats', 'NaN_OneHots'],\n",
    "#     **dataset_params,\n",
    "# #     **training_params,\n",
    "# #     **model_params # perhaps do later\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a1208-433e-4438-8f98-3de95e93af12",
   "metadata": {},
   "source": [
    "## WandB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8155982-c840-4ef5-a78d-15a7f31ed59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wandb config:\n",
    "# wandb_config = {\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'tags': ['EDA'],\n",
    "#     'notes': \"EDA\"\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
