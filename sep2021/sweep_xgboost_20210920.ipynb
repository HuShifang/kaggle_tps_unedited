{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {},
   "source": [
    "# Catboost Hyperparameter Sweep 20210918\n",
    "Largely after https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    !pip install category_encoders\n",
    "    !pip install catboost\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    !pip install cmake --upgrade\n",
    "    # !pip install sklearn --upgrade\n",
    "    !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    %cd /content/xgboost\n",
    "    !mkdir build\n",
    "    %cd build\n",
    "    !cmake .. -DUSE_CUDA=ON\n",
    "    !make -j4\n",
    "    %cd /content/xgboost/python-package\n",
    "    !python setup.py install --use-cuda --use-nccl\n",
    "    !/opt/bin/nvidia-smi\n",
    "    !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "    datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {},
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb288275-a858-4806-9dc0-0b316c334536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "    \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "    \"scale_b4_impute\": False,\n",
    "    \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "    \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "    'optuna': True,\n",
    "    'optuna_trials': 1000,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202109_Kaggle_tabular_playground',\n",
    "    'tags': ['sweep'],\n",
    "    'notes': \"Sweep for XGBoost using Optuna\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912a62f-970a-48b4-b428-d886f2612fc2",
   "metadata": {},
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6625d6-7561-48a2-acb0-6efb3c371005",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source = 'X_NaNcounts_SummaryStats_imputed-Median-wIndicators-StandardScaled.feather'\n",
    "X_train = pd.read_feather(datapath/X_source) \n",
    "y_train = load(datapath/'y.joblib')    \n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8330d84d-3c72-4cca-b95a-739712014dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmodel_config['feature_count'] = X.shape[1]\n",
    "exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "exmodel_config['X_source'] = X_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "#     train_pool = catboost.Pool(train_x, train_y)\n",
    "#     test_pool = catboost.Pool(test_x, test_y)\n",
    "    \n",
    "    # experimental parameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1200),\n",
    "        'max_depth' : trial.suggest_int('depth', 2, 7),                                       \n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 5),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1, 7),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', )\n",
    "    }    \n",
    "        \n",
    "    tree_method = 'gpu_hist' if (gpu_available and colab) else 'auto' \n",
    "        \n",
    "    \n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method=tree_method,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        **params\n",
    "    )        \n",
    "#     wandb.init(wandb_kwargs)\n",
    "    # fit the model on the training set -- note the use of the catboost.Pool instance\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "#     pred_labels = np.rint(preds)\n",
    "    # calls sklearn.utils.resample... not entirely sure why\n",
    "#     y_pred_boot = resample(pred_labels, n_samples = len(train_y))\n",
    "    # Evaluation\n",
    "#     ROC_AUC_Score = roc_auc_score(train_y, y_pred_boot)\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "#                'catboost_params': str(model.get_all_params())\n",
    "              })\n",
    "#     wandb.finish()\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sweep_xgboost_20210920_132821</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/s37e0tny\" target=\"_blank\">https://wandb.ai/hushifang/202109_Kaggle_tabular_playground/runs/s37e0tny</a><br/>\n",
       "                Run data is saved locally in <code>/home/sf/Dropbox/code_cloud/python_code/kaggle/tabular_playgrounds/sep2021/wandb/run-20210920_132822-s37e0tny</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 13:28:28,534]\u001b[0m A new study created in memory with name: xgboost_20210919\u001b[0m\n",
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 13:37:51,697]\u001b[0m Trial 0 finished with value: 0.8118794328459813 and parameters: {'n_estimators': 512, 'depth': 7, 'learning_rate': 0.0802956743641955, 'reg_alpha': 0.16383993835282307, 'reg_lambda': 1.3547246940681168, 'subsample': 0.5779972601681014}. Best is trial 0 with value: 0.8118794328459813.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 1; dropping {'n_estimators': 512, 'depth': 7, 'learning_rate': 0.0802956743641955, 'reg_alpha': 0.16383993835282307, 'reg_lambda': 1.3547246940681168, 'subsample': 0.5779972601681014, 'value': 0.8118794328459813}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8118794328459813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 13:41:36,075]\u001b[0m Trial 1 finished with value: 0.8105687205930888 and parameters: {'n_estimators': 163, 'depth': 7, 'learning_rate': 0.03665534591187186, 'reg_alpha': 0.4160439645256604, 'reg_lambda': 1.0408686202776, 'subsample': 0.9849549260809971}. Best is trial 0 with value: 0.8118794328459813.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 2; dropping {'n_estimators': 163, 'depth': 7, 'learning_rate': 0.03665534591187186, 'reg_alpha': 0.4160439645256604, 'reg_lambda': 1.0408686202776, 'subsample': 0.9849549260809971, 'value': 0.8105687205930888}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8105687205930888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 13:50:27,262]\u001b[0m Trial 2 finished with value: 0.8058181503054008 and parameters: {'n_estimators': 1016, 'depth': 3, 'learning_rate': 0.002972483637079397, 'reg_alpha': 0.004768785415482609, 'reg_lambda': 1.8076507396669295, 'subsample': 0.762378215816119}. Best is trial 0 with value: 0.8118794328459813.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 3; dropping {'n_estimators': 1016, 'depth': 3, 'learning_rate': 0.002972483637079397, 'reg_alpha': 0.004768785415482609, 'reg_lambda': 1.8076507396669295, 'subsample': 0.762378215816119, 'value': 0.8058181503054008}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8058181503054008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 13:55:11,588]\u001b[0m Trial 3 finished with value: 0.812903063006752 and parameters: {'n_estimators': 575, 'depth': 3, 'learning_rate': 0.03909110418963917, 'reg_alpha': 0.003280829084730048, 'reg_lambda': 1.7655941039943173, 'subsample': 0.6831809216468459}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 4; dropping {'n_estimators': 575, 'depth': 3, 'learning_rate': 0.03909110418963917, 'reg_alpha': 0.003280829084730048, 'reg_lambda': 1.7655941039943173, 'subsample': 0.6831809216468459, 'value': 0.812903063006752}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.812903063006752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:04:53,564]\u001b[0m Trial 4 finished with value: 0.8084010278910242 and parameters: {'n_estimators': 602, 'depth': 6, 'learning_rate': 0.003307982168695265, 'reg_alpha': 0.07982478599323917, 'reg_lambda': 3.1670023893135637, 'subsample': 0.5232252063599989}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 5; dropping {'n_estimators': 602, 'depth': 6, 'learning_rate': 0.003307982168695265, 'reg_alpha': 0.07982478599323917, 'reg_lambda': 3.1670023893135637, 'subsample': 0.5232252063599989, 'value': 0.8084010278910242}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8084010278910242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:11:24,893]\u001b[0m Trial 5 finished with value: 0.8033430666975735 and parameters: {'n_estimators': 768, 'depth': 3, 'learning_rate': 0.0014766179636293824, 'reg_alpha': 3.235185145617431, 'reg_lambda': 6.5471718214198065, 'subsample': 0.9041986740582306}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 6; dropping {'n_estimators': 768, 'depth': 3, 'learning_rate': 0.0014766179636293824, 'reg_alpha': 3.235185145617431, 'reg_lambda': 6.5471718214198065, 'subsample': 0.9041986740582306, 'value': 0.8033430666975735}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8033430666975735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:13:51,615]\u001b[0m Trial 6 finished with value: 0.8115603611729848 and parameters: {'n_estimators': 435, 'depth': 2, 'learning_rate': 0.06031361827702156, 'reg_alpha': 0.042472797953697176, 'reg_lambda': 1.268043852943426, 'subsample': 0.7475884550556351}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 7; dropping {'n_estimators': 435, 'depth': 2, 'learning_rate': 0.06031361827702156, 'reg_alpha': 0.042472797953697176, 'reg_lambda': 1.268043852943426, 'subsample': 0.7475884550556351, 'value': 0.8115603611729848}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8115603611729848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:16:50,355]\u001b[0m Trial 7 finished with value: 0.8063263899744333 and parameters: {'n_estimators': 137, 'depth': 7, 'learning_rate': 0.004713690209606067, 'reg_alpha': 0.282260467839396, 'reg_lambda': 1.8341143951012813, 'subsample': 0.7600340105889054}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 8; dropping {'n_estimators': 137, 'depth': 7, 'learning_rate': 0.004713690209606067, 'reg_alpha': 0.282260467839396, 'reg_lambda': 1.8341143951012813, 'subsample': 0.7600340105889054, 'value': 0.8063263899744333}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8063263899744333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:22:45,383]\u001b[0m Trial 8 finished with value: 0.812312959233314 and parameters: {'n_estimators': 701, 'depth': 3, 'learning_rate': 0.3333629787709382, 'reg_alpha': 0.7365344466688366, 'reg_lambda': 6.22255457254043, 'subsample': 0.9474136752138245}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 9; dropping {'n_estimators': 701, 'depth': 3, 'learning_rate': 0.3333629787709382, 'reg_alpha': 0.7365344466688366, 'reg_lambda': 6.22255457254043, 'subsample': 0.9474136752138245, 'value': 0.812312959233314}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.812312959233314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:37:50,181]\u001b[0m Trial 9 finished with value: 0.8079576536058779 and parameters: {'n_estimators': 758, 'depth': 7, 'learning_rate': 0.0016992716001270592, 'reg_alpha': 0.005308046630775945, 'reg_lambda': 1.0919971205991512, 'subsample': 0.6626651653816322}. Best is trial 3 with value: 0.812903063006752.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 10; dropping {'n_estimators': 758, 'depth': 7, 'learning_rate': 0.0016992716001270592, 'reg_alpha': 0.005308046630775945, 'reg_lambda': 1.0919971205991512, 'subsample': 0.6626651653816322, 'value': 0.8079576536058779}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8079576536058779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 14:53:23,683]\u001b[0m Trial 10 finished with value: 0.8134043747396075 and parameters: {'n_estimators': 1140, 'depth': 5, 'learning_rate': 0.013146994020643898, 'reg_alpha': 0.0011653072249925506, 'reg_lambda': 3.2008706016808444, 'subsample': 0.8451235367845727}. Best is trial 10 with value: 0.8134043747396075.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 11; dropping {'n_estimators': 1140, 'depth': 5, 'learning_rate': 0.013146994020643898, 'reg_alpha': 0.0011653072249925506, 'reg_lambda': 3.2008706016808444, 'subsample': 0.8451235367845727, 'value': 0.8134043747396075}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8134043747396075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 15:09:24,527]\u001b[0m Trial 11 finished with value: 0.8131577973103662 and parameters: {'n_estimators': 1176, 'depth': 5, 'learning_rate': 0.01161077070890926, 'reg_alpha': 0.0010326194186662623, 'reg_lambda': 3.4684131972935317, 'subsample': 0.8537728154644986}. Best is trial 10 with value: 0.8134043747396075.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 12; dropping {'n_estimators': 1176, 'depth': 5, 'learning_rate': 0.01161077070890926, 'reg_alpha': 0.0010326194186662623, 'reg_lambda': 3.4684131972935317, 'subsample': 0.8537728154644986, 'value': 0.8131577973103662}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8131577973103662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 15:25:27,081]\u001b[0m Trial 12 finished with value: 0.8128409589259614 and parameters: {'n_estimators': 1171, 'depth': 5, 'learning_rate': 0.010184160002690259, 'reg_alpha': 0.0010947939310625215, 'reg_lambda': 3.5774250279657713, 'subsample': 0.8529852737125874}. Best is trial 10 with value: 0.8134043747396075.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 13; dropping {'n_estimators': 1171, 'depth': 5, 'learning_rate': 0.010184160002690259, 'reg_alpha': 0.0010947939310625215, 'reg_lambda': 3.5774250279657713, 'subsample': 0.8529852737125874, 'value': 0.8128409589259614}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8128409589259614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 15:39:11,927]\u001b[0m Trial 13 finished with value: 0.812844549648754 and parameters: {'n_estimators': 1005, 'depth': 5, 'learning_rate': 0.012359542318369901, 'reg_alpha': 0.018988628612569922, 'reg_lambda': 4.488816530355699, 'subsample': 0.847025685798701}. Best is trial 10 with value: 0.8134043747396075.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 14; dropping {'n_estimators': 1005, 'depth': 5, 'learning_rate': 0.012359542318369901, 'reg_alpha': 0.018988628612569922, 'reg_lambda': 4.488816530355699, 'subsample': 0.847025685798701, 'value': 0.812844549648754}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.812844549648754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:39:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 15:52:08,306]\u001b[0m Trial 14 finished with value: 0.811565320478308 and parameters: {'n_estimators': 1191, 'depth': 4, 'learning_rate': 0.008712328039584173, 'reg_alpha': 0.0010863093764820178, 'reg_lambda': 2.52638754685921, 'subsample': 0.8336228052393176}. Best is trial 10 with value: 0.8134043747396075.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 15; dropping {'n_estimators': 1191, 'depth': 4, 'learning_rate': 0.008712328039584173, 'reg_alpha': 0.0010863093764820178, 'reg_lambda': 2.52638754685921, 'subsample': 0.8336228052393176, 'value': 0.811565320478308}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.811565320478308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 16:05:47,715]\u001b[0m Trial 15 finished with value: 0.8140293568722579 and parameters: {'n_estimators': 962, 'depth': 5, 'learning_rate': 0.020533399820591516, 'reg_alpha': 0.011999383700719572, 'reg_lambda': 4.438778040522018, 'subsample': 0.9146123667705024}. Best is trial 15 with value: 0.8140293568722579.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 15 < 16; dropping {'n_estimators': 962, 'depth': 5, 'learning_rate': 0.020533399820591516, 'reg_alpha': 0.011999383700719572, 'reg_lambda': 4.438778040522018, 'subsample': 0.9146123667705024, 'value': 0.8140293568722579}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8140293568722579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 16:21:27,854]\u001b[0m Trial 16 finished with value: 0.8087283104387397 and parameters: {'n_estimators': 971, 'depth': 6, 'learning_rate': 0.16274644275502326, 'reg_alpha': 0.016868907245532277, 'reg_lambda': 4.608858296497631, 'subsample': 0.9413711284210551}. Best is trial 15 with value: 0.8140293568722579.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 16 < 17; dropping {'n_estimators': 971, 'depth': 6, 'learning_rate': 0.16274644275502326, 'reg_alpha': 0.016868907245532277, 'reg_lambda': 4.608858296497631, 'subsample': 0.9413711284210551, 'value': 0.8087283104387397}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8087283104387397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 16:31:21,725]\u001b[0m Trial 17 finished with value: 0.813441207318907 and parameters: {'n_estimators': 902, 'depth': 4, 'learning_rate': 0.02368628651996643, 'reg_alpha': 0.014940632726242785, 'reg_lambda': 2.351900255673143, 'subsample': 0.9020357017355822}. Best is trial 15 with value: 0.8140293568722579.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 17 < 18; dropping {'n_estimators': 902, 'depth': 4, 'learning_rate': 0.02368628651996643, 'reg_alpha': 0.014940632726242785, 'reg_lambda': 2.351900255673143, 'subsample': 0.9020357017355822, 'value': 0.813441207318907}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.813441207318907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 16:40:28,320]\u001b[0m Trial 18 finished with value: 0.8135290158246458 and parameters: {'n_estimators': 847, 'depth': 4, 'learning_rate': 0.026847776522954295, 'reg_alpha': 0.017424194829017855, 'reg_lambda': 4.993653786715871, 'subsample': 0.9886332327975391}. Best is trial 15 with value: 0.8140293568722579.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 18 < 19; dropping {'n_estimators': 847, 'depth': 4, 'learning_rate': 0.026847776522954295, 'reg_alpha': 0.017424194829017855, 'reg_lambda': 4.993653786715871, 'subsample': 0.9886332327975391, 'value': 0.8135290158246458}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8135290158246458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 16:49:18,049]\u001b[0m Trial 19 finished with value: 0.8144126871557926 and parameters: {'n_estimators': 856, 'depth': 4, 'learning_rate': 0.10232179571464722, 'reg_alpha': 0.045294424261733544, 'reg_lambda': 5.132587161530645, 'subsample': 0.9829415877557487}. Best is trial 19 with value: 0.8144126871557926.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 19 < 20; dropping {'n_estimators': 856, 'depth': 4, 'learning_rate': 0.10232179571464722, 'reg_alpha': 0.045294424261733544, 'reg_lambda': 5.132587161530645, 'subsample': 0.9829415877557487, 'value': 0.8144126871557926}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144126871557926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:49:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:02:27,430]\u001b[0m Trial 20 finished with value: 0.8117042163137203 and parameters: {'n_estimators': 850, 'depth': 6, 'learning_rate': 0.12082943344998677, 'reg_alpha': 0.04420342839271448, 'reg_lambda': 5.442093729092832, 'subsample': 0.941268454961829}. Best is trial 19 with value: 0.8144126871557926.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 20 < 21; dropping {'n_estimators': 850, 'depth': 6, 'learning_rate': 0.12082943344998677, 'reg_alpha': 0.04420342839271448, 'reg_lambda': 5.442093729092832, 'subsample': 0.941268454961829, 'value': 0.8117042163137203}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8117042163137203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:11:59,423]\u001b[0m Trial 21 finished with value: 0.8136939259365102 and parameters: {'n_estimators': 856, 'depth': 4, 'learning_rate': 0.03176040483055847, 'reg_alpha': 0.008784158527276672, 'reg_lambda': 4.754945934060716, 'subsample': 0.9985757992576173}. Best is trial 19 with value: 0.8144126871557926.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 21 < 22; dropping {'n_estimators': 856, 'depth': 4, 'learning_rate': 0.03176040483055847, 'reg_alpha': 0.008784158527276672, 'reg_lambda': 4.754945934060716, 'subsample': 0.9985757992576173, 'value': 0.8136939259365102}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8136939259365102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:22:37,562]\u001b[0m Trial 22 finished with value: 0.811118244307314 and parameters: {'n_estimators': 1051, 'depth': 4, 'learning_rate': 0.22967365808480728, 'reg_alpha': 0.008458254626204245, 'reg_lambda': 4.032089309022949, 'subsample': 0.9954068726374355}. Best is trial 19 with value: 0.8144126871557926.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 22 < 23; dropping {'n_estimators': 1051, 'depth': 4, 'learning_rate': 0.22967365808480728, 'reg_alpha': 0.008458254626204245, 'reg_lambda': 4.032089309022949, 'subsample': 0.9954068726374355, 'value': 0.811118244307314}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.811118244307314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:27:30,660]\u001b[0m Trial 23 finished with value: 0.8135795835661112 and parameters: {'n_estimators': 898, 'depth': 2, 'learning_rate': 0.0666940647920395, 'reg_alpha': 0.09226051852950498, 'reg_lambda': 5.743149276290736, 'subsample': 0.9065630872899011}. Best is trial 19 with value: 0.8144126871557926.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 23 < 24; dropping {'n_estimators': 898, 'depth': 2, 'learning_rate': 0.0666940647920395, 'reg_alpha': 0.09226051852950498, 'reg_lambda': 5.743149276290736, 'subsample': 0.9065630872899011, 'value': 0.8135795835661112}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8135795835661112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:35:30,420]\u001b[0m Trial 24 finished with value: 0.8145132323576978 and parameters: {'n_estimators': 773, 'depth': 4, 'learning_rate': 0.11187107451385256, 'reg_alpha': 0.044342156172368974, 'reg_lambda': 6.983431372261965, 'subsample': 0.9475427898393622}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 24 < 25; dropping {'n_estimators': 773, 'depth': 4, 'learning_rate': 0.11187107451385256, 'reg_alpha': 0.044342156172368974, 'reg_lambda': 6.983431372261965, 'subsample': 0.9475427898393622, 'value': 0.8145132323576978}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8145132323576978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:44:15,711]\u001b[0m Trial 25 finished with value: 0.8030645744833411 and parameters: {'n_estimators': 681, 'depth': 5, 'learning_rate': 0.3910553349537803, 'reg_alpha': 0.04104596738767174, 'reg_lambda': 6.989541304318312, 'subsample': 0.8948881335069706}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 25 < 26; dropping {'n_estimators': 681, 'depth': 5, 'learning_rate': 0.3910553349537803, 'reg_alpha': 0.04104596738767174, 'reg_lambda': 6.989541304318312, 'subsample': 0.8948881335069706, 'value': 0.8030645744833411}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8030645744833411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:44:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:51:24,522]\u001b[0m Trial 26 finished with value: 0.8130487000388198 and parameters: {'n_estimators': 451, 'depth': 6, 'learning_rate': 0.10193953750899713, 'reg_alpha': 0.12024820364428698, 'reg_lambda': 4.117969938004688, 'subsample': 0.8000566329050555}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 26 < 27; dropping {'n_estimators': 451, 'depth': 6, 'learning_rate': 0.10193953750899713, 'reg_alpha': 0.12024820364428698, 'reg_lambda': 4.117969938004688, 'subsample': 0.8000566329050555, 'value': 0.8130487000388198}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8130487000388198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 17:59:13,568]\u001b[0m Trial 27 finished with value: 0.813215783234294 and parameters: {'n_estimators': 766, 'depth': 4, 'learning_rate': 0.1634394186243018, 'reg_alpha': 0.03360991748953612, 'reg_lambda': 5.530928077567169, 'subsample': 0.9441164505646792}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 27 < 28; dropping {'n_estimators': 766, 'depth': 4, 'learning_rate': 0.1634394186243018, 'reg_alpha': 0.03360991748953612, 'reg_lambda': 5.530928077567169, 'subsample': 0.9441164505646792, 'value': 0.813215783234294}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.813215783234294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:59:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:01:43,568]\u001b[0m Trial 28 finished with value: 0.8111904722721202 and parameters: {'n_estimators': 307, 'depth': 3, 'learning_rate': 0.04958454557030743, 'reg_alpha': 1.273819677826861, 'reg_lambda': 6.137487826989507, 'subsample': 0.9550513996856169}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 28 < 29; dropping {'n_estimators': 307, 'depth': 3, 'learning_rate': 0.04958454557030743, 'reg_alpha': 1.273819677826861, 'reg_lambda': 6.137487826989507, 'subsample': 0.9550513996856169, 'value': 0.8111904722721202}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8111904722721202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:15:08,866]\u001b[0m Trial 29 finished with value: 0.8129407702195302 and parameters: {'n_estimators': 1060, 'depth': 5, 'learning_rate': 0.09446029729348193, 'reg_alpha': 0.2641594145132384, 'reg_lambda': 2.9036285629450354, 'subsample': 0.6367861393932243}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 29 < 30; dropping {'n_estimators': 1060, 'depth': 5, 'learning_rate': 0.09446029729348193, 'reg_alpha': 0.2641594145132384, 'reg_lambda': 2.9036285629450354, 'subsample': 0.6367861393932243, 'value': 0.8129407702195302}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8129407702195302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:15:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:25:06,190]\u001b[0m Trial 30 finished with value: 0.8128674387702605 and parameters: {'n_estimators': 939, 'depth': 4, 'learning_rate': 0.017833727927405833, 'reg_alpha': 0.21849403120233776, 'reg_lambda': 3.991536814282991, 'subsample': 0.8799965722808691}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 30 < 31; dropping {'n_estimators': 939, 'depth': 4, 'learning_rate': 0.017833727927405833, 'reg_alpha': 0.21849403120233776, 'reg_lambda': 3.991536814282991, 'subsample': 0.8799965722808691, 'value': 0.8128674387702605}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8128674387702605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:25:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:33:52,311]\u001b[0m Trial 31 finished with value: 0.8139869076364981 and parameters: {'n_estimators': 830, 'depth': 4, 'learning_rate': 0.03365443264611377, 'reg_alpha': 0.008133336016766824, 'reg_lambda': 5.006560723423381, 'subsample': 0.9725610248413489}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 31 < 32; dropping {'n_estimators': 830, 'depth': 4, 'learning_rate': 0.03365443264611377, 'reg_alpha': 0.008133336016766824, 'reg_lambda': 5.006560723423381, 'subsample': 0.9725610248413489, 'value': 0.8139869076364981}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8139869076364981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:33:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:42:18,790]\u001b[0m Trial 32 finished with value: 0.8144790731157706 and parameters: {'n_estimators': 800, 'depth': 4, 'learning_rate': 0.04977914007518635, 'reg_alpha': 0.0029740626461528534, 'reg_lambda': 5.146246657857023, 'subsample': 0.9664511575920548}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 32 < 33; dropping {'n_estimators': 800, 'depth': 4, 'learning_rate': 0.04977914007518635, 'reg_alpha': 0.0029740626461528534, 'reg_lambda': 5.146246657857023, 'subsample': 0.9664511575920548, 'value': 0.8144790731157706}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144790731157706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:42:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:47:17,071]\u001b[0m Trial 33 finished with value: 0.8143922652176314 and parameters: {'n_estimators': 629, 'depth': 3, 'learning_rate': 0.07579698481991169, 'reg_alpha': 0.00278111416178599, 'reg_lambda': 6.7451291915114275, 'subsample': 0.9245585552647498}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 33 < 34; dropping {'n_estimators': 629, 'depth': 3, 'learning_rate': 0.07579698481991169, 'reg_alpha': 0.00278111416178599, 'reg_lambda': 6.7451291915114275, 'subsample': 0.9245585552647498, 'value': 0.8143922652176314}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8143922652176314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:47:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:52:01,757]\u001b[0m Trial 34 finished with value: 0.8144974526279422 and parameters: {'n_estimators': 605, 'depth': 3, 'learning_rate': 0.14309838151708498, 'reg_alpha': 0.002934369458407416, 'reg_lambda': 6.546344840433138, 'subsample': 0.9677487322596153}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 34 < 35; dropping {'n_estimators': 605, 'depth': 3, 'learning_rate': 0.14309838151708498, 'reg_alpha': 0.002934369458407416, 'reg_lambda': 6.546344840433138, 'subsample': 0.9677487322596153, 'value': 0.8144974526279422}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144974526279422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:52:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:56:32,863]\u001b[0m Trial 35 finished with value: 0.814116388837808 and parameters: {'n_estimators': 575, 'depth': 3, 'learning_rate': 0.2375526301435684, 'reg_alpha': 0.002376654467054646, 'reg_lambda': 5.370862008244013, 'subsample': 0.9741597290409271}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 35 < 36; dropping {'n_estimators': 575, 'depth': 3, 'learning_rate': 0.2375526301435684, 'reg_alpha': 0.002376654467054646, 'reg_lambda': 5.370862008244013, 'subsample': 0.9741597290409271, 'value': 0.814116388837808}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.814116388837808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:56:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 18:59:07,513]\u001b[0m Trial 36 finished with value: 0.8137459360956718 and parameters: {'n_estimators': 467, 'depth': 2, 'learning_rate': 0.14736856264565235, 'reg_alpha': 0.0041160418722729995, 'reg_lambda': 6.9513113944118805, 'subsample': 0.8047467351037476}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 36 < 37; dropping {'n_estimators': 467, 'depth': 2, 'learning_rate': 0.14736856264565235, 'reg_alpha': 0.0041160418722729995, 'reg_lambda': 6.9513113944118805, 'subsample': 0.8047467351037476, 'value': 0.8137459360956718}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8137459360956718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:04:40,015]\u001b[0m Trial 37 finished with value: 0.8138914884244538 and parameters: {'n_estimators': 709, 'depth': 3, 'learning_rate': 0.04807145038559184, 'reg_alpha': 0.0017800302533633008, 'reg_lambda': 5.999344735433305, 'subsample': 0.7113414579573186}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 37 < 38; dropping {'n_estimators': 709, 'depth': 3, 'learning_rate': 0.04807145038559184, 'reg_alpha': 0.0017800302533633008, 'reg_lambda': 5.999344735433305, 'subsample': 0.7113414579573186, 'value': 0.8138914884244538}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8138914884244538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:04:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:06:40,539]\u001b[0m Trial 38 finished with value: 0.8140193835807571 and parameters: {'n_estimators': 354, 'depth': 2, 'learning_rate': 0.23560902779999737, 'reg_alpha': 0.030179161599957288, 'reg_lambda': 5.290471532164393, 'subsample': 0.5938241184019405}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 38 < 39; dropping {'n_estimators': 354, 'depth': 2, 'learning_rate': 0.23560902779999737, 'reg_alpha': 0.030179161599957288, 'reg_lambda': 5.290471532164393, 'subsample': 0.5938241184019405, 'value': 0.8140193835807571}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8140193835807571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:12:48,400]\u001b[0m Trial 39 finished with value: 0.8138694548021299 and parameters: {'n_estimators': 778, 'depth': 3, 'learning_rate': 0.0485515001001891, 'reg_alpha': 0.06164964120325414, 'reg_lambda': 2.166406270474441, 'subsample': 0.8827097970602645}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 39 < 40; dropping {'n_estimators': 778, 'depth': 3, 'learning_rate': 0.0485515001001891, 'reg_alpha': 0.06164964120325414, 'reg_lambda': 2.166406270474441, 'subsample': 0.8827097970602645, 'value': 0.8138694548021299}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8138694548021299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:17:08,255]\u001b[0m Trial 40 finished with value: 0.8144073554322189 and parameters: {'n_estimators': 549, 'depth': 3, 'learning_rate': 0.11109459563589717, 'reg_alpha': 0.004710597786373353, 'reg_lambda': 5.986159824837647, 'subsample': 0.9688982060107444}. Best is trial 24 with value: 0.8145132323576978.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 40 < 41; dropping {'n_estimators': 549, 'depth': 3, 'learning_rate': 0.11109459563589717, 'reg_alpha': 0.004710597786373353, 'reg_lambda': 5.986159824837647, 'subsample': 0.9688982060107444, 'value': 0.8144073554322189}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144073554322189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:21:40,103]\u001b[0m Trial 41 finished with value: 0.814542128046985 and parameters: {'n_estimators': 571, 'depth': 3, 'learning_rate': 0.12786046394074213, 'reg_alpha': 0.005576661420749532, 'reg_lambda': 6.137439018465219, 'subsample': 0.9615696854881648}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 41 < 42; dropping {'n_estimators': 571, 'depth': 3, 'learning_rate': 0.12786046394074213, 'reg_alpha': 0.005576661420749532, 'reg_lambda': 6.137439018465219, 'subsample': 0.9615696854881648, 'value': 0.814542128046985}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.814542128046985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:26:46,318]\u001b[0m Trial 42 finished with value: 0.8142801727282212 and parameters: {'n_estimators': 649, 'depth': 3, 'learning_rate': 0.07568298111968415, 'reg_alpha': 0.0020023264972760923, 'reg_lambda': 6.287984791528402, 'subsample': 0.9295905433781845}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 42 < 43; dropping {'n_estimators': 649, 'depth': 3, 'learning_rate': 0.07568298111968415, 'reg_alpha': 0.0020023264972760923, 'reg_lambda': 6.287984791528402, 'subsample': 0.9295905433781845, 'value': 0.8142801727282212}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8142801727282212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:26:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:32:04,421]\u001b[0m Trial 43 finished with value: 0.8140322727308289 and parameters: {'n_estimators': 509, 'depth': 4, 'learning_rate': 0.13745048180048008, 'reg_alpha': 0.006080866770095822, 'reg_lambda': 6.4507663341668655, 'subsample': 0.9687135966554574}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 43 < 44; dropping {'n_estimators': 509, 'depth': 4, 'learning_rate': 0.13745048180048008, 'reg_alpha': 0.006080866770095822, 'reg_lambda': 6.4507663341668655, 'subsample': 0.9687135966554574, 'value': 0.8140322727308289}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8140322727308289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:37:42,461]\u001b[0m Trial 44 finished with value: 0.8133352627428831 and parameters: {'n_estimators': 722, 'depth': 3, 'learning_rate': 0.28750802002781234, 'reg_alpha': 0.0033982489130872356, 'reg_lambda': 1.4329599758216267, 'subsample': 0.9975354419480995}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 44 < 45; dropping {'n_estimators': 722, 'depth': 3, 'learning_rate': 0.28750802002781234, 'reg_alpha': 0.0033982489130872356, 'reg_lambda': 1.4329599758216267, 'subsample': 0.9975354419480995, 'value': 0.8133352627428831}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8133352627428831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:39:44,009]\u001b[0m Trial 45 finished with value: 0.8137174865597263 and parameters: {'n_estimators': 365, 'depth': 2, 'learning_rate': 0.189273693174102, 'reg_alpha': 0.024108660566937397, 'reg_lambda': 5.741388645977484, 'subsample': 0.8716796486169316}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 45 < 46; dropping {'n_estimators': 365, 'depth': 2, 'learning_rate': 0.189273693174102, 'reg_alpha': 0.024108660566937397, 'reg_lambda': 5.741388645977484, 'subsample': 0.8716796486169316, 'value': 0.8137174865597263}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8137174865597263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:39:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:46:07,485]\u001b[0m Trial 46 finished with value: 0.8144881626669886 and parameters: {'n_estimators': 612, 'depth': 4, 'learning_rate': 0.08725604544523212, 'reg_alpha': 0.13138940069510166, 'reg_lambda': 4.914652454201463, 'subsample': 0.9602223750458011}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 46 < 47; dropping {'n_estimators': 612, 'depth': 4, 'learning_rate': 0.08725604544523212, 'reg_alpha': 0.13138940069510166, 'reg_lambda': 4.914652454201463, 'subsample': 0.9602223750458011, 'value': 0.8144881626669886}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144881626669886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:52:10,379]\u001b[0m Trial 47 finished with value: 0.8142397234867482 and parameters: {'n_estimators': 603, 'depth': 4, 'learning_rate': 0.05916484329646784, 'reg_alpha': 0.5215913952879548, 'reg_lambda': 3.525302662574948, 'subsample': 0.5139388480023126}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 47 < 48; dropping {'n_estimators': 603, 'depth': 4, 'learning_rate': 0.05916484329646784, 'reg_alpha': 0.5215913952879548, 'reg_lambda': 3.525302662574948, 'subsample': 0.5139388480023126, 'value': 0.8142397234867482}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8142397234867482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:56:09,549]\u001b[0m Trial 48 finished with value: 0.813898914492808 and parameters: {'n_estimators': 498, 'depth': 3, 'learning_rate': 0.08330645423737457, 'reg_alpha': 0.001668469007711672, 'reg_lambda': 4.337134666927843, 'subsample': 0.9563200576194935}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 48 < 49; dropping {'n_estimators': 498, 'depth': 3, 'learning_rate': 0.08330645423737457, 'reg_alpha': 0.001668469007711672, 'reg_lambda': 4.337134666927843, 'subsample': 0.9563200576194935, 'value': 0.813898914492808}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.813898914492808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 19:59:23,660]\u001b[0m Trial 49 finished with value: 0.8117480535465159 and parameters: {'n_estimators': 232, 'depth': 5, 'learning_rate': 0.041667849998098, 'reg_alpha': 0.14061273051983464, 'reg_lambda': 6.55138065762291, 'subsample': 0.9237022632387138}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 49 < 50; dropping {'n_estimators': 232, 'depth': 5, 'learning_rate': 0.041667849998098, 'reg_alpha': 0.14061273051983464, 'reg_lambda': 6.55138065762291, 'subsample': 0.9237022632387138, 'value': 0.8117480535465159}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8117480535465159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:59:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:03:47,634]\u001b[0m Trial 50 finished with value: 0.8144171950838712 and parameters: {'n_estimators': 559, 'depth': 3, 'learning_rate': 0.1987027199312176, 'reg_alpha': 2.5783766743881915, 'reg_lambda': 4.93378947831062, 'subsample': 0.955571183071978}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 50 < 51; dropping {'n_estimators': 559, 'depth': 3, 'learning_rate': 0.1987027199312176, 'reg_alpha': 2.5783766743881915, 'reg_lambda': 4.93378947831062, 'subsample': 0.955571183071978, 'value': 0.8144171950838712}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144171950838712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:03:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:09:00,773]\u001b[0m Trial 51 finished with value: 0.8134034758480047 and parameters: {'n_estimators': 666, 'depth': 3, 'learning_rate': 0.30010287941615515, 'reg_alpha': 2.0229715634435306, 'reg_lambda': 5.002498612743426, 'subsample': 0.9548371571176639}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 51 < 52; dropping {'n_estimators': 666, 'depth': 3, 'learning_rate': 0.30010287941615515, 'reg_alpha': 2.0229715634435306, 'reg_lambda': 5.002498612743426, 'subsample': 0.9548371571176639, 'value': 0.8134034758480047}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8134034758480047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:09:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:12:01,746]\u001b[0m Trial 52 finished with value: 0.8143349507753981 and parameters: {'n_estimators': 546, 'depth': 2, 'learning_rate': 0.20950063868473595, 'reg_alpha': 0.7801212581795789, 'reg_lambda': 5.834844995410823, 'subsample': 0.9231522255893673}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 52 < 53; dropping {'n_estimators': 546, 'depth': 2, 'learning_rate': 0.20950063868473595, 'reg_alpha': 0.7801212581795789, 'reg_lambda': 5.834844995410823, 'subsample': 0.9231522255893673, 'value': 0.8143349507753981}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8143349507753981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:12:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:18:26,073]\u001b[0m Trial 53 finished with value: 0.8144292583769075 and parameters: {'n_estimators': 614, 'depth': 4, 'learning_rate': 0.13029091320147068, 'reg_alpha': 3.356342498895138, 'reg_lambda': 4.731112677687462, 'subsample': 0.9368984594868393}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 53 < 54; dropping {'n_estimators': 614, 'depth': 4, 'learning_rate': 0.13029091320147068, 'reg_alpha': 3.356342498895138, 'reg_lambda': 4.731112677687462, 'subsample': 0.9368984594868393, 'value': 0.8144292583769075}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144292583769075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:18:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:24:51,771]\u001b[0m Trial 54 finished with value: 0.8143986925197618 and parameters: {'n_estimators': 622, 'depth': 4, 'learning_rate': 0.1278451665476815, 'reg_alpha': 0.011215668354335651, 'reg_lambda': 3.839871755598288, 'subsample': 0.8703168661116796}. Best is trial 41 with value: 0.814542128046985.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 54 < 55; dropping {'n_estimators': 622, 'depth': 4, 'learning_rate': 0.1278451665476815, 'reg_alpha': 0.011215668354335651, 'reg_lambda': 3.839871755598288, 'subsample': 0.8703168661116796, 'value': 0.8143986925197618}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8143986925197618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:24:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:33:02,732]\u001b[0m Trial 55 finished with value: 0.8147633244328913 and parameters: {'n_estimators': 788, 'depth': 4, 'learning_rate': 0.058293193548646094, 'reg_alpha': 0.3884725547374427, 'reg_lambda': 4.612699770937652, 'subsample': 0.82731514381755}. Best is trial 55 with value: 0.8147633244328913.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 55 < 56; dropping {'n_estimators': 788, 'depth': 4, 'learning_rate': 0.058293193548646094, 'reg_alpha': 0.3884725547374427, 'reg_lambda': 4.612699770937652, 'subsample': 0.82731514381755, 'value': 0.8147633244328913}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147633244328913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:33:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:41:26,119]\u001b[0m Trial 56 finished with value: 0.8148195623908341 and parameters: {'n_estimators': 808, 'depth': 4, 'learning_rate': 0.057237821426402304, 'reg_alpha': 0.4055463683892877, 'reg_lambda': 4.305939509602183, 'subsample': 0.8293645394362601}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 56 < 57; dropping {'n_estimators': 808, 'depth': 4, 'learning_rate': 0.057237821426402304, 'reg_alpha': 0.4055463683892877, 'reg_lambda': 4.305939509602183, 'subsample': 0.8293645394362601, 'value': 0.8148195623908341}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148195623908341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 20:52:43,316]\u001b[0m Trial 57 finished with value: 0.8098289247979156 and parameters: {'n_estimators': 741, 'depth': 5, 'learning_rate': 0.006872682517143512, 'reg_alpha': 0.46584261106626323, 'reg_lambda': 3.292485251258308, 'subsample': 0.8210087212262703}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 57 < 58; dropping {'n_estimators': 741, 'depth': 5, 'learning_rate': 0.006872682517143512, 'reg_alpha': 0.46584261106626323, 'reg_lambda': 3.292485251258308, 'subsample': 0.8210087212262703, 'value': 0.8098289247979156}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8098289247979156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:01:51,460]\u001b[0m Trial 58 finished with value: 0.8146301919235228 and parameters: {'n_estimators': 802, 'depth': 4, 'learning_rate': 0.06640030801294809, 'reg_alpha': 0.20719662653013066, 'reg_lambda': 4.331879555547503, 'subsample': 0.7801431889960021}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 58 < 59; dropping {'n_estimators': 802, 'depth': 4, 'learning_rate': 0.06640030801294809, 'reg_alpha': 0.20719662653013066, 'reg_lambda': 4.331879555547503, 'subsample': 0.7801431889960021, 'value': 0.8146301919235228}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8146301919235228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:11:23,455]\u001b[0m Trial 59 finished with value: 0.8121875510351306 and parameters: {'n_estimators': 812, 'depth': 4, 'learning_rate': 0.015716260042277403, 'reg_alpha': 0.351256343352716, 'reg_lambda': 4.2909890100585, 'subsample': 0.751955674741}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 59 < 60; dropping {'n_estimators': 812, 'depth': 4, 'learning_rate': 0.015716260042277403, 'reg_alpha': 0.351256343352716, 'reg_lambda': 4.2909890100585, 'subsample': 0.751955674741, 'value': 0.8121875510351306}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8121875510351306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:11:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:24:04,911]\u001b[0m Trial 60 finished with value: 0.8142292952953711 and parameters: {'n_estimators': 889, 'depth': 5, 'learning_rate': 0.06540294538581184, 'reg_alpha': 0.21928587938395985, 'reg_lambda': 3.0079516507071076, 'subsample': 0.7861621970931588}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 60 < 61; dropping {'n_estimators': 889, 'depth': 5, 'learning_rate': 0.06540294538581184, 'reg_alpha': 0.21928587938395985, 'reg_lambda': 3.0079516507071076, 'subsample': 0.7861621970931588, 'value': 0.8142292952953711}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8142292952953711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:32:03,331]\u001b[0m Trial 61 finished with value: 0.8146641454717669 and parameters: {'n_estimators': 703, 'depth': 4, 'learning_rate': 0.09377731536678985, 'reg_alpha': 0.17105600361750709, 'reg_lambda': 3.7499355067630553, 'subsample': 0.7315102655074958}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 61 < 62; dropping {'n_estimators': 703, 'depth': 4, 'learning_rate': 0.09377731536678985, 'reg_alpha': 0.17105600361750709, 'reg_lambda': 3.7499355067630553, 'subsample': 0.7315102655074958, 'value': 0.8146641454717669}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8146641454717669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:32:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:39:57,757]\u001b[0m Trial 62 finished with value: 0.8145811235823277 and parameters: {'n_estimators': 693, 'depth': 4, 'learning_rate': 0.06101142234003742, 'reg_alpha': 0.6796251376857242, 'reg_lambda': 3.7971453605681726, 'subsample': 0.7765896725085661}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 62 < 63; dropping {'n_estimators': 693, 'depth': 4, 'learning_rate': 0.06101142234003742, 'reg_alpha': 0.6796251376857242, 'reg_lambda': 3.7971453605681726, 'subsample': 0.7765896725085661, 'value': 0.8145811235823277}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8145811235823277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:47:58,193]\u001b[0m Trial 63 finished with value: 0.8139758540978954 and parameters: {'n_estimators': 697, 'depth': 4, 'learning_rate': 0.037213095508854106, 'reg_alpha': 0.6785656774828699, 'reg_lambda': 3.8578804144585463, 'subsample': 0.7353349201136492}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 63 < 64; dropping {'n_estimators': 697, 'depth': 4, 'learning_rate': 0.037213095508854106, 'reg_alpha': 0.6785656774828699, 'reg_lambda': 3.8578804144585463, 'subsample': 0.7353349201136492, 'value': 0.8139758540978954}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8139758540978954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 21:56:41,207]\u001b[0m Trial 64 finished with value: 0.8046758931529954 and parameters: {'n_estimators': 735, 'depth': 4, 'learning_rate': 0.001063524627975749, 'reg_alpha': 1.1169552486210717, 'reg_lambda': 3.7369902574284684, 'subsample': 0.7271351998478126}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 64 < 65; dropping {'n_estimators': 735, 'depth': 4, 'learning_rate': 0.001063524627975749, 'reg_alpha': 1.1169552486210717, 'reg_lambda': 3.7369902574284684, 'subsample': 0.7271351998478126, 'value': 0.8046758931529954}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8046758931529954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:56:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 22:08:07,796]\u001b[0m Trial 65 finished with value: 0.8144049082638276 and parameters: {'n_estimators': 809, 'depth': 5, 'learning_rate': 0.06206971421052344, 'reg_alpha': 0.3670173376965995, 'reg_lambda': 2.758276729790222, 'subsample': 0.7732081471275263}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 65 < 66; dropping {'n_estimators': 809, 'depth': 5, 'learning_rate': 0.06206971421052344, 'reg_alpha': 0.3670173376965995, 'reg_lambda': 2.758276729790222, 'subsample': 0.7732081471275263, 'value': 0.8144049082638276}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144049082638276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:08:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 22:16:56,240]\u001b[0m Trial 66 finished with value: 0.8131630918461552 and parameters: {'n_estimators': 765, 'depth': 4, 'learning_rate': 0.02388017994748562, 'reg_alpha': 0.20005566262287602, 'reg_lambda': 3.35855319869798, 'subsample': 0.7703978641879025}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 66 < 67; dropping {'n_estimators': 765, 'depth': 4, 'learning_rate': 0.02388017994748562, 'reg_alpha': 0.20005566262287602, 'reg_lambda': 3.35855319869798, 'subsample': 0.7703978641879025, 'value': 0.8131630918461552}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8131630918461552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 22:24:37,590]\u001b[0m Trial 67 finished with value: 0.8144159534361797 and parameters: {'n_estimators': 675, 'depth': 4, 'learning_rate': 0.056307624375259914, 'reg_alpha': 0.09649961034559919, 'reg_lambda': 4.186402254788925, 'subsample': 0.8235306496131808}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 67 < 68; dropping {'n_estimators': 675, 'depth': 4, 'learning_rate': 0.056307624375259914, 'reg_alpha': 0.09649961034559919, 'reg_lambda': 4.186402254788925, 'subsample': 0.8235306496131808, 'value': 0.8144159534361797}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144159534361797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 22:34:58,201]\u001b[0m Trial 68 finished with value: 0.8139395034786904 and parameters: {'n_estimators': 925, 'depth': 4, 'learning_rate': 0.1045657127400219, 'reg_alpha': 0.2840546798130174, 'reg_lambda': 4.484391135019249, 'subsample': 0.6930272928229908}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 68 < 69; dropping {'n_estimators': 925, 'depth': 4, 'learning_rate': 0.1045657127400219, 'reg_alpha': 0.2840546798130174, 'reg_lambda': 4.484391135019249, 'subsample': 0.6930272928229908, 'value': 0.8139395034786904}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8139395034786904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 22:47:30,947]\u001b[0m Trial 69 finished with value: 0.8145373876452147 and parameters: {'n_estimators': 875, 'depth': 5, 'learning_rate': 0.03084436473013108, 'reg_alpha': 1.0396814548486069, 'reg_lambda': 4.559126032899704, 'subsample': 0.7969073363517022}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 69 < 70; dropping {'n_estimators': 875, 'depth': 5, 'learning_rate': 0.03084436473013108, 'reg_alpha': 1.0396814548486069, 'reg_lambda': 4.559126032899704, 'subsample': 0.7969073363517022, 'value': 0.8145373876452147}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8145373876452147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:47:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 23:02:04,561]\u001b[0m Trial 70 finished with value: 0.8147603428051814 and parameters: {'n_estimators': 975, 'depth': 5, 'learning_rate': 0.029413518794225584, 'reg_alpha': 0.8612429120082857, 'reg_lambda': 3.6379461951993615, 'subsample': 0.7960769245259984}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 70 < 71; dropping {'n_estimators': 975, 'depth': 5, 'learning_rate': 0.029413518794225584, 'reg_alpha': 0.8612429120082857, 'reg_lambda': 3.6379461951993615, 'subsample': 0.7960769245259984, 'value': 0.8147603428051814}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147603428051814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:02:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 23:14:37,122]\u001b[0m Trial 71 finished with value: 0.8144474150826104 and parameters: {'n_estimators': 877, 'depth': 5, 'learning_rate': 0.030550385351179307, 'reg_alpha': 1.2416553929344327, 'reg_lambda': 3.6949254188182317, 'subsample': 0.7945673184642625}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 71 < 72; dropping {'n_estimators': 877, 'depth': 5, 'learning_rate': 0.030550385351179307, 'reg_alpha': 1.2416553929344327, 'reg_lambda': 3.6949254188182317, 'subsample': 0.7945673184642625, 'value': 0.8144474150826104}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8144474150826104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 23:28:39,945]\u001b[0m Trial 72 finished with value: 0.814495967098035 and parameters: {'n_estimators': 970, 'depth': 5, 'learning_rate': 0.026818142154980303, 'reg_alpha': 0.593934407552809, 'reg_lambda': 3.043275355564574, 'subsample': 0.8278772877070313}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 72 < 73; dropping {'n_estimators': 970, 'depth': 5, 'learning_rate': 0.026818142154980303, 'reg_alpha': 0.593934407552809, 'reg_lambda': 3.043275355564574, 'subsample': 0.8278772877070313, 'value': 0.814495967098035}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.814495967098035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-20 23:46:14,500]\u001b[0m Trial 73 finished with value: 0.8147710352740125 and parameters: {'n_estimators': 1004, 'depth': 6, 'learning_rate': 0.03873902679588235, 'reg_alpha': 0.9940740435926676, 'reg_lambda': 4.0328062536500635, 'subsample': 0.8119212359318025}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 73 < 74; dropping {'n_estimators': 1004, 'depth': 6, 'learning_rate': 0.03873902679588235, 'reg_alpha': 0.9940740435926676, 'reg_lambda': 4.0328062536500635, 'subsample': 0.8119212359318025, 'value': 0.8147710352740125}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147710352740125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 00:03:59,313]\u001b[0m Trial 74 finished with value: 0.8147052752016637 and parameters: {'n_estimators': 1019, 'depth': 6, 'learning_rate': 0.039036120057599266, 'reg_alpha': 0.884171528423455, 'reg_lambda': 3.9869191189810094, 'subsample': 0.8427710173512896}. Best is trial 56 with value: 0.8148195623908341.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 74 < 75; dropping {'n_estimators': 1019, 'depth': 6, 'learning_rate': 0.039036120057599266, 'reg_alpha': 0.884171528423455, 'reg_lambda': 3.9869191189810094, 'subsample': 0.8427710173512896, 'value': 0.8147052752016637}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147052752016637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 00:22:54,756]\u001b[0m Trial 75 finished with value: 0.8149115533014384 and parameters: {'n_estimators': 1088, 'depth': 6, 'learning_rate': 0.040713472881926276, 'reg_alpha': 1.7892193691271923, 'reg_lambda': 4.010015390855034, 'subsample': 0.8401773142110147}. Best is trial 75 with value: 0.8149115533014384.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 75 < 76; dropping {'n_estimators': 1088, 'depth': 6, 'learning_rate': 0.040713472881926276, 'reg_alpha': 1.7892193691271923, 'reg_lambda': 4.010015390855034, 'subsample': 0.8401773142110147, 'value': 0.8149115533014384}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8149115533014384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:22:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 00:41:53,050]\u001b[0m Trial 76 finished with value: 0.8147036614559607 and parameters: {'n_estimators': 1103, 'depth': 6, 'learning_rate': 0.04138000690770366, 'reg_alpha': 1.7454864930446488, 'reg_lambda': 4.013954512589614, 'subsample': 0.84190308550461}. Best is trial 75 with value: 0.8149115533014384.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 76 < 77; dropping {'n_estimators': 1103, 'depth': 6, 'learning_rate': 0.04138000690770366, 'reg_alpha': 1.7454864930446488, 'reg_lambda': 4.013954512589614, 'subsample': 0.84190308550461, 'value': 0.8147036614559607}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147036614559607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 01:01:23,533]\u001b[0m Trial 77 finished with value: 0.8151879038955687 and parameters: {'n_estimators': 1119, 'depth': 6, 'learning_rate': 0.04123392555159452, 'reg_alpha': 4.511876752318655, 'reg_lambda': 4.074347238862406, 'subsample': 0.8408586950521992}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 77 < 78; dropping {'n_estimators': 1119, 'depth': 6, 'learning_rate': 0.04123392555159452, 'reg_alpha': 4.511876752318655, 'reg_lambda': 4.074347238862406, 'subsample': 0.8408586950521992, 'value': 0.8151879038955687}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8151879038955687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:01:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 01:20:44,441]\u001b[0m Trial 78 finished with value: 0.8147762069580133 and parameters: {'n_estimators': 1116, 'depth': 6, 'learning_rate': 0.04228890143498643, 'reg_alpha': 4.795420687531014, 'reg_lambda': 4.029595674374503, 'subsample': 0.8426116860261553}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 78 < 79; dropping {'n_estimators': 1116, 'depth': 6, 'learning_rate': 0.04228890143498643, 'reg_alpha': 4.795420687531014, 'reg_lambda': 4.029595674374503, 'subsample': 0.8426116860261553, 'value': 0.8147762069580133}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147762069580133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:20:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 01:41:50,255]\u001b[0m Trial 79 finished with value: 0.8146071583540928 and parameters: {'n_estimators': 1139, 'depth': 6, 'learning_rate': 0.01820028595836574, 'reg_alpha': 3.751631426165683, 'reg_lambda': 3.366897192266322, 'subsample': 0.8577907052495101}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 79 < 80; dropping {'n_estimators': 1139, 'depth': 6, 'learning_rate': 0.01820028595836574, 'reg_alpha': 3.751631426165683, 'reg_lambda': 3.366897192266322, 'subsample': 0.8577907052495101, 'value': 0.8146071583540928}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8146071583540928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:41:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 02:03:09,738]\u001b[0m Trial 80 finished with value: 0.8146898927687466 and parameters: {'n_estimators': 1012, 'depth': 7, 'learning_rate': 0.0231134096357016, 'reg_alpha': 4.896982506144585, 'reg_lambda': 4.089073642983592, 'subsample': 0.8134277797669518}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 80 < 81; dropping {'n_estimators': 1012, 'depth': 7, 'learning_rate': 0.0231134096357016, 'reg_alpha': 4.896982506144585, 'reg_lambda': 4.089073642983592, 'subsample': 0.8134277797669518, 'value': 0.8146898927687466}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8146898927687466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:03:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 02:22:13,031]\u001b[0m Trial 81 finished with value: 0.8148433461007285 and parameters: {'n_estimators': 1100, 'depth': 6, 'learning_rate': 0.04157692533624798, 'reg_alpha': 1.9173671937200443, 'reg_lambda': 3.547934603653591, 'subsample': 0.8420239460032052}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 81 < 82; dropping {'n_estimators': 1100, 'depth': 6, 'learning_rate': 0.04157692533624798, 'reg_alpha': 1.9173671937200443, 'reg_lambda': 3.547934603653591, 'subsample': 0.8420239460032052, 'value': 0.8148433461007285}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148433461007285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:22:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 02:40:33,548]\u001b[0m Trial 82 finished with value: 0.8147091244776333 and parameters: {'n_estimators': 1056, 'depth': 6, 'learning_rate': 0.040374553247304865, 'reg_alpha': 1.6526247655966668, 'reg_lambda': 3.5829861037175332, 'subsample': 0.8398607845318891}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 82 < 83; dropping {'n_estimators': 1056, 'depth': 6, 'learning_rate': 0.040374553247304865, 'reg_alpha': 1.6526247655966668, 'reg_lambda': 3.5829861037175332, 'subsample': 0.8398607845318891, 'value': 0.8147091244776333}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147091244776333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:40:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 02:59:23,740]\u001b[0m Trial 83 finished with value: 0.8145724881504026 and parameters: {'n_estimators': 1084, 'depth': 6, 'learning_rate': 0.04550079175538268, 'reg_alpha': 1.5379296853385074, 'reg_lambda': 3.5537491317837517, 'subsample': 0.8641998779060365}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 83 < 84; dropping {'n_estimators': 1084, 'depth': 6, 'learning_rate': 0.04550079175538268, 'reg_alpha': 1.5379296853385074, 'reg_lambda': 3.5537491317837517, 'subsample': 0.8641998779060365, 'value': 0.8145724881504026}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8145724881504026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:59:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 03:23:34,868]\u001b[0m Trial 84 finished with value: 0.8147512843171719 and parameters: {'n_estimators': 1160, 'depth': 7, 'learning_rate': 0.035037824528416646, 'reg_alpha': 2.5096623258226423, 'reg_lambda': 4.704717104264199, 'subsample': 0.8897477613483272}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 84 < 85; dropping {'n_estimators': 1160, 'depth': 7, 'learning_rate': 0.035037824528416646, 'reg_alpha': 2.5096623258226423, 'reg_lambda': 4.704717104264199, 'subsample': 0.8897477613483272, 'value': 0.8147512843171719}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147512843171719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:23:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 03:48:52,621]\u001b[0m Trial 85 finished with value: 0.8149506126044247 and parameters: {'n_estimators': 1151, 'depth': 7, 'learning_rate': 0.027630657927283985, 'reg_alpha': 4.796723018269739, 'reg_lambda': 3.1685985796121643, 'subsample': 0.8513407951326758}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 85 < 86; dropping {'n_estimators': 1151, 'depth': 7, 'learning_rate': 0.027630657927283985, 'reg_alpha': 4.796723018269739, 'reg_lambda': 3.1685985796121643, 'subsample': 0.8513407951326758, 'value': 0.8149506126044247}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8149506126044247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:48:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 04:10:56,012]\u001b[0m Trial 86 finished with value: 0.8147093303114211 and parameters: {'n_estimators': 1120, 'depth': 7, 'learning_rate': 0.02871378844796033, 'reg_alpha': 4.386396221501123, 'reg_lambda': 3.1079939947237176, 'subsample': 0.8104010336820461}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 86 < 87; dropping {'n_estimators': 1120, 'depth': 7, 'learning_rate': 0.02871378844796033, 'reg_alpha': 4.386396221501123, 'reg_lambda': 3.1079939947237176, 'subsample': 0.8104010336820461, 'value': 0.8147093303114211}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147093303114211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:11:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 04:31:08,861]\u001b[0m Trial 87 finished with value: 0.8142856632904706 and parameters: {'n_estimators': 1186, 'depth': 6, 'learning_rate': 0.014677850594199404, 'reg_alpha': 2.703026346705201, 'reg_lambda': 2.830396776208374, 'subsample': 0.8523460029681081}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 87 < 88; dropping {'n_estimators': 1186, 'depth': 6, 'learning_rate': 0.014677850594199404, 'reg_alpha': 2.703026346705201, 'reg_lambda': 2.830396776208374, 'subsample': 0.8523460029681081, 'value': 0.8142856632904706}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8142856632904706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:31:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 04:50:52,192]\u001b[0m Trial 88 finished with value: 0.8146870936974328 and parameters: {'n_estimators': 1031, 'depth': 7, 'learning_rate': 0.021663454803392695, 'reg_alpha': 2.1628901388699635, 'reg_lambda': 2.648137276569298, 'subsample': 0.8315841322898249}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 88 < 89; dropping {'n_estimators': 1031, 'depth': 7, 'learning_rate': 0.021663454803392695, 'reg_alpha': 2.1628901388699635, 'reg_lambda': 2.648137276569298, 'subsample': 0.8315841322898249, 'value': 0.8146870936974328}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8146870936974328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:50:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 05:06:46,227]\u001b[0m Trial 89 finished with value: 0.8147070833926456 and parameters: {'n_estimators': 990, 'depth': 6, 'learning_rate': 0.05362788731185257, 'reg_alpha': 3.5181489285272005, 'reg_lambda': 3.2093593526957354, 'subsample': 0.8151127293899503}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 89 < 90; dropping {'n_estimators': 990, 'depth': 6, 'learning_rate': 0.05362788731185257, 'reg_alpha': 3.5181489285272005, 'reg_lambda': 3.2093593526957354, 'subsample': 0.8151127293899503, 'value': 0.8147070833926456}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147070833926456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:06:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 05:25:06,495]\u001b[0m Trial 90 finished with value: 0.8149300286652251 and parameters: {'n_estimators': 1080, 'depth': 6, 'learning_rate': 0.02626666267395986, 'reg_alpha': 3.980226150525091, 'reg_lambda': 3.594926074273673, 'subsample': 0.8579949496777324}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 90 < 91; dropping {'n_estimators': 1080, 'depth': 6, 'learning_rate': 0.02626666267395986, 'reg_alpha': 3.980226150525091, 'reg_lambda': 3.594926074273673, 'subsample': 0.8579949496777324, 'value': 0.8149300286652251}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8149300286652251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:25:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 05:43:23,384]\u001b[0m Trial 91 finished with value: 0.8148049741112654 and parameters: {'n_estimators': 1083, 'depth': 6, 'learning_rate': 0.026389374308605888, 'reg_alpha': 4.052677680716701, 'reg_lambda': 3.4520464430404405, 'subsample': 0.8534511115581337}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 91 < 92; dropping {'n_estimators': 1083, 'depth': 6, 'learning_rate': 0.026389374308605888, 'reg_alpha': 4.052677680716701, 'reg_lambda': 3.4520464430404405, 'subsample': 0.8534511115581337, 'value': 0.8148049741112654}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148049741112654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:43:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 06:01:46,699]\u001b[0m Trial 92 finished with value: 0.8147640361246287 and parameters: {'n_estimators': 1086, 'depth': 6, 'learning_rate': 0.026553404492004728, 'reg_alpha': 4.038127974116472, 'reg_lambda': 3.464712260967998, 'subsample': 0.8810976940213768}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 92 < 93; dropping {'n_estimators': 1086, 'depth': 6, 'learning_rate': 0.026553404492004728, 'reg_alpha': 4.038127974116472, 'reg_lambda': 3.464712260967998, 'subsample': 0.8810976940213768, 'value': 0.8147640361246287}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8147640361246287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:01:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 06:20:11,947]\u001b[0m Trial 93 finished with value: 0.8148374386870304 and parameters: {'n_estimators': 1079, 'depth': 6, 'learning_rate': 0.026065554154458964, 'reg_alpha': 2.971002092974464, 'reg_lambda': 3.42993456075839, 'subsample': 0.9025798196403628}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 93 < 94; dropping {'n_estimators': 1079, 'depth': 6, 'learning_rate': 0.026065554154458964, 'reg_alpha': 2.971002092974464, 'reg_lambda': 3.42993456075839, 'subsample': 0.9025798196403628, 'value': 0.8148374386870304}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148374386870304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:20:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 06:40:07,003]\u001b[0m Trial 94 finished with value: 0.8150952327367202 and parameters: {'n_estimators': 1141, 'depth': 6, 'learning_rate': 0.03399281315320323, 'reg_alpha': 2.9324574258339218, 'reg_lambda': 2.398735855525868, 'subsample': 0.9078299114435469}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 94 < 95; dropping {'n_estimators': 1141, 'depth': 6, 'learning_rate': 0.03399281315320323, 'reg_alpha': 2.9324574258339218, 'reg_lambda': 2.398735855525868, 'subsample': 0.9078299114435469, 'value': 0.8150952327367202}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8150952327367202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:40:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 07:00:17,357]\u001b[0m Trial 95 finished with value: 0.8133252714979684 and parameters: {'n_estimators': 1154, 'depth': 6, 'learning_rate': 0.010451066374890367, 'reg_alpha': 3.0490585281911255, 'reg_lambda': 2.2858143792185333, 'subsample': 0.8965383557188918}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 95 < 96; dropping {'n_estimators': 1154, 'depth': 6, 'learning_rate': 0.010451066374890367, 'reg_alpha': 3.0490585281911255, 'reg_lambda': 2.2858143792185333, 'subsample': 0.8965383557188918, 'value': 0.8133252714979684}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8133252714979684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:00:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 07:20:36,679]\u001b[0m Trial 96 finished with value: 0.8151202037336908 and parameters: {'n_estimators': 1199, 'depth': 6, 'learning_rate': 0.03455254443098114, 'reg_alpha': 4.866296607086757, 'reg_lambda': 2.5393147388161816, 'subsample': 0.9099004270236681}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 96 < 97; dropping {'n_estimators': 1199, 'depth': 6, 'learning_rate': 0.03455254443098114, 'reg_alpha': 4.866296607086757, 'reg_lambda': 2.5393147388161816, 'subsample': 0.9099004270236681, 'value': 0.8151202037336908}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8151202037336908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:20:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 07:39:55,751]\u001b[0m Trial 97 finished with value: 0.8149854918643102 and parameters: {'n_estimators': 1192, 'depth': 6, 'learning_rate': 0.03469760340081413, 'reg_alpha': 2.16003769042208, 'reg_lambda': 2.3920780982316043, 'subsample': 0.9077024172988531}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 97 < 98; dropping {'n_estimators': 1192, 'depth': 6, 'learning_rate': 0.03469760340081413, 'reg_alpha': 2.16003769042208, 'reg_lambda': 2.3920780982316043, 'subsample': 0.9077024172988531, 'value': 0.8149854918643102}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8149854918643102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:40:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 08:04:27,001]\u001b[0m Trial 98 finished with value: 0.8148183952588167 and parameters: {'n_estimators': 1199, 'depth': 7, 'learning_rate': 0.017737980223059995, 'reg_alpha': 2.050586436843394, 'reg_lambda': 2.096766553114743, 'subsample': 0.9117829179794402}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 98 < 99; dropping {'n_estimators': 1199, 'depth': 7, 'learning_rate': 0.017737980223059995, 'reg_alpha': 2.050586436843394, 'reg_lambda': 2.096766553114743, 'subsample': 0.9117829179794402, 'value': 0.8148183952588167}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148183952588167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:04:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 08:23:37,711]\u001b[0m Trial 99 finished with value: 0.8149293715342526 and parameters: {'n_estimators': 1135, 'depth': 6, 'learning_rate': 0.034949574654518444, 'reg_alpha': 3.040952657509712, 'reg_lambda': 2.493165678910283, 'subsample': 0.9036684293976636}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 99 < 100; dropping {'n_estimators': 1135, 'depth': 6, 'learning_rate': 0.034949574654518444, 'reg_alpha': 3.040952657509712, 'reg_lambda': 2.493165678910283, 'subsample': 0.9036684293976636, 'value': 0.8149293715342526}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8149293715342526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:23:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 08:42:51,361]\u001b[0m Trial 100 finished with value: 0.8148505806059572 and parameters: {'n_estimators': 1132, 'depth': 6, 'learning_rate': 0.03349111825997133, 'reg_alpha': 2.9742522652968173, 'reg_lambda': 2.4920359287670286, 'subsample': 0.9022174040798057}. Best is trial 77 with value: 0.8151879038955687.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 100 < 101; dropping {'n_estimators': 1132, 'depth': 6, 'learning_rate': 0.03349111825997133, 'reg_alpha': 2.9742522652968173, 'reg_lambda': 2.4920359287670286, 'subsample': 0.9022174040798057, 'value': 0.8148505806059572}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8148505806059572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:42:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0b5b687b45e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             study_name='xgboost_20210919')\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# setting n_jobs=1 bc wandb apparently requires this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n_jobs = multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9759646974a5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     wandb.init(wandb_kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# fit the model on the training set -- note the use of the catboost.Pool instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         )\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1497\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name='xgboost_20210919')\n",
    "# setting n_jobs=1 bc wandb apparently requires this\n",
    "study.optimize(objective, n_trials = n_trials, callbacks = [wandbc]) #n_jobs = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a746ff-c0e1-4218-8809-f102a58d2491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optuna_xgboost_best_20210920.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(study, filename='optuna_xgboost_study_20210920.joblib')\n",
    "dump(study.best_trial.params, filename='optuna_xgboost_best_20210920.joblib')\n",
    "\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1119,\n",
       " 'depth': 6,\n",
       " 'learning_rate': 0.04123392555159452,\n",
       " 'reg_alpha': 4.511876752318655,\n",
       " 'reg_lambda': 4.074347238862406,\n",
       " 'subsample': 0.8408586950521992}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
