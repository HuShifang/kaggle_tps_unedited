{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e815d3-d755-4fa2-85a5-ea4df4948fcd",
   "metadata": {},
   "source": [
    "Header for notebooks -- customize as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843e3531-f950-4701-9330-07960ae9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "COLAB = False # will trigger manual installation of packages\n",
    "USE_GPU = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a61aa18-6ef3-41d1-bb75-08d1f766dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d84988-5ddb-40d9-bc12-826012acb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"widedeep_corrected_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1e65-6447-47b9-88f2-8d02bbc29af0",
   "metadata": {},
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee16c791-548b-4616-9c82-ea76001e4749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.impute import SimpleImputer #, KNNImputer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler #StandardScaler #, MinMaxScaler, MaxAbsScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "# from BorutaShap import BorutaShap\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957d1322-cdac-411a-9754-9deb360cea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c21f1f-d22d-486b-bb2e-e69db6c62eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauss_rank_scaler import GaussRankScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b139207-5ea6-464d-922e-e4d0a398062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep#, SAINT, TabTransformer, TabNet, TabFastFormer, TabResnet\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW, Adagrad, SGD, RMSprop, LBFGS\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CyclicLR, OneCycleLR, StepLR, CosineAnnealingLR\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, LRHistory, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55072fd2-dcc0-4169-a6f8-54d9b76ab432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71932e1-2e32-4474-acbc-3cbe63ce993e",
   "metadata": {},
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880b9f33-b517-40ef-a3e6-049dcc52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "    datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/nov2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/')\n",
    "    datapath = root/'datasets'\n",
    "    # edapath = root/'EDA'\n",
    "    # modelpath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/models/')\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    \n",
    "    for pth in [datapath, predpath, subpath]:\n",
    "        pth.mkdir(exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9e0d-1301-4ade-a63d-9f3d298c2255",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1905a9de-cd7c-4a73-a39e-b42a8297785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba521a1a-8c41-4b9b-becd-36eb62739ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f63ee2-a167-4111-9b44-bf67c8240603",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad459104-e31a-4aa0-8a9a-bb279e2b9944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_params will initially include either trivial class instances or loaded, precomputed artifacts\n",
    "dataset_params = {\n",
    "    # 'train_source': str(datapath/'X-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'train_source': str(datapath/'X_orig.feather'),\n",
    "    'target_source': str(datapath/'y_corrected.joblib'),\n",
    "    # 'test_source': str(datapath/'X_test-RobustScaled-pca_mle-umap_embedding_20211107-n_comp10-n_neighbors15-rs42.joblib'),\n",
    "    'test_source': str(datapath/'X_test_orig-no_scaling.feather'),\n",
    "    # 'scaler': str(RobustScaler()),\n",
    "    # 'pca': str(load(datapath/'pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "    # 'umap': str(load(datapath/'umap_reducer-20211107-n_comp10-n_neighbors15-rs42-pca_mle-RobustScaled_orig_trainset.joblib')),\n",
    "}   \n",
    "\n",
    "# referring back to the already-entered attributes, specify how the pipeline was sequenced\n",
    "# dataset_params['preprocessing_pipeline'] = str([dataset_params['scaler'], dataset_params['pca'], dataset_params['umap']]) # ACTUALLY this is unwieldy\n",
    "# dataset_params['preprocessing_pipeline'] = '[scaler, pca, umap]' # more fragile, but also more readable\n",
    "\n",
    "# now, load the datasets and generate more metadata from them\n",
    "# X = load(dataset_params['train_source'])\n",
    "X = pd.read_feather(dataset_params['train_source'])\n",
    "y = load(dataset_params['target_source'])\n",
    "# X_test = load(dataset_params['test_source'])\n",
    "X_test = pd.read_feather(dataset_params['test_source'])\n",
    "\n",
    "dataset_params['feature_count'] = X.shape[1]\n",
    "dataset_params['instance_count'] = X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac6b1dd-5c9d-4f95-985c-4250d78d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    \"arch\": 'widedeep-TabMLP',\n",
    "    # \"type\": 'sweep',\n",
    "    # \"denoising\": \"cleanlab\",\n",
    "    \"level\": 1,\n",
    "    'random_state': SEED,\n",
    "    # 'tuner': \"Optuna\",\n",
    "    'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "    'kfolds': 1, # if 1, that means just doing holdout\n",
    "    'test_size': 0.2,\n",
    "    'scaler': str(GaussRankScaler()),\n",
    "    **dataset_params\n",
    "}\n",
    "\n",
    "wandb_config = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['experiment'],\n",
    "    'notes': \"Comparing.\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ce4d6-5c82-40c5-97ba-7c751e1abf6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Noisy Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5febff-4b71-4c29-9946-9763f6e874c3",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "Inspired a bit by Laurent Pourchot's Aug2021 Tabular Playground entry, I'm going to try to generate two versions of the dataset: a categorical one, using bins, and then (for now) a GaussRankScaled one. In the future, I might add further variations, e.g. with feature reduction via PCA and perhaps also UMAP and also denoising; I might also try other normalizations, e.g. Quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31c999-0d5b-49aa-a642-47d2d1cc5331",
   "metadata": {},
   "source": [
    "## Binning (Generating wide cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44132c0b-d796-4b4b-95fc-60e3c88428d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h/t Laurent Pourchot https://www.kaggle.com/pourchot/in-python-tabular-denoising-residual-network/\n",
    "\n",
    "# 100 bins for the bins head of the NN (i.e. percentiles):\n",
    "X_bins = np.zeros((X.shape[0],X.shape[1])) # he used all available data for the first tuple entry, but I'll start like this\n",
    "X_test_bins = np.zeros((X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ea6b5c-fa9a-4849-97b2-9a08f1d296b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]): # assumes X is a pd.DataFrame\n",
    "    X_bins[:,i] = pd.qcut(X.iloc[:,i],X.shape[1],labels=False)#,duplicates = 'drop')\n",
    "    \n",
    "for i in range(X_test.shape[1]): # assumes X_test is a pd.DataFrame\n",
    "    X_test_bins[:,i] = pd.qcut(X_test.iloc[:,i],X_test.shape[1], labels=False)#,duplicates = 'drop')\n",
    "# blabeled = X_bins[:X.shape[0],:]\n",
    "# bunlabeled = X_ins[X.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b110fe-940c-4398-be5b-9189120a1321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_test_bins).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb52aef-d92b-4e22-83fd-b2dc047a5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_bins = X_bins.astype(np.int8)\n",
    "# X_test_bins = X_test_bins.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1099026-a478-4957-ba87-21e2190d1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bins = pd.DataFrame(X_bins, index=X.index, columns=[f'rkd_f{col}' for col in range(100)])\n",
    "X_test_bins = pd.DataFrame(X_test_bins, index=X_test.index, columns=[f'rkd_f{col}' for col in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffdd70-5f2a-4adf-9229-b6e79a06f144",
   "metadata": {},
   "source": [
    "## Normalizing (Preprocessing Deep Cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0635e740-9d6f-4831-8675-cd8474b29f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GaussRankScaler(n_jobs=-1, epsilon=0.005)\n",
    "X_gauss = scaler.fit_transform(X)\n",
    "X_test_gauss = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b1295b-2978-47c8-a7aa-0fa6b1deece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(X_test_gauss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d834554d-14a3-4fec-b8d8-847564eb42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gauss = pd.DataFrame(X_gauss, columns=X.columns, index=X.index)\n",
    "X_test_gauss = pd.DataFrame(X_test_gauss, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36717c69-40c0-4514-9a09-57255766c32a",
   "metadata": {},
   "source": [
    "## Preparing Data for WideDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c53650-a1e6-4de2-bea4-d61c9324c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = X_gauss.join(X_bins)\n",
    "X_test_pre = X_test_gauss.join(X_test_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641faa72-4dbd-4556-b9d0-0f09c0bf358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = X_pre.iloc[:,:100].columns\n",
    "wide_cols = X_pre.iloc[:, 100:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d84d03-bbc6-4885-8e01-873d7db12511",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(X_pre)\n",
    "X_test_wide = wide_preprocessor.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "423a1a9c-71ce-46fa-8eab-785eb1f422aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:179: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    }
   ],
   "source": [
    "tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols, scale=False, for_transformer=False,embed_cols=wide_cols, already_standard=True)\n",
    "X_tab = tab_preprocessor.fit_transform(X_pre)\n",
    "X_test_tab = tab_preprocessor.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "592823da-f2b7-45d1-8d79-0dc3c246bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b8904e-d0a8-42c0-b295-c0805f90dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeptabular = TabMlp(continuous_cols=X_gauss.columns, column_idx=tab_preprocessor.column_idx)\n",
    "deeptabular = TabMlp(continuous_cols=cont_cols, column_idx=tab_preprocessor.column_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06e533e1-6465-4f65-83fc-8edae1bfe8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6ed610e-6758-45f3-aa1f-30481e73721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_deep_train, X_deep_valid\n",
    "X_wide_train, X_wide_valid, y_train, y_valid = train_test_split(X_wide, y, test_size=0.2, random_state=42)\n",
    "X_tab_train, X_tab_valid, _, _ = train_test_split(X_tab, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03f57f09-b0a8-45d4-b784-6bc9fb18fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62eab0-957c-4513-bc9e-4c56cb86fd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d12b8-f459-4922-94d6-e597400f3ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 469/469 [00:05<00:00, 81.93it/s, loss=1.13, metrics={'acc': 0.7708}] \n",
      "epoch 2: 100%|██████████| 469/469 [00:05<00:00, 89.98it/s, loss=0.845, metrics={'acc': 0.8317}] \n",
      "epoch 3: 100%|██████████| 469/469 [00:05<00:00, 88.96it/s, loss=0.788, metrics={'acc': 0.8371}]\n",
      "epoch 4: 100%|██████████| 469/469 [00:05<00:00, 88.59it/s, loss=0.732, metrics={'acc': 0.841}]  \n",
      "epoch 5: 100%|██████████| 469/469 [00:05<00:00, 88.14it/s, loss=0.685, metrics={'acc': 0.8446}]\n",
      "epoch 6: 100%|██████████| 469/469 [00:05<00:00, 88.78it/s, loss=0.642, metrics={'acc': 0.8478}] \n",
      "epoch 7: 100%|██████████| 469/469 [00:05<00:00, 88.03it/s, loss=0.597, metrics={'acc': 0.8519}]\n",
      "epoch 8: 100%|██████████| 469/469 [00:05<00:00, 88.77it/s, loss=0.562, metrics={'acc': 0.854}]  \n",
      "epoch 9: 100%|██████████| 469/469 [00:05<00:00, 88.08it/s, loss=0.523, metrics={'acc': 0.8577}]\n",
      "epoch 10: 100%|██████████| 469/469 [00:05<00:00, 88.69it/s, loss=0.49, metrics={'acc': 0.8606}]  \n",
      "epoch 11: 100%|██████████| 469/469 [00:05<00:00, 79.14it/s, loss=0.455, metrics={'acc': 0.8646}]\n",
      "epoch 12: 100%|██████████| 469/469 [00:05<00:00, 84.27it/s, loss=0.424, metrics={'acc': 0.8679}]\n",
      "epoch 13: 100%|██████████| 469/469 [00:05<00:00, 81.18it/s, loss=0.395, metrics={'acc': 0.8712}]\n",
      "epoch 14: 100%|██████████| 469/469 [00:05<00:00, 81.22it/s, loss=0.37, metrics={'acc': 0.8745}] \n",
      "epoch 15: 100%|██████████| 469/469 [00:05<00:00, 80.51it/s, loss=0.342, metrics={'acc': 0.8794}]\n",
      "epoch 16: 100%|██████████| 469/469 [00:06<00:00, 77.04it/s, loss=0.318, metrics={'acc': 0.8833}]\n",
      "epoch 17: 100%|██████████| 469/469 [00:05<00:00, 79.61it/s, loss=0.297, metrics={'acc': 0.8871}]\n",
      "epoch 18: 100%|██████████| 469/469 [00:05<00:00, 81.85it/s, loss=0.278, metrics={'acc': 0.8913}]\n",
      "epoch 19: 100%|██████████| 469/469 [00:05<00:00, 79.45it/s, loss=0.261, metrics={'acc': 0.8951}]\n",
      "epoch 20: 100%|██████████| 469/469 [00:05<00:00, 85.01it/s, loss=0.245, metrics={'acc': 0.899}] \n",
      "epoch 21: 100%|██████████| 469/469 [00:05<00:00, 78.54it/s, loss=0.23, metrics={'acc': 0.9045}] \n",
      "epoch 22: 100%|██████████| 469/469 [00:05<00:00, 79.31it/s, loss=0.218, metrics={'acc': 0.908}] \n",
      "epoch 23: 100%|██████████| 469/469 [00:05<00:00, 78.45it/s, loss=0.207, metrics={'acc': 0.9113}]\n",
      "epoch 24: 100%|██████████| 469/469 [00:06<00:00, 77.68it/s, loss=0.197, metrics={'acc': 0.916}] \n",
      "epoch 25: 100%|██████████| 469/469 [00:05<00:00, 79.66it/s, loss=0.19, metrics={'acc': 0.9187}] \n",
      "epoch 26: 100%|██████████| 469/469 [00:05<00:00, 79.38it/s, loss=0.182, metrics={'acc': 0.9224}]\n",
      "epoch 27: 100%|██████████| 469/469 [00:05<00:00, 88.03it/s, loss=0.176, metrics={'acc': 0.9255}] \n",
      "epoch 28: 100%|██████████| 469/469 [00:05<00:00, 86.01it/s, loss=0.171, metrics={'acc': 0.9284}]\n",
      "epoch 29: 100%|██████████| 469/469 [00:05<00:00, 86.44it/s, loss=0.167, metrics={'acc': 0.9299}]\n",
      "epoch 30: 100%|██████████| 469/469 [00:05<00:00, 86.63it/s, loss=0.162, metrics={'acc': 0.9328}]\n",
      "epoch 31: 100%|██████████| 469/469 [00:05<00:00, 82.53it/s, loss=0.159, metrics={'acc': 0.9344}]\n",
      "epoch 32: 100%|██████████| 469/469 [00:05<00:00, 80.92it/s, loss=0.157, metrics={'acc': 0.9359}]\n",
      "epoch 33: 100%|██████████| 469/469 [00:05<00:00, 83.55it/s, loss=0.153, metrics={'acc': 0.9382}]\n",
      "epoch 34: 100%|██████████| 469/469 [00:05<00:00, 85.34it/s, loss=0.151, metrics={'acc': 0.9388}]\n",
      "epoch 35: 100%|██████████| 469/469 [00:05<00:00, 85.81it/s, loss=0.15, metrics={'acc': 0.9405}] \n",
      "epoch 36: 100%|██████████| 469/469 [00:05<00:00, 84.33it/s, loss=0.148, metrics={'acc': 0.9419}]\n",
      "epoch 37: 100%|██████████| 469/469 [00:05<00:00, 81.78it/s, loss=0.146, metrics={'acc': 0.9425}]\n",
      "epoch 38: 100%|██████████| 469/469 [00:05<00:00, 85.32it/s, loss=0.144, metrics={'acc': 0.9435}]\n",
      "epoch 39: 100%|██████████| 469/469 [00:05<00:00, 85.83it/s, loss=0.142, metrics={'acc': 0.9452}]\n",
      "epoch 40: 100%|██████████| 469/469 [00:05<00:00, 84.10it/s, loss=0.141, metrics={'acc': 0.945}] \n",
      "epoch 41: 100%|██████████| 469/469 [00:05<00:00, 81.27it/s, loss=0.14, metrics={'acc': 0.9462}] \n",
      "epoch 42: 100%|██████████| 469/469 [00:05<00:00, 83.06it/s, loss=0.139, metrics={'acc': 0.947}] \n",
      "epoch 43: 100%|██████████| 469/469 [00:05<00:00, 82.74it/s, loss=0.138, metrics={'acc': 0.9472}]\n",
      "epoch 44: 100%|██████████| 469/469 [00:05<00:00, 84.73it/s, loss=0.136, metrics={'acc': 0.9484}]\n",
      "epoch 45: 100%|██████████| 469/469 [00:05<00:00, 82.43it/s, loss=0.135, metrics={'acc': 0.9494}]\n",
      "epoch 46: 100%|██████████| 469/469 [00:05<00:00, 86.10it/s, loss=0.134, metrics={'acc': 0.9497}]\n",
      "epoch 47:  30%|███       | 141/469 [00:01<00:03, 90.48it/s, loss=0.132, metrics={'acc': 0.9521}]"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "\n",
    "wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_wide_train.shape[0], epochs=n_epochs)\n",
    "deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_tab_train.shape[0], epochs=n_epochs)\n",
    "\n",
    "optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    LRHistory(n_epochs=n_epochs), \n",
    "]\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model, \n",
    "                  objective='binary', \n",
    "                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                  seed=42, \n",
    "                  optimizers=optimizers,\n",
    "                  callbacks=callbacks\n",
    "                 )\n",
    "\n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "trainer.fit( # this is where problem is beginning\n",
    "    X_wide=X_wide_train,\n",
    "    X_tab=X_tab_train,\n",
    "    target=y_train,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    ")\n",
    "\n",
    "y_valid_preds = trainer.predict_proba(X_wide=X_wide_valid, X_tab=X_tab_valid, batch_size=1024)[:,1]\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f08ac1-3aae-47c4-924b-e743ae6be3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024,)[:,1]\n",
    "np.isnan(dirty_preds).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f42a01-bcd4-4697-9bf6-1ca0cba17010",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(dirty_preds, predpath/'cleanlab_widedeep_20211123-TabMLP-dirtydata-holdout-baseline_preds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a8323-f198-4135-80bd-16c9232914fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1562f5-75ad-4f3a-a865-eac345b18b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31e289-f25a-42ce-84c5-bc9ca127d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = dirty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179f9af-05e7-4773-bb41-d0e2172bc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b85bf9b3-b202-4df6-8c69-3ff3abb16430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}-TabMLP-corrected_data-holdout-baseline_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc1d702b-f01a-4900-88b5-65df54a89eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3hezw9hp\" target=\"_blank\">cleanlab_widedeep_20211123c_141600</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3hezw9hp?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5ad414a850>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"202111_Kaggle_tabular_playground\",\n",
    "    save_code=True,\n",
    "    tags=wandb_config['tags'],\n",
    "    name=wandb_config['name'],\n",
    "    notes=wandb_config['notes'],\n",
    "    config=exmodel_config\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79c60c7c-3d20-4a3d-a5b7-46995cb0935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b29b7ec9-e7ae-4d78-9b48-f172a9ff5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3e21faa-a6cc-4975-9a93-90ac2fd9c98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'======================================================================\\nLayer (type:depth-idx)                        Param #\\n======================================================================\\nWideDeep                                      --\\n├─Wide: 1-1                                   --\\n│    └─Embedding: 2-1                         10,001\\n├─Sequential: 1-2                             --\\n│    └─TabMlp: 2-2                            --\\n│    │    └─CatEmbeddingsAndCont: 3-1         200\\n│    │    └─MLP: 3-2                          40,300\\n│    └─Linear: 2-3                            101\\n======================================================================\\nTotal params: 50,602\\nTrainable params: 50,602\\nNon-trainable params: 0\\n======================================================================'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb355f-5921-4d54-b33a-c9d64005b047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c85df80a-f46e-46b9-8411-5e303c1abd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "wandb.log({'overall_valid_auc': roc_auc_score(y_true=y_valid, y_score=y_valid_preds),\n",
    "           'model_params': model.parameters,\n",
    "           'model_summary': str(torchinfo.summary(model)),\n",
    "           'model_seed': 42,\n",
    "           'leadboard_auc': 0.72913,\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6089ae0-18ee-4c87-915a-8a8da8b26f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 418212... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.35MB of 0.35MB uploaded (0.10MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>leadboard_auc</td><td>▁</td></tr><tr><td>model_seed</td><td>▁</td></tr><tr><td>overall_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>leadboard_auc</td><td>0.72913</td></tr><tr><td>model_params</td><td>torch.nn.modules.mod...</td></tr><tr><td>model_seed</td><td>42</td></tr><tr><td>model_summary</td><td>====================...</td></tr><tr><td>overall_valid_auc</td><td>0.74197</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cleanlab_widedeep_20211123c_141600</strong>: <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3hezw9hp\" target=\"_blank\">https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/3hezw9hp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211123_144451-3hezw9hp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32619f35-01b4-4fd2-b974-0e1cb24bdbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce235fa1-af61-4995-80d3-451979bb9939",
   "metadata": {},
   "source": [
    "# CleanLab version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86d4e38e-61a9-4e8f-b0e4-1c8342f2bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_gauss, X_test_gauss, X_pre, X_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e14abd28-96b3-49b8-a449-b32be06a7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "clean_trainer = Trainer(model=model, \n",
    "                  objective='binary', \n",
    "                  metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                  seed=42, \n",
    "                  optimizers=optimizers,\n",
    "                  callbacks=callbacks\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4d8b284-7d03-44f9-a769-e4edb208547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_params = {\n",
    "    # 'prune_method': trial.suggest_categorical('prune_method', ['prune_by_noise_rate', 'prune_by_class', 'both']),\n",
    "    # 'converge_latent_estimates': trial.suggest_categorical('converge_latent_estimates', [True, False]),\n",
    "    # 'pulearning': trial.suggest_categorical('pulearning', [0,1,None])\n",
    "    'prune_method': 'both',\n",
    "    'converge_latent_estimates': True,\n",
    "    'pulearning': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e883fcf7-1cd4-494a-8f32-e549465e2f4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpytorch_widedeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwide_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWideDeep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcustom_loss_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr_schedulers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LRScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LRScheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreducelronplateau_criterion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitializers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_widedeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_widedeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColorJitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFiveCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrayscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearTransformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomAffine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomApply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomChoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomGrayscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomOrder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomSizedCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomVerticalFlip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTenCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_widedeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_widedeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlambda_sparse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/pytorch_widedeep/training/trainer.py\n",
       "\u001b[0;31mType:\u001b[0m      BoundFunctionWrapper\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Trainer.__init__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82066ef-451f-461f-8001-b9f0e6a15cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class MyTabMLP(BaseEstimator): # Inherits sklearn base classifier\n",
    "    def __init__(self, ):\n",
    "        Trainer.__init__()\n",
    "    def fit(self, X, y, sample_weight = None):\n",
    "        X['wide']\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    def predict_proba(self, X):\n",
    "        pass\n",
    "    def score(self, X, y, sample_weight = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd616b85-03a4-4135-93e1-e84855310c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = LearningWithNoisyLabels(clf=model, cv_n_folds=1, seed=42, **rp_params)\n",
    "rp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15108996-aa48-4052-ba07-1301126d01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "clean_trainer.fit( # this is where problem is beginning\n",
    "    X_wide=X_wide_train,\n",
    "    X_tab=X_tab_train,\n",
    "    target=y_train,\n",
    "    n_epochs=50,\n",
    "    batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    ")\n",
    "\n",
    "y_valid_preds = trainer.predict_proba(X_wide=X_wide_valid, X_tab=X_tab_valid, batch_size=1024)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "963f7ece-9b7d-448e-987e-6ee9ee1b18eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccd5ce47-7627-4587-a0b5-52a0fee34701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd0d2396-1a31-4737-8fd0-0381729f436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_preds_float64 = dirty_preds.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a757680-3474-4fed-bbea-d1ea0f076e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = dirty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98abb20b-309e-4085-a0c6-c8b2f9bd7394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.781741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.547938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.714756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.340266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.561223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  600000  0.781741\n",
       "1  600001  0.547938\n",
       "2  600002  0.714756\n",
       "3  600003  0.340266\n",
       "4  600004  0.561223"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dabbf0b-f062-4112-a8ce-2e8e13d86cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}-TabMLP-dirtydata-holdout-baseline_preds_floatified.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ef2e4-ef67-49dc-99ef-f3d50b13371f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa743d4f-d9d6-453e-bb42-2b9659caa09d",
   "metadata": {},
   "source": [
    "## Clean Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9bae97a-57ec-4ed7-84ab-31aad0b52bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/16vn06qn\" target=\"_blank\">cleanlab_20211122_150040</a></strong> to <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/16vn06qn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f73450cf130>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmodel_config['denoising'] = 'cleanlab'\n",
    "\n",
    "wandb_config = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202111_Kaggle_tabular_playground',\n",
    "    'tags': ['experiment'],\n",
    "    'notes': \"Going to try CleanLab with the 'best' params from the previous sweep, but wanting to see what the actual LB score is, and how it compares to the noisy one. Using a default LGBMClassfier with holdout on robust-scaled original dataset.\",\n",
    "    'config': exmodel_config,\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"202111_Kaggle_tabular_playground\",\n",
    "    save_code=True,\n",
    "    tags=wandb_config['tags'],\n",
    "    name=wandb_config['name'],\n",
    "    notes=wandb_config['notes'],\n",
    "    config=exmodel_config\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82ea6e18-16a1-4a98-9d79-b7c0931ea263",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_params = {\n",
    "    # 'prune_method': trial.suggest_categorical('prune_method', ['prune_by_noise_rate', 'prune_by_class', 'both']),\n",
    "    # 'converge_latent_estimates': trial.suggest_categorical('converge_latent_estimates', [True, False]),\n",
    "    # 'pulearning': trial.suggest_categorical('pulearning', [0,1,None])\n",
    "    'prune_method': 'both',\n",
    "    'converge_latent_estimates': True,\n",
    "    'pulearning': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d57d0368-3acb-4b6c-a0a5-44e1661265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        #                     device_type='cpu',\n",
    "        #                     n_jobs=-1,\n",
    "        #                 eval_metric='auc',\n",
    "        device_type='gpu',\n",
    "        max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "        gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d8e3de-4992-406d-9470-648b48a2725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2b8ae6b-529b-4fdf-b9e8-881edf2a7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae65f62b-94b8-46ca-b30f-acdbca4d222e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27296268,  0.01579322, -0.19031588, ...,  0.50363337,\n",
       "         0.17720313, -0.58369832],\n",
       "       [-0.18106382,  0.2410393 ,  5.30773161, ...,  0.24955035,\n",
       "        -0.48450355, -0.62285755],\n",
       "       [ 6.07300903, -0.85078822,  0.17280319, ..., -0.62764574,\n",
       "        -0.67894852,  0.73726127],\n",
       "       ...,\n",
       "       [ 4.18856991, -0.68824246,  0.21225385, ...,  0.88726112,\n",
       "         6.19955807, -0.09918299],\n",
       "       [-0.300117  ,  0.13080398, -0.54802214, ..., -0.3979886 ,\n",
       "        -0.01474   ,  0.22398866],\n",
       "       [-0.29279129,  0.62179137,  0.07317624, ...,  0.14508993,\n",
       "        12.038684  ,  0.6437292 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f76d719d-2198-46d6-a2f8-e30b99892221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27745959, -0.79095855,  3.57879036, ...,  0.40431588,\n",
       "         0.30027418,  0.45467042],\n",
       "       [-0.35032922, -0.36662758, -0.83368479, ...,  0.48734142,\n",
       "        -0.59656634,  9.97028335],\n",
       "       [ 2.07990909,  0.20997962, -0.0127639 , ..., -0.80240405,\n",
       "        -0.22697866,  0.23615553],\n",
       "       ...,\n",
       "       [ 0.80633635,  0.39936366,  0.49845399, ...,  0.68680344,\n",
       "        -1.04204429,  0.24502101],\n",
       "       [-0.06863608, -0.27843164, -0.36283929, ...,  0.18702425,\n",
       "         0.57010813, -0.05371796],\n",
       "       [-0.3620719 , -0.30144763, -0.06982129, ..., -0.73907299,\n",
       "        -1.0792864 ,  0.24365673]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c26a7ae5-ca5b-41ef-af17-943b04998612",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f56bc7d2-223f-4e36-902a-d5e877f68af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(device_type='gpu', gpu_use_dp=False, max_bin=63,\n",
       "               objective='binary', random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp = LearningWithNoisyLabels(clf=lgb_model, **rp_params)\n",
    "rp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98e318a7-ba89-4150-aa16-4e25f256cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7242336321944994"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rp.predict_proba(X_valid)[:,1]\n",
    "valid_auc = roc_auc_score(y_true=y_valid, y_score=preds)\n",
    "valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b6da3dd-9e49-4a38-90fb-5fae870a0ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__boosting_type': 'gbdt',\n",
       " 'clf__class_weight': None,\n",
       " 'clf__colsample_bytree': 1.0,\n",
       " 'clf__importance_type': 'split',\n",
       " 'clf__learning_rate': 0.1,\n",
       " 'clf__max_depth': -1,\n",
       " 'clf__min_child_samples': 20,\n",
       " 'clf__min_child_weight': 0.001,\n",
       " 'clf__min_split_gain': 0.0,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__n_jobs': -1,\n",
       " 'clf__num_leaves': 31,\n",
       " 'clf__objective': 'binary',\n",
       " 'clf__random_state': 42,\n",
       " 'clf__reg_alpha': 0.0,\n",
       " 'clf__reg_lambda': 0.0,\n",
       " 'clf__silent': 'warn',\n",
       " 'clf__subsample': 1.0,\n",
       " 'clf__subsample_for_bin': 200000,\n",
       " 'clf__subsample_freq': 0,\n",
       " 'clf__device_type': 'gpu',\n",
       " 'clf__max_bin': 63,\n",
       " 'clf__gpu_use_dp': False,\n",
       " 'clf': LGBMClassifier(device_type='gpu', gpu_use_dp=False, max_bin=63,\n",
       "                objective='binary', random_state=42),\n",
       " 'converge_latent_estimates': True,\n",
       " 'cv_n_folds': 5,\n",
       " 'n_jobs': 16,\n",
       " 'prune_method': 'both',\n",
       " 'pulearning': 1,\n",
       " 'seed': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8905b40c-f3c9-49c4-891a-51c8c7b1b1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 332071... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.09MB of 0.09MB uploaded (0.04MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_seed</td><td>▁</td></tr><tr><td>overall_valid_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cleanlab_params</td><td>{'clf__boosting_type...</td></tr><tr><td>model_params</td><td>{'boosting_type': 'g...</td></tr><tr><td>model_seed</td><td>42</td></tr><tr><td>overall_valid_auc</td><td>0.72423</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cleanlab_20211122_150040</strong>: <a href=\"https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/16vn06qn\" target=\"_blank\">https://wandb.ai/hushifang/202111_Kaggle_tabular_playground/runs/16vn06qn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211122_150040-16vn06qn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'overall_valid_auc': valid_auc,\n",
    "           'model_params': str(lgb_model.get_params()),\n",
    "           'model_seed': 42,\n",
    "           'cleanlab_params': str(rp.get_params())\n",
    "          })\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bcbf1ec-1d14-4511-9d4e-244db30272b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/nov2021/preds/cleanlab_lgbm_20211122.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(preds, predpath/'cleanlab_lgbm_20211122.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a369599-a3df-4206-89b1-b05553ad7f02",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77cb7e71-aae5-466d-8272-c5f71fbc02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_feather(dataset_params['test_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42ff29c1-b032-43be-952e-a5504e53dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f0621aa-1840-4a69-a73c-923c38dbc52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f35f742-1029-4ba4-9367-7752a8a18c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.54904070e-01,  8.92660373e-01,  1.74689787e+00, ...,\n",
       "        -3.14632989e-01,  7.56057179e-01, -5.35039504e-01],\n",
       "       [-2.40419666e-01, -7.73033673e-01, -9.03498547e-01, ...,\n",
       "         4.04404276e-01, -1.09484041e-01,  7.09297297e-01],\n",
       "       [ 3.67480353e+00, -3.04606091e-02, -9.53230106e-01, ...,\n",
       "         2.60323086e-01,  5.22578209e-01,  7.16351788e-02],\n",
       "       ...,\n",
       "       [ 7.74437122e-01,  4.76283375e-03, -7.63896086e-01, ...,\n",
       "        -1.52318988e+00,  7.39754091e+00,  7.52089854e-01],\n",
       "       [ 4.71329335e+00,  3.45526482e-01, -4.12767694e-01, ...,\n",
       "        -9.01228907e-01, -3.59849849e-02,  2.78337176e-01],\n",
       "       [ 1.01900951e+00,  5.92913219e-02,  9.90131581e-01, ...,\n",
       "        -9.60166650e-01,  1.45144893e-01,  5.01730920e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1bb7c3d-8902-4348-aa47-a60d0e6e63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_preds = rp.predict_proba(X_test)[:,1]\n",
    "clean_preds = lgb_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edfbe152-d6ba-4af1-bf37-6aac29852460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(datapath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b99dd91d-cc7b-49d5-a262-6d3f80e82279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  target\n",
       "0  600000     0.5\n",
       "1  600001     0.5\n",
       "2  600002     0.5\n",
       "3  600003     0.5\n",
       "4  600004     0.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6de390d5-0fb7-42c3-8667-b73df65920e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8a7cfad-81ca-40ec-a0b1-2ec5ff4d1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ac838fd-e9a6-49fc-aa4d-7f2ae2d2c4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540000, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "344a6439-1eed-4ed5-99c9-8d55a4bcc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = dirty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "932dd2da-0087-4fbd-856d-87b7b821d65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.866322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.948761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.976896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.810975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.665766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  600000  0.866322\n",
       "1  600001  0.948761\n",
       "2  600002  0.976896\n",
       "3  600003  0.810975\n",
       "4  600004  0.665766"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f76a9-54bf-41de-a76c-8113e72ad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_path = datapath/'submissions'\n",
    "# submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8eae3ee-6dfd-43a3-9ed2-e5798193e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_basic_LGBM_preds.csv\", index=False)\n",
    "# sample_df.to_csv(subpath/f\"{wandb_config['name']}_3level-X_orig+KMeans8+synth-GBM-stack_ensemble_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f130574-29d6-402d-b461-6ee3975db800",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.loc[:, 'target'] = clean_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "333aebf9-4804-4378-8f1c-2af72b22e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.647848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.632269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.797033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>0.556056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.410237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  600000  0.647848\n",
       "1  600001  0.632269\n",
       "2  600002  0.797033\n",
       "3  600003  0.556056\n",
       "4  600004  0.410237"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e87363c-9d65-46ea-a938-2fcaeb7695dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(subpath/f\"{wandb_config['name']}_cleanlab_basic_LGBM_preds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286efee9-2fdb-413d-bb51-f1c5e62e78ad",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "Actually, Cleanlab works: LB score with cleaning is 0.72402 compared to 0.71712 with the dirty one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f155602d-6895-403b-8b3b-31b4f6f3987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(arch:str, X, y, X_test, params:dict={}, start_fold=0, \n",
    "                         exmodel_config=exmodel_config, wandb_config=wandb_config, \n",
    "                         random_state=42, shuffle_kfolds=True, wandb_tracked=True, encode_cats=False):\n",
    "    \"\"\"\n",
    "    Function to handle model training process in the context of cross-validation -- via hold-out or via k-fold.\n",
    "    If exmodel_config['cross_val_strategy'] == None, then any kfolds= input is ignored; otherwise, the number specified is used.\n",
    "    \n",
    "    :param kfolds: int specifying number of k-folds to use in cross-validation\n",
    "    :param exmodel_config: dict containing general config including for cross-validation -- `kfold=1` implies hold-out\n",
    "    \"\"\"\n",
    "#     if exmodel_config['kfolds'] == 1:\n",
    "#         print(\"Proceeding with holdout\")\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "#                                                           test_size=0.2, \n",
    "#                                                           random_state=SEED)                 \n",
    "    \n",
    "    # prepare for k-fold cross-validation; random-state here is notebook-wide, not per-model\n",
    "    # shuffle on the initial sets, but not subsequently -- performing the same operation twice means a very different dataset\n",
    "    if shuffle_kfolds:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        kfold = exmodel_config['cross_val_strategy'](n_splits=exmodel_config['kfolds'], shuffle=False)\n",
    "    \n",
    "    if wandb_tracked:\n",
    "        exmodel_config['arch'] = arch\n",
    "        exmodel_config[f'{arch}_params'] = str(params)\n",
    "        wandb.init(\n",
    "            project=\"202111_Kaggle_tabular_playground\",\n",
    "            save_code=True,\n",
    "            tags=wandb_config['tags'],\n",
    "            name=wandb_config['name'],\n",
    "            notes=wandb_config['notes'],\n",
    "            config=exmodel_config\n",
    "    )   \n",
    "    \n",
    "    # setup for serialization\n",
    "    # runpath = Path(modelpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds/\")\n",
    "    # (runpath).mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # initialize lists for out-of-fold preds and ground truth\n",
    "    oof_preds, oof_y = [], []\n",
    "    \n",
    "    # initialize a numpy.ndarray containing the fold-model's preds for test set\n",
    "    test_preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    # if using deep learning with pytorch-widedeep, do data preprocessing now, before splits\n",
    "    if 'widedeep' in arch:\n",
    "        # NOTE THAT ENCODING NOT DEPLOYED FOR THIS YET\n",
    "        # preprocessing first\n",
    "        wide_cols = [f for f in X.columns if X[f].nunique() == 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() == 2] # binary indicator vars are wide\n",
    "        cont_cols = [f for f in X.columns if X[f].nunique() > 2] #list(X_train.columns) if X_train.iloc[:,f].nunique() > 2] # others are cont\n",
    "\n",
    "        # wide part\n",
    "        # wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "        # X_wide = wide_preprocessor.fit_transform(X)\n",
    "#         print(f\"X_wide.shape = {X_wide.shape}\")\n",
    "#         X_wide = np.array(X_train[wide_cols])\n",
    "        \n",
    "\n",
    "        # deep part\n",
    "        tab_preprocessor = TabPreprocessor(continuous_cols=cont_cols)#, embed_cols=embed_cols, )\n",
    "        X_tab = tab_preprocessor.fit_transform(X)   \n",
    "#         print(f\"X_tab.shape = {X_tab.shape}\")\n",
    "        \n",
    "        # transforming the test set\n",
    "        X_test_wide = wide_preprocessor.transform(X_test)\n",
    "        X_test_tab = tab_preprocessor.transform(X_test)\n",
    "        \n",
    "        # at this point, X_wide, X_tab, X_test_wide, and X_test_tab will all be np.ndarrays\n",
    "    \n",
    "#     else: # if using a GBM, simply convert the pd.DataFrames to np.ndarrays\n",
    "#         X = np.array(X) # CAN YOU USE CATEGORY_ENCODERS ON NP.NDARRAYS?\n",
    "#         X_test = np.array(X_test)\n",
    "    \n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(X,y)):\n",
    "#         print(f\"type(train_ids) = {type(train_ids)} and train_ids.shape = {train_ids.shape}\")\n",
    "#         print(f\"type(valid_ids) = {type(valid_ids)} and train_ids.shape = {valid_ids.shape}\")\n",
    "        if fold < start_fold: # skip folds that are already trained\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            y_train, y_valid = y[train_ids], y[valid_ids] # y will be an np.ndarray already; handling will be same regardless of model\n",
    "            if 'widedeep' in arch: # handle wide and deep tabs in parallel\n",
    "                X_train_wide, X_valid_wide = X_wide[train_ids, :], X_wide[valid_ids, :]\n",
    "                X_train_tab, X_valid_tab = X_tab[train_ids, :], X_tab[valid_ids, :]\n",
    "#                 print(f\"X_train_wide.shape = {X_train_wide.shape}\")\n",
    "#                 print(f\"X_train_tab.shape = {X_train_tab.shape}\")\n",
    "#                 print(f\"X_test_wide.shape = {X_test_wide.shape}\")\n",
    "#                 print(f\"X_test_tab.shape = {X_test_tab.shape}\")\n",
    "            else: # handle datasets for GBMs\n",
    "                if isinstance(X, np.ndarray):\n",
    "                    X_train, X_valid = X[train_ids], X[valid_ids]\n",
    "                else:\n",
    "                    X_train, X_valid = X.iloc[train_ids,:], X.iloc[valid_ids,:] # bc need pandas.DataFrames for ce\n",
    "                # if encode_cats:\n",
    "                #     encoder = ce.WOEEncoder(cols=categoricals)\n",
    "                #     encoder.fit(X_train,y_train)\n",
    "                #     X_train = encoder.transform(X_train)\n",
    "                #     X_valid = encoder.transform(X_valid)\n",
    "                # # exmodel_config['feature_count'] = len(X.columns)\n",
    "                #     wandb.log({\n",
    "                #         'feature_count': X_train.shape[1],\n",
    "                #         'instance_count': X_train.shape[0],\n",
    "                #         'encoder': str(encoder)\n",
    "                #     })\n",
    "#                 exmodel_config['instance_count'] = X_train.shape[0]\n",
    "#                 exmodel_config['encoder'] = str(encoder)\n",
    "#                     X_test = encoder.transform(X_test)\n",
    "#                 y_train, y_valid = y[train_ids], y[valid_ids]\n",
    "            \n",
    "        # scaling\n",
    "        scaler = RobustScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "    \n",
    "        # define models\n",
    "        if arch == 'xgboost':\n",
    "            model = XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                tree_method='gpu_hist',\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1, \n",
    "                verbosity=1, \n",
    "                objective='binary:logistic',\n",
    "                **params)\n",
    "            if wandb_tracked:\n",
    "                model.fit(X_train, y_train, callbacks=[wandb.xgboost.wandb_callback()])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "        elif arch == 'lightgbm':\n",
    "            try:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "#                     device_type='cpu',\n",
    "#                     n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "                    device_type='gpu',\n",
    "                    max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "                    gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            except LightGBMError:\n",
    "                model = LGBMClassifier(\n",
    "                    objective='binary',\n",
    "                    random_state=random_state,\n",
    "                    device_type='cpu',\n",
    "                    n_jobs=-1,\n",
    "    #                 eval_metric='auc',\n",
    "    #                 device_type='gpu',\n",
    "    #                 max_bin=63, # 15 might be even better for GPU perf, but depends on dataset -- see https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html\n",
    "    #                 gpu_use_dp=False, # forces use of single precision rather than double for better perf, esp on consumer Nvidia chips\n",
    "                    **params)\n",
    "                \n",
    "                if wandb_tracked:\n",
    "                    model.fit(X_train, y_train, callbacks=[wandb.lightgbm.wandb_callback()],)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "\n",
    "            \n",
    "        elif arch == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                silent=True,\n",
    "                random_state=random_state,\n",
    "                **params) \n",
    "        \n",
    "            model.fit(X_train, y_train)\n",
    "            y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            # add the fold's predictions to the model's test-set predictions (will divide later)\n",
    "            test_preds += model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "        elif 'widedeep' in arch: # only coding for TabMlp right now\n",
    "#             X_train = pd.DataFrame(X_train, columns=[f\"f{x}\" for x in range(X_train.shape[1])])\n",
    "#             X_valid = pd.DataFrame(X_valid, columns=[f\"f{x}\" for x in range(X_valid.shape[1])])\n",
    "#             X_test = pd.DataFrame(X_test, columns=[f\"f{x}\" for x in range(X_test.shape[1])])\n",
    "            \n",
    "            wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "            deeptabular = TabMlp(\n",
    "                mlp_hidden_dims=[64,32],\n",
    "                column_idx=tab_preprocessor.column_idx,\n",
    "            #     embed_input=tab_preprocessor.embeddings_input,\n",
    "                continuous_cols=cont_cols,\n",
    "            )\n",
    "            \n",
    "            # model instantiation and training\n",
    "            model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "            \n",
    "            \n",
    "            n_epochs = 300\n",
    "\n",
    "            # pytorch hyperparams\n",
    "            wide_opt = AdamW(model.wide.parameters(), lr=0.1)\n",
    "            deep_opt = AdamW(model.deeptabular.parameters(), lr=0.1)\n",
    "            \n",
    "            wide_sch = OneCycleLR(optimizer=wide_opt, max_lr=0.01, steps_per_epoch=X_train_wide.shape[0], epochs=n_epochs)\n",
    "            deep_sch = OneCycleLR(optimizer=deep_opt, max_lr=0.01, steps_per_epoch=X_train_tab.shape[0], epochs=n_epochs)\n",
    "            \n",
    "            optimizers = {'wide': wide_opt, 'deeptabular': deep_opt }\n",
    "            lr_schedulers = {'wide': wide_sch, 'deeptabular': deep_sch }\n",
    "            \n",
    "            \n",
    "            callbacks = [\n",
    "                LRHistory(n_epochs=n_epochs), \n",
    "            ]\n",
    "            \n",
    "            # trainer\n",
    "            trainer = Trainer(model=model, \n",
    "                              objective='binary', \n",
    "                              metrics=[Accuracy], # with AUROC got TypeError: '>' not supported between instances of 'NoneType' and 'int' \n",
    "                              seed=random_state, \n",
    "                              optimizers=optimizers,\n",
    "                              callbacks=callbacks\n",
    "                             )\n",
    "            \n",
    "#             print(f\"type(X_train_wide) is {type(X_train_wide)} and type(X_train_tab) is {type(X_train_tab)}\")\n",
    "            trainer.fit( # this is where problem is beginning\n",
    "                X_wide=X_train_wide,\n",
    "                X_tab=X_train_tab,\n",
    "                target=y_train,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=1024, # default value is 32\n",
    "#                 val_split=0.2, # no need for this\n",
    "            )\n",
    "            \n",
    "            y_valid_preds = trainer.predict_proba(X_wide=X_valid_wide, X_tab=X_valid_tab, batch_size=1024)[:,1]\n",
    "            \n",
    "            # add the fold-model's OOF preds and ground truths to the out-of-loop lists\n",
    "            oof_preds.extend(y_valid_preds)\n",
    "            oof_y.extend(y_valid)\n",
    "            \n",
    "            \n",
    "            # test set inference\n",
    "            fold_test_preds = trainer.predict_proba(X_wide=X_test_wide, X_tab=X_test_tab, batch_size=1024)[:,1]\n",
    "            test_preds += fold_test_preds\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "#         valid_loss = log_loss(y_valid, y_pred)\n",
    "        # give the valid AUC score, for edification\n",
    "        fold_valid_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "        if wandb_tracked:\n",
    "            wandb.log({f'fold{fold}_valid_roc_auc': fold_valid_auc})\n",
    "        print(f\"Valid AUC for fold {fold} is {fold_valid_auc}\")   \n",
    "        # dump(model, Path(runpath/f\"{arch}_fold{fold}_rs{random_state}_model.joblib\"))\n",
    "\n",
    "    model_valid_auc = roc_auc_score(oof_y, oof_preds)\n",
    "    print(f\"Valid AUC score for {arch} model is {model_valid_auc}\")\n",
    "    if wandb_tracked:\n",
    "        wandb.log({'overall_valid_auc': model_valid_auc,\n",
    "                   'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()),\n",
    "                   'model_seed': random_state,\n",
    "                  })\n",
    "        wandb.finish()\n",
    "    \n",
    "    # finalize test preds\n",
    "    test_preds /= exmodel_config['kfolds']\n",
    "    \n",
    "    # save OOF preds and test-set preds\n",
    "#     if 'widedeep' in arch:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_{n_epochs}epochs-per-fold_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "#     else:\n",
    "#         dump(oof_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_oof_preds.joblib\"))\n",
    "#         dump(test_preds, Path(predpath/f\"{wandb_config['name']}_{arch}_{exmodel_config['kfolds']}folds_rs{random_state}_test_preds.joblib\"))\n",
    "    \n",
    "    if not (datapath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\").is_file():\n",
    "        dump(oof_y, predpath/f\"{exmodel_config['kfolds']}folds_rs{SEED}_oof_y.joblib\")\n",
    "    \n",
    "#     if wandb_tracked:\n",
    "# #         if 'widedeep' in arch:\n",
    "#         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "#                    'model_params': str(model.parameters()) if 'widedeep' in arch else str(model.get_params()), \n",
    "#         #                    'model_params': str(model.get_params()),\n",
    "#         })\n",
    "# #         wandb.log({'model_valid_auc': model_valid_auc,\n",
    "# #                    'oof_preds': oof_preds,\n",
    "# #                    'test_preds': test_preds,\n",
    "# # #                    'model_params': str(model.get_params()),\n",
    "# #                   })\n",
    "#         wandb.finish()\n",
    "    return oof_preds, test_preds\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
