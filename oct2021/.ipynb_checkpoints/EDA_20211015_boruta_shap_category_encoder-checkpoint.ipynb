{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53",
   "metadata": {
    "id": "1d4e7f70-25a3-4d58-b98a-3a695e55ee53"
   },
   "source": [
    "# Dataset Sweep usign XGBoost on GPU\n",
    "Trying different variations on the dataset using PCA, other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_qtimPUchWD",
   "metadata": {
    "id": "U_qtimPUchWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4",
   "metadata": {
    "id": "1e124c3d-0e1f-4053-8e72-52569a4fe3e4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb",
   "metadata": {
    "id": "dae2ff1e-bd1f-4cc9-8357-5a88d1746ffb"
   },
   "outputs": [],
   "source": [
    "# two manual flags (ex-config)\n",
    "colab = False\n",
    "gpu_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16849bd2-428c-497b-ba3b-675002f8d041",
   "metadata": {
    "id": "16849bd2-428c-497b-ba3b-675002f8d041"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12d2654b-3bc6-49b5-ade8-cc82112b60e5",
    "outputId": "6bd53922-c4d7-43ce-c04f-ac1079087966"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = f\"sweep_xgboost_{datetime.now().strftime('%Y%m%d')}.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "416d6118-e543-4df4-9219-2d4a63743c3a",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "5483656e-2943-4d97-b5d4-65cfb9795430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle Google Colab-specific library installation/updating\n",
    "if colab:\n",
    "    # much of the below inspired by or cribbed from the May 2021 Kaggle Tabular Playground winner, at \n",
    "    # https://colab.research.google.com/gist/academicsuspect/0aac7bd6e506f5f70295bfc9a3dc2250/tabular-may-baseline.ipynb?authuser=1#scrollTo=LJoVKJb5wN0L\n",
    "    \n",
    "    # Kaggle API for downloading the datasets\n",
    "    !pip install --upgrade -q kaggle\n",
    "\n",
    "    # weights and biases\n",
    "    !pip install -qqqU wandb\n",
    "    \n",
    "    # Optuna for parameter search\n",
    "    !pip install -q optuna\n",
    "\n",
    "    # !pip install --upgrade xgboost\n",
    "\n",
    "    # upgrade sklearn\n",
    "    !pip install --upgrade scikit-learn\n",
    "\n",
    "    # !pip install category_encoders\n",
    "    # !pip install catboost\n",
    "#     !pip install --upgrade -q lightgbm\n",
    "\n",
    "    # lighgbm gpu compatible\n",
    "    # !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "    # ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "    \n",
    "    # # this part is from https://github.com/rapidsai/gputreeshap/issues/24\n",
    "    # !pip install cmake --upgrade\n",
    "    # # !pip install sklearn --upgrade\n",
    "    # !git clone --recursive https://github.com/dmlc/xgboost\n",
    "    # %cd /content/xgboost\n",
    "    # !mkdir build\n",
    "    # %cd build\n",
    "    # !cmake .. -DUSE_CUDA=ON\n",
    "    # !make -j4\n",
    "    # %cd /content/xgboost/python-package\n",
    "    # !python setup.py install --use-cuda --use-nccl\n",
    "    # !/opt/bin/nvidia-smi\n",
    "    # !pip install shap\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd",
   "metadata": {
    "id": "d40df194-4474-4bcf-ac5a-98efe24b91fd"
   },
   "source": [
    "Now, non-stdlib imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a01e85f7-d602-4dde-bef9-611683cd74c4",
   "metadata": {
    "id": "a01e85f7-d602-4dde-bef9-611683cd74c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# general ML tooling\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import wandb\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "# from wandb.xgboost import wandb_callback\n",
    "# from wandb.lightgbm import wandb_callback\n",
    "# from sklearn.impute import KNNImputer, StandardImputer\n",
    "# import timm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from joblib import dump, load\n",
    "# feature engineering tools\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# import featuretools as ft\n",
    "\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "# import catboost\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accfe297-1d47-41bd-9c84-a819d5e565f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9987ab54-45db-40b2-abad-bfc5d6523fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe",
   "metadata": {
    "id": "5f6166c2-ca44-4b7c-a4dc-3db47c2624fe"
   },
   "source": [
    "Now, datapath setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351",
   "metadata": {
    "id": "3c18a787-2193-43cb-87ee-51c6ae7b6351"
   },
   "outputs": [],
   "source": [
    "# # This is the code for reading the train.csv and converting it to a .feather file\n",
    "# df = pd.read_csv(datapath/'train.csv', index_col='id', low_memory=False)\n",
    "# df.index.name = None\n",
    "# df.to_feather(path='./dataset_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67530ca9-6317-48be-bf6c-8621158b0020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a41cd7e-accb-41c4-ad8b-0eaa3e2b0ad5",
    "outputId": "76d62b41-4171-40fa-936c-4481a9fdab36"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # handling datapath\n",
    "#     datapath = Path('/content/drive/MyDrive/kaggle/tabular_playgrounds/sep2021/')\n",
    "    \n",
    "else:\n",
    "    # if on local machine\n",
    "#     datapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/sep2021/')  \n",
    "    root = Path('/home/sf/code/kaggle/tabular_playgrounds/oct2021/')\n",
    "    datapath = root/'datasets'\n",
    "    edapath = root/'EDA'\n",
    "    modelpath = root/'models'\n",
    "    predpath = root/'preds'\n",
    "    subpath = root/'submissions'\n",
    "    studypath = root/'optuna_studies'\n",
    "    altdatapath = Path('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/')\n",
    "    \n",
    "    for pth in [root, datapath, edapath, modelpath, predpath, subpath, altdatapath]:\n",
    "        pth.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f",
   "metadata": {
    "id": "d1c652e6-5946-46aa-a13e-4c0ebe8a0e4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_trials = int(1000)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbec2e77-2081-4815-ac6d-39f2a2616386",
   "metadata": {
    "id": "fbec2e77-2081-4815-ac6d-39f2a2616386"
   },
   "outputs": [],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5",
   "metadata": {
    "id": "2f6e47b3-43bd-4d35-b463-9d76100c6ed5"
   },
   "source": [
    "## Ex-Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93f08480-1725-4520-8995-92b76b8f2cea",
   "metadata": {
    "id": "fb288275-a858-4806-9dc0-0b316c334536"
   },
   "outputs": [],
   "source": [
    "# meta-config for preprocessing and cross-validation, but NOT for model parameters\n",
    "# in the sweep version, this includes both ex-model parameters and defaults for model parameters\n",
    "exmodel_config = {\n",
    "    # model config\n",
    "    \"library\": 'xgboost',\n",
    "#     \"model\": XGBClassifier,\n",
    "#     \"n_estimators\": 100, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"test_size\": 0.2,\n",
    "#     \"reg_lambda\": None, \n",
    "#     \"scaler\": \"sklearn.preprocessing.StandardScaler()\", # TODO: experiment with others (but imputation may be slow)\n",
    "#     \"scale_b4_impute\": False,\n",
    "#     \"imputer\": \"sklearn.impute.SimpleImputer(strategy='median', add_indicator=True)\",\n",
    "#     \"knn_imputer_n_neighbors\": None, # None if a different imputer is used\n",
    "#     \"feature_selector\": SelectKBest,\n",
    "#     \"k_best\": 80,\n",
    "#     \"feature_selection_scoring\": f_regression,\n",
    "    'random_state': SEED,\n",
    "#     'optuna': True,\n",
    "#     'optuna_trials': 50,\n",
    "#     'subsample': 1,\n",
    "#     'cross_val_strategy': None, # None for holdout, or the relevant sklearn class\n",
    "#     'kfolds': 1, # if 1, that means just doing holdout\n",
    "#     'test_size': 0.2,\n",
    "    # these are XGBoost default (my choice) params \n",
    "#     \"tree_method\": \"auto\", # set to 'gpu_hist' to try GPU if available\n",
    "#     \"booster\": 'gbtree', # dart may be marginally better, but will opt for this quicker approach as a default\n",
    "#     \"n_estimators\": 200, \n",
    "#     \"max_depth\": 3,\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"n_jobs\": -1,\n",
    "#     \"verbosity\": 1,\n",
    "#     \"subsample\": 1,\n",
    "#     'features_created': False,\n",
    "#     'feature_creator': None,\n",
    "}\n",
    "\n",
    "wandb_kwargs = {\n",
    "    # wandb config\n",
    "    'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "    'project': '202110_Kaggle_tabular_playground',\n",
    "    'tags': ['EDA'],\n",
    "    'notes': \"Testing BorutaShap\",\n",
    "    'config': exmodel_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9012-34f1-435a-ba16-4416e0d4a286",
   "metadata": {
    "id": "a52d9012-34f1-435a-ba16-4416e0d4a286"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ca14-2718-49d9-89e2-91d55f72d706",
   "metadata": {
    "id": "c912a62f-970a-48b4-b428-d886f2612fc2"
   },
   "source": [
    "**TODO** Write some conditional logic here to automate it -- possibly as part of a sklearn.*pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bdd965b-a823-432d-a1ef-4c676bb2be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = datapath/'train.feather'\n",
    "# train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "# df = pd.read_feather(path=train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cff1e9b6-ad6c-4f52-943b-4e7c5eb34c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(datapath/'train.feather')\n",
    "# X_orig = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e1b4da3-35ca-413f-84e7-4d7dc65adeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 285)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa405c53-3afb-491b-bdd1-fa0669a49945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_orig.to_feather(path=altdatapath/'X_orig.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4648555d-63f0-419d-bae4-1fa574ab53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = datapath/'train.feather'\n",
    "train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "X = pd.read_feather(train_source)\n",
    "y = load(datapath/'y.joblib')\n",
    "# df = pd.read_feather(path=train_source)\n",
    "# df.index.name = 'id'\n",
    "# y = df.target\n",
    "# features = [x for x in df.columns if x != 'target']\n",
    "# X = df[features]\n",
    "# X = df.iloc[:, :-1]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "# test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "# X_test = pd.read_feather(path=test_source)\n",
    "# X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6524dc1b-79ef-4056-b100-8288282ae272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e4cbc6-36c5-4d1f-8b8c-107dd9e9841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 136)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea4edb0-22e4-42c9-93fe-027cb2613401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f174</th>\n",
       "      <th>f72</th>\n",
       "      <th>f265</th>\n",
       "      <th>f44</th>\n",
       "      <th>f53</th>\n",
       "      <th>f62</th>\n",
       "      <th>f16</th>\n",
       "      <th>f206</th>\n",
       "      <th>f74</th>\n",
       "      <th>f33</th>\n",
       "      <th>...</th>\n",
       "      <th>f201</th>\n",
       "      <th>f113</th>\n",
       "      <th>f134</th>\n",
       "      <th>f269</th>\n",
       "      <th>f245</th>\n",
       "      <th>f95</th>\n",
       "      <th>f227</th>\n",
       "      <th>f125</th>\n",
       "      <th>f99</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.192042</td>\n",
       "      <td>0.519336</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.257688</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216079</td>\n",
       "      <td>0.087502</td>\n",
       "      <td>0.217984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559151</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.407014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821982</td>\n",
       "      <td>0.224053</td>\n",
       "      <td>0.447242</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.415982</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240681</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>0.222525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145737</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.111834</td>\n",
       "      <td>0.090468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162094</td>\n",
       "      <td>0.239486</td>\n",
       "      <td>0.749593</td>\n",
       "      <td>0.257763</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.274105</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163251</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144596</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.110486</td>\n",
       "      <td>0.090032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834834</td>\n",
       "      <td>0.175250</td>\n",
       "      <td>0.605277</td>\n",
       "      <td>0.335907</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.319312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163644</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.248067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146811</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.361132</td>\n",
       "      <td>0.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844187</td>\n",
       "      <td>0.249345</td>\n",
       "      <td>0.415167</td>\n",
       "      <td>0.319548</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233770</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.219750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.148517</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.092484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f174       f72  f265       f44       f53       f62       f16      f206  \\\n",
       "0  0.010250  0.004855     0  0.193430  0.192042  0.519336  0.341702  0.011936   \n",
       "1  0.005768  0.004312     0  0.821982  0.224053  0.447242  0.459358  0.011285   \n",
       "2  0.012026  0.004507     0  0.162094  0.239486  0.749593  0.257763  0.009230   \n",
       "3  0.011034  0.002806     0  0.834834  0.175250  0.605277  0.335907  0.007412   \n",
       "4  0.008832  0.004219     1  0.844187  0.249345  0.415167  0.319548  0.013731   \n",
       "\n",
       "        f74       f33  ...      f201      f113      f134  f269  f245  \\\n",
       "0  0.257688  0.034818  ...  0.216079  0.087502  0.217984     1     1   \n",
       "1  0.415982  0.033018  ...  0.240681  0.084309  0.222525     0     0   \n",
       "2  0.274105  0.035977  ...  0.163251  0.085933  0.224012     0     1   \n",
       "3  0.260443  0.319312  ...  0.163644  0.085584  0.248067     0     1   \n",
       "4  0.215576  0.034490  ...  0.233770  0.083699  0.219750     0     1   \n",
       "\n",
       "        f95      f227      f125       f99      f164  \n",
       "0  0.559151  0.011277  0.003969  0.112203  0.407014  \n",
       "1  0.145737  0.011031  0.004784  0.111834  0.090468  \n",
       "2  0.144596  0.009546  0.003502  0.110486  0.090032  \n",
       "3  0.146811  0.006251  0.008915  0.361132  0.091527  \n",
       "4  0.148517  0.006527  0.005913  0.113454  0.092484  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d06b71-025d-49fb-98ad-ff5c16bb5d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d59cb10-054e-4738-b25b-549b5c0271d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f174</th>\n",
       "      <th>f72</th>\n",
       "      <th>f265</th>\n",
       "      <th>f44</th>\n",
       "      <th>f53</th>\n",
       "      <th>f62</th>\n",
       "      <th>f16</th>\n",
       "      <th>f206</th>\n",
       "      <th>f74</th>\n",
       "      <th>f33</th>\n",
       "      <th>...</th>\n",
       "      <th>f201</th>\n",
       "      <th>f113</th>\n",
       "      <th>f134</th>\n",
       "      <th>f269</th>\n",
       "      <th>f245</th>\n",
       "      <th>f95</th>\n",
       "      <th>f227</th>\n",
       "      <th>f125</th>\n",
       "      <th>f99</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.046739</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.407147</td>\n",
       "      <td>0.661738</td>\n",
       "      <td>0.249887</td>\n",
       "      <td>0.650502</td>\n",
       "      <td>0.336334</td>\n",
       "      <td>0.056784</td>\n",
       "      <td>0.240953</td>\n",
       "      <td>0.080244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210863</td>\n",
       "      <td>0.101885</td>\n",
       "      <td>0.263044</td>\n",
       "      <td>0.203648</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.042318</td>\n",
       "      <td>0.031749</td>\n",
       "      <td>0.128153</td>\n",
       "      <td>0.104802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.116847</td>\n",
       "      <td>0.081462</td>\n",
       "      <td>0.491303</td>\n",
       "      <td>0.271317</td>\n",
       "      <td>0.075834</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.085286</td>\n",
       "      <td>0.147618</td>\n",
       "      <td>0.048202</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070827</td>\n",
       "      <td>0.068861</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>0.402710</td>\n",
       "      <td>0.476754</td>\n",
       "      <td>0.169444</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.078482</td>\n",
       "      <td>0.050170</td>\n",
       "      <td>0.050141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432623</td>\n",
       "      <td>0.191362</td>\n",
       "      <td>0.602382</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.213355</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162036</td>\n",
       "      <td>0.084297</td>\n",
       "      <td>0.221328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144194</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.111953</td>\n",
       "      <td>0.089887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>0.660250</td>\n",
       "      <td>0.334909</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.230692</td>\n",
       "      <td>0.039549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179171</td>\n",
       "      <td>0.085480</td>\n",
       "      <td>0.223481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147330</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.113108</td>\n",
       "      <td>0.090908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835743</td>\n",
       "      <td>0.280985</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>0.373706</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>0.252494</td>\n",
       "      <td>0.044129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245364</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>0.253211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151214</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.114421</td>\n",
       "      <td>0.092017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995534</td>\n",
       "      <td>0.986195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980173</td>\n",
       "      <td>0.989510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.990459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f174             f72            f265             f44  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.046739        0.026249        0.407147        0.661738   \n",
       "std          0.116847        0.081462        0.491303        0.271317   \n",
       "min          0.000056        0.000076        0.000000        0.000667   \n",
       "25%          0.006189        0.003836        0.000000        0.432623   \n",
       "50%          0.008418        0.005295        0.000000        0.828384   \n",
       "75%          0.010921        0.006884        1.000000        0.835743   \n",
       "max          0.995534        0.986195        1.000000        1.000000   \n",
       "\n",
       "                  f53             f62             f16            f206  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.249887        0.650502        0.336334        0.056784   \n",
       "std          0.075834        0.089373        0.085286        0.147618   \n",
       "min          0.041605        0.000030        0.000000        0.000000   \n",
       "25%          0.191362        0.602382        0.304199        0.008683   \n",
       "50%          0.231455        0.660250        0.334909        0.011664   \n",
       "75%          0.280985        0.709352        0.373706        0.014846   \n",
       "max          0.980173        0.989510        1.000000        0.999671   \n",
       "\n",
       "                  f74             f33  ...            f201            f113  \\\n",
       "count  1000000.000000  1000000.000000  ...  1000000.000000  1000000.000000   \n",
       "mean         0.240953        0.080244  ...        0.210863        0.101885   \n",
       "std          0.048202        0.109916  ...        0.070827        0.068861   \n",
       "min          0.000000        0.001174  ...        0.000000        0.019806   \n",
       "25%          0.213355        0.035840  ...        0.162036        0.084297   \n",
       "50%          0.230692        0.039549  ...        0.179171        0.085480   \n",
       "75%          0.252494        0.044129  ...        0.245364        0.086748   \n",
       "max          0.990459        1.000000  ...        0.972467        1.000000   \n",
       "\n",
       "                 f134            f269            f245             f95  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.263044        0.203648        0.650685        0.219554   \n",
       "std          0.090291        0.402710        0.476754        0.169444   \n",
       "min          0.003320        0.000000        0.000000        0.030003   \n",
       "25%          0.221328        0.000000        0.000000        0.144194   \n",
       "50%          0.223481        0.000000        1.000000        0.147330   \n",
       "75%          0.253211        0.000000        1.000000        0.151214   \n",
       "max          0.927632        1.000000        1.000000        0.958551   \n",
       "\n",
       "                 f227            f125             f99            f164  \n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000  \n",
       "mean         0.042318        0.031749        0.128153        0.104802  \n",
       "std          0.097016        0.078482        0.050170        0.050141  \n",
       "min          0.000041        0.000112        0.000000        0.012092  \n",
       "25%          0.006148        0.004718        0.111953        0.089887  \n",
       "50%          0.008488        0.006382        0.113108        0.090908  \n",
       "75%          0.011224        0.008270        0.114421        0.092017  \n",
       "max          0.995261        1.000000        1.000000        0.968850  \n",
       "\n",
       "[8 rows x 136 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7fc3ade-47f5-455e-9eae-23f035f093aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f265': 2},\n",
       " {'f255': 2},\n",
       " {'f22': 2},\n",
       " {'f117': 75104},\n",
       " {'f256': 2},\n",
       " {'f103': 76473},\n",
       " {'f260': 2},\n",
       " {'f252': 2},\n",
       " {'f247': 2},\n",
       " {'f274': 2},\n",
       " {'f243': 2},\n",
       " {'f108': 66767},\n",
       " {'f210': 65746},\n",
       " {'f43': 2},\n",
       " {'f258': 2},\n",
       " {'f266': 2},\n",
       " {'f269': 2},\n",
       " {'f245': 2},\n",
       " {'f99': 86896}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) < 100000]\n",
    "low_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f477e01d-c7c3-41ce-be7e-1bbe25f14c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f174': 542053},\n",
       " {'f72': 573057},\n",
       " {'f44': 241770},\n",
       " {'f53': 240013},\n",
       " {'f62': 332336},\n",
       " {'f16': 313228},\n",
       " {'f206': 431717},\n",
       " {'f74': 175223},\n",
       " {'f33': 324185},\n",
       " {'f143': 444524},\n",
       " {'f6': 421827},\n",
       " {'f169': 606385},\n",
       " {'f29': 132977},\n",
       " {'f208': 365225},\n",
       " {'f107': 147096},\n",
       " {'f71': 125690},\n",
       " {'f152': 399983},\n",
       " {'f90': 426170},\n",
       " {'f18': 163185},\n",
       " {'f56': 225538},\n",
       " {'f77': 322750},\n",
       " {'f4': 401939},\n",
       " {'f5': 241585},\n",
       " {'f87': 198478},\n",
       " {'f129': 183006},\n",
       " {'f7': 265619},\n",
       " {'f58': 482130},\n",
       " {'f187': 188558},\n",
       " {'f3': 244851},\n",
       " {'f225': 558377},\n",
       " {'f229': 358098},\n",
       " {'f20': 226437},\n",
       " {'f211': 223364},\n",
       " {'f70': 157423},\n",
       " {'f199': 302838},\n",
       " {'f61': 268732},\n",
       " {'f118': 189040},\n",
       " {'f144': 607935},\n",
       " {'f93': 410485},\n",
       " {'f130': 352035},\n",
       " {'f128': 177314},\n",
       " {'f27': 223306},\n",
       " {'f1': 374634},\n",
       " {'f85': 325589},\n",
       " {'f212': 216199},\n",
       " {'f80': 140510},\n",
       " {'f86': 365382},\n",
       " {'f76': 212732},\n",
       " {'f200': 420271},\n",
       " {'f64': 132128},\n",
       " {'f83': 202494},\n",
       " {'f127': 226315},\n",
       " {'f138': 497263},\n",
       " {'f11': 141980},\n",
       " {'f19': 161302},\n",
       " {'f82': 107320},\n",
       " {'f231': 325664},\n",
       " {'f239': 239593},\n",
       " {'f60': 245103},\n",
       " {'f119': 171081},\n",
       " {'f42': 171131},\n",
       " {'f2': 452401},\n",
       " {'f75': 116914},\n",
       " {'f79': 188230},\n",
       " {'f214': 460571},\n",
       " {'f73': 328802},\n",
       " {'f92': 386351},\n",
       " {'f40': 294067},\n",
       " {'f156': 152362},\n",
       " {'f157': 492134},\n",
       " {'f147': 251131},\n",
       " {'f226': 594319},\n",
       " {'f52': 120431},\n",
       " {'f98': 367956},\n",
       " {'f179': 497596},\n",
       " {'f173': 500033},\n",
       " {'f112': 305296},\n",
       " {'f140': 128487},\n",
       " {'f89': 324090},\n",
       " {'f141': 489019},\n",
       " {'f65': 307414},\n",
       " {'f195': 412007},\n",
       " {'f192': 490036},\n",
       " {'f14': 302868},\n",
       " {'f139': 436631},\n",
       " {'f78': 260647},\n",
       " {'f222': 355695},\n",
       " {'f184': 513613},\n",
       " {'f163': 453071},\n",
       " {'f114': 499970},\n",
       " {'f96': 146100},\n",
       " {'f154': 446224},\n",
       " {'f35': 123688},\n",
       " {'f133': 214341},\n",
       " {'f241': 244154},\n",
       " {'f55': 177793},\n",
       " {'f8': 428659},\n",
       " {'f17': 231233},\n",
       " {'f48': 182403},\n",
       " {'f191': 529250},\n",
       " {'f12': 246156},\n",
       " {'f63': 259988},\n",
       " {'f69': 214266},\n",
       " {'f26': 183403},\n",
       " {'f162': 445373},\n",
       " {'f213': 175959},\n",
       " {'f238': 179040},\n",
       " {'f150': 226675},\n",
       " {'f13': 257319},\n",
       " {'f136': 101424},\n",
       " {'f201': 199649},\n",
       " {'f113': 141591},\n",
       " {'f134': 195021},\n",
       " {'f95': 160801},\n",
       " {'f227': 553207},\n",
       " {'f125': 579880},\n",
       " {'f164': 125692}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher_cardinality_features = [{f: len(X[f].unique())} for f in X.columns if len(X[f].unique()) > 100000]\n",
    "higher_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017d3d8c-2b4e-45f2-aee4-ecf5ab4452e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in X.columns:\n",
    "#     pct_diff = (1000000 - X[f].nunique()) / 1000000\n",
    "#     if pct_diff >= 0.9:\n",
    "#         print(f\"for {f}: {pct_diff}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834c63e7-ebc6-41d7-ae9e-44e23823714e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in X.columns:\n",
    "#     pct_diff = (1000000 - X[f].nunique()) / 1000000\n",
    "#     if pct_diff >= 0.8:\n",
    "#         print(f\"for {f}: {pct_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc8a0af-0c2a-4889-8d7d-2ff810c3356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [f for f in X.columns if ((1000000 - X[f].nunique()) / 1000000) >=0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a10ee18-1828-4956-92ba-1623697e19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d193ee2-055a-4098-96cf-a2c10b850daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ce.woe.WOEEncoder(cols=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fcbae3b-21a9-4c90-ac50-85f20faa3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbcfd3b9-c288-4b63-8772-b758e4fc087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb61bf31-b2c2-4a49-9783-57adbce550c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X_woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16abc985-3a89-45d2-bf20-611a87e3ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c828b2c2-bbf0-4d7a-a2aa-0e103f894df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_test(X,y):\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "    #         n_jobs=-1,\n",
    "    #         **params\n",
    "    )    \n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813b42c-8375-40d4-9424-21a1d82351ea",
   "metadata": {},
   "source": [
    "The best parametece.sum_codingto present have been:\n",
    "\n",
    "```python\n",
    "best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "```\n",
    "\n",
    "These params get the following ROC_AUC scores on a 20% holdout for these dataset versions:\n",
    "\n",
    "| Version | Feature Count | category_encoder | Valid ROC-AUC |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| original | 285 | none | 0.8572984856383443 |\n",
    "| Boruta green-only | 98 | none | 0.8553163413048461 |\n",
    "| Boruta green-and-blue | 109 | none | 0.8558487581638441 |\n",
    "| Boruta with SHAP | 136 | none | 0.8566790062778752 |\n",
    "| Boruta with SHAP | 136 | woe | 0.8899772033406148 |\n",
    "| original | 285 | woe | 0.8903361849466815 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033696c5-e21b-4005-8d28-b741516738f2",
   "metadata": {},
   "source": [
    "So, Boruta with SHAP performs better than Boruta with green-only *and* Boruta with green and blue, landing 0.8566790062778752"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b20a9-e2f5-4515-a018-38dda183557e",
   "metadata": {},
   "source": [
    "So, boruta with green only gets 0.8553163413048461, vs 0.8572984856383443 for the same model on the vanilla training set. Not bad.\n",
    "\n",
    "Let's try a more conservative take -- the green zone *plus* the blue zone (i.e. the take-it-or-leave-it features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fdefdf2-442e-49e5-911f-8567231125d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_test(X_woe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b0455ba-ac71-4d12-90f3-d7652021ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_feather(datapath/'train.feather').iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ab90b2-cfe8-4979-8701-a31282b6eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 136)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fad2ce44-ae26-4296-9fd3-16a58f8d3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f699676-cd46-48da-b7d4-6de4e987c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe_orig = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15ba69ba-b56c-4100-8664-b98d5b49b1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline_test(X_woe_orig,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d66676f6-c5ab-41a5-8610-febaa2b31fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe.to_feather(path=altdatapath/'X_boruta_SHAP_woe.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ef3f1f8-f422-4f4d-8cd6-b5f2476fa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_woe_orig.to_feather(path=altdatapath/'X_orig_woe.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7424fb-4012-416c-9bd4-f2433a3f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_woe, X_woe_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d53c9c23-3fe3-434f-911a-ca0d8c54aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [\n",
    "#     ce.SumEncoder(cols=categoricals),\n",
    "#     ce.BackwardDifferenceEncoder(cols=categoricals),\n",
    "    ce.CatBoostEncoder(cols=categoricals), # best yet, > 0.89\n",
    "    ce.CountEncoder(cols=categoricals), #  pretty weak, ~0.855\n",
    "#     ce.GLMMEncoder(cols=categoricals),\n",
    "#     ce.HelmertEncoder(cols=categoricals),\n",
    "#     ce.JamesSteinEncoder(cols=categoricals),\n",
    "#     ce.LeaveOneOutEncoder(cols=categoricals),\n",
    "#     ce.MEstimateEncoder(cols=categoricals),\n",
    "#     ce.OrdinalEncoder(cols=categoricals),\n",
    "#     ce.PolynomialEncoder(cols=categoricals),\n",
    "    ce.TargetEncoder(cols=categoricals),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d613988-f901-49af-8836-84b52fb3dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_source = altdatapath/'X_boruta_shap_200trials.feather'\n",
    "# del X \n",
    "# X = pd.read_feather(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e9273fc-a668-4528-9191-73a88508c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CatBoostEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                      'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                      'f258', 'f266', 'f269', 'f245', 'f99'])\n",
      "[17:02:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8910374882085335\n",
      "Testing CountEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                   'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                   'f258', 'f266', 'f269', 'f245', 'f99'],\n",
      "             combine_min_nan_groups=True)\n",
      "[17:05:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8566317964270773\n",
      "Testing TargetEncoder(cols=['f265', 'f255', 'f22', 'f117', 'f256', 'f103', 'f260',\n",
      "                    'f252', 'f247', 'f274', 'f243', 'f108', 'f210', 'f43',\n",
      "                    'f258', 'f266', 'f269', 'f245', 'f99'])\n",
      "[17:09:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8911081124097271\n"
     ]
    }
   ],
   "source": [
    "for encoder in encoders:\n",
    "    print(f\"Testing {str(encoder)}\")\n",
    "    encoder.fit(X,y)\n",
    "    X_enc = encoder.transform(X)\n",
    "    baseline_test(X_enc,y)\n",
    "    del X_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d37db-558d-474d-9eca-ce2d38b7636f",
   "metadata": {
    "id": "431d37db-558d-474d-9eca-ce2d38b7636f"
   },
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ff4abf-560b-450e-a7a5-040878b66565",
   "metadata": {
    "id": "69ff4abf-560b-450e-a7a5-040878b66565"
   },
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\n",
    "#     # wandb config:\n",
    "#     'name': f\"{os.environ['WANDB_NOTEBOOK_NAME'][:-6]}_{datetime.now().strftime('%H%M%S')}\", # just removes the .ipynb extension, leaving the notebook filename's stem\n",
    "#     'project': '202109_Kaggle_tabular_playground',\n",
    "#     'tags': ['sweep'],\n",
    "#     'notes': \"Sweep for CatBoost using Optuna\",\n",
    "#     'config': exmodel_config,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993947ab-fae6-4d7e-b73a-eb4e171ea61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 285)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82cb1b5b-73c9-45d2-943a-5361328f07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b055e2b-ebbb-4d36-b995-7a50d4adbc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eca68f8-930e-4c4f-9d0f-767ebe561d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_picker = XGBClassifier(\n",
    "#     verbosity = 1,\n",
    "#     tree_method = 'gpu_hist',\n",
    "#     booster = 'gbtree',\n",
    "#     random_state = SEED\n",
    "# )\n",
    "\n",
    "feature_picker = CatBoostClassifier(task_type='GPU', silent=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6230e00-931d-4e25-b4a4-1f2305fdbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta = BorutaShap(model=feature_picker,\n",
    "                    importance_measure='shap',\n",
    "                    classification=True)\n",
    "#     verbose=True,\n",
    "# #     random_state=SEED,\n",
    "#     estimator=feature_picker,\n",
    "#     n_estimators='auto',\n",
    "#     max_iter=200,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5ea27b-53a5-4c4c-a45a-2528c86349c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe31795217c42ef87dad7a193276d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 attributes confirmed important: ['f174', 'f72', 'f265', 'f44', 'f53', 'f62', 'f16', 'f206', 'f74', 'f33', 'f143', 'f6', 'f169', 'f29', 'f255', 'f208', 'f107', 'f71', 'f152', 'f90', 'f22', 'f18', 'f56', 'f77', 'f4', 'f5', 'f87', 'f129', 'f117', 'f7', 'f58', 'f256', 'f187', 'f103', 'f3', 'f225', 'f229', 'f20', 'f211', 'f260', 'f70', 'f199', 'f61', 'f118', 'f144', 'f93', 'f130', 'f128', 'f27', 'f1', 'f85', 'f212', 'f252', 'f80', 'f86', 'f76', 'f200', 'f64', 'f83', 'f127', 'f138', 'f11', 'f19', 'f82', 'f231', 'f247', 'f239', 'f60', 'f119', 'f42', 'f2', 'f75', 'f79', 'f214', 'f73', 'f92', 'f40', 'f156', 'f157', 'f147', 'f226', 'f52', 'f98', 'f179', 'f274', 'f173', 'f112', 'f140', 'f89', 'f141', 'f65', 'f195', 'f192', 'f14', 'f139', 'f78', 'f222', 'f184', 'f163', 'f114', 'f96', 'f243', 'f108', 'f154', 'f35', 'f133', 'f241', 'f55', 'f210', 'f8', 'f17', 'f48', 'f191', 'f12', 'f63', 'f69', 'f26', 'f162', 'f43', 'f213', 'f238', 'f258', 'f150', 'f266', 'f13', 'f136', 'f201', 'f113', 'f134', 'f269', 'f245', 'f95', 'f227', 'f125', 'f99', 'f164']\n",
      "146 attributes confirmed unimportant: ['f68', 'f142', 'f185', 'f146', 'f31', 'f122', 'f167', 'f46', 'f158', 'f172', 'f41', 'f66', 'f30', 'f186', 'f47', 'f168', 'f45', 'f21', 'f280', 'f116', 'f34', 'f145', 'f115', 'f220', 'f10', 'f207', 'f190', 'f109', 'f230', 'f251', 'f49', 'f67', 'f250', 'f81', 'f151', 'f36', 'f59', 'f205', 'f166', 'f228', 'f105', 'f177', 'f137', 'f275', 'f123', 'f155', 'f215', 'f217', 'f233', 'f277', 'f171', 'f54', 'f279', 'f246', 'f111', 'f132', 'f153', 'f104', 'f23', 'f180', 'f194', 'f271', 'f268', 'f24', 'f131', 'f283', 'f160', 'f165', 'f202', 'f189', 'f224', 'f237', 'f278', 'f38', 'f124', 'f9', 'f176', 'f236', 'f94', 'f223', 'f254', 'f235', 'f135', 'f39', 'f204', 'f15', 'f282', 'f262', 'f37', 'f216', 'f0', 'f240', 'f32', 'f148', 'f219', 'f263', 'f244', 'f175', 'f25', 'f209', 'f276', 'f259', 'f270', 'f126', 'f221', 'f91', 'f28', 'f183', 'f196', 'f248', 'f170', 'f188', 'f88', 'f100', 'f50', 'f253', 'f84', 'f159', 'f281', 'f218', 'f242', 'f232', 'f102', 'f161', 'f149', 'f182', 'f284', 'f120', 'f51', 'f101', 'f234', 'f257', 'f272', 'f273', 'f267', 'f198', 'f264', 'f106', 'f178', 'f110', 'f203', 'f97', 'f197', 'f261', 'f121', 'f249']\n",
      "3 tentative attributes remains: ['f181', 'f57', 'f193']\n"
     ]
    }
   ],
   "source": [
    "boruta.fit(X=X, y=y, n_trials=200, sample=False, train_or_test='train', normalize=False, verbose=True, random_state=SEED, stratify=False)\n",
    "# boruta = load('/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e09f3111-5c8a-4e29-8f26-a90916a100c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boruta.plot(which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "731d3a0f-3b6f-4cd1-8d20-e89e9fc941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap = boruta.Subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722eb36e-4d38-4f02-a924-d40779ff7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb568c-130f-490b-8032-a365774c7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green_zone = X.columns[boruta.support_].to_list()\n",
    "# blue_zone = X.columns[boruta.support_weak_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f9ae9-71fc-4c53-b611-a9e47cac9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_ranks = boruta.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae4c65-54e1-4663-8205-59891154d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_filtered = boruta.transform(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc719a0a-2e9e-4954-a098-ecf70c5d3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_shap.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X_boruta_shap, filename=altdatapath/'X_boruta_shap_200trials.joblib')\n",
    "dump(boruta, filename=altdatapath/'boruta_shap.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46bb0214-7786-48c1-aba4-fda2357c3b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_boruta_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7afef0c9-08d4-4326-bf27-ee4908d1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e6300f4-721e-4126-8f5d-6f6ff1172adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_shap.to_feather(path=altdatapath/'X_boruta_shap_200trials.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6faff75-3cc9-4aea-9a6e-79ea36ac35db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f174</th>\n",
       "      <th>f72</th>\n",
       "      <th>f265</th>\n",
       "      <th>f44</th>\n",
       "      <th>f53</th>\n",
       "      <th>f62</th>\n",
       "      <th>f16</th>\n",
       "      <th>f206</th>\n",
       "      <th>f74</th>\n",
       "      <th>f33</th>\n",
       "      <th>...</th>\n",
       "      <th>f201</th>\n",
       "      <th>f113</th>\n",
       "      <th>f134</th>\n",
       "      <th>f269</th>\n",
       "      <th>f245</th>\n",
       "      <th>f95</th>\n",
       "      <th>f227</th>\n",
       "      <th>f125</th>\n",
       "      <th>f99</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.192042</td>\n",
       "      <td>0.519336</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.257688</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216079</td>\n",
       "      <td>0.087502</td>\n",
       "      <td>0.217984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559151</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.407014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821982</td>\n",
       "      <td>0.224053</td>\n",
       "      <td>0.447242</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.415982</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240681</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>0.222525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145737</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.111834</td>\n",
       "      <td>0.090468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162094</td>\n",
       "      <td>0.239486</td>\n",
       "      <td>0.749593</td>\n",
       "      <td>0.257763</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.274105</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163251</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144596</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.110486</td>\n",
       "      <td>0.090032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834834</td>\n",
       "      <td>0.175250</td>\n",
       "      <td>0.605277</td>\n",
       "      <td>0.335907</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.319312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163644</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.248067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146811</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.361132</td>\n",
       "      <td>0.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844187</td>\n",
       "      <td>0.249345</td>\n",
       "      <td>0.415167</td>\n",
       "      <td>0.319548</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.215576</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233770</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.219750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.148517</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.092484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f174       f72  f265       f44       f53       f62       f16      f206  \\\n",
       "0  0.010250  0.004855     0  0.193430  0.192042  0.519336  0.341702  0.011936   \n",
       "1  0.005768  0.004312     0  0.821982  0.224053  0.447242  0.459358  0.011285   \n",
       "2  0.012026  0.004507     0  0.162094  0.239486  0.749593  0.257763  0.009230   \n",
       "3  0.011034  0.002806     0  0.834834  0.175250  0.605277  0.335907  0.007412   \n",
       "4  0.008832  0.004219     1  0.844187  0.249345  0.415167  0.319548  0.013731   \n",
       "\n",
       "        f74       f33  ...      f201      f113      f134  f269  f245  \\\n",
       "0  0.257688  0.034818  ...  0.216079  0.087502  0.217984     1     1   \n",
       "1  0.415982  0.033018  ...  0.240681  0.084309  0.222525     0     0   \n",
       "2  0.274105  0.035977  ...  0.163251  0.085933  0.224012     0     1   \n",
       "3  0.260443  0.319312  ...  0.163644  0.085584  0.248067     0     1   \n",
       "4  0.215576  0.034490  ...  0.233770  0.083699  0.219750     0     1   \n",
       "\n",
       "        f95      f227      f125       f99      f164  \n",
       "0  0.559151  0.011277  0.003969  0.112203  0.407014  \n",
       "1  0.145737  0.011031  0.004784  0.111834  0.090468  \n",
       "2  0.144596  0.009546  0.003502  0.110486  0.090032  \n",
       "3  0.146811  0.006251  0.008915  0.361132  0.091527  \n",
       "4  0.148517  0.006527  0.005913  0.113454  0.092484  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boruta_shap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645beb05-411a-4f71-8ad3-3e355a502bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(boruta, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/boruta_200iter.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8c5ca-20b2-4b6c-8ac5-97054c6c1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(green_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377b4a2-dcf7-4139-8d0f-6e8d98a658e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(blue_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54976834-33a4-48f5-9df8-27e42c786864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed15bc-0223-41af-a506-b9395ff8907b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f79d4-336b-4d0b-88c3-39c7195b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3000f1-35e5-4bf7-8cac-ce351fc498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3eb45-bc64-4375-a533-dba7760033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b7113-4389-484b-85b0-1206d99861d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X_filtered), type(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b68e1908-a301-4939-8b01-3635133e5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_boruta_shap, np.array(y), test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec43ce0-12e4-44c3-86a4-1b1125250a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8566790062778752\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) # was 0.7783978025549229 for pca_poly; 0.8572984856383443 for vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1419c9e3-d0b9-40e2-b53c-de93779e1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3878f19-14e3-4b91-9fb5-78662b01e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_blue_green = np.concatenate((X_filtered, np.array(X[blue_zone])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55114317-dd1e-4521-806c-0e63edfa4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 109)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boruta_blue_green.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5efbff7b-7bca-4d3d-83be-ca2465a9e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC Score of XGBoost = 0.8558487581638441\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_boruta_blue_green, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754fe12-1939-4128-9825-78fb3f54f10a",
   "metadata": {},
   "source": [
    "So Boruta with green and blue gets 0.8558487581638441 -- a bit better than the green-zone only. Now, let's try adding polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6adeaa-0713-40df-9a32-c7abec077807",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_boruta_blue_green_poly = poly.fit_transform(X_boruta_blue_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46b765-584f-4b28-a80d-d76639da9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(X_boruta_blue_green, '/media/sf/easystore/kaggle_data/tabular_playgrounds/oct2021/alt_datasets/X_boruta_200iter_green+blue_109features.joblib')\n",
    "del X_boruta_blue_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37893d85-c063-4425-9665-cb5b969c62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da6f7-7573-4aae-b7c8-f90696304bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c16bd622-ec4b-4744-b552-2ec6b869d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_pca_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f10abfc-2f98-4814-ac42-98fab0eab6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = datapath/'train.feather'\n",
    "df = pd.read_feather(path=train_source)\n",
    "df.index.name = 'id'\n",
    "y = df.target\n",
    "features = [x for x in df.columns if x != 'target']\n",
    "X = df[features]\n",
    "# X.index.name = 'id'\n",
    "# y.index.name = 'id'\n",
    "# X = np.array(X_train)\n",
    "# y = np.array(y_train)\n",
    "\n",
    "# del df, X_train, y_train\n",
    "\n",
    "\n",
    "# exmodel_config['feature_count'] = len(X.columns)\n",
    "# exmodel_config['feature_count'] = X.shape[1]\n",
    "# exmodel_config['instance_count'] = X.shape[0]\n",
    "\n",
    "# exmodel_config['feature_generator'] = None\n",
    "# exmodel_config['feature_generator'] = \"Summary statistics\"\n",
    "\n",
    "# exmodel_config['train_source'] = str(train_source)\n",
    "test_source = datapath/'test.feather'\n",
    "# exmodel_config['test_source'] = str(test_source)\n",
    "X_test = pd.read_feather(path=test_source)\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "# X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b81d1498-77b6-4a04-bc77-db6e40a705ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.906420714280384,\n",
       "              gamma=1.472322916021486, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.024785857161974977,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=8.829122644339664,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3878,\n",
       "              n_jobs=16, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=26.867682044658245, reg_lambda=10.839759074147148,\n",
       "              scale_pos_weight=1, subsample=0.8208581489835881,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_np, test_size=0.2, random_state=int(SEED), shuffle=True)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd3d5544-df0e-4af5-9096-3e3e821dcaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8572984856383443\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model.predict_proba(X_valid)[:,1]\n",
    "# rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "# Evaluation\n",
    "valid_auc = roc_auc_score(y_valid, preds)\n",
    "print('ROC AUC Score of XGBoost =', valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b",
   "metadata": {
    "id": "1d93b6f2-2d65-48a9-9862-510bd7d2b75b"
   },
   "outputs": [],
   "source": [
    "# originally from https://www.kaggle.com/satorushibata/optimize-catboost-hyperparameter-with-optuna-gpu\n",
    "def objective(trial):\n",
    "    # split the (original Kaggle training) data into partitions\n",
    "    # if study.best_trial:\n",
    "    #     print(\"Dumping best params, which are:\")\n",
    "    #     print(str(study.best_trial.params))\n",
    "    #     dump(study.best_trial.params, filename=datapath/'optuna_catboost_best_20210920.joblib')\n",
    "    \n",
    "#     pca_components = trial.suggest_int('pca_components', 50, 285)\n",
    "    pca = PCA(n_components=pca_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "#     dump(pca60, edapath/'PCA_60.joblibg')\n",
    "    \n",
    "    # else:\n",
    "    #     print(\"No best study yet\")\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.33, random_state=int(SEED), shuffle=True)\n",
    "    # create wrappers for the training and validation partitions\n",
    "    # train_pool = catboost.Pool(X_train, y_train)\n",
    "    # valid_pool = catboost.Pool(X_valid, y_valid)\n",
    "    \n",
    "    # experimental parameters\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 900, 6000), # was 900-4500 for CPU\n",
    "#         'max_depth' : trial.suggest_int('depth', 3, 10),                                       \n",
    "#         'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.4),               \n",
    "#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.001, 30),\n",
    "#         'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.001, 30),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "# #         'booster': trial.suggest_categorical('boosting_type', ['gbtree', 'dart']),\n",
    "#         'min_child_weight': trial.suggest_uniform('min_child_weight', 0.001, 10),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1),\n",
    "#         'gamma': trial.suggest_uniform('gamma', 0.1, 30)\n",
    "#     }  \n",
    "\n",
    "    best_xgboost_params = {\n",
    "        'n_estimators': 3878,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.024785857161974977,\n",
    "        'reg_alpha': 26.867682044658245,\n",
    "        'reg_lambda': 10.839759074147148,\n",
    "        'subsample': 0.8208581489835881,\n",
    "        'min_child_weight': 8.829122644339664,\n",
    "        'colsample_bytree': 0.906420714280384,\n",
    "        'gamma': 1.472322916021486\n",
    "    }\n",
    "\n",
    "    # instantiate the model, with some parameters locked in, and experimnental ones passed via splat \n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        verbosity=1,\n",
    "        tree_method='gpu_hist',\n",
    "        booster='gbtree', # not bothering with dart for time reasons\n",
    "        random_state=SEED,\n",
    "        **best_xgboost_params\n",
    "#         n_jobs=-1,\n",
    "#         **params\n",
    "    )    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    # generate predictions\n",
    "    preds = model.predict_proba(X_valid)[:,1]\n",
    "    # rounds to the nearest integer, and the nearest even in case of _.5s\n",
    "\n",
    "    # Evaluation\n",
    "    valid_auc = roc_auc_score(y_valid, preds)\n",
    "    print('ROC AUC Score of XGBoost =', valid_auc)\n",
    "    wandb.log({'valid_auc': valid_auc,\n",
    "              })\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e85f589-1507-4b75-80d9-8b062970102f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "0e85f589-1507-4b75-80d9-8b062970102f",
    "outputId": "6a01a1a1-8060-429d-9a47-670cbc0435d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-69ea9289a2cf>:1: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find sweep_xgboost_20211010.ipynb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhushifang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground/runs/2b286ehp\" target=\"_blank\">sweep_xgboost_20211010_115658</a></strong> to <a href=\"https://wandb.ai/hushifang/202110_Kaggle_tabular_playground\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
   "metadata": {
    "id": "ab6749b1-dd7d-4789-b0e2-8491d78fe89b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-10 11:57:06,723]\u001b[0m A new study created in memory with name: pca_20211010\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", \n",
    "                            sampler = TPESampler(seed=int(SEED)), \n",
    "                            study_name=f\"pca_{datetime.now().strftime('%Y%m%d')}\")\n",
    "\n",
    "# study = load(studypath/f\"optuna_xgboost_study_106trials_20211004.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02e3b84-ee16-48b9-94db-c738b408a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a454cc8-f135-4d36-8b6c-a964f4b52288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3860cbd2-1d08-4b2e-ac53-92b8a2ce016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Error thrown by xgboost trainer.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.core.XGBoostError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8ad6db-2722-4f04-bd51-4b795bec93c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1cSVFH9gkW_",
    "outputId": "ccc874e6-7dd4-4e24-bec8-35ae48180b40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ed3ac943a45fa8dc339194d2cab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:57:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 0 < 1; dropping {'pca_components': 138, 'value': 0.8283967087232865}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8283967087232865\n",
      "\u001b[32m[I 2021-10-10 11:59:12,446]\u001b[0m Trial 0 finished with value: 0.8283967087232865 and parameters: {'pca_components': 138}. Best is trial 0 with value: 0.8283967087232865.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c995da28a1d44a78001aca7668f1bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 2; dropping {'pca_components': 274, 'value': 0.8472107426301871}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472107426301871\n",
      "\u001b[32m[I 2021-10-10 12:02:45,979]\u001b[0m Trial 1 finished with value: 0.8472107426301871 and parameters: {'pca_components': 274}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fccb3fa1d664c2c9182df86e0916f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 3; dropping {'pca_components': 222, 'value': 0.8411313966895685}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8411313966895685\n",
      "\u001b[32m[I 2021-10-10 12:06:07,082]\u001b[0m Trial 2 finished with value: 0.8411313966895685 and parameters: {'pca_components': 222}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfa85acfc834a6eb8f4993b66a345d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 4; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:09:03,422]\u001b[0m Trial 3 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeb5cbc6d8f498aaeafbcbd5baf86c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 5; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:10:25,360]\u001b[0m Trial 4 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ed1965573401a893b3bcf5d741830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 6; dropping {'pca_components': 86, 'value': 0.806690388517508}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.806690388517508\n",
      "\u001b[32m[I 2021-10-10 12:11:46,686]\u001b[0m Trial 5 finished with value: 0.806690388517508 and parameters: {'pca_components': 86}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5122220c3f24f86abb9c62111e5b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 7; dropping {'pca_components': 63, 'value': 0.7904181686815366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.7904181686815366\n",
      "\u001b[32m[I 2021-10-10 12:12:47,694]\u001b[0m Trial 6 finished with value: 0.7904181686815366 and parameters: {'pca_components': 63}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add254087a4548f8943e78283019acf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 8; dropping {'pca_components': 254, 'value': 0.8452885185751505}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8452885185751505\n",
      "\u001b[32m[I 2021-10-10 12:15:43,607]\u001b[0m Trial 7 finished with value: 0.8452885185751505 and parameters: {'pca_components': 254}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa23627f1d4045d888d13dfda8f652fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 9; dropping {'pca_components': 191, 'value': 0.8342598041011918}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8342598041011918\n",
      "\u001b[32m[I 2021-10-10 12:18:38,689]\u001b[0m Trial 8 finished with value: 0.8342598041011918 and parameters: {'pca_components': 191}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5422d08b044f46318acef3ee9a059d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 10; dropping {'pca_components': 217, 'value': 0.8409412517853502}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8409412517853502\n",
      "\u001b[32m[I 2021-10-10 12:21:58,921]\u001b[0m Trial 9 finished with value: 0.8409412517853502 and parameters: {'pca_components': 217}. Best is trial 1 with value: 0.8472107426301871.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5828e8c8e4c4e88ada0bcfd0a1e657c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 11; dropping {'pca_components': 281, 'value': 0.8474176983005992}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474176983005992\n",
      "\u001b[32m[I 2021-10-10 12:25:32,672]\u001b[0m Trial 10 finished with value: 0.8474176983005992 and parameters: {'pca_components': 281}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d792ab5b54f7e94cac11539cb2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 12; dropping {'pca_components': 270, 'value': 0.8462401528718595}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8462401528718595\n",
      "\u001b[32m[I 2021-10-10 12:29:05,642]\u001b[0m Trial 11 finished with value: 0.8462401528718595 and parameters: {'pca_components': 270}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ede0e145554dab8b24e39e112f384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 13; dropping {'pca_components': 278, 'value': 0.8472224222376469}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8472224222376469\n",
      "\u001b[32m[I 2021-10-10 12:32:39,229]\u001b[0m Trial 12 finished with value: 0.8472224222376469 and parameters: {'pca_components': 278}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c03a5fab942cc8bc82dedea9ea5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:58] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 14; dropping {'pca_components': 239, 'value': 0.8446363408619656}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8446363408619656\n",
      "\u001b[32m[I 2021-10-10 12:35:35,341]\u001b[0m Trial 13 finished with value: 0.8446363408619656 and parameters: {'pca_components': 239}. Best is trial 10 with value: 0.8474176983005992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8986b171a6b14e7db312199a0ada6e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 15; dropping {'pca_components': 283, 'value': 0.8474194357944366}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of XGBoost = 0.8474194357944366\n",
      "\u001b[32m[I 2021-10-10 12:39:09,826]\u001b[0m Trial 14 finished with value: 0.8474194357944366 and parameters: {'pca_components': 283}. Best is trial 14 with value: 0.8474194357944366.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5e682ca174a228a244baa13a8c099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31be9a9972d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandbc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoostError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e2748e41b07>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpca_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca_components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m285\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     dump(pca60, edapath/'PCA_60.joblibg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# sign flipping is done inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             U, S, Vt = randomized_svd(X, n_components=n_components,\n\u001b[0m\u001b[1;32m    549\u001b[0m                                       \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                       \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     Q = randomized_range_finder(\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Sample the range of A using by linear projection of Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Extract an orthonormal basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'economic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    162\u001b[0m                       lwork=lwork, overwrite_a=1)\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'economic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         Q, = safecall(gor_un_gqr, \"gorgqr/gungqr\", qr, tau, lwork=lwork,\n\u001b[0m\u001b[1;32m    165\u001b[0m                       overwrite_a=1)\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tabular-x/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36msafecall\u001b[0;34m(f, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lwork'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ValueError(\"illegal value in %dth argument of internal %s\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(1,200):\n",
    "    study.optimize(objective, n_trials = 1, callbacks = [wandbc], show_progress_bar=True, catch=(xgboost.core.XGBoostError,)) \n",
    "    dump(study, filename=datapath/f\"optuna_dataset-pca_study_{x}trials_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "#     dump(study.best_trial.params, filename=datapath/f'optuna_lightgbm_study_best-thru-{x*5}trials_20210927.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d6fb3-b4b3-40bd-8ff9-e2919c234f7d",
   "metadata": {
    "id": "27a746ff-c0e1-4218-8809-f102a58d2491"
   },
   "outputs": [],
   "source": [
    "# dump(study, filename=datapath/f\"optuna_xgboost_100trials-complete_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# dump(study.best_trial.params, filename=datapath/f\"optuna_lightgbm_all-500trials-best_{datetime.now().strftime('%Y%m%d')}.joblib\")\n",
    "# pickle.dump(study.best_trial.params, open('CatBoost_Hyperparameter.pickle', 'wb'))\n",
    "# print('CatBoost Hyperparameter:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd",
   "metadata": {
    "id": "f02e689e-b20c-48e5-a7d9-02467b4f3dbd"
   },
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ybeYZ3omaLWK",
   "metadata": {
    "id": "ybeYZ3omaLWK"
   },
   "outputs": [],
   "source": [
    "wandb.log({'xgboost_params': study.best_trial.params})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e398cb-f0f4-4400-8fe7-9012b4bc33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sweep_lightgbm_20210922.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
